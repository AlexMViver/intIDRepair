<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="18.523" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter6938193300846416323.jar /home/alex/Repositories/hive/service/target/surefire 2024-05-01T05-01-21_120-jvmRun1 surefire3626180966697497253tmp surefire_812145387992497431563tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter6938193300846416323.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="14.481">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,076512 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4b520ea8
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,028111 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 894800
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T00:25:41.963-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-00:25:43.815, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-00:25:43.816, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@157853da...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@157853da OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3a1dd365
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@3de8f619
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619] started OK.
2024-05-01T00:25:43,927  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T00:25:44,401  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T00:25:44,475  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:25:44,475  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:25:44,475  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:25:44,476  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:25:44,476  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:25:44,476  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:25:44,476  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T00:25:44,477  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:25:44,477  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:25:44,477  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:25:44,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:25:44,478  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 42faadd9-0b39-4b23-bc53-749cab9191ac
2024-05-01T00:25:44,512  INFO [main] SessionState: Hive Session ID = 42faadd9-0b39-4b23-bc53-749cab9191ac
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:44,526  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:44,885  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/42faadd9-0b39-4b23-bc53-749cab9191ac
2024-05-01T00:25:44,889  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/42faadd9-0b39-4b23-bc53-749cab9191ac
2024-05-01T00:25:44,892  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/42faadd9-0b39-4b23-bc53-749cab9191ac/_tmp_space.db
2024-05-01T00:25:44,917  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=42faadd9-0b39-4b23-bc53-749cab9191ac, clientType=HIVESERVER2]
2024-05-01T00:25:44,971  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:25:45,208  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:25:45,245  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:25:45,253  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T00:25:45,253  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T00:25:45,276  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T00:25:45,282  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T00:25:46,015  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T00:25:46,018  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T00:25:46,749  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T00:25:46,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: null will be shutdown
2024-05-01T00:25:46,775  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f created in the thread with id: 1
2024-05-01T00:25:49,645  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T00:25:49,646  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T00:25:49,646  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64 from thread id: 1
2024-05-01T00:25:49,781  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T00:25:49,814  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T00:25:49,853  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T00:25:49,855  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T00:25:49,982  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T00:25:49,990  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T00:25:49,991  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T00:25:49,994  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T00:25:50,021  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T00:25:50,024  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T00:25:50,025  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T00:25:50,026  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T00:25:50,028  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T00:25:50,031  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T00:25:50,033  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T00:25:50,034  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T00:25:50,041  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T00:25:50,042  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T00:25:50,043  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T00:25:50,047  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:25:50,194  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:25:50,761  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,765  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,768  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,769  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,769  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,771  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,771  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T00:25:50,822  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T00:25:50,823  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T00:25:50,823  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T00:25:50,824  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T00:25:50,825  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T00:25:50,828  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-05-01T00:25:50,835  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-05-01T00:25:50,849  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T00:25:50,849  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T00:25:50,849  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T00:25:50,850  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T00:25:50,851  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T00:25:50,852  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T00:25:50,874  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T00:25:50,879  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:50,884  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:50,896  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33
2024-05-01T00:25:50,900  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33
2024-05-01T00:25:50,904  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/_tmp_space.db
2024-05-01T00:25:50,909  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T00:25:50,909  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T00:25:50,911  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:25:50,912  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:25:50,914  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f will be shutdown
2024-05-01T00:25:50,915  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 created in the thread with id: 1
2024-05-01T00:25:50,933  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:25:50,934  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:25:50,936  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-05-01T00:25:50,997  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:25:50,997  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 will be shutdown
2024-05-01T00:25:50,998  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:25:50,998  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T00:25:50,999  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33
2024-05-01T00:25:51,002  INFO [main] service.CompositeService: Session opened, SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33], current sessions:1
2024-05-01T00:25:51,008  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T00:25:51,015  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:51,034  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=40d47d28-4a3d-48cd-b94f-9059a8f5183d] SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33]
2024-05-01T00:25:51,039  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c.test
2024-05-01T00:25:51,053  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c, startTime=1714548351030, sessionId=5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33, createTime=1714548350881, userName=anonymous, ipAddress=null]
2024-05-01T00:25:51,116  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Compiling command(queryId=alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:51,834  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:25:51,836  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: null will be shutdown
2024-05-01T00:25:51,837  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 created in the thread with id: 1
2024-05-01T00:25:51,845  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d from thread id: 1
2024-05-01T00:25:52,037  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] reflections.Reflections: Reflections took 157 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T00:25:52,169  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] reflections.Reflections: Reflections took 78 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T00:25:52,249  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] reflections.Reflections: Reflections took 74 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T00:25:52,342  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
2024-05-01T00:25:52,345  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:52,345  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33, clientType=HIVESERVER2]
2024-05-01T00:25:52,349  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:52,349  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:52,349  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:52,353  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:52,365  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:53,579  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:54,179  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:54,184  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:54,197  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:54,197  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:54,237  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-51_079_7309441670845354625-1
2024-05-01T00:25:54,279  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:54,365  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:54,388  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:54,457  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:54,463  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:54,464  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:54,464  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:54,464  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:54,464  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:54,464  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:54,466  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:54,466  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
2024-05-01T00:25:54,467  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:54,469  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:54,480  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:54,486  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:54,486  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=73, flushCache_()=13, getAllFunctions_()=61}
2024-05-01T00:25:54,487  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Completed compiling command(queryId=alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c); Time taken: 3.372 seconds
2024-05-01T00:25:54,487  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:54,488  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T00:25:54,495  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:54,499  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Executing command(queryId=alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:54,501  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T00:25:54,501  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:54,501  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001
2024-05-01T00:25:54,501  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001
2024-05-01T00:25:54,504  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
2024-05-01T00:25:54,504  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Query ID = alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
Total jobs = 1
2024-05-01T00:25:54,504  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:54,504  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:54,514  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:54,515  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:54,524  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:54,529  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:54,529  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/dummy_path
2024-05-01T00:25:54,618  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:54,639  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T00:25:54,783  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T00:25:54,801  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T00:25:54,815  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T00:25:54,816  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T00:25:54,839  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:54,891  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:54,902  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:54,905  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:54,907  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-05-01T00:25:54,918  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/dummy_path
2024-05-01T00:25:54,963  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:54,988  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:54,989  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:55,024  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:55,113  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2084306119_0001
2024-05-01T00:25:55,114  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:25:55,348  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T00:25:55,350  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:25:55,351  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:55,352  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:55,366  INFO [Thread-61] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:25:55,370  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2084306119_0001_m_000000_0
2024-05-01T00:25:55,409  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:25:55,417  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:25:55,424  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:25:55,453  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T00:25:55,460  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:25:55,467  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:25:55,469  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:25:55,471  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:25:55,471  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:25:55,474  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:25:55,475  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:25:55,476  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@75d7d706, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5d37b516, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@6a294cc
2024-05-01T00:25:55,484  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-51_079_7309441670845354625-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:55,484  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-51_079_7309441670845354625-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:55,484  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-51_079_7309441670845354625-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:55,512  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T00:25:55,512  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T00:25:55,512  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:25:55,512  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:25:55,513  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T00:25:55,515  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T00:25:55,518  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:25:55,525  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2084306119_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T00:25:55,526  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:25:55,527  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2084306119_0001_m_000000_0' done.
2024-05-01T00:25:55,528  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2084306119_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5586
		FILE: Number of bytes written=1157184
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=894959616
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:25:55,529  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2084306119_0001_m_000000_0
2024-05-01T00:25:55,529  INFO [Thread-61] mapred.LocalJobRunner: map task executor complete.
2024-05-01 00:25:56,365 Stage-1 map = 100%,  reduce = 0%
2024-05-01T00:25:56,365  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Task: 2024-05-01 00:25:56,365 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local2084306119_0001
2024-05-01T00:25:56,370  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.Task: Ended Job = job_local2084306119_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:56,381  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T00:25:56,381  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:56,381  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001
2024-05-01T00:25:56,381  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1/-mr-10001
2024-05-01T00:25:56,382  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:56,382  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T00:25:56,382  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T00:25:56,391  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:56,391  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:56,391  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Completed executing command(queryId=alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c); Time taken: 1.883 seconds
2024-05-01T00:25:56,392  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:56,395  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,396  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=33275cf4-4e6e-48a0-bf95-90bef4f430a3] SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33]
2024-05-01T00:25:56,397  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce.test
2024-05-01T00:25:56,400  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce, startTime=1714548356396, sessionId=5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33, createTime=1714548350881, userName=anonymous, ipAddress=null]
2024-05-01T00:25:56,401  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Compiling command(queryId=alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,403  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce
2024-05-01T00:25:56,403  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:56,404  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:56,404  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,404  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,404  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,404  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:56,421  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,523  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,523  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,525  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,525  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,527  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1
2024-05-01T00:25:56,536  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:56,539  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:56,540  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:56,558  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:56,559  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:56,559  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce
2024-05-01T00:25:56,559  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:56,559  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:56,560  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:56,561  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:56,561  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-05-01T00:25:56,561  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Completed compiling command(queryId=alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce); Time taken: 0.16 seconds
2024-05-01T00:25:56,562  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:56,562  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,564  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Thread context registration is done.
2024-05-01T00:25:56,564  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=60529712-fe5c-48fc-82f8-58e0535af433] SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33]
2024-05-01T00:25:56,565  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:56,565  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f.test
2024-05-01T00:25:56,570  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f, startTime=1714548356563, sessionId=5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33, createTime=1714548350881, userName=anonymous, ipAddress=null]
2024-05-01T00:25:56,570  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:56,571  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,571  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T00:25:56,571  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:56,572  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:56,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Compiling command(queryId=alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001
2024-05-01T00:25:56,572  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001
2024-05-01T00:25:56,572  WARN [HiveServer2-Background-Pool: Thread-121] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce
2024-05-01T00:25:56,572  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Query ID = alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce
Total jobs = 1
2024-05-01T00:25:56,572  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:56,572  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,574  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:56,575  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:56,576  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:56,583  INFO [HiveServer2-Background-Pool: Thread-121] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:56,584  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:56,584  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/dummy_path
2024-05-01T00:25:56,594  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,600  INFO [HiveServer2-Background-Pool: Thread-121] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:56,603  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:56,604  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:56,611  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:56,620  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:56,629  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:56,629  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:56,630  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/dummy_path
2024-05-01T00:25:56,638  INFO [HiveServer2-Background-Pool: Thread-121] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:56,639  INFO [HiveServer2-Background-Pool: Thread-121] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:56,639  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:56,672  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:56,679  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,680  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,682  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,682  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,683  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1
2024-05-01T00:25:56,693  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:56,696  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:56,697  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:56,710  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Submitting tokens for job: job_local1207849535_0002
2024-05-01T00:25:56,710  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:56,712  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:56,713  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:56,713  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f
2024-05-01T00:25:56,713  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:56,713  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:56,714  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:56,714  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:56,714  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-05-01T00:25:56,715  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Completed compiling command(queryId=alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f); Time taken: 0.142 seconds
2024-05-01T00:25:56,715  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:56,716  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Thread context registration is done.
2024-05-01T00:25:56,716  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,717  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:56,717  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=02493320-1ba4-4d57-bd3e-15673f751b63] SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33]
2024-05-01T00:25:56,718  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4.test
2024-05-01T00:25:56,722  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4, startTime=1714548356716, sessionId=5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33, createTime=1714548350881, userName=anonymous, ipAddress=null]
2024-05-01T00:25:56,722  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:56,723  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,723  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T00:25:56,724  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table2024-05-01T00:25:56,724  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Compiling command(queryId=alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4): select reflect("java.lang.Thread", "sleep", bigint(1000))

2024-05-01T00:25:56,724  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001
2024-05-01T00:25:56,724  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001
2024-05-01T00:25:56,725  WARN [HiveServer2-Background-Pool: Thread-156] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f
2024-05-01T00:25:56,725  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Query ID = alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f
Total jobs = 1
2024-05-01T00:25:56,725  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:56,725  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:56,726  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4
2024-05-01T00:25:56,726  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:56,726  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:56,726  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,726  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,726  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,727  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:56,729  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:56,729  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:56,741  INFO [HiveServer2-Background-Pool: Thread-156] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:56,742  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:56,742  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/dummy_path
2024-05-01T00:25:56,747  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,761  INFO [HiveServer2-Background-Pool: Thread-156] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:56,764  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:56,765  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:56,772  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:56,783  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:56,820  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:56,821  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:56,822  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/dummy_path
2024-05-01T00:25:56,829  INFO [HiveServer2-Background-Pool: Thread-156] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:56,829  INFO [HiveServer2-Background-Pool: Thread-156] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:56,830  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:56,841  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,841  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,844  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,844  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,845  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1
2024-05-01T00:25:56,854  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:56,857  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:56,858  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:56,861  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:25:56,862  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T00:25:56,863  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:25:56,864  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:56,866  INFO [Thread-113] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:25:56,867  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1207849535_0002_m_000000_0
2024-05-01T00:25:56,868  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:25:56,868  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:25:56,869  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:25:56,872  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:56,874  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:25:56,876  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:25:56,876  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:25:56,877  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:25:56,877  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:25:56,877  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:25:56,877  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:25:56,878  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@53584cc6, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5290c652, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@2b9bb7b7
2024-05-01T00:25:56,882  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:56,883  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:56,884  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:56,886  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:56,886  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:56,887  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-05-01T00:25:56,887  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Completed compiling command(queryId=alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4); Time taken: 0.162 seconds
2024-05-01T00:25:56,887  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:56,888  INFO [HiveServer2-Background-Pool: Thread-192] common.LogUtils: Thread context registration is done.
2024-05-01T00:25:56,888  INFO [HiveServer2-Background-Pool: Thread-192] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:56,888  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,889  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:56,890  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Executing command(queryId=alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,890  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4cda1d0a-017e-496a-b237-8e287b2259c5] SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33]
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,890  INFO [HiveServer2-Background-Pool: Thread-192] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,890  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Thread context registration is done.
PREHOOK: type: QUERY
2024-05-01T00:25:56,890  INFO [HiveServer2-Background-Pool: Thread-192] SessionState: PREHOOK: type: QUERY
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9.test
2024-05-01T00:25:56,896  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9, startTime=1714548356889, sessionId=5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33, createTime=1714548350881, userName=anonymous, ipAddress=null]
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:56,896  INFO [HiveServer2-Background-Pool: Thread-192] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001
2024-05-01T00:25:56,897  INFO [HiveServer2-Background-Pool: Thread-192] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001
2024-05-01T00:25:56,897  WARN [HiveServer2-Background-Pool: Thread-192] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4
2024-05-01T00:25:56,897  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Query ID = alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4
Total jobs = 1
2024-05-01T00:25:56,897  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:56,897  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:56,898  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Compiling command(queryId=alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:56,899  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9
2024-05-01T00:25:56,900  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:56,900  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:56,900  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:56,900  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:56,900  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:56,900  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:56,900  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:56,900  INFO [HiveServer2-Background-Pool: Thread-192] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:56,909  INFO [HiveServer2-Background-Pool: Thread-192] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:56,909  INFO [HiveServer2-Background-Pool: Thread-192] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:56,910  INFO [HiveServer2-Background-Pool: Thread-192] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/dummy_path
2024-05-01T00:25:56,918  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Submitting tokens for job: job_local712453406_0003
2024-05-01T00:25:56,918  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:25:56,918  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:56,924  INFO [HiveServer2-Background-Pool: Thread-192] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:56,926  INFO [HiveServer2-Background-Pool: Thread-192] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:56,927  WARN [HiveServer2-Background-Pool: Thread-192] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:56,933  WARN [HiveServer2-Background-Pool: Thread-192] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:56,942  WARN [HiveServer2-Background-Pool: Thread-192] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:56,949  WARN [HiveServer2-Background-Pool: Thread-192] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:56,949  INFO [HiveServer2-Background-Pool: Thread-192] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:56,950  INFO [HiveServer2-Background-Pool: Thread-192] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/dummy_path
2024-05-01T00:25:56,957  INFO [HiveServer2-Background-Pool: Thread-192] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:56,957  INFO [HiveServer2-Background-Pool: Thread-192] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:56,957  INFO [HiveServer2-Background-Pool: Thread-192] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:57,003  INFO [HiveServer2-Background-Pool: Thread-192] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:57,022  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:57,022  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:57,024  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:57,024  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:57,026  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1
2024-05-01T00:25:57,028  INFO [HiveServer2-Background-Pool: Thread-192] mapreduce.JobSubmitter: Submitting tokens for job: job_local916474633_0004
2024-05-01T00:25:57,028  INFO [HiveServer2-Background-Pool: Thread-192] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:25:57,033  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:57,035  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:57,036  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:57,038  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:25:57,038  INFO [Thread-160] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T00:25:57,039  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:25:57,039  INFO [Thread-160] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:57,041  INFO [Thread-160] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:25:57,041  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local712453406_0003_m_000000_0
2024-05-01T00:25:57,042  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:25:57,042  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:25:57,043  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:25:57,045  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:57,046  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:25:57,046  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:25:57,046  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:25:57,047  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:25:57,047  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:25:57,047  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:25:57,047  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:25:57,048  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@4f94fe8f, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@b2ae627, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@370ebf87
2024-05-01T00:25:57,052  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:57,052  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:57,052  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:57,052  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:57,052  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:57,052  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:57,053  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:57,053  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:57,053  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9
2024-05-01T00:25:57,053  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:57,053  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:57,054  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:57,054  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:57,054  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=8, flushCache_()=0}
2024-05-01T00:25:57,054  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Completed compiling command(queryId=alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9); Time taken: 0.156 seconds
2024-05-01T00:25:57,055  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:57,055  INFO [HiveServer2-Background-Pool: Thread-236] common.LogUtils: Thread context registration is done.
2024-05-01T00:25:57,055  INFO [HiveServer2-Background-Pool: Thread-236] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:57,055  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:57,056  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Executing command(queryId=alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T00:25:57,057  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T00:25:57,057  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:57,057  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001
2024-05-01T00:25:57,057  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001
2024-05-01T00:25:57,057  WARN [HiveServer2-Background-Pool: Thread-236] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9
2024-05-01T00:25:57,058  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Query ID = alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9
Total jobs = 1
2024-05-01T00:25:57,058  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:57,058  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:57,060  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:57,060  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:57,066  INFO [HiveServer2-Background-Pool: Thread-236] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:57,066  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:57,066  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/dummy_path
2024-05-01T00:25:57,080  INFO [HiveServer2-Background-Pool: Thread-236] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:57,081  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:57,082  WARN [HiveServer2-Background-Pool: Thread-236] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:57,087  WARN [HiveServer2-Background-Pool: Thread-236] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:57,095  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:57,101  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:57,102  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:57,103  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/dummy_path
2024-05-01T00:25:57,107  INFO [HiveServer2-Background-Pool: Thread-236] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:57,108  INFO [HiveServer2-Background-Pool: Thread-236] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:57,108  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:57,129  INFO [HiveServer2-Background-Pool: Thread-192] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:25:57,129  INFO [Thread-185] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T00:25:57,129  INFO [HiveServer2-Background-Pool: Thread-192] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:25:57,129  INFO [Thread-185] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:57,131  INFO [Thread-185] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:25:57,131  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local916474633_0004_m_000000_0
2024-05-01T00:25:57,131  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:57,132  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:25:57,133  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:25:57,134  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:25:57,136  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:57,136  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:25:57,136  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:25:57,137  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:25:57,137  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:25:57,137  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:25:57,137  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:25:57,138  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:25:57,138  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@7a4d9bb8, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@71f07e7, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@2be30cd8
2024-05-01T00:25:57,154  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: Submitting tokens for job: job_local570756488_0005
2024-05-01T00:25:57,154  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:25:57,227  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T00:25:57,228  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:57,228  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:25:57,228  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:57,230  INFO [Thread-218] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:25:57,230  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local570756488_0005_m_000000_0
2024-05-01T00:25:57,231  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:25:57,231  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:25:57,232  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:25:57,233  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:25:57,233  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:25:57,234  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:25:57,234  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:25:57,235  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:25:57,235  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:25:57,235  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:25:57,235  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:25:57,235  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@3f002df0, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@12ed357b, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@4783b332
2024-05-01T00:25:57,569  INFO [main] service.CompositeService: Session closed, SessionHandle [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33], current sessions:0
2024-05-01T00:25:57,569  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=60529712-fe5c-48fc-82f8-58e0535af433]
2024-05-01T00:25:57,569  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Removed queryId: alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=60529712-fe5c-48fc-82f8-58e0535af433] with tag: null
2024-05-01T00:25:57,570  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f
2024-05-01T00:25:57,570  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T00:25:57,570  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01 00:25:57,570 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,570  WARN [Thread-160] mapred.LocalJobRunner: job_local712453406_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:25:57,571  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,571  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: 2024-05-01 00:25:57,570 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,571  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-3
2024-05-01T00:25:57,571  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,571  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,571  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T00:25:57,571  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-3 operation was queued
Ended Job = job_local712453406_0003 with errors
2024-05-01T00:25:57,571 ERROR [HiveServer2-Background-Pool: Thread-156] exec.Task: Ended Job = job_local712453406_0003 with errors
2024-05-01T00:25:57,571  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1
2024-05-01T00:25:57,571  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1 operation was queued
2024-05-01T00:25:57,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:25:57,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:25:57,572  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-3
2024-05-01T00:25:57,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f without delay
2024-05-01T00:25:57,572  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1
2024-05-01T00:25:57,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=40d47d28-4a3d-48cd-b94f-9059a8f5183d]
2024-05-01T00:25:57,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Removed queryId: alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=40d47d28-4a3d-48cd-b94f-9059a8f5183d] with tag: null
2024-05-01T00:25:57,572  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1 operation was queued
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
Error during job, obtaining debugging information...
2024-05-01T00:25:57,573 ERROR [Thread-223] exec.Task: Error during job, obtaining debugging information...
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c without delay
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=33275cf4-4e6e-48a0-bf95-90bef4f430a3]
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Removed queryId: alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=33275cf4-4e6e-48a0-bf95-90bef4f430a3] with tag: null
2024-05-01T00:25:57,573  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce
2024-05-01T00:25:57,573  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T00:25:57,574  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-51_079_7309441670845354625-1
2024-05-01T00:25:57,574  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 00:25:57,574 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,574  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: 2024-05-01 00:25:57,574 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,575  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-2
2024-05-01T00:25:57,575  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-2 operation was queued
2024-05-01T00:25:57,575  WARN [Thread-113] mapred.LocalJobRunner: job_local1207849535_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:25:57,575  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1
2024-05-01T00:25:57,575  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1 operation was queued
2024-05-01T00:25:57,576  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:25:57,576  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:25:57,576  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-2
2024-05-01T00:25:57,576  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce without delay
2024-05-01T00:25:57,576  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=02493320-1ba4-4d57-bd3e-15673f751b63]
2024-05-01T00:25:57,576  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1
2024-05-01T00:25:57,576  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Removed queryId: alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=02493320-1ba4-4d57-bd3e-15673f751b63] with tag: null
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T00:25:57,576  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4
2024-05-01T00:25:57,576  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,576  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,576  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,577  WARN [HiveServer2-Background-Pool: Thread-192] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 00:25:57,576 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,577  INFO [HiveServer2-Background-Pool: Thread-192] exec.Task: 2024-05-01 00:25:57,576 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,580  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T00:25:57,581  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-4
2024-05-01T00:25:57,581  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-4 operation was queued
2024-05-01T00:25:57,581  WARN [Thread-185] mapred.LocalJobRunner: job_local916474633_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:25:57,581  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1
2024-05-01T00:25:57,581  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1 operation was queued
2024-05-01T00:25:57,581  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-05-01T00:25:57,581  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:25:57,581  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:25:57,582  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4 without delay
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T00:25:57,582  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,582  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4cda1d0a-017e-496a-b237-8e287b2259c5]
2024-05-01T00:25:57,582  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,582  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_tmp.-ext-10002/000000_0
FAILED: Operation cancelled2024-05-01T00:25:57,583  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-4

2024-05-01T00:25:57,583 ERROR [HiveServer2-Background-Pool: Thread-156] ql.Driver: FAILED: Operation cancelled
2024-05-01T00:25:57,583  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:57,583  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T00:25:57,583  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T00:25:57,583  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-05-01T00:25:57,582  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.OperationManager: Removed queryId: alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4cda1d0a-017e-496a-b237-8e287b2259c5] with tag: null
2024-05-01T00:25:57,583  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T00:25:57,583  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:57,583  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:57,584  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501002556_3a557f35-eeb3-42bd-a37c-b34efd3ed93f) has been interrupted after 0.86 seconds
2024-05-01T00:25:57,584  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9
2024-05-01T00:25:57,584  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 00:25:57,584 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,584  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: 2024-05-01 00:25:57,584 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:25:57,585  WARN [HiveServer2-Background-Pool: Thread-156] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T00:25:57,586  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:57,600  WARN [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T00:25:57,601  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-5
2024-05-01T00:25:57,601  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-5 operation was queued
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T00:25:57,602  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1
2024-05-01T00:25:57,602  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,602  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1 operation was queued
2024-05-01T00:25:57,601  WARN [Thread-218] mapred.LocalJobRunner: job_local570756488_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:25:57,602  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:25:57,602  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:25:57,602  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9 without delay
2024-05-01T00:25:57,602  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-5
2024-05-01T00:25:57,602  INFO [5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33
2024-05-01T00:25:57,603  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1
2024-05-01T00:25:57,602  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,603  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,604  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 operation was queued
2024-05-01T00:25:57,604  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33 operation was queued
2024-05-01T00:25:57,605  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33
2024-05-01T00:25:57,605 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:25:57,605  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:25:57,605  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_724_8450489495471799036-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_724_8450489495471799036-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,606 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:25:57,606  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:25:57,607  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:25:57,607  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:25:57,607  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T00:25:57,607  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,607  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,607  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_571_7654186616465654226-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_571_7654186616465654226-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,611 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:25:57,611  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T00:25:57,612  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,612  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,612  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_401_6590848595048529112-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_401_6590848595048529112-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,612 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:561)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:561)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:561)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:57,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/hive_2024-05-01_00-25-56_897_4493093351724929466-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-56_897_4493093351724929466-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:57,617  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:25:57,618  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 will be shutdown
2024-05-01T00:25:57,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:25:57,619  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T00:25:57,635  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T00:25:57,638  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T00:25:57,638  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T00:25:57,638  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="1.919">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:25:57,700  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T00:25:57,701  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:25:57,701  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:25:57,701  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:25:57,701  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:25:57,701  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = aa019a26-6ae6-4674-8a94-00082dd81463
2024-05-01T00:25:57,701  INFO [main] SessionState: Hive Session ID = aa019a26-6ae6-4674-8a94-00082dd81463
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:57,702  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:57,709  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/aa019a26-6ae6-4674-8a94-00082dd81463
2024-05-01T00:25:57,712  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/aa019a26-6ae6-4674-8a94-00082dd81463
2024-05-01T00:25:57,715  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/aa019a26-6ae6-4674-8a94-00082dd81463/_tmp_space.db
2024-05-01T00:25:57,716  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=aa019a26-6ae6-4674-8a94-00082dd81463, clientType=HIVESERVER2]
2024-05-01T00:25:57,716  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:25:57,717  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:25:57,717  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:25:57,718  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: null will be shutdown
2024-05-01T00:25:57,718  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5216532a created in the thread with id: 1
2024-05-01T00:25:57,721  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5 from thread id: 1
2024-05-01T00:25:57,721  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:25:57,721  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:25:57,722  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T00:25:57,722  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T00:25:57,722  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T00:25:57,722  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T00:25:57,722  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T00:25:57,723  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T00:25:57,726  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T00:25:57,736  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T00:25:57,736  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:57,737  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:57,744  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0dad0201-24aa-42e7-bca8-cd6e93cccdb6
2024-05-01T00:25:57,747  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6
2024-05-01T00:25:57,750  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/_tmp_space.db
2024-05-01T00:25:57,751  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T00:25:57,751  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T00:25:57,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:25:57,751  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5216532a will be shutdown
2024-05-01T00:25:57,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:25:57,751  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T00:25:57,751  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6
2024-05-01T00:25:57,751  INFO [main] service.CompositeService: Session opened, SessionHandle [0dad0201-24aa-42e7-bca8-cd6e93cccdb6], current sessions:1
2024-05-01T00:25:57,752  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T00:25:57,752  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:57,752  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a40a36a4-fb17-491e-ab0e-37c635ed2db5] SessionHandle [0dad0201-24aa-42e7-bca8-cd6e93cccdb6]
2024-05-01T00:25:57,753  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36.test
2024-05-01T00:25:57,756  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36, startTime=1714548357752, sessionId=0dad0201-24aa-42e7-bca8-cd6e93cccdb6, createTime=1714548357736, userName=anonymous, ipAddress=null]
2024-05-01T00:25:57,757  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Compiling command(queryId=alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:57,758  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:25:57,759  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:25:57,759  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:25:57,760  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: null will be shutdown
2024-05-01T00:25:57,760  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fc40856 created in the thread with id: 1
2024-05-01T00:25:57,764  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016 from thread id: 1
2024-05-01T00:25:57,764  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:25:57,764  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=0dad0201-24aa-42e7-bca8-cd6e93cccdb6, clientType=HIVESERVER2]
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:57,765  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:57,766  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:57,780  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:57,838  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:57,838  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:57,840  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:57,840  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:57,841  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-57_757_2850408265822522208-1
2024-05-01T00:25:57,848  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:57,850  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:57,850  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:57,862  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:57,863  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36
2024-05-01T00:25:57,863  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:57,863  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:57,864  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:57,864  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:57,864  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=0}
2024-05-01T00:25:57,864  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Completed compiling command(queryId=alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36); Time taken: 0.107 seconds
2024-05-01T00:25:57,864  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Executing command(queryId=alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001
2024-05-01T00:25:57,865  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001
2024-05-01T00:25:57,866  WARN [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36
2024-05-01T00:25:57,866  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Query ID = alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36
Total jobs = 1
2024-05-01T00:25:57,866  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:57,866  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:57,870  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:57,870  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:57,873  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:57,873  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:57,874  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/dummy_path
2024-05-01T00:25:57,886  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:57,887  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T00:25:57,888  WARN [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:57,894  WARN [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:57,902  WARN [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:57,908  WARN [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:57,908  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:57,909  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/dummy_path
2024-05-01T00:25:57,914  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:57,914  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:57,915  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:57,938  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:57,960  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1980439859_0006
2024-05-01T00:25:57,960  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:25:58,031  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:25:58,032  INFO [Thread-296] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T00:25:58,032  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:25:58,032  INFO [Thread-296] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:25:58,034  INFO [Thread-296] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:25:58,034  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1980439859_0006_m_000000_0
2024-05-01T00:25:58,037  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:25:58,038  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:25:58,041  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:25:58,042  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T00:25:58,042  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:25:58,046  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:25:58,046  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:25:58,047  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:25:58,047  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:25:58,047  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:25:58,047  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:25:58,047  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@16e7040b, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7ec9efd0, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@7bd651e3
2024-05-01T00:25:58,048  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-57_757_2850408265822522208-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:58,048  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-57_757_2850408265822522208-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:25:58,048  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-57_757_2850408265822522208-1/_tmp.-ext-10002/000000_0
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:25:58,060  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:25:58,061  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:25:58,061  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T00:25:58,061  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T00:25:58,062  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:25:58,065  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1980439859_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T00:25:58,066  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:25:58,066  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1980439859_0006_m_000000_0' done.
2024-05-01T00:25:58,067  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1980439859_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33492
		FILE: Number of bytes written=6928598
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=988807168
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:25:58,067  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1980439859_0006_m_000000_0
2024-05-01T00:25:58,067  INFO [Thread-296] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:25:58,575  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1207849535_0002 with errors
2024-05-01T00:25:58,575 ERROR [HiveServer2-Background-Pool: Thread-121] exec.Task: Ended Job = job_local1207849535_0002 with errors
Error during job, obtaining debugging information...
2024-05-01T00:25:58,576 ERROR [Thread-303] exec.Task: Error during job, obtaining debugging information...
2024-05-01T00:25:58,577  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T00:25:58,577 ERROR [HiveServer2-Background-Pool: Thread-121] ql.Driver: FAILED: Operation cancelled
2024-05-01T00:25:58,577  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:58,577  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Total time spent in each metastore function (ms): {close_()=2}
2024-05-01T00:25:58,577  WARN [HiveServer2-Background-Pool: Thread-192] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
MapReduce Jobs Launched: 
2024-05-01T00:25:58,577  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T00:25:58,577  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Ended Job = job_local916474633_0004 with errors
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL2024-05-01T00:25:58,578 ERROR [HiveServer2-Background-Pool: Thread-192] exec.Task: Ended Job = job_local916474633_0004 with errors

2024-05-01T00:25:58,578  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:58,578  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:58,578  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501002556_750e6434-24f2-4689-a965-a97987c4c5ce) has been interrupted after 2.006 seconds
Error during job, obtaining debugging information...
2024-05-01T00:25:58,578 ERROR [Thread-305] exec.Task: Error during job, obtaining debugging information...
2024-05-01T00:25:58,578  WARN [HiveServer2-Background-Pool: Thread-121] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T00:25:58,579  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:58,579  INFO [HiveServer2-Background-Pool: Thread-192] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T00:25:58,579 ERROR [HiveServer2-Background-Pool: Thread-192] ql.Driver: FAILED: Operation cancelled
2024-05-01T00:25:58,579  INFO [HiveServer2-Background-Pool: Thread-192] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:58,580  INFO [HiveServer2-Background-Pool: Thread-192] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T00:25:58,580  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T00:25:58,580  WARN [HiveServer2-Background-Pool: Thread-192] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T00:25:58,580  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:58,580  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:58,580  INFO [HiveServer2-Background-Pool: Thread-192] ql.Driver: Executing command(queryId=alex_20240501002556_e1efd142-6702-4f8e-ba84-ce3d33a5f5a4) has been interrupted after 1.69 seconds
2024-05-01T00:25:58,580  WARN [HiveServer2-Background-Pool: Thread-192] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T00:25:58,581  INFO [HiveServer2-Background-Pool: Thread-192] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:58,585  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local570756488_0005 with errors
2024-05-01T00:25:58,585 ERROR [HiveServer2-Background-Pool: Thread-236] exec.Task: Ended Job = job_local570756488_0005 with errors
Error during job, obtaining debugging information...
2024-05-01T00:25:58,586 ERROR [Thread-307] exec.Task: Error during job, obtaining debugging information...
2024-05-01T00:25:58,587  INFO [HiveServer2-Background-Pool: Thread-236] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T00:25:58,587 ERROR [HiveServer2-Background-Pool: Thread-236] ql.Driver: FAILED: Operation cancelled
2024-05-01T00:25:58,587  INFO [HiveServer2-Background-Pool: Thread-236] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:58,587  INFO [HiveServer2-Background-Pool: Thread-236] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T00:25:58,588  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T00:25:58,588  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T00:25:58,588  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:58,588  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:58,588  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Executing command(queryId=alex_20240501002556_1e93b01b-3bc5-4322-9750-2370b3ffcac9) has been interrupted after 1.531 seconds
2024-05-01T00:25:58,588  WARN [HiveServer2-Background-Pool: Thread-236] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T00:25:58,589  INFO [HiveServer2-Background-Pool: Thread-236] common.LogUtils: Unregistered logging context.
2024-05-01 00:25:59,035 Stage-1 map = 100%,  reduce = 0%
2024-05-01T00:25:59,035  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Task: 2024-05-01 00:25:59,035 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1980439859_0006
2024-05-01T00:25:59,037  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.Task: Ended Job = job_local1980439859_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:59,040  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T00:25:59,040  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:59,040  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001
2024-05-01T00:25:59,040  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1/-mr-10001
2024-05-01T00:25:59,040  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:59,041  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T00:25:59,041  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T00:25:59,041  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:59,041  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:25:59,041  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Completed executing command(queryId=alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36); Time taken: 1.175 seconds
2024-05-01T00:25:59,041  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:59,042  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T00:25:59,043  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=9efa54a4-39e4-4a59-ac8a-5181a446a736] SessionHandle [0dad0201-24aa-42e7-bca8-cd6e93cccdb6]
2024-05-01T00:25:59,043  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27.test
2024-05-01T00:25:59,048  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27, startTime=1714548359042, sessionId=0dad0201-24aa-42e7-bca8-cd6e93cccdb6, createTime=1714548357736, userName=anonymous, ipAddress=null]
2024-05-01T00:25:59,049  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Compiling command(queryId=alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T00:25:59,052  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27
2024-05-01T00:25:59,052  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:59,053  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-05-01T00:25:59,055  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-05-01T00:25:59,169  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] reflections.Reflections: Reflections took 103 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T00:25:59,244  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27
2024-05-01T00:25:59,244  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:59,244  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-05-01T00:25:59,244  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:59,245  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=10, flushCache_()=0}
2024-05-01T00:25:59,245  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Completed compiling command(queryId=alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27); Time taken: 0.195 seconds
2024-05-01T00:25:59,245  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:59,245  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-05-01T00:25:59,245  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Executing command(queryId=alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T00:25:59,245  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-05-01T00:25:59,246  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-05-01T00:25:59,246  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T00:25:59,246  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T00:25:59,246  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-05-01T00:25:59,369  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1714548359, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFiles=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-05-01T00:25:59,380  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/service/target/warehouse/sample_shutdown_hook
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T00:25:59,528  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-05-01T00:25:59,528  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-05-01T00:25:59,528  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T00:25:59,528  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T00:25:59,528  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:25:59,528  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, createTable_(Table)=158}
2024-05-01T00:25:59,529  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Driver: Completed executing command(queryId=alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27); Time taken: 0.283 seconds
2024-05-01T00:25:59,529  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:25:59,529  INFO [main] service.CompositeService: Session closed, SessionHandle [0dad0201-24aa-42e7-bca8-cd6e93cccdb6], current sessions:0
2024-05-01T00:25:59,529  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=9efa54a4-39e4-4a59-ac8a-5181a446a736]
2024-05-01T00:25:59,529  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.OperationManager: Removed queryId: alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=9efa54a4-39e4-4a59-ac8a-5181a446a736] with tag: null
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002559_32d2d70a-622f-47da-a9da-38d09530ee27 without delay
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a40a36a4-fb17-491e-ab0e-37c635ed2db5]
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.OperationManager: Removed queryId: alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a40a36a4-fb17-491e-ab0e-37c635ed2db5] with tag: null
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1 operation was queued
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:25:59,530  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/alex_20240501002557_ef3d5f6e-e9ae-479a-9b1b-ea99b0bd9a36 without delay
2024-05-01T00:25:59,531  INFO [0dad0201-24aa-42e7-bca8-cd6e93cccdb6 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0dad0201-24aa-42e7-bca8-cd6e93cccdb6
2024-05-01T00:25:59,532  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6/hive_2024-05-01_00-25-57_757_2850408265822522208-1
2024-05-01T00:25:59,532  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0dad0201-24aa-42e7-bca8-cd6e93cccdb6 operation was queued
2024-05-01T00:25:59,532  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6 operation was queued
2024-05-01T00:25:59,559  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0dad0201-24aa-42e7-bca8-cd6e93cccdb6
2024-05-01T00:25:59,559  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0dad0201-24aa-42e7-bca8-cd6e93cccdb6
2024-05-01T00:25:59,560  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:25:59,560  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fc40856 will be shutdown
2024-05-01T00:25:59,561  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:25:59,561  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.102">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:25:59,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T00:25:59,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:25:59,626  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:25:59,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:25:59,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:25:59,626  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 7b24da06-16b6-42be-9e3a-960ab5bcd41f
2024-05-01T00:25:59,626  INFO [main] SessionState: Hive Session ID = 7b24da06-16b6-42be-9e3a-960ab5bcd41f
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:59,627  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:59,634  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7b24da06-16b6-42be-9e3a-960ab5bcd41f
2024-05-01T00:25:59,637  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/7b24da06-16b6-42be-9e3a-960ab5bcd41f
2024-05-01T00:25:59,641  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7b24da06-16b6-42be-9e3a-960ab5bcd41f/_tmp_space.db
2024-05-01T00:25:59,641  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7b24da06-16b6-42be-9e3a-960ab5bcd41f, clientType=HIVESERVER2]
2024-05-01T00:25:59,642  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:25:59,643  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:25:59,643  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:25:59,644  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: null will be shutdown
2024-05-01T00:25:59,644  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7097ead6 created in the thread with id: 1
2024-05-01T00:25:59,655  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848 from thread id: 1
2024-05-01T00:25:59,655  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:25:59,655  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:25:59,655  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T00:25:59,655  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T00:25:59,656  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T00:25:59,656  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T00:25:59,656  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T00:25:59,657  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T00:25:59,659  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T00:25:59,673  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T00:25:59,673  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:59,675  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T00:25:59,682  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bdd19a5f-6289-48ae-81a2-dcf73283e7b5
2024-05-01T00:25:59,685  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5
2024-05-01T00:25:59,688  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/_tmp_space.db
2024-05-01T00:25:59,689  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T00:25:59,689  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T00:25:59,689  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:25:59,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7097ead6 will be shutdown
2024-05-01T00:25:59,689  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:25:59,689  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T00:25:59,690  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5
2024-05-01T00:25:59,690  INFO [main] service.CompositeService: Session opened, SessionHandle [bdd19a5f-6289-48ae-81a2-dcf73283e7b5], current sessions:1
2024-05-01T00:25:59,690  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T00:25:59,690  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:59,691  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b999ad24-71c0-40cf-99fe-5a461fc3fe03] SessionHandle [bdd19a5f-6289-48ae-81a2-dcf73283e7b5]
2024-05-01T00:25:59,691  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de.test
2024-05-01T00:25:59,696  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de, startTime=1714548359690, sessionId=bdd19a5f-6289-48ae-81a2-dcf73283e7b5, createTime=1714548359673, userName=anonymous, ipAddress=null]
2024-05-01T00:25:59,697  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Compiling command(queryId=alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:59,698  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:25:59,698  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:25:59,698  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:25:59,699  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: null will be shutdown
2024-05-01T00:25:59,699  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@460df441 created in the thread with id: 1
2024-05-01T00:25:59,703  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f from thread id: 1
2024-05-01T00:25:59,703  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:25:59,704  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:25:59,704  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de
2024-05-01T00:25:59,704  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:25:59,704  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=bdd19a5f-6289-48ae-81a2-dcf73283e7b5, clientType=HIVESERVER2]
2024-05-01T00:25:59,705  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:25:59,705  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:59,705  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:59,705  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:59,705  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:25:59,719  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:59,827  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:25:59,828  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:25:59,833  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:25:59,833  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:25:59,834  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-59_696_8356396835173235845-1
2024-05-01T00:25:59,841  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:25:59,843  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:25:59,843  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:25:59,854  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:25:59,855  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:25:59,856  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=61, flushCache_()=0}
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Completed compiling command(queryId=alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de); Time taken: 0.159 seconds
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:25:59,857  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Executing command(queryId=alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001
2024-05-01T00:25:59,858  WARN [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Query ID = alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de
Total jobs = 1
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:25:59,858  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:25:59,862  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:59,862  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:25:59,865  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:25:59,865  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:25:59,865  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/dummy_path
2024-05-01T00:25:59,878  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:25:59,879  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T00:25:59,880  WARN [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:59,885  WARN [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:25:59,892  WARN [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:25:59,898  WARN [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:25:59,899  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:25:59,900  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/dummy_path
2024-05-01T00:25:59,905  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:25:59,905  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:25:59,905  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:25:59,929  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:25:59,959  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1663051101_0007
2024-05-01T00:25:59,959  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:26:00,031  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:26:00,031  INFO [Thread-350] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T00:26:00,031  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:26:00,031  INFO [Thread-350] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:26:00,033  INFO [Thread-350] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:26:00,033  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1663051101_0007_m_000000_0
2024-05-01T00:26:00,037  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:26:00,038  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:26:00,042  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:26:00,044  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T00:26:00,044  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:26:00,048  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:26:00,048  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:26:00,049  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:26:00,049  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:26:00,049  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:26:00,050  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:26:00,050  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@347b4450, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@36248b91, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@705bd2f9
2024-05-01T00:26:00,051  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-59_696_8356396835173235845-1/_tmp.-ext-10002/000000_0
2024-05-01T00:26:00,051  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-59_696_8356396835173235845-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:26:00,051  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001/.hive-staging_hive_2024-05-01_00-25-59_696_8356396835173235845-1/_tmp.-ext-10002/000000_0
2024-05-01T00:26:00,063  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T00:26:00,063  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T00:26:00,064  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T00:26:00,065  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T00:26:00,066  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:26:00,069  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1663051101_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T00:26:00,070  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:26:00,070  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1663051101_0007_m_000000_0' done.
2024-05-01T00:26:00,070  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1663051101_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39078
		FILE: Number of bytes written=8085782
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=994574336
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:26:00,070  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1663051101_0007_m_000000_0
2024-05-01T00:26:00,071  INFO [Thread-350] mapred.LocalJobRunner: map task executor complete.
2024-05-01 00:26:01,035 Stage-1 map = 100%,  reduce = 0%
2024-05-01T00:26:01,035  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Task: 2024-05-01 00:26:01,035 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1663051101_0007
2024-05-01T00:26:01,036  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.Task: Ended Job = job_local1663051101_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T00:26:01,039  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T00:26:01,039  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:26:01,039  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001
2024-05-01T00:26:01,039  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1/-mr-10001
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Completed executing command(queryId=alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de); Time taken: 1.182 seconds
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:26:01,040  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T00:26:01,041  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=67c23cb6-d623-4fed-8e00-42bc83ffa748] SessionHandle [bdd19a5f-6289-48ae-81a2-dcf73283e7b5]
2024-05-01T00:26:01,041  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7.test
2024-05-01T00:26:01,046  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7, startTime=1714548361041, sessionId=bdd19a5f-6289-48ae-81a2-dcf73283e7b5, createTime=1714548359673, userName=anonymous, ipAddress=null]
2024-05-01T00:26:01,047  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Compiling command(queryId=alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T00:26:01,048  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7
2024-05-01T00:26:01,048  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T00:26:01,048  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T00:26:01,048  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:26:01,048  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:26:01,048  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:26:01,049  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T00:26:01,063  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:26:01,126  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T00:26:01,126  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T00:26:01,128  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T00:26:01,128  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T00:26:01,129  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/-mr-10001/.hive-staging_hive_2024-05-01_00-26-01_047_8627354574113036518-1
2024-05-01T00:26:01,136  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T00:26:01,141  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T00:26:01,142  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T00:26:01,153  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7
2024-05-01T00:26:01,154  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T00:26:01,155  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T00:26:01,156  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T00:26:01,156  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T00:26:01,156  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-05-01T00:26:01,156  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Completed compiling command(queryId=alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7); Time taken: 0.109 seconds
2024-05-01T00:26:01,156  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] common.LogUtils: Unregistered logging context.
2024-05-01T00:26:01,156  INFO [HiveServer2-Background-Pool: Thread-444] common.LogUtils: Thread context registration is done.
2024-05-01T00:26:01,156  INFO [HiveServer2-Background-Pool: Thread-444] reexec.ReExecDriver: Execution #1 of query
2024-05-01T00:26:01,158  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T00:26:01,158  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Executing command(queryId=alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T00:26:01,158  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-05-01T00:26:01,158  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T00:26:01,158  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/-mr-10001
2024-05-01T00:26:01,158  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/-mr-10001
2024-05-01T00:26:01,159  WARN [HiveServer2-Background-Pool: Thread-444] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7
2024-05-01T00:26:01,159  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Query ID = alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7
Total jobs = 1
2024-05-01T00:26:01,159  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T00:26:01,159  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Launching Job 1 out of 1
2024-05-01T00:26:01,163  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:26:01,163  INFO [HiveServer2-Background-Pool: Thread-444] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T00:26:01,169  INFO [HiveServer2-Background-Pool: Thread-444] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T00:26:01,169  INFO [HiveServer2-Background-Pool: Thread-444] exec.Utilities: Processing alias _dummy_table
2024-05-01T00:26:01,169  INFO [HiveServer2-Background-Pool: Thread-444] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/dummy_path
2024-05-01T00:26:01,182  INFO [HiveServer2-Background-Pool: Thread-444] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T00:26:01,183  INFO [HiveServer2-Background-Pool: Thread-444] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:26:01,184  WARN [HiveServer2-Background-Pool: Thread-444] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:26:01,189  WARN [HiveServer2-Background-Pool: Thread-444] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:26:01,196  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:26:01,201  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:26:01,202  INFO [HiveServer2-Background-Pool: Thread-444] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T00:26:01,203  INFO [HiveServer2-Background-Pool: Thread-444] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/dummy_path
2024-05-01T00:26:01,207  INFO [HiveServer2-Background-Pool: Thread-444] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:26:01,208  INFO [HiveServer2-Background-Pool: Thread-444] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T00:26:01,208  INFO [HiveServer2-Background-Pool: Thread-444] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T00:26:01,231  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:26:01,254  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.JobSubmitter: Submitting tokens for job: job_local1981323349_0008
2024-05-01T00:26:01,254  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:26:01,324  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T00:26:01,325  INFO [HiveServer2-Background-Pool: Thread-444] exec.Task: Job running in-process (local Hadoop)
2024-05-01T00:26:01,325  INFO [Thread-389] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:26:01,325  INFO [Thread-389] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T00:26:01,326  INFO [Thread-389] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:26:01,327  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1981323349_0008_m_000000_0
2024-05-01T00:26:01,327  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:26:01,328  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T00:26:01,329  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T00:26:01,330  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T00:26:01,330  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T00:26:01,331  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T00:26:01,331  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T00:26:01,331  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T00:26:01,331  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T00:26:01,331  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T00:26:01,332  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T00:26:01,332  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@3dfc1d97, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@50245897, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@71559584
DEBUG StatusLogger Removing appender alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
DEBUG StatusLogger Removing appender alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
DEBUG StatusLogger Deleting route with alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c key 
DEBUG StatusLogger Deleting route with alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c key 
DEBUG StatusLogger Stopping route with alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c key
DEBUG StatusLogger Stopping route with alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c key
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5ccab3cb-74a4-4cd3-9ad4-ea816e3bcf33/alex_20240501002551_5e864303-944f-4c96-be10-7502ff47221c.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-05-01T00:26:01,658  INFO [main] service.CompositeService: Session closed, SessionHandle [bdd19a5f-6289-48ae-81a2-dcf73283e7b5], current sessions:0
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b999ad24-71c0-40cf-99fe-5a461fc3fe03]
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.OperationManager: Removed queryId: alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b999ad24-71c0-40cf-99fe-5a461fc3fe03] with tag: null
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1 operation was queued
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002559_f790b70e-827d-41ae-8185-e1afb506a0de without delay
2024-05-01T00:26:01,658  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=67c23cb6-d623-4fed-8e00-42bc83ffa748]
2024-05-01T00:26:01,659  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.OperationManager: Removed queryId: alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=67c23cb6-d623-4fed-8e00-42bc83ffa748] with tag: null
2024-05-01T00:26:01,659  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7
2024-05-01T00:26:01,659  WARN [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-05-01T00:26:01,659  WARN [Thread-389] mapred.LocalJobRunner: job_local1981323349_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:26:01,659  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-6
2024-05-01T00:26:01,659  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/-mr-10001/.hive-staging_hive_2024-05-01_00-26-01_047_8627354574113036518-1/_tmp.-ext-10002/000000_0
2024-05-01T00:26:01,660  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-6 operation was queued
2024-05-01T00:26:01,660  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/-mr-10001/.hive-staging_hive_2024-05-01_00-26-01_047_8627354574113036518-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T00:26:01,660  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T00:26:01,660  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1/-mr-10001/.hive-staging_hive_2024-05-01_00-26-01_047_8627354574113036518-1/_tmp.-ext-10002/000000_0
2024-05-01T00:26:01,660  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1
2024-05-01 00:26:01,660 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:26:01,660  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-25-59_696_8356396835173235845-1
2024-05-01T00:26:01,660  INFO [HiveServer2-Background-Pool: Thread-444] exec.Task: 2024-05-01 00:26:01,660 Stage-1 map = 0%,  reduce = 0%
2024-05-01T00:26:01,660  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1 operation was queued
2024-05-01T00:26:01,660  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T00:26:01,660  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T00:26:01,660  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T00:26:01,660  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-6
2024-05-01T00:26:01,660  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7 without delay
Ended Job = job_local1981323349_0008 with errors
2024-05-01T00:26:01,660 ERROR [HiveServer2-Background-Pool: Thread-444] exec.Task: Ended Job = job_local1981323349_0008 with errors
2024-05-01T00:26:01,660  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5/hive_2024-05-01_00-26-01_047_8627354574113036518-1
2024-05-01T00:26:01,661  INFO [bdd19a5f-6289-48ae-81a2-dcf73283e7b5 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bdd19a5f-6289-48ae-81a2-dcf73283e7b5
Error during job, obtaining debugging information...
2024-05-01T00:26:01,661 ERROR [Thread-394] exec.Task: Error during job, obtaining debugging information...
2024-05-01T00:26:01,662  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bdd19a5f-6289-48ae-81a2-dcf73283e7b5 operation was queued
2024-05-01T00:26:01,662  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5 operation was queued
2024-05-01T00:26:01,662  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bdd19a5f-6289-48ae-81a2-dcf73283e7b5
2024-05-01T00:26:01,662  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/bdd19a5f-6289-48ae-81a2-dcf73283e7b5
2024-05-01T00:26:01,663  INFO [HiveServer2-Background-Pool: Thread-444] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled2024-05-01T00:26:01,663  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	

2024-05-01T00:26:01,663 ERROR [HiveServer2-Background-Pool: Thread-444] ql.Driver: FAILED: Operation cancelled
2024-05-01T00:26:01,663  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@460df441 will be shutdown
2024-05-01T00:26:01,663  INFO [HiveServer2-Background-Pool: Thread-444] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T00:26:01,663  INFO [HiveServer2-Background-Pool: Thread-444] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 2024-05-01T00:26:01,663  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	

2024-05-01T00:26:01,663  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T00:26:01,663  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T00:26:01,664  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T00:26:01,664  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:26:01,664  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T00:26:01,664  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Executing command(queryId=alex_20240501002601_5a53bd69-1bd8-4b4d-99cd-7f94d932a0b7) has been interrupted after 0.505 seconds
2024-05-01T00:26:01,664  WARN [HiveServer2-Background-Pool: Thread-444] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T00:26:01,664  INFO [HiveServer2-Background-Pool: Thread-444] common.LogUtils: Unregistered logging context.
]]></system-err>
  </testcase>
</testsuite>