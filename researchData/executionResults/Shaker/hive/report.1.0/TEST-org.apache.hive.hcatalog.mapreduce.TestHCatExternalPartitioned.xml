<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="47.132" tests="8" errors="0" skipped="2" failures="6">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter8863971970348380702.jar /home/alex/Repositories/hive/hcatalog/core/target/surefire 2024-05-01T05-01-21_120-jvmRun1 surefire927240753838355662tmp surefire_9337230869348681739606tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/hcatalog/core/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter8863971970348380702.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/hcatalog/core/../../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/hcatalog/core/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/hcatalog/core/../../"/>
  </properties>
  <testcase name="testHCatPartitionedTable[0]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="7.832">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,103020 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@5aa9e4eb
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,027546 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 51823243
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T00:48:53.014-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-00:48:54.720, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-00:48:54.721, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@488d1cd7
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@33d512c1
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1] started OK.
2024-05-01T00:48:54,935  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T00:48:55,045  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/core/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1714549734793/warehouse
2024-05-01T00:48:55,377  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T00:48:55,448  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:48:55,448  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:48:55,449  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:48:55,449  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:48:55,449  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:48:55,449  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:48:55,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:48:55,451  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:48:55,451  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:48:55,451  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:48:55,452  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:48:55,456  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=0 initial-capacity=50 maximum-capacity=50
2024-05-01T00:48:55,536  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:48:55,795  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:48:55,834  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:48:55,853  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T00:48:55,853  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T00:48:55,880  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T00:48:55,886  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T00:48:56,597  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T00:48:56,601  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T00:48:57,220  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T00:48:57,221  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: null will be shutdown
2024-05-01T00:48:57,251  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 created in the thread with id: 1
2024-05-01T00:48:59,811  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T00:48:59,811  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T00:48:59,811  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133 from thread id: 1
2024-05-01T00:49:00,416  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T00:49:00,457  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T00:49:00,500  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T00:49:00,502  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T00:49:00,614  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T00:49:00,621  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T00:49:00,622  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T00:49:00,625  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T00:49:00,653  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T00:49:00,656  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T00:49:00,658  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T00:49:00,659  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T00:49:00,661  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T00:49:00,664  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T00:49:00,666  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T00:49:00,666  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T00:49:00,671  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T00:49:00,672  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T00:49:00,673  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T00:49:00,676  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:00,822  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:00,851  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:00,851  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 will be shutdown
2024-05-01T00:49:00,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:00,852  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T00:49:00,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:00,855  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:00,856  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: null will be shutdown
2024-05-01T00:49:00,856  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 created in the thread with id: 1
2024-05-01T00:49:00,873  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff from thread id: 1
2024-05-01T00:49:00,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:00,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:00,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:00,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:00,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:00,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:00,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:00,978  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:00,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:00,979  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:00,979  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:01,010  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:01,010  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:01,011  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 will be shutdown
2024-05-01T00:49:01,011  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 created in the thread with id: 1
2024-05-01T00:49:01,016  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = ab76eb4a-030d-45a0-926d-55c7674ab71c
2024-05-01T00:49:01,024  INFO [main] SessionState: Hive Session ID = ab76eb4a-030d-45a0-926d-55c7674ab71c
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:01,037  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:01,093  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/ab76eb4a-030d-45a0-926d-55c7674ab71c
2024-05-01T00:49:01,097  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/ab76eb4a-030d-45a0-926d-55c7674ab71c
2024-05-01T00:49:01,100  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/ab76eb4a-030d-45a0-926d-55c7674ab71c/_tmp_space.db
2024-05-01T00:49:01,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:01,238  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_TEXTFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_TEXTFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T00:49:01,248  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile
2024-05-01T00:49:01,470  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:01,470  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:01,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:01,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:01,472  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:01,472  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:01,473  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:01,490  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:01,490  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:01,492  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 will be shutdown
2024-05-01T00:49:01,492  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d created in the thread with id: 1
2024-05-01T00:49:01,498  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:01,498  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:01,498  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:01,499  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d will be shutdown
2024-05-01T00:49:01,499  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:01,499  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T00:49:01,499  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:01,502  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:01,503  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: null will be shutdown
2024-05-01T00:49:01,503  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 created in the thread with id: 1
2024-05-01T00:49:01,509  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0 from thread id: 1
2024-05-01T00:49:01,514  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:01,562  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:01,741  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T00:49:01,756  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T00:49:01,769  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T00:49:01,769  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T00:49:01,830  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:01,830  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:01,830  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:01,831  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:01,832  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:01,834  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:01,834  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:01,835  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 will be shutdown
2024-05-01T00:49:01,835  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 created in the thread with id: 1
2024-05-01T00:49:01,840  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:01,840  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:01,841  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:01,841  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 will be shutdown
2024-05-01T00:49:01,841  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:01,841  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T00:49:01,841  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:01,843  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:01,843  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: null will be shutdown
2024-05-01T00:49:01,844  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb created in the thread with id: 1
2024-05-01T00:49:01,847  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933 from thread id: 1
2024-05-01T00:49:01,850  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value1,501]	
2024-05-01T00:49:01,921  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:01,930  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:01,964  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:02,019  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:02,060  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1751341830_0001
2024-05-01T00:49:02,060  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:02,183  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:02,184  INFO [main] mapreduce.Job: Running job: job_local1751341830_0001
2024-05-01T00:49:02,185  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:02,202  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,203  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,211  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:02,219  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,219  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,240  INFO [Thread-43] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:02,241  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1751341830_0001_m_000000_0
2024-05-01T00:49:02,271  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,271  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,274  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,274  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,288  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:02,293  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T00:49:02,313  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,313  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,398  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:02,409  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1751341830_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:02,409  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,409  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,416  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:02,416  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1751341830_0001_m_000000_0 is allowed to commit now
2024-05-01T00:49:02,416  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:02,416  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:02,430  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1751341830_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,13022871490901766/part1=p1value1/part0=501
2024-05-01T00:49:02,431  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:02,431  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1751341830_0001_m_000000_0' done.
2024-05-01T00:49:02,435  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1751341830_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=512500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=711458816
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:02,435  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1751341830_0001_m_000000_0
2024-05-01T00:49:02,436  INFO [Thread-43] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:02,498  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:02,498  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:02,498  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:02,499  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:02,499  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:02,499  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:02,499  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:02,499  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:02,499  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:02,500  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:02,500  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:02,500  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:02,501  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:02,502  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:02,502  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:02,502  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@497890f7, with PersistenceManager: null will be shutdown
2024-05-01T00:49:02,503  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@497890f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7add0c17 created in the thread with id: 69
2024-05-01T00:49:02,509  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@497890f7 from thread id: 69
2024-05-01T00:49:02,509  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:02,509  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:02,510  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:02,510  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@497890f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7add0c17 will be shutdown
2024-05-01T00:49:02,510  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:02,510  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-05-01T00:49:02,510  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:02,511  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:02,512  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b0f52fe, with PersistenceManager: null will be shutdown
2024-05-01T00:49:02,512  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b0f52fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@134e37bf created in the thread with id: 69
2024-05-01T00:49:02,515  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b0f52fe from thread id: 69
2024-05-01T00:49:02,574  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:02,575  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:02,576  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:02,576  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T00:49:02,607  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,13022871490901766/part1=p1value1/part0=501].
2024-05-01T00:49:02,607  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:02,653  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:02,654  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:02,655  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:02,655  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:02,655  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:02,655  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:02,656  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:02,656  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:02,657  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b0f52fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@134e37bf will be shutdown
2024-05-01T00:49:02,657  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b0f52fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ae697a8 created in the thread with id: 69
2024-05-01T00:49:02,661  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:02,661  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:02,661  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:02,661  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b0f52fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ae697a8 will be shutdown
2024-05-01T00:49:02,662  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:02,662  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T00:49:02,662  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:02,663  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:02,663  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fe82dd8, with PersistenceManager: null will be shutdown
2024-05-01T00:49:02,663  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fe82dd8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@511ca0bc created in the thread with id: 69
2024-05-01T00:49:02,667  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fe82dd8 from thread id: 69
2024-05-01T00:49:02,669  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:02,669  WARN [Thread-43] mapred.LocalJobRunner: job_local1751341830_0001
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,13022871490901766/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:03,189  INFO [main] mapreduce.Job: Job job_local1751341830_0001 running in uber mode : false
2024-05-01T00:49:03,190  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:03,193  INFO [main] mapreduce.Job: Job job_local1751341830_0001 failed with state FAILED due to: NA
2024-05-01T00:49:03,199  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=512500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=711458816
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:03,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:03,267  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:03,267  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:03,267  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:03,267  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:03,268  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:03,271  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:03,271  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:03,271  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb will be shutdown
2024-05-01T00:49:03,272  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61853c7e created in the thread with id: 1
2024-05-01T00:49:03,276  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:03,276  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:03,276  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:03,276  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61853c7e will be shutdown
2024-05-01T00:49:03,276  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:03,276  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T00:49:03,277  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:03,277  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:03,278  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: null will be shutdown
2024-05-01T00:49:03,278  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ccc1026 created in the thread with id: 1
2024-05-01T00:49:03,281  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52 from thread id: 1
2024-05-01T00:49:03,283  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:03,293  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:03,301  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:03,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:03,340  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:03,340  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:03,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:03,341  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:03,342  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:03,343  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:03,343  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:03,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ccc1026 will be shutdown
2024-05-01T00:49:03,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5be51aa created in the thread with id: 1
2024-05-01T00:49:03,347  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:03,347  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:03,347  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:03,347  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5be51aa will be shutdown
2024-05-01T00:49:03,348  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:03,348  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-05-01T00:49:03,348  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:03,348  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:03,349  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: null will be shutdown
2024-05-01T00:49:03,349  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@577bfadb created in the thread with id: 1
2024-05-01T00:49:03,353  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb from thread id: 1
2024-05-01T00:49:03,354  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T00:49:03,380  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:03,386  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:03,387  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:03,409  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:03,429  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local797067504_0002
2024-05-01T00:49:03,429  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:03,497  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:03,497  INFO [main] mapreduce.Job: Running job: job_local797067504_0002
2024-05-01T00:49:03,497  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:03,501  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,501  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,503  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:03,504  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,504  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,518  INFO [Thread-91] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:03,518  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local797067504_0002_m_000000_0
2024-05-01T00:49:03,522  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,522  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,524  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,524  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,524  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:03,525  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:03,529  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,529  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,544  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:03,545  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local797067504_0002_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:03,545  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,545  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,549  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:03,549  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local797067504_0002_m_000000_0 is allowed to commit now
2024-05-01T00:49:03,549  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:03,549  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:03,560  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local797067504_0002_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,6521038060759471/part1=p1value2/part0=502
2024-05-01T00:49:03,561  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:03,561  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local797067504_0002_m_000000_0' done.
2024-05-01T00:49:03,561  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local797067504_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1022829
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=711458816
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:03,561  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local797067504_0002_m_000000_0
2024-05-01T00:49:03,561  INFO [Thread-91] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:03,615  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:03,615  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:03,616  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:03,617  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:03,618  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:03,618  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:03,618  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:03,619  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e4de1ed, with PersistenceManager: null will be shutdown
2024-05-01T00:49:03,619  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e4de1ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70e3eed0 created in the thread with id: 119
2024-05-01T00:49:03,624  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e4de1ed from thread id: 119
2024-05-01T00:49:03,624  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:03,625  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:03,625  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:03,625  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e4de1ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70e3eed0 will be shutdown
2024-05-01T00:49:03,625  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:03,625  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-05-01T00:49:03,625  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:03,626  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:03,627  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@672c7a30, with PersistenceManager: null will be shutdown
2024-05-01T00:49:03,627  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@672c7a30, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c4150d5 created in the thread with id: 119
2024-05-01T00:49:03,631  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@672c7a30 from thread id: 119
2024-05-01T00:49:03,683  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:03,683  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:03,683  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:03,683  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:03,683  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:03,684  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:03,684  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:03,684  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:03,684  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:03,684  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:03,684  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:03,684  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:03,710  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,6521038060759471/part1=p1value2/part0=502].
2024-05-01T00:49:03,710  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:03,756  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:03,756  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:03,756  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:03,756  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:03,757  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:03,758  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:03,759  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:03,759  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:03,759  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@672c7a30, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c4150d5 will be shutdown
2024-05-01T00:49:03,759  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@672c7a30, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d5b12d9 created in the thread with id: 119
2024-05-01T00:49:03,763  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:03,763  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:03,764  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:03,764  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@672c7a30, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d5b12d9 will be shutdown
2024-05-01T00:49:03,764  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:03,764  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -9
2024-05-01T00:49:03,764  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:03,766  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:03,766  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@231de80f, with PersistenceManager: null will be shutdown
2024-05-01T00:49:03,766  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@231de80f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d144a40 created in the thread with id: 119
2024-05-01T00:49:03,770  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@231de80f from thread id: 119
2024-05-01T00:49:03,771  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:03,771  WARN [Thread-91] mapred.LocalJobRunner: job_local797067504_0002
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,6521038060759471/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:04,498  INFO [main] mapreduce.Job: Job job_local797067504_0002 running in uber mode : false
2024-05-01T00:49:04,498  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:04,498  INFO [main] mapreduce.Job: Job job_local797067504_0002 failed with state FAILED due to: NA
2024-05-01T00:49:04,500  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1022829
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=711458816
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:04,571  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:04,571  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:04,571  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:04,571  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:04,572  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:04,572  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:04,573  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:04,578  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:04,578  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:04,578  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@577bfadb will be shutdown
2024-05-01T00:49:04,579  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22fb9a2c created in the thread with id: 1
2024-05-01T00:49:04,583  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:04,583  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:04,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:04,584  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22fb9a2c will be shutdown
2024-05-01T00:49:04,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:04,584  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -10
2024-05-01T00:49:04,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:04,585  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:04,586  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1805383, with PersistenceManager: null will be shutdown
2024-05-01T00:49:04,586  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1805383, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64fdcf99 created in the thread with id: 1
2024-05-01T00:49:04,590  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1805383 from thread id: 1
2024-05-01T00:49:04,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:04,601  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:04,610  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:04,651  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:04,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:04,653  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:04,653  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:04,654  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:04,654  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:04,655  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1805383, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64fdcf99 will be shutdown
2024-05-01T00:49:04,655  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1805383, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77cddc0c created in the thread with id: 1
2024-05-01T00:49:04,659  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:04,659  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:04,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:04,659  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1805383, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77cddc0c will be shutdown
2024-05-01T00:49:04,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:04,659  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -11
2024-05-01T00:49:04,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:04,660  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:04,661  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c3e363, with PersistenceManager: null will be shutdown
2024-05-01T00:49:04,661  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c3e363, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16c5b50a created in the thread with id: 1
2024-05-01T00:49:04,665  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c3e363 from thread id: 1
2024-05-01T00:49:04,667  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T00:49:04,685  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:04,691  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:04,692  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:04,714  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:04,733  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1873600058_0003
2024-05-01T00:49:04,733  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:04,793  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:04,794  INFO [main] mapreduce.Job: Running job: job_local1873600058_0003
2024-05-01T00:49:04,794  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:04,797  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,797  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,799  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:04,801  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,801  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,815  INFO [Thread-137] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:04,815  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1873600058_0003_m_000000_0
2024-05-01T00:49:04,818  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,818  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,821  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,822  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,822  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:04,823  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:04,827  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,827  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,844  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:04,845  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1873600058_0003_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:04,845  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,845  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,850  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:04,850  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1873600058_0003_m_000000_0 is allowed to commit now
2024-05-01T00:49:04,850  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:04,850  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:04,861  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1873600058_0003_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9448824734294088/part1=p1value2/part0=502
2024-05-01T00:49:04,862  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:04,862  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1873600058_0003_m_000000_0' done.
2024-05-01T00:49:04,862  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1873600058_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1535548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=712507392
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:04,862  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1873600058_0003_m_000000_0
2024-05-01T00:49:04,863  INFO [Thread-137] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:04,914  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:04,914  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:04,914  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:04,915  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:04,916  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:04,917  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:04,918  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:04,918  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:04,918  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e65cd8f, with PersistenceManager: null will be shutdown
2024-05-01T00:49:04,919  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e65cd8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12898a68 created in the thread with id: 167
2024-05-01T00:49:04,923  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e65cd8f from thread id: 167
2024-05-01T00:49:04,923  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:04,923  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:04,924  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:04,924  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e65cd8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12898a68 will be shutdown
2024-05-01T00:49:04,924  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:04,924  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -12
2024-05-01T00:49:04,924  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:04,925  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:04,926  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7676e3d4, with PersistenceManager: null will be shutdown
2024-05-01T00:49:04,926  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7676e3d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24960479 created in the thread with id: 167
2024-05-01T00:49:04,930  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7676e3d4 from thread id: 167
2024-05-01T00:49:04,982  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:04,982  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:04,982  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:04,982  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:04,982  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:04,982  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:04,983  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:04,983  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:04,983  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:04,983  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:04,983  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:04,983  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:05,007  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9448824734294088/part1=p1value2/part0=502].
2024-05-01T00:49:05,007  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:05,048  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:05,048  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:05,048  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:05,048  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:05,048  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:05,049  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:05,049  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:05,049  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:05,049  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:05,049  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:05,049  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:05,049  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:05,050  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:05,050  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:05,051  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7676e3d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24960479 will be shutdown
2024-05-01T00:49:05,051  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7676e3d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bb6d99 created in the thread with id: 167
2024-05-01T00:49:05,054  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:05,054  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:05,054  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:05,054  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7676e3d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bb6d99 will be shutdown
2024-05-01T00:49:05,054  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:05,054  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -13
2024-05-01T00:49:05,054  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:05,055  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:05,055  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62fce8b7, with PersistenceManager: null will be shutdown
2024-05-01T00:49:05,056  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62fce8b7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@780a0ecb created in the thread with id: 167
2024-05-01T00:49:05,058  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62fce8b7 from thread id: 167
2024-05-01T00:49:05,060  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:05,060  WARN [Thread-137] mapred.LocalJobRunner: job_local1873600058_0003
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9448824734294088/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:05,794  INFO [main] mapreduce.Job: Job job_local1873600058_0003 running in uber mode : false
2024-05-01T00:49:05,795  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:05,795  INFO [main] mapreduce.Job: Job job_local1873600058_0003 failed with state FAILED due to: NA
2024-05-01T00:49:05,796  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1535548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=712507392
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:05,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:05,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:05,845  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:05,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:05,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:05,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:05,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:05,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:05,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:05,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:05,846  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:05,846  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:05,847  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:05,849  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:05,849  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:05,849  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c3e363, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16c5b50a will be shutdown
2024-05-01T00:49:05,850  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c3e363, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43786627 created in the thread with id: 1
2024-05-01T00:49:05,854  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:05,854  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:05,854  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:05,854  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c3e363, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43786627 will be shutdown
2024-05-01T00:49:05,854  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:05,854  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -14
2024-05-01T00:49:05,855  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:05,856  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:05,856  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d120d7c, with PersistenceManager: null will be shutdown
2024-05-01T00:49:05,856  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d120d7c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ee77baf created in the thread with id: 1
2024-05-01T00:49:05,859  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d120d7c from thread id: 1
2024-05-01T00:49:05,860  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:05,869  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:05,876  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:05,914  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:05,915  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:05,915  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:05,916  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:05,917  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:05,917  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d120d7c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ee77baf will be shutdown
2024-05-01T00:49:05,917  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d120d7c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4dd1d2bb created in the thread with id: 1
2024-05-01T00:49:05,920  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:05,921  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:05,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:05,921  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d120d7c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4dd1d2bb will be shutdown
2024-05-01T00:49:05,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:05,921  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -15
2024-05-01T00:49:05,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:05,922  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:05,922  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61957d9c, with PersistenceManager: null will be shutdown
2024-05-01T00:49:05,922  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61957d9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29c59b6e created in the thread with id: 1
2024-05-01T00:49:05,925  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61957d9c from thread id: 1
2024-05-01T00:49:05,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:05,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:05,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:05,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:05,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:05,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:05,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:05,978  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:05,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:05,978  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:05,978  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:05,978  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:05,979  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:05,981  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:05,981  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:05,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61957d9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29c59b6e will be shutdown
2024-05-01T00:49:05,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61957d9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70d5d96b created in the thread with id: 1
2024-05-01T00:49:05,985  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:05,985  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:05,986  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:05,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61957d9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70d5d96b will be shutdown
2024-05-01T00:49:05,987  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:05,987  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -16
2024-05-01T00:49:05,988  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:05,989  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:05,989  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba562e0, with PersistenceManager: null will be shutdown
2024-05-01T00:49:05,989  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba562e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a51336a created in the thread with id: 1
2024-05-01T00:49:05,993  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba562e0 from thread id: 1
2024-05-01T00:49:05,995  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:06,005  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:06,051  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:06,051  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:06,051  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:06,051  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:06,051  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:06,052  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:06,052  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:06,052  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:06,052  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:06,052  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:06,052  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:06,053  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:06,053  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:06,055  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:06,055  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:06,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba562e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a51336a will be shutdown
2024-05-01T00:49:06,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba562e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11ad095c created in the thread with id: 1
2024-05-01T00:49:06,058  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:06,058  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:06,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:06,058  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba562e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11ad095c will be shutdown
2024-05-01T00:49:06,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:06,059  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -17
2024-05-01T00:49:06,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:06,060  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:06,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7752c0e7, with PersistenceManager: null will be shutdown
2024-05-01T00:49:06,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7752c0e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77ba583 created in the thread with id: 1
2024-05-01T00:49:06,063  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7752c0e7 from thread id: 1
2024-05-01T00:49:06,064  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:06,072  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:06,079  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:06,114  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:06,114  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:06,114  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:06,114  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:06,114  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:06,115  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:06,115  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:06,115  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:06,115  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:06,115  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:06,115  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:06,115  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:06,116  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:06,116  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:06,117  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7752c0e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77ba583 will be shutdown
2024-05-01T00:49:06,117  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7752c0e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5fbae40 created in the thread with id: 1
2024-05-01T00:49:06,119  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:06,120  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:06,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:06,120  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7752c0e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5fbae40 will be shutdown
2024-05-01T00:49:06,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:06,120  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -18
2024-05-01T00:49:06,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:06,121  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:06,121  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@136fece2, with PersistenceManager: null will be shutdown
2024-05-01T00:49:06,121  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@136fece2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56478522 created in the thread with id: 1
2024-05-01T00:49:06,124  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@136fece2 from thread id: 1
2024-05-01T00:49:06,131  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:06,136  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:06,137  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:06,158  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:06,175  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1103807198_0004
2024-05-01T00:49:06,175  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:06,226  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:06,226  INFO [main] mapreduce.Job: Running job: job_local1103807198_0004
2024-05-01T00:49:06,226  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:06,230  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:06,231  INFO [Thread-188] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:06,232  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1103807198_0004_m_000000_0
2024-05-01T00:49:06,235  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:06,236  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T00:49:06,245  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1103807198_0004_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.4209769686727306/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T00:49:06,245  INFO [Thread-188] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:06,250  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.4209769686727306].
2024-05-01T00:49:06,250  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:06,290  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:06,291  INFO [Thread-188] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:06,292  INFO [Thread-188] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:06,293  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:06,293  INFO [Thread-188] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:06,293  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56cb3418, with PersistenceManager: null will be shutdown
2024-05-01T00:49:06,293  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56cb3418, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e608729 created in the thread with id: 220
2024-05-01T00:49:06,296  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56cb3418 from thread id: 220
2024-05-01T00:49:06,296  INFO [Thread-188] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:06,296  INFO [Thread-188] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:06,296  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:06,296  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56cb3418, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e608729 will be shutdown
2024-05-01T00:49:06,296  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:06,296  INFO [Thread-188] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -19
2024-05-01T00:49:06,296  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:06,297  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:06,297  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a2fa52b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:06,298  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a2fa52b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7a0ec28 created in the thread with id: 220
2024-05-01T00:49:06,300  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a2fa52b from thread id: 220
2024-05-01T00:49:06,301  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:06,301  WARN [Thread-188] mapred.LocalJobRunner: job_local1103807198_0004
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T00:49:07,226  INFO [main] mapreduce.Job: Job job_local1103807198_0004 running in uber mode : false
2024-05-01T00:49:07,227  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:07,227  INFO [main] mapreduce.Job: Job job_local1103807198_0004 failed with state FAILED due to: NA
2024-05-01T00:49:07,227  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:07,269  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:07,269  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:07,269  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:07,270  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:07,270  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:07,271  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:07,272  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:07,272  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:07,273  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@136fece2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56478522 will be shutdown
2024-05-01T00:49:07,273  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@136fece2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@563843f1 created in the thread with id: 1
2024-05-01T00:49:07,275  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:07,276  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:07,276  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:07,276  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@136fece2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@563843f1 will be shutdown
2024-05-01T00:49:07,276  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:07,276  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -20
2024-05-01T00:49:07,276  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:07,277  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:07,277  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: null will be shutdown
2024-05-01T00:49:07,277  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ac685ef created in the thread with id: 1
2024-05-01T00:49:07,280  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224 from thread id: 1
2024-05-01T00:49:07,281  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:07,289  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:07,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:07,308  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:07,314  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:07,319  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:07,343  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T00:49:07,367  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1664754711_0005
2024-05-01T00:49:07,367  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:07,417  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:07,417  INFO [main] mapreduce.Job: Running job: job_local1664754711_0005
2024-05-01T00:49:07,417  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:07,419  INFO [Thread-208] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:07,419  INFO [Thread-208] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:07,419  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T00:49:07,429  INFO [Thread-208] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:07,429  INFO [Thread-208] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:08,418  INFO [main] mapreduce.Job: Job job_local1664754711_0005 running in uber mode : false
2024-05-01T00:49:08,418  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:08,418  INFO [main] mapreduce.Job: Job job_local1664754711_0005 completed successfully
2024-05-01T00:49:08,418  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:08,419  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:08,426  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:08,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:08,712  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:08,713  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:08,713  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[1]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.612">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:08,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:08,768  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:08,768  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:08,770  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:08,770  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:08,770  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ac685ef will be shutdown
2024-05-01T00:49:08,770  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a8b9458 created in the thread with id: 1
2024-05-01T00:49:08,777  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 7d536253-0af4-4a33-908e-ee833f07169a
2024-05-01T00:49:08,777  INFO [main] SessionState: Hive Session ID = 7d536253-0af4-4a33-908e-ee833f07169a
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:08,778  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:08,784  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/7d536253-0af4-4a33-908e-ee833f07169a
2024-05-01T00:49:08,787  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/7d536253-0af4-4a33-908e-ee833f07169a
2024-05-01T00:49:08,816  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/7d536253-0af4-4a33-908e-ee833f07169a/_tmp_space.db
2024-05-01T00:49:08,816  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:08,824  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_SEQUENCEFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.mapred.SequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_SEQUENCEFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T00:49:08,828  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile
2024-05-01T00:49:08,918  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:08,918  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:08,918  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:08,918  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:08,918  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:08,918  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:08,919  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:08,919  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:08,919  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:08,919  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:08,919  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:08,919  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:08,920  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:08,922  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:08,922  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:08,923  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a8b9458 will be shutdown
2024-05-01T00:49:08,923  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73234691 created in the thread with id: 1
2024-05-01T00:49:08,926  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:08,926  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:08,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:08,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2acca224, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73234691 will be shutdown
2024-05-01T00:49:08,927  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:08,927  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -21
2024-05-01T00:49:08,927  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:08,928  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:08,928  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: null will be shutdown
2024-05-01T00:49:08,928  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2474df51 created in the thread with id: 1
2024-05-01T00:49:08,930  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373 from thread id: 1
2024-05-01T00:49:08,931  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:08,957  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:08,965  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:09,002  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:09,003  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:09,003  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:09,004  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:09,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2474df51 will be shutdown
2024-05-01T00:49:09,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3291d9c2 created in the thread with id: 1
2024-05-01T00:49:09,007  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:09,007  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:09,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:09,008  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3291d9c2 will be shutdown
2024-05-01T00:49:09,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:09,008  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -22
2024-05-01T00:49:09,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:09,009  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:09,009  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: null will be shutdown
2024-05-01T00:49:09,009  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79273a4f created in the thread with id: 1
2024-05-01T00:49:09,012  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a from thread id: 1
2024-05-01T00:49:09,013  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value1,501]	
2024-05-01T00:49:09,035  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:09,040  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:09,041  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:09,061  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:09,078  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local40515961_0006
2024-05-01T00:49:09,078  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:09,128  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:09,128  INFO [main] mapreduce.Job: Running job: job_local40515961_0006
2024-05-01T00:49:09,128  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:09,130  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,130  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,132  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:09,133  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,133  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,147  INFO [Thread-242] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:09,147  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local40515961_0006_m_000000_0
2024-05-01T00:49:09,155  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,155  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,157  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,157  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,157  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:09,158  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T00:49:09,165  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,165  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,195  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:09,199  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local40515961_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:09,199  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,199  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,203  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:09,203  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local40515961_0006_m_000000_0 is allowed to commit now
2024-05-01T00:49:09,203  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:09,203  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:09,214  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local40515961_0006_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,08137873593195377/part1=p1value1/part0=501
2024-05-01T00:49:09,215  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:09,215  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local40515961_0006_m_000000_0' done.
2024-05-01T00:49:09,215  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local40515961_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3066834
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=781189120
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:09,215  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local40515961_0006_m_000000_0
2024-05-01T00:49:09,215  INFO [Thread-242] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:09,260  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:09,261  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:09,262  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:09,262  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:09,262  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:09,263  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20beaff0, with PersistenceManager: null will be shutdown
2024-05-01T00:49:09,263  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20beaff0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@655c939a created in the thread with id: 276
2024-05-01T00:49:09,265  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20beaff0 from thread id: 276
2024-05-01T00:49:09,265  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:09,265  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:09,266  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:09,266  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20beaff0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@655c939a will be shutdown
2024-05-01T00:49:09,266  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:09,266  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -23
2024-05-01T00:49:09,266  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:09,267  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:09,267  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30ca3b17, with PersistenceManager: null will be shutdown
2024-05-01T00:49:09,267  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30ca3b17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@94f40bb created in the thread with id: 276
2024-05-01T00:49:09,269  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30ca3b17 from thread id: 276
2024-05-01T00:49:09,312  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:09,312  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:09,313  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:09,313  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T00:49:09,337  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,08137873593195377/part1=p1value1/part0=501].
2024-05-01T00:49:09,337  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:09,378  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:09,379  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:09,379  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:09,380  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:09,380  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:09,380  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30ca3b17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@94f40bb will be shutdown
2024-05-01T00:49:09,380  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30ca3b17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66318cdf created in the thread with id: 276
2024-05-01T00:49:09,383  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:09,384  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:09,384  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:09,384  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30ca3b17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66318cdf will be shutdown
2024-05-01T00:49:09,384  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:09,384  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -24
2024-05-01T00:49:09,384  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:09,386  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:09,386  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f81bb26, with PersistenceManager: null will be shutdown
2024-05-01T00:49:09,386  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f81bb26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40410a60 created in the thread with id: 276
2024-05-01T00:49:09,389  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f81bb26 from thread id: 276
2024-05-01T00:49:09,390  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:09,390  WARN [Thread-242] mapred.LocalJobRunner: job_local40515961_0006
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,08137873593195377/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:10,128  INFO [main] mapreduce.Job: Job job_local40515961_0006 running in uber mode : false
2024-05-01T00:49:10,129  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:10,129  INFO [main] mapreduce.Job: Job job_local40515961_0006 failed with state FAILED due to: NA
2024-05-01T00:49:10,130  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3066834
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=781189120
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:10,177  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:10,178  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:10,179  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:10,180  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:10,180  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:10,181  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79273a4f will be shutdown
2024-05-01T00:49:10,181  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6879e983 created in the thread with id: 1
2024-05-01T00:49:10,183  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:10,183  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:10,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:10,183  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6879e983 will be shutdown
2024-05-01T00:49:10,184  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:10,184  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -25
2024-05-01T00:49:10,184  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:10,184  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:10,185  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: null will be shutdown
2024-05-01T00:49:10,185  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@673a9db4 created in the thread with id: 1
2024-05-01T00:49:10,188  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4 from thread id: 1
2024-05-01T00:49:10,189  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:10,198  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:10,205  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:10,238  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:10,238  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:10,239  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:10,239  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:10,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@673a9db4 will be shutdown
2024-05-01T00:49:10,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@515940af created in the thread with id: 1
2024-05-01T00:49:10,242  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:10,242  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:10,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:10,242  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@515940af will be shutdown
2024-05-01T00:49:10,243  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:10,243  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -26
2024-05-01T00:49:10,243  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:10,243  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:10,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: null will be shutdown
2024-05-01T00:49:10,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e2578ea created in the thread with id: 1
2024-05-01T00:49:10,246  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818 from thread id: 1
2024-05-01T00:49:10,248  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T00:49:10,272  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:10,277  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:10,278  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:10,299  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:10,316  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local594782576_0007
2024-05-01T00:49:10,316  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:10,365  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:10,365  INFO [main] mapreduce.Job: Running job: job_local594782576_0007
2024-05-01T00:49:10,365  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:10,368  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,368  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,370  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:10,371  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,371  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,384  INFO [Thread-288] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:10,385  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local594782576_0007_m_000000_0
2024-05-01T00:49:10,387  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,387  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,390  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,390  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,390  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:10,391  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:10,393  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,393  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,407  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:10,407  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local594782576_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:10,408  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,408  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,411  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:10,411  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local594782576_0007_m_000000_0 is allowed to commit now
2024-05-01T00:49:10,411  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:10,411  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:10,422  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local594782576_0007_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5933344981628592/part1=p1value2/part0=502
2024-05-01T00:49:10,423  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:10,423  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local594782576_0007_m_000000_0' done.
2024-05-01T00:49:10,423  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local594782576_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3577509
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=781189120
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:10,423  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local594782576_0007_m_000000_0
2024-05-01T00:49:10,423  INFO [Thread-288] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:10,477  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:10,477  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:10,478  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:10,478  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:10,479  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:10,479  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20e5636d, with PersistenceManager: null will be shutdown
2024-05-01T00:49:10,479  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20e5636d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23d40658 created in the thread with id: 324
2024-05-01T00:49:10,481  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20e5636d from thread id: 324
2024-05-01T00:49:10,481  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:10,481  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:10,481  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:10,481  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20e5636d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23d40658 will be shutdown
2024-05-01T00:49:10,481  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:10,481  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -27
2024-05-01T00:49:10,481  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:10,482  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:10,482  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@384aca9c, with PersistenceManager: null will be shutdown
2024-05-01T00:49:10,483  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@384aca9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33c19ed3 created in the thread with id: 324
2024-05-01T00:49:10,484  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@384aca9c from thread id: 324
2024-05-01T00:49:10,529  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:10,530  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:10,531  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:10,554  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5933344981628592/part1=p1value2/part0=502].
2024-05-01T00:49:10,554  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:10,594  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:10,595  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:10,595  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:10,596  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:10,596  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:10,596  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@384aca9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33c19ed3 will be shutdown
2024-05-01T00:49:10,596  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@384aca9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6216fb51 created in the thread with id: 324
2024-05-01T00:49:10,599  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:10,599  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:10,600  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:10,600  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@384aca9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6216fb51 will be shutdown
2024-05-01T00:49:10,600  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:10,600  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -28
2024-05-01T00:49:10,600  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:10,601  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:10,601  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8630bb, with PersistenceManager: null will be shutdown
2024-05-01T00:49:10,601  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8630bb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d72e8bf created in the thread with id: 324
2024-05-01T00:49:10,603  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8630bb from thread id: 324
2024-05-01T00:49:10,605  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:10,605  WARN [Thread-288] mapred.LocalJobRunner: job_local594782576_0007
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5933344981628592/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:11,365  INFO [main] mapreduce.Job: Job job_local594782576_0007 running in uber mode : false
2024-05-01T00:49:11,366  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:11,366  INFO [main] mapreduce.Job: Job job_local594782576_0007 failed with state FAILED due to: NA
2024-05-01T00:49:11,368  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3577509
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=781189120
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:11,414  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:11,415  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:11,417  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:11,417  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:11,417  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e2578ea will be shutdown
2024-05-01T00:49:11,417  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ebf776c created in the thread with id: 1
2024-05-01T00:49:11,419  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:11,420  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:11,420  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:11,420  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ebf776c will be shutdown
2024-05-01T00:49:11,420  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:11,420  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -29
2024-05-01T00:49:11,420  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:11,421  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:11,421  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: null will be shutdown
2024-05-01T00:49:11,421  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@570299e3 created in the thread with id: 1
2024-05-01T00:49:11,423  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02 from thread id: 1
2024-05-01T00:49:11,424  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:11,434  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:11,441  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:11,477  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:11,477  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:11,477  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:11,478  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:11,478  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:11,479  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:11,479  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:11,479  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@570299e3 will be shutdown
2024-05-01T00:49:11,480  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f430ea8 created in the thread with id: 1
2024-05-01T00:49:11,482  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:11,482  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:11,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:11,482  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f430ea8 will be shutdown
2024-05-01T00:49:11,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:11,482  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -30
2024-05-01T00:49:11,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:11,483  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:11,483  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: null will be shutdown
2024-05-01T00:49:11,484  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c6b300a created in the thread with id: 1
2024-05-01T00:49:11,485  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615 from thread id: 1
2024-05-01T00:49:11,487  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T00:49:11,503  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:11,508  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:11,509  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:11,530  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:11,546  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2060714134_0008
2024-05-01T00:49:11,546  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:11,598  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:11,599  INFO [main] mapreduce.Job: Running job: job_local2060714134_0008
2024-05-01T00:49:11,599  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:11,601  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,601  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,603  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:11,603  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,603  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,617  INFO [Thread-334] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:11,617  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2060714134_0008_m_000000_0
2024-05-01T00:49:11,619  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,619  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,621  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,621  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,621  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:11,622  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:11,624  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,624  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,638  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:11,638  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2060714134_0008_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:11,638  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,638  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,642  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:11,642  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2060714134_0008_m_000000_0 is allowed to commit now
2024-05-01T00:49:11,643  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:11,643  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:11,653  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2060714134_0008_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8856792338578993/part1=p1value2/part0=502
2024-05-01T00:49:11,654  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:11,654  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2060714134_0008_m_000000_0' done.
2024-05-01T00:49:11,654  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2060714134_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4090574
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=781189120
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:11,654  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2060714134_0008_m_000000_0
2024-05-01T00:49:11,654  INFO [Thread-334] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:11,706  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:11,707  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:11,707  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:11,707  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:11,707  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:11,708  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:11,709  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:11,709  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:11,710  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@22050ab5, with PersistenceManager: null will be shutdown
2024-05-01T00:49:11,710  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@22050ab5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d958fb0 created in the thread with id: 372
2024-05-01T00:49:11,712  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@22050ab5 from thread id: 372
2024-05-01T00:49:11,712  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:11,712  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:11,713  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:11,713  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@22050ab5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d958fb0 will be shutdown
2024-05-01T00:49:11,713  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:11,713  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -31
2024-05-01T00:49:11,713  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:11,714  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:11,714  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575b7f9e, with PersistenceManager: null will be shutdown
2024-05-01T00:49:11,714  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575b7f9e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@275f5fed created in the thread with id: 372
2024-05-01T00:49:11,717  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575b7f9e from thread id: 372
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:11,765  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:11,766  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:11,766  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:11,820  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8856792338578993/part1=p1value2/part0=502].
2024-05-01T00:49:11,820  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:11,865  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:11,865  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:11,865  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:11,865  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:11,865  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:11,865  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:11,866  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:11,866  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:11,866  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:11,866  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:11,866  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:11,866  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:11,867  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:11,867  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:11,868  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575b7f9e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@275f5fed will be shutdown
2024-05-01T00:49:11,868  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575b7f9e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56dee7e created in the thread with id: 372
2024-05-01T00:49:11,870  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:11,870  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:11,870  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:11,870  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575b7f9e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56dee7e will be shutdown
2024-05-01T00:49:11,870  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:11,870  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -32
2024-05-01T00:49:11,871  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:11,871  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:11,871  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38bea39c, with PersistenceManager: null will be shutdown
2024-05-01T00:49:11,872  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38bea39c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3efa32d1 created in the thread with id: 372
2024-05-01T00:49:11,874  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38bea39c from thread id: 372
2024-05-01T00:49:11,875  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:11,875  WARN [Thread-334] mapred.LocalJobRunner: job_local2060714134_0008
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8856792338578993/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:12,599  INFO [main] mapreduce.Job: Job job_local2060714134_0008 running in uber mode : false
2024-05-01T00:49:12,599  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:12,600  INFO [main] mapreduce.Job: Job job_local2060714134_0008 failed with state FAILED due to: NA
2024-05-01T00:49:12,601  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4090574
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=781189120
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:12,646  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:12,647  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:12,647  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:12,647  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:12,649  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:12,649  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:12,649  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c6b300a will be shutdown
2024-05-01T00:49:12,649  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5340ccb9 created in the thread with id: 1
2024-05-01T00:49:12,651  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:12,651  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:12,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:12,652  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5340ccb9 will be shutdown
2024-05-01T00:49:12,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:12,652  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -33
2024-05-01T00:49:12,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:12,653  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:12,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: null will be shutdown
2024-05-01T00:49:12,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10e4ee33 created in the thread with id: 1
2024-05-01T00:49:12,655  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320 from thread id: 1
2024-05-01T00:49:12,656  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:12,663  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:12,669  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:12,701  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:12,701  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:12,701  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:12,702  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:12,702  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:12,703  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:12,703  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:12,703  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10e4ee33 will be shutdown
2024-05-01T00:49:12,703  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f9ccd0c created in the thread with id: 1
2024-05-01T00:49:12,705  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:12,705  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:12,705  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:12,705  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f9ccd0c will be shutdown
2024-05-01T00:49:12,706  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:12,706  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -34
2024-05-01T00:49:12,706  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:12,706  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:12,707  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: null will be shutdown
2024-05-01T00:49:12,707  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e4c4fda created in the thread with id: 1
2024-05-01T00:49:12,708  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f from thread id: 1
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:12,754  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:12,755  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:12,755  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:12,758  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:12,758  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:12,758  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e4c4fda will be shutdown
2024-05-01T00:49:12,758  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77db231c created in the thread with id: 1
2024-05-01T00:49:12,760  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:12,760  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:12,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:12,761  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77db231c will be shutdown
2024-05-01T00:49:12,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:12,761  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -35
2024-05-01T00:49:12,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:12,762  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:12,762  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: null will be shutdown
2024-05-01T00:49:12,762  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e617c0e created in the thread with id: 1
2024-05-01T00:49:12,765  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3 from thread id: 1
2024-05-01T00:49:12,766  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:12,775  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:12,824  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:12,824  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:12,824  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:12,824  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:12,824  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:12,825  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:12,825  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:12,825  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:12,825  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:12,825  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:12,825  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:12,825  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:12,826  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:12,827  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:12,827  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:12,828  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e617c0e will be shutdown
2024-05-01T00:49:12,828  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e73f5e7 created in the thread with id: 1
2024-05-01T00:49:12,831  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:12,831  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:12,831  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:12,831  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e73f5e7 will be shutdown
2024-05-01T00:49:12,831  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:12,832  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -36
2024-05-01T00:49:12,832  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:12,833  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:12,833  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:12,833  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@178c6261 created in the thread with id: 1
2024-05-01T00:49:12,836  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b from thread id: 1
2024-05-01T00:49:12,837  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:12,846  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:12,853  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:12,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:12,903  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:12,903  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:12,904  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:12,904  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:12,905  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@178c6261 will be shutdown
2024-05-01T00:49:12,905  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c846d55 created in the thread with id: 1
2024-05-01T00:49:12,907  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:12,907  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:12,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:12,907  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c846d55 will be shutdown
2024-05-01T00:49:12,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:12,907  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -37
2024-05-01T00:49:12,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:12,908  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:12,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: null will be shutdown
2024-05-01T00:49:12,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e1b5532 created in the thread with id: 1
2024-05-01T00:49:12,910  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc from thread id: 1
2024-05-01T00:49:12,918  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:12,923  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:12,923  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:12,945  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:12,961  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1341846293_0009
2024-05-01T00:49:12,961  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:13,013  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:13,013  INFO [main] mapreduce.Job: Running job: job_local1341846293_0009
2024-05-01T00:49:13,014  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:13,016  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:13,017  INFO [Thread-385] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:13,017  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1341846293_0009_m_000000_0
2024-05-01T00:49:13,020  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:13,020  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T00:49:13,026  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1341846293_0009_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.6485584915952375/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T00:49:13,026  INFO [Thread-385] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:13,027  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.6485584915952375].
2024-05-01T00:49:13,027  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:13,066  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:13,066  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:13,067  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:13,067  INFO [Thread-385] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:13,068  INFO [Thread-385] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:13,069  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:13,069  INFO [Thread-385] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:13,070  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4619c1c, with PersistenceManager: null will be shutdown
2024-05-01T00:49:13,070  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4619c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e02d5a6 created in the thread with id: 425
2024-05-01T00:49:13,072  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4619c1c from thread id: 425
2024-05-01T00:49:13,072  INFO [Thread-385] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:13,072  INFO [Thread-385] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:13,072  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:13,072  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4619c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e02d5a6 will be shutdown
2024-05-01T00:49:13,073  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:13,073  INFO [Thread-385] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -38
2024-05-01T00:49:13,073  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:13,073  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:13,074  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c957f00, with PersistenceManager: null will be shutdown
2024-05-01T00:49:13,074  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c957f00, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@710a1f1a created in the thread with id: 425
2024-05-01T00:49:13,076  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c957f00 from thread id: 425
2024-05-01T00:49:13,078  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:13,078  WARN [Thread-385] mapred.LocalJobRunner: job_local1341846293_0009
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T00:49:14,014  INFO [main] mapreduce.Job: Job job_local1341846293_0009 running in uber mode : false
2024-05-01T00:49:14,014  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:14,014  INFO [main] mapreduce.Job: Job job_local1341846293_0009 failed with state FAILED due to: NA
2024-05-01T00:49:14,014  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:14,054  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:14,055  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:14,055  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:14,057  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:14,057  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:14,057  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e1b5532 will be shutdown
2024-05-01T00:49:14,057  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61d150af created in the thread with id: 1
2024-05-01T00:49:14,059  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:14,059  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:14,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:14,059  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61d150af will be shutdown
2024-05-01T00:49:14,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:14,059  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -39
2024-05-01T00:49:14,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:14,060  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:14,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: null will be shutdown
2024-05-01T00:49:14,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dbcee03 created in the thread with id: 1
2024-05-01T00:49:14,062  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39 from thread id: 1
2024-05-01T00:49:14,063  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:14,070  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:14,070  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:14,078  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:14,084  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:14,089  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:14,114  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T00:49:14,136  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1218261165_0010
2024-05-01T00:49:14,136  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:14,197  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:14,197  INFO [main] mapreduce.Job: Running job: job_local1218261165_0010
2024-05-01T00:49:14,198  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:14,198  INFO [Thread-405] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:14,198  INFO [Thread-405] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:14,198  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T00:49:14,206  INFO [Thread-405] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:14,206  INFO [Thread-405] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:15,198  INFO [main] mapreduce.Job: Job job_local1218261165_0010 running in uber mode : false
2024-05-01T00:49:15,198  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:15,198  INFO [main] mapreduce.Job: Job job_local1218261165_0010 completed successfully
2024-05-01T00:49:15,198  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:15,199  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:15,206  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:15,206  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,334  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,335  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[2]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.409">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,377  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:15,379  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:15,379  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:15,379  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dbcee03 will be shutdown
2024-05-01T00:49:15,379  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b3f62d7 created in the thread with id: 1
2024-05-01T00:49:15,381  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 94dc6522-fc34-4980-a223-2e908e22ed91
2024-05-01T00:49:15,381  INFO [main] SessionState: Hive Session ID = 94dc6522-fc34-4980-a223-2e908e22ed91
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:15,382  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:15,388  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/94dc6522-fc34-4980-a223-2e908e22ed91
2024-05-01T00:49:15,391  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/94dc6522-fc34-4980-a223-2e908e22ed91
2024-05-01T00:49:15,394  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/94dc6522-fc34-4980-a223-2e908e22ed91/_tmp_space.db
2024-05-01T00:49:15,394  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:15,395  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_RCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_RCFILE, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T00:49:15,398  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile
2024-05-01T00:49:15,457  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,457  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,457  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,458  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:15,458  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:15,459  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:15,461  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:15,461  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:15,461  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b3f62d7 will be shutdown
2024-05-01T00:49:15,462  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42012093 created in the thread with id: 1
2024-05-01T00:49:15,464  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:15,464  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:15,465  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:15,465  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42012093 will be shutdown
2024-05-01T00:49:15,465  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:15,465  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -40
2024-05-01T00:49:15,465  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:15,466  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:15,466  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: null will be shutdown
2024-05-01T00:49:15,467  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ba27ce6 created in the thread with id: 1
2024-05-01T00:49:15,469  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321 from thread id: 1
2024-05-01T00:49:15,470  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:15,479  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:15,488  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,523  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,524  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,524  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:15,524  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:15,524  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:15,525  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:15,525  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ba27ce6 will be shutdown
2024-05-01T00:49:15,525  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ea45a5b created in the thread with id: 1
2024-05-01T00:49:15,527  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:15,527  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:15,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:15,527  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ea45a5b will be shutdown
2024-05-01T00:49:15,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:15,527  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -41
2024-05-01T00:49:15,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:15,528  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:15,528  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: null will be shutdown
2024-05-01T00:49:15,529  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ad6895a created in the thread with id: 1
2024-05-01T00:49:15,531  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73 from thread id: 1
2024-05-01T00:49:15,532  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value1,501]	
2024-05-01T00:49:15,547  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:15,552  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:15,553  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:15,573  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:15,588  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local143713924_0011
2024-05-01T00:49:15,588  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:15,638  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:15,638  INFO [main] mapreduce.Job: Running job: job_local143713924_0011
2024-05-01T00:49:15,639  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:15,641  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,641  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,642  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:15,643  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,643  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,656  INFO [Thread-439] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:15,656  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local143713924_0011_m_000000_0
2024-05-01T00:49:15,661  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,661  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,662  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:15,663  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T00:49:15,668  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,668  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,700  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:15,700  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T00:49:15,700  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T00:49:15,704  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local143713924_0011_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:15,704  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,704  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,709  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:15,709  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local143713924_0011_m_000000_0 is allowed to commit now
2024-05-01T00:49:15,709  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:15,709  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:15,721  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local143713924_0011_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7307926513807301/part1=p1value1/part0=501
2024-05-01T00:49:15,721  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:15,721  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local143713924_0011_m_000000_0' done.
2024-05-01T00:49:15,722  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local143713924_0011_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5624609
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=784334848
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:15,722  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local143713924_0011_m_000000_0
2024-05-01T00:49:15,722  INFO [Thread-439] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:15,765  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,765  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,765  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,765  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,766  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:15,766  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:15,767  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:15,767  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:15,767  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:15,767  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@341f6c9a, with PersistenceManager: null will be shutdown
2024-05-01T00:49:15,767  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@341f6c9a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@339a9a13 created in the thread with id: 481
2024-05-01T00:49:15,769  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@341f6c9a from thread id: 481
2024-05-01T00:49:15,769  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:15,769  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:15,770  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:15,770  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@341f6c9a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@339a9a13 will be shutdown
2024-05-01T00:49:15,770  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:15,770  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -42
2024-05-01T00:49:15,770  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:15,771  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:15,771  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e88eccb, with PersistenceManager: null will be shutdown
2024-05-01T00:49:15,771  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e88eccb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f5518c6 created in the thread with id: 481
2024-05-01T00:49:15,773  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e88eccb from thread id: 481
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,825  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,826  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,826  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:15,826  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T00:49:15,847  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7307926513807301/part1=p1value1/part0=501].
2024-05-01T00:49:15,847  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:15,885  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:15,886  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:15,886  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:15,886  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:15,886  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:15,886  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:15,887  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e88eccb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f5518c6 will be shutdown
2024-05-01T00:49:15,887  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e88eccb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4bd9b1af created in the thread with id: 481
2024-05-01T00:49:15,888  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:15,889  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:15,889  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:15,889  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e88eccb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4bd9b1af will be shutdown
2024-05-01T00:49:15,889  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:15,889  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -43
2024-05-01T00:49:15,889  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:15,890  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:15,890  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10592596, with PersistenceManager: null will be shutdown
2024-05-01T00:49:15,890  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10592596, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e499362 created in the thread with id: 481
2024-05-01T00:49:15,892  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10592596 from thread id: 481
2024-05-01T00:49:15,893  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:15,893  WARN [Thread-439] mapred.LocalJobRunner: job_local143713924_0011
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7307926513807301/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:16,639  INFO [main] mapreduce.Job: Job job_local143713924_0011 running in uber mode : false
2024-05-01T00:49:16,639  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:16,639  INFO [main] mapreduce.Job: Job job_local143713924_0011 failed with state FAILED due to: NA
2024-05-01T00:49:16,640  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5624609
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=784334848
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:16,686  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:16,686  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:16,687  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:16,688  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:16,688  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:16,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ad6895a will be shutdown
2024-05-01T00:49:16,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33f4844b created in the thread with id: 1
2024-05-01T00:49:16,691  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:16,691  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:16,691  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:16,692  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33f4844b will be shutdown
2024-05-01T00:49:16,692  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:16,692  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -44
2024-05-01T00:49:16,692  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:16,693  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:16,693  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: null will be shutdown
2024-05-01T00:49:16,694  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106edde4 created in the thread with id: 1
2024-05-01T00:49:16,696  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be from thread id: 1
2024-05-01T00:49:16,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:16,705  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:16,711  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:16,744  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:16,744  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:16,745  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:16,745  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:16,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106edde4 will be shutdown
2024-05-01T00:49:16,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32f54c2a created in the thread with id: 1
2024-05-01T00:49:16,748  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:16,748  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:16,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:16,748  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32f54c2a will be shutdown
2024-05-01T00:49:16,749  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:16,749  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -45
2024-05-01T00:49:16,749  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:16,750  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:16,750  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f8ab988, with PersistenceManager: null will be shutdown
2024-05-01T00:49:16,750  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f8ab988, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@46c475ba created in the thread with id: 1
2024-05-01T00:49:16,752  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f8ab988 from thread id: 1
2024-05-01T00:49:16,753  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T00:49:16,769  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:16,774  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:16,775  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:16,796  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:16,843  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local707042407_0012
2024-05-01T00:49:16,843  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:16,891  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:16,891  INFO [main] mapreduce.Job: Running job: job_local707042407_0012
2024-05-01T00:49:16,892  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:16,894  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,894  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,895  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:16,896  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,896  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,909  INFO [Thread-485] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:16,909  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local707042407_0012_m_000000_0
2024-05-01T00:49:16,912  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,912  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,913  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,913  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,913  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:16,914  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:16,916  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,916  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,931  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:16,931  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T00:49:16,931  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T00:49:16,931  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local707042407_0012_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:16,931  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,931  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,935  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:16,935  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local707042407_0012_m_000000_0 is allowed to commit now
2024-05-01T00:49:16,935  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:16,935  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:16,946  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local707042407_0012_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,948744617381047/part1=p1value2/part0=502
2024-05-01T00:49:16,947  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:16,947  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local707042407_0012_m_000000_0' done.
2024-05-01T00:49:16,947  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local707042407_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6135389
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=857210880
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:16,947  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local707042407_0012_m_000000_0
2024-05-01T00:49:16,947  INFO [Thread-485] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:17,010  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:17,011  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:17,011  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:17,012  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:17,012  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:17,013  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19b5546b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:17,013  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19b5546b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30699825 created in the thread with id: 529
2024-05-01T00:49:17,015  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19b5546b from thread id: 529
2024-05-01T00:49:17,015  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:17,015  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:17,015  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:17,015  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19b5546b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30699825 will be shutdown
2024-05-01T00:49:17,015  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:17,015  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -46
2024-05-01T00:49:17,015  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:17,016  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:17,017  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f1fed91, with PersistenceManager: null will be shutdown
2024-05-01T00:49:17,017  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f1fed91, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48a30cb6 created in the thread with id: 529
2024-05-01T00:49:17,019  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f1fed91 from thread id: 529
2024-05-01T00:49:17,064  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:17,064  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:17,064  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:17,064  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:17,064  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:17,064  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:17,065  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:17,065  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:17,065  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:17,065  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:17,065  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:17,065  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:17,087  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,948744617381047/part1=p1value2/part0=502].
2024-05-01T00:49:17,088  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:17,128  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:17,128  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:17,128  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:17,128  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:17,128  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:17,129  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:17,129  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:17,129  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:17,129  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:17,129  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:17,129  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:17,129  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:17,130  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:17,130  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:17,130  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f1fed91, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48a30cb6 will be shutdown
2024-05-01T00:49:17,130  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f1fed91, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6395c63a created in the thread with id: 529
2024-05-01T00:49:17,132  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:17,132  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:17,132  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:17,132  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f1fed91, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6395c63a will be shutdown
2024-05-01T00:49:17,132  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:17,132  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -47
2024-05-01T00:49:17,132  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:17,133  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:17,133  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44484338, with PersistenceManager: null will be shutdown
2024-05-01T00:49:17,134  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44484338, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67323405 created in the thread with id: 529
2024-05-01T00:49:17,135  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44484338 from thread id: 529
2024-05-01T00:49:17,136  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:17,136  WARN [Thread-485] mapred.LocalJobRunner: job_local707042407_0012
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,948744617381047/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:17,892  INFO [main] mapreduce.Job: Job job_local707042407_0012 running in uber mode : false
2024-05-01T00:49:17,892  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:17,892  INFO [main] mapreduce.Job: Job job_local707042407_0012 failed with state FAILED due to: NA
2024-05-01T00:49:17,893  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6135389
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=857210880
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:17,941  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:17,941  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:17,942  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:17,943  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:17,944  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:17,944  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f8ab988, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@46c475ba will be shutdown
2024-05-01T00:49:17,944  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f8ab988, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fc14dc0 created in the thread with id: 1
2024-05-01T00:49:17,946  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:17,947  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:17,947  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:17,947  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f8ab988, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fc14dc0 will be shutdown
2024-05-01T00:49:17,947  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:17,947  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -48
2024-05-01T00:49:17,947  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:17,948  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:17,948  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dd46693, with PersistenceManager: null will be shutdown
2024-05-01T00:49:17,949  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dd46693, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27107a97 created in the thread with id: 1
2024-05-01T00:49:17,951  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dd46693 from thread id: 1
2024-05-01T00:49:17,952  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:17,961  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:17,968  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:18,003  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:18,003  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:18,004  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:18,004  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:18,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dd46693, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27107a97 will be shutdown
2024-05-01T00:49:18,005  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dd46693, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3599b18 created in the thread with id: 1
2024-05-01T00:49:18,006  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:18,006  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:18,007  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:18,007  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dd46693, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3599b18 will be shutdown
2024-05-01T00:49:18,007  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:18,007  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -49
2024-05-01T00:49:18,007  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:18,008  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:18,008  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23e297d9, with PersistenceManager: null will be shutdown
2024-05-01T00:49:18,008  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23e297d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e8e02a3 created in the thread with id: 1
2024-05-01T00:49:18,010  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23e297d9 from thread id: 1
2024-05-01T00:49:18,011  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T00:49:18,024  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:18,029  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:18,029  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:18,049  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:18,065  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local804083360_0013
2024-05-01T00:49:18,066  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:18,115  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:18,116  INFO [main] mapreduce.Job: Running job: job_local804083360_0013
2024-05-01T00:49:18,116  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:18,117  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,117  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,118  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:18,119  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,119  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,132  INFO [Thread-531] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:18,132  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local804083360_0013_m_000000_0
2024-05-01T00:49:18,134  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,134  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,136  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,136  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,136  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:18,136  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:18,138  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,138  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,151  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:18,152  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T00:49:18,152  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T00:49:18,152  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local804083360_0013_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:18,152  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,152  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,155  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:18,156  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local804083360_0013_m_000000_0 is allowed to commit now
2024-05-01T00:49:18,156  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:18,156  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:18,166  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local804083360_0013_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,3112721119850499/part1=p1value2/part0=502
2024-05-01T00:49:18,167  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:18,167  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local804083360_0013_m_000000_0' done.
2024-05-01T00:49:18,167  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local804083360_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6646174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=857210880
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:18,168  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local804083360_0013_m_000000_0
2024-05-01T00:49:18,168  INFO [Thread-531] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:18,212  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:18,212  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:18,213  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:18,213  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:18,213  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:18,214  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee66a89, with PersistenceManager: null will be shutdown
2024-05-01T00:49:18,214  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee66a89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52187bba created in the thread with id: 577
2024-05-01T00:49:18,215  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee66a89 from thread id: 577
2024-05-01T00:49:18,216  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:18,216  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:18,216  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:18,216  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee66a89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52187bba will be shutdown
2024-05-01T00:49:18,216  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:18,216  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -50
2024-05-01T00:49:18,216  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:18,217  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:18,217  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216ee8cd, with PersistenceManager: null will be shutdown
2024-05-01T00:49:18,217  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216ee8cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a3290ec created in the thread with id: 577
2024-05-01T00:49:18,218  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216ee8cd from thread id: 577
2024-05-01T00:49:18,234  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:18,262  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:18,263  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:18,263  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:18,285  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,3112721119850499/part1=p1value2/part0=502].
2024-05-01T00:49:18,286  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:18,332  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:18,332  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:18,333  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:18,333  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:18,333  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216ee8cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a3290ec will be shutdown
2024-05-01T00:49:18,333  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216ee8cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bccdaef created in the thread with id: 577
2024-05-01T00:49:18,335  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:18,335  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:18,335  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:18,335  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216ee8cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bccdaef will be shutdown
2024-05-01T00:49:18,335  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:18,336  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -51
2024-05-01T00:49:18,336  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:18,336  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:18,337  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@110e1303, with PersistenceManager: null will be shutdown
2024-05-01T00:49:18,337  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@110e1303, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60c53a9f created in the thread with id: 577
2024-05-01T00:49:18,339  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@110e1303 from thread id: 577
2024-05-01T00:49:18,340  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:18,340  WARN [Thread-531] mapred.LocalJobRunner: job_local804083360_0013
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,3112721119850499/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:19,116  INFO [main] mapreduce.Job: Job job_local804083360_0013 running in uber mode : false
2024-05-01T00:49:19,116  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:19,116  INFO [main] mapreduce.Job: Job job_local804083360_0013 failed with state FAILED due to: NA
2024-05-01T00:49:19,118  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6646174
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=857210880
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:19,178  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:19,178  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:19,179  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:19,180  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:19,180  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:19,181  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23e297d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e8e02a3 will be shutdown
2024-05-01T00:49:19,181  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23e297d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f229c40 created in the thread with id: 1
2024-05-01T00:49:19,182  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:19,183  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:19,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:19,183  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23e297d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f229c40 will be shutdown
2024-05-01T00:49:19,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:19,183  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -52
2024-05-01T00:49:19,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:19,184  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,184  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b2fc2c0, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,184  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b2fc2c0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33197c2f created in the thread with id: 1
2024-05-01T00:49:19,186  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b2fc2c0 from thread id: 1
2024-05-01T00:49:19,186  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:19,192  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:19,197  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:19,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:19,230  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:19,230  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:19,230  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:19,230  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:19,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b2fc2c0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33197c2f will be shutdown
2024-05-01T00:49:19,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b2fc2c0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@18ad085a created in the thread with id: 1
2024-05-01T00:49:19,232  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:19,233  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:19,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:19,233  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b2fc2c0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@18ad085a will be shutdown
2024-05-01T00:49:19,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:19,233  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -53
2024-05-01T00:49:19,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:19,233  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,234  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351fadfa, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,234  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351fadfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e1953f7 created in the thread with id: 1
2024-05-01T00:49:19,236  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351fadfa from thread id: 1
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:19,281  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:19,281  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:19,282  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:19,283  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:19,284  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:19,284  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351fadfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e1953f7 will be shutdown
2024-05-01T00:49:19,284  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351fadfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5dd12c19 created in the thread with id: 1
2024-05-01T00:49:19,286  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:19,286  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:19,286  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:19,286  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351fadfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5dd12c19 will be shutdown
2024-05-01T00:49:19,286  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:19,286  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -54
2024-05-01T00:49:19,286  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:19,287  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,287  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@329aa2d1, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,287  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@329aa2d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@103033fe created in the thread with id: 1
2024-05-01T00:49:19,289  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@329aa2d1 from thread id: 1
2024-05-01T00:49:19,290  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:19,295  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:19,340  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:19,341  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:19,341  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:19,343  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:19,343  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:19,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@329aa2d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@103033fe will be shutdown
2024-05-01T00:49:19,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@329aa2d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@414d466e created in the thread with id: 1
2024-05-01T00:49:19,345  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:19,345  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:19,345  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:19,345  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@329aa2d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@414d466e will be shutdown
2024-05-01T00:49:19,345  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:19,345  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -55
2024-05-01T00:49:19,345  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:19,346  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,346  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eb38e5, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,346  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eb38e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73633230 created in the thread with id: 1
2024-05-01T00:49:19,347  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eb38e5 from thread id: 1
2024-05-01T00:49:19,348  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:19,354  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:19,359  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:19,392  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:19,392  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:19,393  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:19,393  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:19,393  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eb38e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73633230 will be shutdown
2024-05-01T00:49:19,393  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eb38e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d6dc2b8 created in the thread with id: 1
2024-05-01T00:49:19,395  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:19,395  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:19,395  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:19,395  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eb38e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d6dc2b8 will be shutdown
2024-05-01T00:49:19,395  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:19,395  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -56
2024-05-01T00:49:19,395  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:19,396  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,396  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f7949dc, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,396  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f7949dc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bd8c398 created in the thread with id: 1
2024-05-01T00:49:19,398  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f7949dc from thread id: 1
2024-05-01T00:49:19,404  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:19,409  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:19,410  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:19,430  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:19,446  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1050270917_0014
2024-05-01T00:49:19,446  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:19,494  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:19,494  INFO [main] mapreduce.Job: Running job: job_local1050270917_0014
2024-05-01T00:49:19,495  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:19,497  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:19,498  INFO [Thread-582] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:19,498  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1050270917_0014_m_000000_0
2024-05-01T00:49:19,501  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:19,501  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T00:49:19,505  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1050270917_0014_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.6366089576668678/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T00:49:19,505  INFO [Thread-582] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:19,507  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.6366089576668678].
2024-05-01T00:49:19,507  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:19,544  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:19,544  INFO [Thread-582] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:19,545  INFO [Thread-582] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:19,545  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,545  INFO [Thread-582] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:19,546  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9a7739e, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,546  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9a7739e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31062473 created in the thread with id: 630
2024-05-01T00:49:19,548  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9a7739e from thread id: 630
2024-05-01T00:49:19,548  INFO [Thread-582] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:19,548  INFO [Thread-582] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:19,548  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:19,548  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9a7739e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31062473 will be shutdown
2024-05-01T00:49:19,548  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:19,548  INFO [Thread-582] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -57
2024-05-01T00:49:19,548  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:19,549  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:19,549  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57ee3710, with PersistenceManager: null will be shutdown
2024-05-01T00:49:19,549  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57ee3710, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17eaf9c1 created in the thread with id: 630
2024-05-01T00:49:19,551  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57ee3710 from thread id: 630
2024-05-01T00:49:19,552  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:19,552  WARN [Thread-582] mapred.LocalJobRunner: job_local1050270917_0014
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T00:49:20,495  INFO [main] mapreduce.Job: Job job_local1050270917_0014 running in uber mode : false
2024-05-01T00:49:20,495  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:20,495  INFO [main] mapreduce.Job: Job job_local1050270917_0014 failed with state FAILED due to: NA
2024-05-01T00:49:20,495  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:20,534  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:20,535  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:20,535  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:20,537  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:20,537  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:20,537  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f7949dc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bd8c398 will be shutdown
2024-05-01T00:49:20,537  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f7949dc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d1eb214 created in the thread with id: 1
2024-05-01T00:49:20,540  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:20,540  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:20,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:20,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f7949dc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d1eb214 will be shutdown
2024-05-01T00:49:20,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:20,540  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -58
2024-05-01T00:49:20,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:20,541  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:20,542  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: null will be shutdown
2024-05-01T00:49:20,542  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57a0aeb8 created in the thread with id: 1
2024-05-01T00:49:20,544  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54 from thread id: 1
2024-05-01T00:49:20,545  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:20,552  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:20,553  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:20,557  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:20,564  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:20,569  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:20,590  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T00:49:20,607  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local592515928_0015
2024-05-01T00:49:20,607  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:20,663  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:20,663  INFO [main] mapreduce.Job: Running job: job_local592515928_0015
2024-05-01T00:49:20,663  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:20,664  INFO [Thread-602] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:20,664  INFO [Thread-602] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:20,664  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T00:49:20,672  INFO [Thread-602] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:20,672  INFO [Thread-602] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:21,663  INFO [main] mapreduce.Job: Job job_local592515928_0015 running in uber mode : false
2024-05-01T00:49:21,664  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:21,664  INFO [main] mapreduce.Job: Job job_local592515928_0015 completed successfully
2024-05-01T00:49:21,664  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:21,664  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:21,670  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:21,670  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T00:49:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:21,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:21,744  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:21,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:21,744  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:21,744  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[3]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.391">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:21,790  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:21,791  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:21,791  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:21,791  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:21,791  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:21,792  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:21,793  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:21,793  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57a0aeb8 will be shutdown
2024-05-01T00:49:21,793  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68303aad created in the thread with id: 1
2024-05-01T00:49:21,795  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 0cd7c978-d997-4f73-a986-cd917241d2aa
2024-05-01T00:49:21,795  INFO [main] SessionState: Hive Session ID = 0cd7c978-d997-4f73-a986-cd917241d2aa
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:21,796  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:21,802  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/0cd7c978-d997-4f73-a986-cd917241d2aa
2024-05-01T00:49:21,805  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/0cd7c978-d997-4f73-a986-cd917241d2aa
2024-05-01T00:49:21,807  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/0cd7c978-d997-4f73-a986-cd917241d2aa/_tmp_space.db
2024-05-01T00:49:21,808  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:21,809  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_ORCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_ORCFILE, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T00:49:21,811  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:21,874  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:21,874  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:21,875  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:21,876  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:21,876  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:21,877  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68303aad will be shutdown
2024-05-01T00:49:21,877  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60510791 created in the thread with id: 1
2024-05-01T00:49:21,879  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:21,879  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:21,879  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:21,879  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca5da54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60510791 will be shutdown
2024-05-01T00:49:21,879  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:21,879  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -59
2024-05-01T00:49:21,880  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:21,880  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:21,880  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eac39b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:21,881  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eac39b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ef0bc5b created in the thread with id: 1
2024-05-01T00:49:21,882  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eac39b from thread id: 1
2024-05-01T00:49:21,883  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:21,888  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:21,901  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:21,936  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:21,937  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:21,938  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:21,938  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:21,938  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eac39b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ef0bc5b will be shutdown
2024-05-01T00:49:21,938  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eac39b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4509414e created in the thread with id: 1
2024-05-01T00:49:21,940  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:21,940  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:21,940  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:21,940  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32eac39b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4509414e will be shutdown
2024-05-01T00:49:21,940  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:21,941  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -60
2024-05-01T00:49:21,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:21,942  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:21,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1067192a, with PersistenceManager: null will be shutdown
2024-05-01T00:49:21,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1067192a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f7f9d3f created in the thread with id: 1
2024-05-01T00:49:21,944  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1067192a from thread id: 1
2024-05-01T00:49:21,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value1,501]	
2024-05-01T00:49:21,961  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:21,966  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:21,967  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:21,987  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:22,006  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1406171563_0016
2024-05-01T00:49:22,006  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:22,092  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:22,092  INFO [main] mapreduce.Job: Running job: job_local1406171563_0016
2024-05-01T00:49:22,093  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:22,094  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,094  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,095  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:22,096  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,096  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,109  INFO [Thread-636] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:22,109  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1406171563_0016_m_000000_0
2024-05-01T00:49:22,115  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,115  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,117  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,117  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,117  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:22,117  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T00:49:22,124  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,124  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,158  INFO [LocalJobRunner Map Task Executor #0] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-05-01T00:49:22,163  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6536977210346968/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1406171563_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T00:49:22,220  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6536977210346968/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1406171563_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T00:49:22,226  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:22,268  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1406171563_0016_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:22,268  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,268  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,272  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:22,272  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1406171563_0016_m_000000_0 is allowed to commit now
2024-05-01T00:49:22,272  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:22,272  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:22,283  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1406171563_0016_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6536977210346968/part1=p1value1/part0=501
2024-05-01T00:49:22,284  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:22,284  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1406171563_0016_m_000000_0' done.
2024-05-01T00:49:22,284  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1406171563_0016_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8180182
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=860356608
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:22,284  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1406171563_0016_m_000000_0
2024-05-01T00:49:22,284  INFO [Thread-636] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:22,328  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:22,329  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:22,329  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:22,329  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:22,329  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:22,329  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:22,329  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:22,330  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:22,330  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:22,330  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3eb64be8, with PersistenceManager: null will be shutdown
2024-05-01T00:49:22,330  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3eb64be8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6eaf58af created in the thread with id: 686
2024-05-01T00:49:22,332  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3eb64be8 from thread id: 686
2024-05-01T00:49:22,332  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:22,332  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:22,332  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:22,332  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3eb64be8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6eaf58af will be shutdown
2024-05-01T00:49:22,332  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:22,332  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -61
2024-05-01T00:49:22,332  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:22,333  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:22,333  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63d44ede, with PersistenceManager: null will be shutdown
2024-05-01T00:49:22,333  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63d44ede, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27771687 created in the thread with id: 686
2024-05-01T00:49:22,335  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63d44ede from thread id: 686
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:22,378  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:22,378  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T00:49:22,400  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6536977210346968/part1=p1value1/part0=501].
2024-05-01T00:49:22,400  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:22,438  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:22,438  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:22,439  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:22,439  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:22,439  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63d44ede, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27771687 will be shutdown
2024-05-01T00:49:22,439  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63d44ede, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3cb69a9b created in the thread with id: 686
2024-05-01T00:49:22,441  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:22,441  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:22,441  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:22,441  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63d44ede, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3cb69a9b will be shutdown
2024-05-01T00:49:22,441  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:22,441  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -62
2024-05-01T00:49:22,441  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:22,442  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:22,442  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e16c5fd, with PersistenceManager: null will be shutdown
2024-05-01T00:49:22,442  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e16c5fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d4d6ce3 created in the thread with id: 686
2024-05-01T00:49:22,444  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e16c5fd from thread id: 686
2024-05-01T00:49:22,445  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:22,445  WARN [Thread-636] mapred.LocalJobRunner: job_local1406171563_0016
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6536977210346968/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:23,093  INFO [main] mapreduce.Job: Job job_local1406171563_0016 running in uber mode : false
2024-05-01T00:49:23,093  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:23,093  INFO [main] mapreduce.Job: Job job_local1406171563_0016 failed with state FAILED due to: NA
2024-05-01T00:49:23,094  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8180182
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=860356608
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:23,139  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:23,140  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:23,140  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:23,140  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:23,140  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:23,141  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:23,142  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:23,142  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:23,142  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1067192a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f7f9d3f will be shutdown
2024-05-01T00:49:23,142  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1067192a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25031fd4 created in the thread with id: 1
2024-05-01T00:49:23,144  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:23,144  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:23,144  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:23,144  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1067192a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25031fd4 will be shutdown
2024-05-01T00:49:23,145  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:23,145  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -63
2024-05-01T00:49:23,145  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:23,145  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:23,146  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20524816, with PersistenceManager: null will be shutdown
2024-05-01T00:49:23,146  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20524816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a7cbeed created in the thread with id: 1
2024-05-01T00:49:23,147  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20524816 from thread id: 1
2024-05-01T00:49:23,148  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:23,155  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:23,162  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:23,197  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:23,198  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:23,198  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:23,198  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:23,199  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20524816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a7cbeed will be shutdown
2024-05-01T00:49:23,199  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20524816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77feca04 created in the thread with id: 1
2024-05-01T00:49:23,200  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:23,200  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:23,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:23,201  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20524816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77feca04 will be shutdown
2024-05-01T00:49:23,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:23,201  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -64
2024-05-01T00:49:23,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:23,201  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:23,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4a985388, with PersistenceManager: null will be shutdown
2024-05-01T00:49:23,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4a985388, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15c8b75c created in the thread with id: 1
2024-05-01T00:49:23,203  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4a985388 from thread id: 1
2024-05-01T00:49:23,204  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T00:49:23,216  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:23,221  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:23,221  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:23,241  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:23,257  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local327417919_0017
2024-05-01T00:49:23,257  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:23,306  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:23,306  INFO [main] mapreduce.Job: Running job: job_local327417919_0017
2024-05-01T00:49:23,306  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:23,307  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,307  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,308  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:23,309  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,309  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,322  INFO [Thread-682] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:23,322  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local327417919_0017_m_000000_0
2024-05-01T00:49:23,324  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,324  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,325  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,325  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,325  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:23,326  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:23,327  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,327  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,329  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7096824022872387/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local327417919_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T00:49:23,340  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7096824022872387/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local327417919_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T00:49:23,340  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:23,344  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local327417919_0017_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:23,344  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,344  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,347  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:23,348  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local327417919_0017_m_000000_0 is allowed to commit now
2024-05-01T00:49:23,348  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:23,348  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:23,357  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local327417919_0017_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7096824022872387/part1=p1value2/part0=502
2024-05-01T00:49:23,358  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:23,358  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local327417919_0017_m_000000_0' done.
2024-05-01T00:49:23,358  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local327417919_0017_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8690535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=860356608
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:23,358  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local327417919_0017_m_000000_0
2024-05-01T00:49:23,358  INFO [Thread-682] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:23,404  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:23,404  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:23,405  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:23,406  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:23,406  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:23,406  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@757edea3, with PersistenceManager: null will be shutdown
2024-05-01T00:49:23,406  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@757edea3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32dfe673 created in the thread with id: 734
2024-05-01T00:49:23,407  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@757edea3 from thread id: 734
2024-05-01T00:49:23,408  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:23,408  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:23,408  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:23,408  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@757edea3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32dfe673 will be shutdown
2024-05-01T00:49:23,408  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:23,408  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -65
2024-05-01T00:49:23,408  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:23,409  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:23,409  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@da99f56, with PersistenceManager: null will be shutdown
2024-05-01T00:49:23,409  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@da99f56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1307b9eb created in the thread with id: 734
2024-05-01T00:49:23,411  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@da99f56 from thread id: 734
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:23,454  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:23,455  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:23,476  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7096824022872387/part1=p1value2/part0=502].
2024-05-01T00:49:23,476  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:23,514  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:23,514  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:23,515  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:23,515  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:23,515  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@da99f56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1307b9eb will be shutdown
2024-05-01T00:49:23,516  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@da99f56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ecf244f created in the thread with id: 734
2024-05-01T00:49:23,517  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:23,518  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:23,518  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:23,518  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@da99f56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ecf244f will be shutdown
2024-05-01T00:49:23,518  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:23,518  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -66
2024-05-01T00:49:23,518  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:23,519  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:23,519  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f7da3d, with PersistenceManager: null will be shutdown
2024-05-01T00:49:23,519  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f7da3d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7963eebe created in the thread with id: 734
2024-05-01T00:49:23,521  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f7da3d from thread id: 734
2024-05-01T00:49:23,522  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:23,522  WARN [Thread-682] mapred.LocalJobRunner: job_local327417919_0017
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7096824022872387/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:24,306  INFO [main] mapreduce.Job: Job job_local327417919_0017 running in uber mode : false
2024-05-01T00:49:24,306  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:24,306  INFO [main] mapreduce.Job: Job job_local327417919_0017 failed with state FAILED due to: NA
2024-05-01T00:49:24,308  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8690535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=860356608
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:24,352  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:24,353  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:24,353  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:24,353  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:24,355  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:24,355  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:24,355  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4a985388, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15c8b75c will be shutdown
2024-05-01T00:49:24,355  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4a985388, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14cc1f5c created in the thread with id: 1
2024-05-01T00:49:24,357  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:24,357  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:24,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:24,357  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4a985388, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14cc1f5c will be shutdown
2024-05-01T00:49:24,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:24,357  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -67
2024-05-01T00:49:24,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:24,358  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:24,358  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab780fd, with PersistenceManager: null will be shutdown
2024-05-01T00:49:24,358  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab780fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b8683b8 created in the thread with id: 1
2024-05-01T00:49:24,360  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab780fd from thread id: 1
2024-05-01T00:49:24,361  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:24,366  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:24,371  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:24,403  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:24,403  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:24,403  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:24,404  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:24,404  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:24,405  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:24,405  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:24,405  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab780fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b8683b8 will be shutdown
2024-05-01T00:49:24,405  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab780fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37806ccb created in the thread with id: 1
2024-05-01T00:49:24,407  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:24,407  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:24,407  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:24,407  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab780fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37806ccb will be shutdown
2024-05-01T00:49:24,407  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:24,407  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -68
2024-05-01T00:49:24,408  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:24,408  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:24,408  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a5b69c, with PersistenceManager: null will be shutdown
2024-05-01T00:49:24,408  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a5b69c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b22bcad created in the thread with id: 1
2024-05-01T00:49:24,410  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a5b69c from thread id: 1
2024-05-01T00:49:24,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T00:49:24,421  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:24,426  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:24,427  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:24,446  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:24,461  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1379410149_0018
2024-05-01T00:49:24,461  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:24,516  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:24,516  INFO [main] mapreduce.Job: Running job: job_local1379410149_0018
2024-05-01T00:49:24,517  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:24,518  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,518  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,519  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:24,519  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,519  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,532  INFO [Thread-728] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:24,532  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1379410149_0018_m_000000_0
2024-05-01T00:49:24,534  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,534  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,535  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,535  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,536  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:24,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:24,538  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,538  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,540  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7749677999244925/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1379410149_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T00:49:24,550  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7749677999244925/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1379410149_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T00:49:24,551  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:24,553  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1379410149_0018_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:24,553  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,553  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,557  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:24,557  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1379410149_0018_m_000000_0 is allowed to commit now
2024-05-01T00:49:24,557  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:24,557  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:24,567  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1379410149_0018_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7749677999244925/part1=p1value2/part0=502
2024-05-01T00:49:24,567  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:24,567  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1379410149_0018_m_000000_0' done.
2024-05-01T00:49:24,567  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1379410149_0018_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9203278
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=860356608
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:24,567  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1379410149_0018_m_000000_0
2024-05-01T00:49:24,567  INFO [Thread-728] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:24,611  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:24,611  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:24,612  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:24,613  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:24,613  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:24,613  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@504cd4aa, with PersistenceManager: null will be shutdown
2024-05-01T00:49:24,613  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@504cd4aa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f2f061d created in the thread with id: 782
2024-05-01T00:49:24,614  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@504cd4aa from thread id: 782
2024-05-01T00:49:24,614  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:24,615  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:24,615  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:24,615  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@504cd4aa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f2f061d will be shutdown
2024-05-01T00:49:24,615  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:24,615  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -69
2024-05-01T00:49:24,615  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:24,616  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:24,616  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@154fb767, with PersistenceManager: null will be shutdown
2024-05-01T00:49:24,616  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@154fb767, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71747aa5 created in the thread with id: 782
2024-05-01T00:49:24,618  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@154fb767 from thread id: 782
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:24,661  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:24,661  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:24,683  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7749677999244925/part1=p1value2/part0=502].
2024-05-01T00:49:24,684  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:24,721  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:24,721  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:24,722  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:24,722  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:24,723  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@154fb767, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71747aa5 will be shutdown
2024-05-01T00:49:24,723  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@154fb767, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f1bfc95 created in the thread with id: 782
2024-05-01T00:49:24,724  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:24,724  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:24,725  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:24,725  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@154fb767, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f1bfc95 will be shutdown
2024-05-01T00:49:24,725  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:24,725  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -70
2024-05-01T00:49:24,725  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:24,726  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:24,726  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368c9627, with PersistenceManager: null will be shutdown
2024-05-01T00:49:24,726  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368c9627, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@290626da created in the thread with id: 782
2024-05-01T00:49:24,728  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368c9627 from thread id: 782
2024-05-01T00:49:24,728  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:24,728  WARN [Thread-728] mapred.LocalJobRunner: job_local1379410149_0018
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7749677999244925/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:25,019  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T00:49:25,517  INFO [main] mapreduce.Job: Job job_local1379410149_0018 running in uber mode : false
2024-05-01T00:49:25,517  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:25,517  INFO [main] mapreduce.Job: Job job_local1379410149_0018 failed with state FAILED due to: NA
2024-05-01T00:49:25,518  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9203278
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=860356608
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:25,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:25,564  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:25,564  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:25,566  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:25,566  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:25,566  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a5b69c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b22bcad will be shutdown
2024-05-01T00:49:25,566  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a5b69c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40874f54 created in the thread with id: 1
2024-05-01T00:49:25,568  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:25,568  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:25,568  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:25,568  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a5b69c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40874f54 will be shutdown
2024-05-01T00:49:25,568  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:25,568  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -71
2024-05-01T00:49:25,568  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:25,569  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,569  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53a645a2, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,569  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53a645a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c8d20bb created in the thread with id: 1
2024-05-01T00:49:25,571  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53a645a2 from thread id: 1
2024-05-01T00:49:25,572  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:25,579  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:25,585  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:25,623  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:25,623  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:25,624  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:25,624  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:25,624  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53a645a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c8d20bb will be shutdown
2024-05-01T00:49:25,624  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53a645a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79fbcef4 created in the thread with id: 1
2024-05-01T00:49:25,626  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:25,626  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:25,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:25,626  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53a645a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79fbcef4 will be shutdown
2024-05-01T00:49:25,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:25,626  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -72
2024-05-01T00:49:25,627  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:25,627  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@374712f8, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@374712f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33aa4326 created in the thread with id: 1
2024-05-01T00:49:25,630  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@374712f8 from thread id: 1
2024-05-01T00:49:25,674  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:25,675  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:25,675  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:25,676  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:25,677  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:25,677  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:25,678  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@374712f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33aa4326 will be shutdown
2024-05-01T00:49:25,678  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@374712f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e200307 created in the thread with id: 1
2024-05-01T00:49:25,679  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:25,679  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:25,680  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:25,680  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@374712f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e200307 will be shutdown
2024-05-01T00:49:25,680  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:25,680  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -73
2024-05-01T00:49:25,680  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:25,680  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,681  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@163cd4a6, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,681  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@163cd4a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d0f03f6 created in the thread with id: 1
2024-05-01T00:49:25,683  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@163cd4a6 from thread id: 1
2024-05-01T00:49:25,684  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:25,688  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:25,733  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:25,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:25,734  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:25,734  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:25,734  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:25,734  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:25,736  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:25,736  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:25,736  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@163cd4a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d0f03f6 will be shutdown
2024-05-01T00:49:25,736  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@163cd4a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@541d8a9e created in the thread with id: 1
2024-05-01T00:49:25,738  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:25,738  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:25,738  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:25,738  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@163cd4a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@541d8a9e will be shutdown
2024-05-01T00:49:25,738  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:25,738  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -74
2024-05-01T00:49:25,738  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:25,739  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,739  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b3b5252, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,739  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b3b5252, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@adb15df created in the thread with id: 1
2024-05-01T00:49:25,741  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b3b5252 from thread id: 1
2024-05-01T00:49:25,742  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:25,747  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:25,753  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:25,786  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:25,786  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:25,787  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:25,787  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:25,787  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b3b5252, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@adb15df will be shutdown
2024-05-01T00:49:25,787  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b3b5252, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c1d25fa created in the thread with id: 1
2024-05-01T00:49:25,789  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:25,789  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:25,789  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:25,789  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b3b5252, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c1d25fa will be shutdown
2024-05-01T00:49:25,789  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:25,789  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -75
2024-05-01T00:49:25,789  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:25,790  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,790  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@42718ebf, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,790  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@42718ebf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a6fc2e1 created in the thread with id: 1
2024-05-01T00:49:25,792  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@42718ebf from thread id: 1
2024-05-01T00:49:25,798  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:25,803  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:25,803  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:25,823  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:25,838  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local130056536_0019
2024-05-01T00:49:25,838  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:25,921  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:25,921  INFO [main] mapreduce.Job: Running job: job_local130056536_0019
2024-05-01T00:49:25,921  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:25,924  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:25,925  INFO [Thread-779] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:25,925  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local130056536_0019_m_000000_0
2024-05-01T00:49:25,928  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:25,929  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T00:49:25,932  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local130056536_0019_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.5710729987854128/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T00:49:25,932  INFO [Thread-779] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:25,934  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.5710729987854128].
2024-05-01T00:49:25,934  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:25,972  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:25,973  INFO [Thread-779] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:25,973  INFO [Thread-779] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:25,974  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,974  INFO [Thread-779] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:25,974  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b8327, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,974  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b8327, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a84bf89 created in the thread with id: 835
2024-05-01T00:49:25,976  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b8327 from thread id: 835
2024-05-01T00:49:25,976  INFO [Thread-779] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:25,976  INFO [Thread-779] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:25,976  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:25,976  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b8327, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a84bf89 will be shutdown
2024-05-01T00:49:25,976  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:25,976  INFO [Thread-779] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -76
2024-05-01T00:49:25,976  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:25,977  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:25,977  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@186d1a16, with PersistenceManager: null will be shutdown
2024-05-01T00:49:25,978  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@186d1a16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@516d9a9d created in the thread with id: 835
2024-05-01T00:49:25,979  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@186d1a16 from thread id: 835
2024-05-01T00:49:25,980  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:25,980  WARN [Thread-779] mapred.LocalJobRunner: job_local130056536_0019
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T00:49:26,922  INFO [main] mapreduce.Job: Job job_local130056536_0019 running in uber mode : false
2024-05-01T00:49:26,922  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:26,922  INFO [main] mapreduce.Job: Job job_local130056536_0019 failed with state FAILED due to: NA
2024-05-01T00:49:26,922  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:26,961  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:26,961  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:26,962  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:26,963  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:26,963  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:26,964  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@42718ebf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a6fc2e1 will be shutdown
2024-05-01T00:49:26,964  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@42718ebf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d1b96b9 created in the thread with id: 1
2024-05-01T00:49:26,965  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:26,965  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:26,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:26,966  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@42718ebf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d1b96b9 will be shutdown
2024-05-01T00:49:26,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:26,966  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -77
2024-05-01T00:49:26,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:26,966  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:26,967  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: null will be shutdown
2024-05-01T00:49:26,967  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74f54f8e created in the thread with id: 1
2024-05-01T00:49:26,968  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf from thread id: 1
2024-05-01T00:49:26,969  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:26,974  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:26,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:26,978  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:26,984  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:26,989  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:27,010  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T00:49:27,025  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1301256424_0020
2024-05-01T00:49:27,025  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:27,074  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:27,074  INFO [main] mapreduce.Job: Running job: job_local1301256424_0020
2024-05-01T00:49:27,074  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:27,074  INFO [Thread-799] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:27,074  INFO [Thread-799] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:27,074  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T00:49:27,083  INFO [Thread-799] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:27,083  INFO [Thread-799] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:28,074  INFO [main] mapreduce.Job: Job job_local1301256424_0020 running in uber mode : false
2024-05-01T00:49:28,074  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:28,074  INFO [main] mapreduce.Job: Job job_local1301256424_0020 completed successfully
2024-05-01T00:49:28,075  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:28,075  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:28,079  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:28,080  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,135  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[4]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,179  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,182  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,182  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,182  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74f54f8e will be shutdown
2024-05-01T00:49:28,182  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76ecbfbf created in the thread with id: 1
2024-05-01T00:49:28,184  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = e62fde2d-805e-4088-a836-31250d92c453
2024-05-01T00:49:28,184  INFO [main] SessionState: Hive Session ID = e62fde2d-805e-4088-a836-31250d92c453
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:28,185  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:28,191  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/e62fde2d-805e-4088-a836-31250d92c453
2024-05-01T00:49:28,193  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/e62fde2d-805e-4088-a836-31250d92c453
2024-05-01T00:49:28,196  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/e62fde2d-805e-4088-a836-31250d92c453/_tmp_space.db
2024-05-01T00:49:28,197  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_PARQUETFILE	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[5]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T00:49:28,239  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,239  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,239  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,239  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,240  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,242  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,242  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,242  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76ecbfbf will be shutdown
2024-05-01T00:49:28,243  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f65b61d created in the thread with id: 1
2024-05-01T00:49:28,244  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = d25f87b5-a4f2-46b3-8346-f49b84c291d6
2024-05-01T00:49:28,244  INFO [main] SessionState: Hive Session ID = d25f87b5-a4f2-46b3-8346-f49b84c291d6
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:28,245  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:28,251  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/d25f87b5-a4f2-46b3-8346-f49b84c291d6
2024-05-01T00:49:28,253  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/d25f87b5-a4f2-46b3-8346-f49b84c291d6
2024-05-01T00:49:28,256  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/d25f87b5-a4f2-46b3-8346-f49b84c291d6/_tmp_space.db
2024-05-01T00:49:28,257  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_AVRO	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[6]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.314">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T00:49:28,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,298  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,298  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,299  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,300  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,300  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,301  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f65b61d will be shutdown
2024-05-01T00:49:28,301  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74832504 created in the thread with id: 1
2024-05-01T00:49:28,302  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 874704b7-3f7a-48b2-8caa-035897ed918d
2024-05-01T00:49:28,302  INFO [main] SessionState: Hive Session ID = 874704b7-3f7a-48b2-8caa-035897ed918d
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:28,303  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:28,309  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/874704b7-3f7a-48b2-8caa-035897ed918d
2024-05-01T00:49:28,311  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/874704b7-3f7a-48b2-8caa-035897ed918d
2024-05-01T00:49:28,314  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/874704b7-3f7a-48b2-8caa-035897ed918d/_tmp_space.db
2024-05-01T00:49:28,314  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:28,316  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_JSONFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_JSONFILE, serializationLib:org.apache.hadoop.hive.serde2.JsonSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T00:49:28,317  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,373  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,373  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:28,374  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:28,375  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,375  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,376  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74832504 will be shutdown
2024-05-01T00:49:28,376  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@537fb7bf created in the thread with id: 1
2024-05-01T00:49:28,377  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:28,377  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:28,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:28,378  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ea3ecf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@537fb7bf will be shutdown
2024-05-01T00:49:28,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:28,378  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -78
2024-05-01T00:49:28,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:28,378  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:28,379  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73864c16, with PersistenceManager: null will be shutdown
2024-05-01T00:49:28,379  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73864c16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5016934 created in the thread with id: 1
2024-05-01T00:49:28,380  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73864c16 from thread id: 1
2024-05-01T00:49:28,381  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:28,386  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:28,398  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,430  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,431  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:28,431  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,431  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,432  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73864c16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5016934 will be shutdown
2024-05-01T00:49:28,432  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73864c16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27879518 created in the thread with id: 1
2024-05-01T00:49:28,433  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:28,433  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:28,434  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:28,434  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73864c16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27879518 will be shutdown
2024-05-01T00:49:28,434  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:28,434  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -79
2024-05-01T00:49:28,434  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:28,434  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:28,435  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: null will be shutdown
2024-05-01T00:49:28,435  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d837af7 created in the thread with id: 1
2024-05-01T00:49:28,436  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558 from thread id: 1
2024-05-01T00:49:28,437  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value1,501]	
2024-05-01T00:49:28,449  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:28,454  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:28,455  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:28,476  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:28,491  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1978546954_0021
2024-05-01T00:49:28,491  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:28,540  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:28,540  INFO [main] mapreduce.Job: Running job: job_local1978546954_0021
2024-05-01T00:49:28,540  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:28,542  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,542  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,543  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:28,544  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,544  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,557  INFO [Thread-841] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:28,557  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1978546954_0021_m_000000_0
2024-05-01T00:49:28,561  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,561  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,562  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,562  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,562  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:28,563  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T00:49:28,568  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,568  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,588  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:28,591  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1978546954_0021_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:28,591  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,591  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,594  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:28,594  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1978546954_0021_m_000000_0 is allowed to commit now
2024-05-01T00:49:28,594  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:28,594  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:28,604  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1978546954_0021_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,06313206481512912/part1=p1value1/part0=501
2024-05-01T00:49:28,604  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:28,604  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1978546954_0021_m_000000_0' done.
2024-05-01T00:49:28,604  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1978546954_0021_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10736634
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=912261120
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:28,604  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1978546954_0021_m_000000_0
2024-05-01T00:49:28,604  INFO [Thread-841] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,648  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,648  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:28,649  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,649  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:28,649  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,649  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b1106f8, with PersistenceManager: null will be shutdown
2024-05-01T00:49:28,649  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b1106f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@303a807c created in the thread with id: 899
2024-05-01T00:49:28,651  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b1106f8 from thread id: 899
2024-05-01T00:49:28,651  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:28,651  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:28,651  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:28,651  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b1106f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@303a807c will be shutdown
2024-05-01T00:49:28,651  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:28,651  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -80
2024-05-01T00:49:28,651  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:28,652  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:28,652  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@244bc582, with PersistenceManager: null will be shutdown
2024-05-01T00:49:28,652  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@244bc582, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f3a34e1 created in the thread with id: 899
2024-05-01T00:49:28,653  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@244bc582 from thread id: 899
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,696  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,697  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T00:49:28,718  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,06313206481512912/part1=p1value1/part0=501].
2024-05-01T00:49:28,719  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:28,756  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:28,757  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:28,757  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:28,757  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:28,757  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@244bc582, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f3a34e1 will be shutdown
2024-05-01T00:49:28,758  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@244bc582, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52058157 created in the thread with id: 899
2024-05-01T00:49:28,759  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:28,759  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:28,759  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:28,759  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@244bc582, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52058157 will be shutdown
2024-05-01T00:49:28,759  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:28,759  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -81
2024-05-01T00:49:28,759  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:28,760  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:28,760  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52760aa4, with PersistenceManager: null will be shutdown
2024-05-01T00:49:28,760  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52760aa4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@81a5e8 created in the thread with id: 899
2024-05-01T00:49:28,762  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52760aa4 from thread id: 899
2024-05-01T00:49:28,762  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:28,762  WARN [Thread-841] mapred.LocalJobRunner: job_local1978546954_0021
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,06313206481512912/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:29,541  INFO [main] mapreduce.Job: Job job_local1978546954_0021 running in uber mode : false
2024-05-01T00:49:29,541  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:29,541  INFO [main] mapreduce.Job: Job job_local1978546954_0021 failed with state FAILED due to: NA
2024-05-01T00:49:29,542  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10736634
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=912261120
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:29,586  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:29,587  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:29,587  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:29,588  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:29,589  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:29,589  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:29,590  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d837af7 will be shutdown
2024-05-01T00:49:29,590  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b5f72fa created in the thread with id: 1
2024-05-01T00:49:29,592  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:29,592  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:29,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:29,592  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b5f72fa will be shutdown
2024-05-01T00:49:29,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:29,592  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -82
2024-05-01T00:49:29,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:29,593  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:29,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: null will be shutdown
2024-05-01T00:49:29,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2da7ef3e created in the thread with id: 1
2024-05-01T00:49:29,596  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34 from thread id: 1
2024-05-01T00:49:29,597  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:29,604  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:29,613  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:29,663  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:29,664  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:29,664  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:29,664  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2da7ef3e will be shutdown
2024-05-01T00:49:29,665  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52b4da7c created in the thread with id: 1
2024-05-01T00:49:29,667  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:29,667  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:29,667  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:29,667  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52b4da7c will be shutdown
2024-05-01T00:49:29,667  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:29,667  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -83
2024-05-01T00:49:29,667  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:29,668  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:29,669  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: null will be shutdown
2024-05-01T00:49:29,669  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48149568 created in the thread with id: 1
2024-05-01T00:49:29,670  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555 from thread id: 1
2024-05-01T00:49:29,671  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T00:49:29,683  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:29,688  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:29,688  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:29,709  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:29,728  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1103204934_0022
2024-05-01T00:49:29,728  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:29,782  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:29,782  INFO [main] mapreduce.Job: Running job: job_local1103204934_0022
2024-05-01T00:49:29,783  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:29,784  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,784  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,785  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:29,786  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,786  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,799  INFO [Thread-887] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:29,799  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1103204934_0022_m_000000_0
2024-05-01T00:49:29,800  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,800  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,802  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,802  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,802  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:29,803  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:29,804  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,804  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,818  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:29,819  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1103204934_0022_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:29,819  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,819  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,822  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:29,822  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1103204934_0022_m_000000_0 is allowed to commit now
2024-05-01T00:49:29,822  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:29,822  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:29,833  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1103204934_0022_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,6953942024808624/part1=p1value2/part0=502
2024-05-01T00:49:29,833  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:29,833  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1103204934_0022_m_000000_0' done.
2024-05-01T00:49:29,833  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1103204934_0022_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11249589
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=912261120
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:29,833  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1103204934_0022_m_000000_0
2024-05-01T00:49:29,834  INFO [Thread-887] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:29,878  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:29,878  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:29,878  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:29,878  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:29,879  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:29,879  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:29,880  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:29,880  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:29,880  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:29,880  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5946376a, with PersistenceManager: null will be shutdown
2024-05-01T00:49:29,881  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5946376a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@759ad3c5 created in the thread with id: 947
2024-05-01T00:49:29,882  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5946376a from thread id: 947
2024-05-01T00:49:29,882  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:29,882  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:29,882  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:29,882  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5946376a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@759ad3c5 will be shutdown
2024-05-01T00:49:29,882  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:29,883  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -84
2024-05-01T00:49:29,883  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:29,883  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:29,884  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2875ea98, with PersistenceManager: null will be shutdown
2024-05-01T00:49:29,884  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2875ea98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37ced038 created in the thread with id: 947
2024-05-01T00:49:29,885  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2875ea98 from thread id: 947
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:29,928  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:29,929  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:29,950  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,6953942024808624/part1=p1value2/part0=502].
2024-05-01T00:49:29,950  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:29,989  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:29,990  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:29,990  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:29,990  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:29,991  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2875ea98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37ced038 will be shutdown
2024-05-01T00:49:29,991  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2875ea98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d75f5d5 created in the thread with id: 947
2024-05-01T00:49:29,992  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:29,992  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:29,992  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:29,992  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2875ea98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d75f5d5 will be shutdown
2024-05-01T00:49:29,992  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:29,992  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -85
2024-05-01T00:49:29,993  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:29,993  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:29,993  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35e1380, with PersistenceManager: null will be shutdown
2024-05-01T00:49:29,993  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35e1380, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73a18e35 created in the thread with id: 947
2024-05-01T00:49:29,995  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35e1380 from thread id: 947
2024-05-01T00:49:29,995  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:29,995  WARN [Thread-887] mapred.LocalJobRunner: job_local1103204934_0022
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,6953942024808624/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:30,783  INFO [main] mapreduce.Job: Job job_local1103204934_0022 running in uber mode : false
2024-05-01T00:49:30,783  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:30,783  INFO [main] mapreduce.Job: Job job_local1103204934_0022 failed with state FAILED due to: NA
2024-05-01T00:49:30,784  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11249589
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=912261120
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:30,829  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:30,829  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:30,830  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:30,831  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:30,831  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:30,832  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48149568 will be shutdown
2024-05-01T00:49:30,832  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@411b75b4 created in the thread with id: 1
2024-05-01T00:49:30,833  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:30,833  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:30,833  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:30,833  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@411b75b4 will be shutdown
2024-05-01T00:49:30,834  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:30,834  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -86
2024-05-01T00:49:30,834  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:30,834  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:30,835  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: null will be shutdown
2024-05-01T00:49:30,835  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31b2c451 created in the thread with id: 1
2024-05-01T00:49:30,836  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d from thread id: 1
2024-05-01T00:49:30,837  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:30,843  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:30,851  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:30,883  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:30,884  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:30,884  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:30,884  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:30,885  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31b2c451 will be shutdown
2024-05-01T00:49:30,885  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d0f2154 created in the thread with id: 1
2024-05-01T00:49:30,886  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:30,887  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:30,887  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:30,887  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d0f2154 will be shutdown
2024-05-01T00:49:30,887  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:30,887  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -87
2024-05-01T00:49:30,887  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:30,888  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:30,888  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:30,889  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75af5f2a created in the thread with id: 1
2024-05-01T00:49:30,890  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b from thread id: 1
2024-05-01T00:49:30,891  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T00:49:30,903  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:30,908  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:30,908  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:30,928  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:30,945  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local986274705_0023
2024-05-01T00:49:30,945  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:30,994  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:30,994  INFO [main] mapreduce.Job: Running job: job_local986274705_0023
2024-05-01T00:49:30,994  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:30,996  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:30,996  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:30,997  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:30,998  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:30,998  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:31,012  INFO [Thread-933] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:31,012  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local986274705_0023_m_000000_0
2024-05-01T00:49:31,014  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:31,014  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:31,015  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:31,015  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:31,015  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:31,015  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:31,017  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:31,017  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:31,031  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:31,032  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local986274705_0023_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:31,032  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:31,032  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:31,061  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:31,061  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local986274705_0023_m_000000_0 is allowed to commit now
2024-05-01T00:49:31,061  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:31,061  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:31,071  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local986274705_0023_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,012633229227127285/part1=p1value2/part0=502
2024-05-01T00:49:31,071  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:31,071  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local986274705_0023_m_000000_0' done.
2024-05-01T00:49:31,072  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local986274705_0023_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11760164
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=914882560
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:31,072  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local986274705_0023_m_000000_0
2024-05-01T00:49:31,072  INFO [Thread-933] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:31,122  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:31,122  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:31,123  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:31,124  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:31,124  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:31,124  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6095465e, with PersistenceManager: null will be shutdown
2024-05-01T00:49:31,124  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6095465e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ec5d209 created in the thread with id: 995
2024-05-01T00:49:31,126  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6095465e from thread id: 995
2024-05-01T00:49:31,126  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:31,126  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:31,126  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:31,126  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6095465e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ec5d209 will be shutdown
2024-05-01T00:49:31,126  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:31,126  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -88
2024-05-01T00:49:31,126  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:31,127  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:31,127  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41790e5, with PersistenceManager: null will be shutdown
2024-05-01T00:49:31,127  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41790e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f930fee created in the thread with id: 995
2024-05-01T00:49:31,129  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41790e5 from thread id: 995
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:31,168  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:31,169  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:31,169  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:31,191  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,012633229227127285/part1=p1value2/part0=502].
2024-05-01T00:49:31,191  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:31,228  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:31,228  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:31,229  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:31,229  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:31,229  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41790e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f930fee will be shutdown
2024-05-01T00:49:31,229  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41790e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fa4f4ef created in the thread with id: 995
2024-05-01T00:49:31,231  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:31,231  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:31,231  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:31,231  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41790e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fa4f4ef will be shutdown
2024-05-01T00:49:31,231  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:31,231  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -89
2024-05-01T00:49:31,231  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:31,232  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:31,232  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2be25b6f, with PersistenceManager: null will be shutdown
2024-05-01T00:49:31,232  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2be25b6f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@214e85c4 created in the thread with id: 995
2024-05-01T00:49:31,233  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2be25b6f from thread id: 995
2024-05-01T00:49:31,234  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:31,234  WARN [Thread-933] mapred.LocalJobRunner: job_local986274705_0023
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,012633229227127285/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:31,500  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T00:49:31,994  INFO [main] mapreduce.Job: Job job_local986274705_0023 running in uber mode : false
2024-05-01T00:49:31,995  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:31,995  INFO [main] mapreduce.Job: Job job_local986274705_0023 failed with state FAILED due to: NA
2024-05-01T00:49:31,996  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11760164
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=914882560
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:32,040  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:32,040  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:32,041  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:32,041  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:32,042  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:32,043  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:32,043  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:32,043  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75af5f2a will be shutdown
2024-05-01T00:49:32,043  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33ea437a created in the thread with id: 1
2024-05-01T00:49:32,045  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:32,045  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:32,045  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:32,045  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33ea437a will be shutdown
2024-05-01T00:49:32,045  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:32,045  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -90
2024-05-01T00:49:32,045  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:32,046  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,046  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eef8498, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,046  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eef8498, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b158e16 created in the thread with id: 1
2024-05-01T00:49:32,048  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eef8498 from thread id: 1
2024-05-01T00:49:32,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:32,053  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:32,060  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:32,093  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:32,093  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:32,094  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:32,094  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:32,094  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eef8498, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b158e16 will be shutdown
2024-05-01T00:49:32,094  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eef8498, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55fbebba created in the thread with id: 1
2024-05-01T00:49:32,096  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:32,096  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:32,096  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:32,096  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eef8498, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55fbebba will be shutdown
2024-05-01T00:49:32,096  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:32,096  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -91
2024-05-01T00:49:32,096  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:32,097  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,097  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@165634aa, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,097  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@165634aa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c2503d2 created in the thread with id: 1
2024-05-01T00:49:32,098  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@165634aa from thread id: 1
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:32,144  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:32,145  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:32,145  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:32,147  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:32,147  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:32,147  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@165634aa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c2503d2 will be shutdown
2024-05-01T00:49:32,147  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@165634aa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4268c16 created in the thread with id: 1
2024-05-01T00:49:32,148  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:32,149  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:32,149  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:32,149  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@165634aa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4268c16 will be shutdown
2024-05-01T00:49:32,149  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:32,149  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -92
2024-05-01T00:49:32,149  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:32,150  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,150  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fa35f7e, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,150  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fa35f7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7df0bb1 created in the thread with id: 1
2024-05-01T00:49:32,151  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fa35f7e from thread id: 1
2024-05-01T00:49:32,152  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:32,157  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:32,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:32,202  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:32,202  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:32,203  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:32,204  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:32,204  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:32,204  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fa35f7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7df0bb1 will be shutdown
2024-05-01T00:49:32,205  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fa35f7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16fa28eb created in the thread with id: 1
2024-05-01T00:49:32,206  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:32,206  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:32,206  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:32,206  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fa35f7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16fa28eb will be shutdown
2024-05-01T00:49:32,207  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:32,207  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -93
2024-05-01T00:49:32,207  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:32,207  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,208  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ea3b20d, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,208  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ea3b20d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17856f0 created in the thread with id: 1
2024-05-01T00:49:32,209  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ea3b20d from thread id: 1
2024-05-01T00:49:32,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:32,215  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:32,221  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:32,252  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:32,253  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:32,253  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:32,254  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:32,254  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ea3b20d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17856f0 will be shutdown
2024-05-01T00:49:32,254  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ea3b20d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61cf142f created in the thread with id: 1
2024-05-01T00:49:32,255  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:32,256  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:32,256  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:32,256  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ea3b20d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61cf142f will be shutdown
2024-05-01T00:49:32,256  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:32,256  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -94
2024-05-01T00:49:32,256  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:32,257  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,257  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@445265b0, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,257  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@445265b0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7eba962d created in the thread with id: 1
2024-05-01T00:49:32,258  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@445265b0 from thread id: 1
2024-05-01T00:49:32,265  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:32,270  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:32,270  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:32,290  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:32,305  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local579951911_0024
2024-05-01T00:49:32,305  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:32,353  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:32,354  INFO [main] mapreduce.Job: Running job: job_local579951911_0024
2024-05-01T00:49:32,354  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:32,356  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:32,357  INFO [Thread-984] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:32,357  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local579951911_0024_m_000000_0
2024-05-01T00:49:32,359  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:32,359  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T00:49:32,363  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local579951911_0024_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.7423826362745386/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T00:49:32,363  INFO [Thread-984] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:32,364  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.7423826362745386].
2024-05-01T00:49:32,365  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:32,404  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:32,404  INFO [Thread-984] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:32,405  INFO [Thread-984] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:32,405  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,405  INFO [Thread-984] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:32,406  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad407e5, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,406  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad407e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78e7806c created in the thread with id: 1048
2024-05-01T00:49:32,407  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad407e5 from thread id: 1048
2024-05-01T00:49:32,407  INFO [Thread-984] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:32,407  INFO [Thread-984] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:32,407  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:32,407  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad407e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78e7806c will be shutdown
2024-05-01T00:49:32,407  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:32,407  INFO [Thread-984] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -95
2024-05-01T00:49:32,407  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:32,408  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:32,408  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@51b4bf4, with PersistenceManager: null will be shutdown
2024-05-01T00:49:32,408  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@51b4bf4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10ca8903 created in the thread with id: 1048
2024-05-01T00:49:32,409  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@51b4bf4 from thread id: 1048
2024-05-01T00:49:32,410  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:32,410  WARN [Thread-984] mapred.LocalJobRunner: job_local579951911_0024
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T00:49:33,354  INFO [main] mapreduce.Job: Job job_local579951911_0024 running in uber mode : false
2024-05-01T00:49:33,354  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:33,354  INFO [main] mapreduce.Job: Job job_local579951911_0024 failed with state FAILED due to: NA
2024-05-01T00:49:33,354  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:33,394  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:33,394  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:33,395  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:33,396  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:33,396  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:33,397  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@445265b0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7eba962d will be shutdown
2024-05-01T00:49:33,397  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@445265b0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ef6a063 created in the thread with id: 1
2024-05-01T00:49:33,398  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:33,398  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:33,398  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:33,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@445265b0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ef6a063 will be shutdown
2024-05-01T00:49:33,399  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:33,399  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -96
2024-05-01T00:49:33,399  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:33,399  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:33,400  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: null will be shutdown
2024-05-01T00:49:33,400  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c821dc7 created in the thread with id: 1
2024-05-01T00:49:33,401  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5 from thread id: 1
2024-05-01T00:49:33,402  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:33,407  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:33,407  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:33,410  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:33,416  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:33,421  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:33,441  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T00:49:33,457  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local292841436_0025
2024-05-01T00:49:33,457  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:33,506  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:33,506  INFO [main] mapreduce.Job: Running job: job_local292841436_0025
2024-05-01T00:49:33,507  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:33,507  INFO [Thread-1004] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:33,507  INFO [Thread-1004] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:33,507  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T00:49:33,516  INFO [Thread-1004] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:33,516  INFO [Thread-1004] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:34,507  INFO [main] mapreduce.Job: Job job_local292841436_0025 running in uber mode : false
2024-05-01T00:49:34,507  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:34,507  INFO [main] mapreduce.Job: Job job_local292841436_0025 completed successfully
2024-05-01T00:49:34,507  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:34,507  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:34,514  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:34,514  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:34,568  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[7]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.351">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:34,614  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:34,614  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:34,615  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c821dc7 will be shutdown
2024-05-01T00:49:34,615  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2de22e7 created in the thread with id: 1
2024-05-01T00:49:34,616  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 2e605170-5d28-40a0-bc4b-ab736ace5510
2024-05-01T00:49:34,617  INFO [main] SessionState: Hive Session ID = 2e605170-5d28-40a0-bc4b-ab736ace5510
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:34,617  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T00:49:34,623  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/2e605170-5d28-40a0-bc4b-ab736ace5510
2024-05-01T00:49:34,626  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/2e605170-5d28-40a0-bc4b-ab736ace5510
2024-05-01T00:49:34,628  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/2e605170-5d28-40a0-bc4b-ab736ace5510/_tmp_space.db
2024-05-01T00:49:34,629  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:34,630  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_rcfile_columnar, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_rcfile_columnar, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T00:49:34,631  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar
2024-05-01T00:49:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:34,688  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:34,689  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:34,690  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:34,690  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:34,690  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2de22e7 will be shutdown
2024-05-01T00:49:34,690  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5930a229 created in the thread with id: 1
2024-05-01T00:49:34,692  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:34,692  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:34,692  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:34,692  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5930a229 will be shutdown
2024-05-01T00:49:34,692  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:34,692  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -97
2024-05-01T00:49:34,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:34,693  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:34,693  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: null will be shutdown
2024-05-01T00:49:34,693  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d9db780 created in the thread with id: 1
2024-05-01T00:49:34,695  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9 from thread id: 1
2024-05-01T00:49:34,696  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:34,701  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:34,709  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:34,745  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:34,745  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:34,746  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:34,746  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:34,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d9db780 will be shutdown
2024-05-01T00:49:34,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6aa16117 created in the thread with id: 1
2024-05-01T00:49:34,748  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:34,748  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:34,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:34,748  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6aa16117 will be shutdown
2024-05-01T00:49:34,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:34,748  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -98
2024-05-01T00:49:34,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:34,749  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:34,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: null will be shutdown
2024-05-01T00:49:34,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56b4951a created in the thread with id: 1
2024-05-01T00:49:34,750  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e from thread id: 1
2024-05-01T00:49:34,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value1,501]	
2024-05-01T00:49:34,763  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:34,768  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:34,769  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:34,788  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:34,804  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local846213839_0026
2024-05-01T00:49:34,804  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:34,862  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:34,862  INFO [main] mapreduce.Job: Running job: job_local846213839_0026
2024-05-01T00:49:34,862  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:34,864  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,864  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,865  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:34,866  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,866  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,879  INFO [Thread-1038] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:34,879  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local846213839_0026_m_000000_0
2024-05-01T00:49:34,883  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,883  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,884  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,884  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,885  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:34,885  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T00:49:34,891  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,891  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,906  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:34,906  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T00:49:34,906  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T00:49:34,909  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local846213839_0026_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:34,909  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,909  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,913  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:34,913  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local846213839_0026_m_000000_0 is allowed to commit now
2024-05-01T00:49:34,913  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:34,913  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:34,923  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local846213839_0026_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,13045789663301277/part1=p1value1/part0=501
2024-05-01T00:49:34,923  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:34,924  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local846213839_0026_m_000000_0' done.
2024-05-01T00:49:34,924  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local846213839_0026_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13289329
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=914882560
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:34,924  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local846213839_0026_m_000000_0
2024-05-01T00:49:34,924  INFO [Thread-1038] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:34,968  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:34,968  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:34,969  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:34,970  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:34,970  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:34,970  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67473eb4, with PersistenceManager: null will be shutdown
2024-05-01T00:49:34,970  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67473eb4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5db7e545 created in the thread with id: 1104
2024-05-01T00:49:34,972  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67473eb4 from thread id: 1104
2024-05-01T00:49:34,972  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:34,972  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:34,972  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:34,972  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67473eb4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5db7e545 will be shutdown
2024-05-01T00:49:34,972  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:34,973  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -99
2024-05-01T00:49:34,973  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:34,974  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:34,974  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d073b95, with PersistenceManager: null will be shutdown
2024-05-01T00:49:34,974  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d073b95, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36b0b549 created in the thread with id: 1104
2024-05-01T00:49:34,976  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d073b95 from thread id: 1104
2024-05-01T00:49:35,017  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:35,017  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:35,018  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:35,018  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=501, part1=p1value1}].
2024-05-01T00:49:35,040  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,13045789663301277/part1=p1value1/part0=501].
2024-05-01T00:49:35,040  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:35,078  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:35,078  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:35,079  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:35,079  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:35,079  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d073b95, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36b0b549 will be shutdown
2024-05-01T00:49:35,080  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d073b95, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b6d5fb7 created in the thread with id: 1104
2024-05-01T00:49:35,081  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:35,081  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:35,081  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:35,081  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d073b95, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b6d5fb7 will be shutdown
2024-05-01T00:49:35,082  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:35,082  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -100
2024-05-01T00:49:35,082  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:35,082  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:35,083  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796b687b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:35,083  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796b687b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70365936 created in the thread with id: 1104
2024-05-01T00:49:35,084  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796b687b from thread id: 1104
2024-05-01T00:49:35,085  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:35,085  WARN [Thread-1038] mapred.LocalJobRunner: job_local846213839_0026
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,13045789663301277/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:35,862  INFO [main] mapreduce.Job: Job job_local846213839_0026 running in uber mode : false
2024-05-01T00:49:35,862  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:35,863  INFO [main] mapreduce.Job: Job job_local846213839_0026 failed with state FAILED due to: NA
2024-05-01T00:49:35,863  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13289329
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=914882560
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:35,908  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:35,909  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:35,909  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:35,911  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:35,911  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:35,911  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56b4951a will be shutdown
2024-05-01T00:49:35,911  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b4133d0 created in the thread with id: 1
2024-05-01T00:49:35,913  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:35,913  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:35,913  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:35,913  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b4133d0 will be shutdown
2024-05-01T00:49:35,913  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:35,913  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -101
2024-05-01T00:49:35,913  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:35,914  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:35,914  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: null will be shutdown
2024-05-01T00:49:35,914  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c8ab21f created in the thread with id: 1
2024-05-01T00:49:35,916  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f from thread id: 1
2024-05-01T00:49:35,916  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:35,921  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:35,926  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:35,958  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:35,958  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:35,959  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:35,959  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:35,959  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c8ab21f will be shutdown
2024-05-01T00:49:35,959  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6142b9dd created in the thread with id: 1
2024-05-01T00:49:35,961  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:35,961  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:35,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:35,961  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6142b9dd will be shutdown
2024-05-01T00:49:35,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:35,961  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -102
2024-05-01T00:49:35,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:35,962  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:35,962  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: null will be shutdown
2024-05-01T00:49:35,962  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27d6ff8c created in the thread with id: 1
2024-05-01T00:49:35,964  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6 from thread id: 1
2024-05-01T00:49:35,965  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T00:49:35,975  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:35,980  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:35,980  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:36,000  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:36,015  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2912264_0027
2024-05-01T00:49:36,015  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:36,063  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:36,063  INFO [main] mapreduce.Job: Running job: job_local2912264_0027
2024-05-01T00:49:36,063  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:36,064  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,064  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,065  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:36,066  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,066  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,079  INFO [Thread-1084] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:36,079  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2912264_0027_m_000000_0
2024-05-01T00:49:36,081  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,081  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,082  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,082  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,082  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:36,082  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:36,084  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,084  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,098  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:36,098  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T00:49:36,098  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T00:49:36,098  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2912264_0027_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:36,098  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,098  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,102  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:36,102  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2912264_0027_m_000000_0 is allowed to commit now
2024-05-01T00:49:36,102  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:36,102  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:36,113  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2912264_0027_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7557071233521973/part1=p1value2/part0=502
2024-05-01T00:49:36,113  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:36,113  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2912264_0027_m_000000_0' done.
2024-05-01T00:49:36,113  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2912264_0027_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13795457
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=914882560
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:36,113  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2912264_0027_m_000000_0
2024-05-01T00:49:36,114  INFO [Thread-1084] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:36,157  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:36,157  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:36,157  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:36,157  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:36,157  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:36,157  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:36,158  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:36,158  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:36,158  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:36,158  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:36,158  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:36,158  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:36,159  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:36,159  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:36,159  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:36,159  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1537a7cd, with PersistenceManager: null will be shutdown
2024-05-01T00:49:36,159  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1537a7cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4846a97 created in the thread with id: 1152
2024-05-01T00:49:36,161  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1537a7cd from thread id: 1152
2024-05-01T00:49:36,161  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:36,161  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:36,161  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:36,161  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1537a7cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4846a97 will be shutdown
2024-05-01T00:49:36,161  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:36,161  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -103
2024-05-01T00:49:36,161  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:36,162  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:36,162  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1887fb, with PersistenceManager: null will be shutdown
2024-05-01T00:49:36,163  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1887fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5731bf6d created in the thread with id: 1152
2024-05-01T00:49:36,164  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1887fb from thread id: 1152
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:36,206  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:36,207  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:36,207  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:36,207  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:36,207  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:36,229  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7557071233521973/part1=p1value2/part0=502].
2024-05-01T00:49:36,229  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:36,267  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:36,268  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:36,269  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:36,269  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:36,269  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1887fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5731bf6d will be shutdown
2024-05-01T00:49:36,269  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1887fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b132b95 created in the thread with id: 1152
2024-05-01T00:49:36,270  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:36,271  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:36,271  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:36,271  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1887fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b132b95 will be shutdown
2024-05-01T00:49:36,271  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:36,271  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -104
2024-05-01T00:49:36,271  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:36,272  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:36,272  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cfccacb, with PersistenceManager: null will be shutdown
2024-05-01T00:49:36,272  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cfccacb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34a7ccb9 created in the thread with id: 1152
2024-05-01T00:49:36,273  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cfccacb from thread id: 1152
2024-05-01T00:49:36,274  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:36,274  WARN [Thread-1084] mapred.LocalJobRunner: job_local2912264_0027
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7557071233521973/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:37,063  INFO [main] mapreduce.Job: Job job_local2912264_0027 running in uber mode : false
2024-05-01T00:49:37,063  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:37,064  INFO [main] mapreduce.Job: Job job_local2912264_0027 failed with state FAILED due to: NA
2024-05-01T00:49:37,064  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13795457
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=914882560
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:37,109  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:37,109  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:37,110  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:37,111  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:37,111  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:37,111  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27d6ff8c will be shutdown
2024-05-01T00:49:37,112  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@441e789e created in the thread with id: 1
2024-05-01T00:49:37,114  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:37,114  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:37,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:37,114  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@441e789e will be shutdown
2024-05-01T00:49:37,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:37,114  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -105
2024-05-01T00:49:37,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:37,115  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:37,115  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:37,115  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8174ce created in the thread with id: 1
2024-05-01T00:49:37,116  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b from thread id: 1
2024-05-01T00:49:37,117  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:37,121  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:37,128  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:37,171  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:37,171  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:37,171  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:37,171  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:37,171  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:37,171  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:37,172  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:37,172  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:37,172  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:37,172  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:37,172  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:37,172  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:37,173  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:37,173  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:37,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8174ce will be shutdown
2024-05-01T00:49:37,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ba056ab created in the thread with id: 1
2024-05-01T00:49:37,175  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:37,176  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:37,176  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:37,176  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ba056ab will be shutdown
2024-05-01T00:49:37,176  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:37,176  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -106
2024-05-01T00:49:37,176  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:37,177  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:37,177  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: null will be shutdown
2024-05-01T00:49:37,177  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61ce2d47 created in the thread with id: 1
2024-05-01T00:49:37,179  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698 from thread id: 1
2024-05-01T00:49:37,180  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T00:49:37,194  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:37,199  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:37,199  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:37,220  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:37,239  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1939945592_0028
2024-05-01T00:49:37,239  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:37,350  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:37,350  INFO [main] mapreduce.Job: Running job: job_local1939945592_0028
2024-05-01T00:49:37,350  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:37,351  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,351  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,352  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:37,353  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,353  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,366  INFO [Thread-1130] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:37,366  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1939945592_0028_m_000000_0
2024-05-01T00:49:37,368  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,368  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,369  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,369  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,369  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:37,370  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T00:49:37,371  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,371  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,384  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:37,384  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T00:49:37,384  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T00:49:37,384  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1939945592_0028_m_000000_0 is done. And is in the process of committing
2024-05-01T00:49:37,384  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,384  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,388  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T00:49:37,388  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1939945592_0028_m_000000_0 is allowed to commit now
2024-05-01T00:49:37,388  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:37,388  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:37,398  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1939945592_0028_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9462305615030214/part1=p1value2/part0=502
2024-05-01T00:49:37,398  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T00:49:37,398  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1939945592_0028_m_000000_0' done.
2024-05-01T00:49:37,398  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1939945592_0028_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14308757
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=923271168
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:37,398  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1939945592_0028_m_000000_0
2024-05-01T00:49:37,398  INFO [Thread-1130] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:37,455  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:37,455  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:37,456  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:37,457  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:37,457  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:37,457  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1029cafb, with PersistenceManager: null will be shutdown
2024-05-01T00:49:37,457  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1029cafb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fd5380a created in the thread with id: 1200
2024-05-01T00:49:37,458  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1029cafb from thread id: 1200
2024-05-01T00:49:37,458  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:37,459  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:37,459  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:37,459  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1029cafb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fd5380a will be shutdown
2024-05-01T00:49:37,459  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:37,459  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -107
2024-05-01T00:49:37,459  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:37,460  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:37,460  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62e33541, with PersistenceManager: null will be shutdown
2024-05-01T00:49:37,460  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62e33541, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64c508e8 created in the thread with id: 1200
2024-05-01T00:49:37,461  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62e33541 from thread id: 1200
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:37,506  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:37,506  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T00:49:37,529  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9462305615030214/part1=p1value2/part0=502].
2024-05-01T00:49:37,529  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:37,567  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:37,567  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:37,568  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:37,568  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:37,568  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62e33541, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64c508e8 will be shutdown
2024-05-01T00:49:37,568  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62e33541, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55535eba created in the thread with id: 1200
2024-05-01T00:49:37,570  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:37,570  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:37,570  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:37,570  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62e33541, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55535eba will be shutdown
2024-05-01T00:49:37,570  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:37,570  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -108
2024-05-01T00:49:37,570  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:37,571  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:37,571  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a894464, with PersistenceManager: null will be shutdown
2024-05-01T00:49:37,571  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a894464, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49922aa2 created in the thread with id: 1200
2024-05-01T00:49:37,572  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a894464 from thread id: 1200
2024-05-01T00:49:37,573  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:37,573  WARN [Thread-1130] mapred.LocalJobRunner: job_local1939945592_0028
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9462305615030214/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T00:49:37,927  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T00:49:38,350  INFO [main] mapreduce.Job: Job job_local1939945592_0028 running in uber mode : false
2024-05-01T00:49:38,350  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T00:49:38,350  INFO [main] mapreduce.Job: Job job_local1939945592_0028 failed with state FAILED due to: NA
2024-05-01T00:49:38,351  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14308757
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=923271168
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:38,396  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:38,396  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:38,398  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:38,398  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:38,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61ce2d47 will be shutdown
2024-05-01T00:49:38,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7dd4f726 created in the thread with id: 1
2024-05-01T00:49:38,399  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:38,400  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:38,400  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:38,400  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7dd4f726 will be shutdown
2024-05-01T00:49:38,400  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:38,400  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -109
2024-05-01T00:49:38,400  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:38,401  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,401  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655d64, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,401  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655d64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22ff53d1 created in the thread with id: 1
2024-05-01T00:49:38,402  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655d64 from thread id: 1
2024-05-01T00:49:38,403  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:38,407  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:38,412  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:38,443  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:38,444  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:38,444  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:38,444  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:38,445  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655d64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22ff53d1 will be shutdown
2024-05-01T00:49:38,445  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655d64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59f2a9e9 created in the thread with id: 1
2024-05-01T00:49:38,446  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:38,446  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:38,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:38,447  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655d64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59f2a9e9 will be shutdown
2024-05-01T00:49:38,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:38,447  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -110
2024-05-01T00:49:38,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:38,447  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,448  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54353bb1, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,448  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54353bb1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a837f7 created in the thread with id: 1
2024-05-01T00:49:38,449  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54353bb1 from thread id: 1
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:38,494  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:38,494  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:38,495  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:38,496  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:38,496  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:38,497  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54353bb1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a837f7 will be shutdown
2024-05-01T00:49:38,497  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54353bb1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f9f3516 created in the thread with id: 1
2024-05-01T00:49:38,498  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:38,498  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:38,498  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:38,498  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54353bb1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f9f3516 will be shutdown
2024-05-01T00:49:38,498  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:38,498  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -111
2024-05-01T00:49:38,499  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:38,499  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,499  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@228f15de, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,499  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@228f15de, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f8a82e9 created in the thread with id: 1
2024-05-01T00:49:38,501  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@228f15de from thread id: 1
2024-05-01T00:49:38,501  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:38,506  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:38,549  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:38,549  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:38,550  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:38,550  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:38,551  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:38,552  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:38,552  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:38,552  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@228f15de, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f8a82e9 will be shutdown
2024-05-01T00:49:38,552  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@228f15de, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11f415e4 created in the thread with id: 1
2024-05-01T00:49:38,554  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:38,554  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:38,554  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:38,554  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@228f15de, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11f415e4 will be shutdown
2024-05-01T00:49:38,554  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:38,554  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -112
2024-05-01T00:49:38,554  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:38,555  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,555  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ea4abef, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,555  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ea4abef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a4ddaed created in the thread with id: 1
2024-05-01T00:49:38,556  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ea4abef from thread id: 1
2024-05-01T00:49:38,557  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:38,562  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:38,568  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:38,600  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:38,600  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:38,601  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:38,601  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:38,601  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ea4abef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a4ddaed will be shutdown
2024-05-01T00:49:38,602  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ea4abef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e43fc06 created in the thread with id: 1
2024-05-01T00:49:38,603  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:38,603  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:38,603  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:38,603  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ea4abef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e43fc06 will be shutdown
2024-05-01T00:49:38,603  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:38,604  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -113
2024-05-01T00:49:38,604  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:38,604  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,604  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bcf8bd7, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,605  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bcf8bd7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c92d694 created in the thread with id: 1
2024-05-01T00:49:38,606  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bcf8bd7 from thread id: 1
2024-05-01T00:49:38,612  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:38,617  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:38,617  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T00:49:38,637  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T00:49:38,652  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local31257485_0029
2024-05-01T00:49:38,652  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:38,701  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:38,701  INFO [main] mapreduce.Job: Running job: job_local31257485_0029
2024-05-01T00:49:38,701  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:38,703  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T00:49:38,704  INFO [Thread-1181] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:38,704  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local31257485_0029_m_000000_0
2024-05-01T00:49:38,706  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T00:49:38,707  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T00:49:38,710  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local31257485_0029_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.26350325765593674/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T00:49:38,711  INFO [Thread-1181] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:38,712  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.26350325765593674].
2024-05-01T00:49:38,712  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T00:49:38,749  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:38,749  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:38,749  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:38,749  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:38,750  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:38,750  INFO [Thread-1181] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T00:49:38,751  INFO [Thread-1181] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:38,751  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,751  INFO [Thread-1181] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:38,751  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bfaea7, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,751  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bfaea7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@401a6a2b created in the thread with id: 1253
2024-05-01T00:49:38,753  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bfaea7 from thread id: 1253
2024-05-01T00:49:38,753  INFO [Thread-1181] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:38,753  INFO [Thread-1181] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:38,753  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:38,754  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bfaea7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@401a6a2b will be shutdown
2024-05-01T00:49:38,754  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:38,754  INFO [Thread-1181] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -114
2024-05-01T00:49:38,754  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:38,754  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:38,755  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1db64a5b, with PersistenceManager: null will be shutdown
2024-05-01T00:49:38,755  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1db64a5b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33de05c4 created in the thread with id: 1253
2024-05-01T00:49:38,756  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1db64a5b from thread id: 1253
2024-05-01T00:49:38,757  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T00:49:38,757  WARN [Thread-1181] mapred.LocalJobRunner: job_local31257485_0029
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T00:49:39,701  INFO [main] mapreduce.Job: Job job_local31257485_0029 running in uber mode : false
2024-05-01T00:49:39,701  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:39,702  INFO [main] mapreduce.Job: Job job_local31257485_0029 failed with state FAILED due to: NA
2024-05-01T00:49:39,702  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:39,740  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T00:49:39,741  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T00:49:39,741  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T00:49:39,743  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T00:49:39,743  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T00:49:39,743  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bcf8bd7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c92d694 will be shutdown
2024-05-01T00:49:39,743  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bcf8bd7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71390c8 created in the thread with id: 1
2024-05-01T00:49:39,744  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T00:49:39,744  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T00:49:39,745  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T00:49:39,745  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bcf8bd7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71390c8 will be shutdown
2024-05-01T00:49:39,745  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T00:49:39,745  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -115
2024-05-01T00:49:39,745  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T00:49:39,746  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T00:49:39,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@385ff04e, with PersistenceManager: null will be shutdown
2024-05-01T00:49:39,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@385ff04e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42ff5c92 created in the thread with id: 1
2024-05-01T00:49:39,747  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@385ff04e from thread id: 1
2024-05-01T00:49:39,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:39,752  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:39,752  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:39,755  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T00:49:39,761  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T00:49:39,766  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T00:49:39,786  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T00:49:39,803  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local763912644_0030
2024-05-01T00:49:39,803  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T00:49:39,858  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T00:49:39,858  INFO [main] mapreduce.Job: Running job: job_local763912644_0030
2024-05-01T00:49:39,858  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T00:49:39,858  INFO [Thread-1201] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T00:49:39,858  INFO [Thread-1201] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T00:49:39,858  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T00:49:39,866  INFO [Thread-1201] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T00:49:39,866  INFO [Thread-1201] mapred.LocalJobRunner: map task executor complete.
2024-05-01T00:49:40,858  INFO [main] mapreduce.Job: Job job_local763912644_0030 running in uber mode : false
2024-05-01T00:49:40,858  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T00:49:40,859  INFO [main] mapreduce.Job: Job job_local763912644_0030 completed successfully
2024-05-01T00:49:40,859  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T00:49:40,859  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:40,863  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T00:49:40,863  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T00:49:40,919  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
</testsuite>