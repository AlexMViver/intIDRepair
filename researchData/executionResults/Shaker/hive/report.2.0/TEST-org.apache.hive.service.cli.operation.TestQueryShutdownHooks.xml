<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="18.507" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5274177455006435396.jar /home/alex/Repositories/hive/service/target/surefire 2024-05-01T09-25-38_262-jvmRun1 surefire5314596294989973003tmp surefire_812282423241040379677tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5274177455006435396.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="14.559">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,078040 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4b520ea8
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,028224 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 894159
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T04:51:35.757-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-04:51:37.642, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-04:51:37.642, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@157853da...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@157853da OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3a1dd365
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@3de8f619
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619] started OK.
2024-05-01T04:51:37,750  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T04:51:38,231  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T04:51:38,305  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T04:51:38,305  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T04:51:38,306  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T04:51:38,306  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T04:51:38,306  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T04:51:38,306  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T04:51:38,307  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T04:51:38,307  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T04:51:38,307  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T04:51:38,307  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T04:51:38,307  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T04:51:38,308  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = ef31ac68-6c23-4437-aac7-e159ea03a6ca
2024-05-01T04:51:38,347  INFO [main] SessionState: Hive Session ID = ef31ac68-6c23-4437-aac7-e159ea03a6ca
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:38,365  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:38,708  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ef31ac68-6c23-4437-aac7-e159ea03a6ca
2024-05-01T04:51:38,712  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/ef31ac68-6c23-4437-aac7-e159ea03a6ca
2024-05-01T04:51:38,716  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ef31ac68-6c23-4437-aac7-e159ea03a6ca/_tmp_space.db
2024-05-01T04:51:38,738  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ef31ac68-6c23-4437-aac7-e159ea03a6ca, clientType=HIVESERVER2]
2024-05-01T04:51:38,794  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T04:51:39,001  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T04:51:39,036  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T04:51:39,045  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T04:51:39,045  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T04:51:39,070  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T04:51:39,075  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T04:51:39,864  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T04:51:39,868  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T04:51:40,535  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T04:51:40,535  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: null will be shutdown
2024-05-01T04:51:40,562  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f created in the thread with id: 1
2024-05-01T04:51:43,436  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T04:51:43,437  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T04:51:43,437  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64 from thread id: 1
2024-05-01T04:51:43,595  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T04:51:43,639  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T04:51:43,681  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T04:51:43,683  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T04:51:43,805  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T04:51:43,814  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T04:51:43,815  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T04:51:43,819  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T04:51:43,857  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T04:51:43,861  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T04:51:43,863  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T04:51:43,863  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T04:51:43,866  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T04:51:43,869  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T04:51:43,871  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T04:51:43,871  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T04:51:43,880  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T04:51:43,881  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T04:51:43,882  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T04:51:43,886  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T04:51:44,035  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T04:51:44,571  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,576  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,579  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,580  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,580  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,582  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,582  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T04:51:44,633  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T04:51:44,634  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T04:51:44,635  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T04:51:44,635  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T04:51:44,636  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T04:51:44,639  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-05-01T04:51:44,645  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-05-01T04:51:44,659  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T04:51:44,659  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T04:51:44,660  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T04:51:44,660  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T04:51:44,661  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T04:51:44,661  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T04:51:44,686  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T04:51:44,692  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:44,700  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:44,712  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/b983d77d-bd6b-4cb6-be34-e4852ea35665
2024-05-01T04:51:44,716  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665
2024-05-01T04:51:44,721  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/b983d77d-bd6b-4cb6-be34-e4852ea35665/_tmp_space.db
2024-05-01T04:51:44,724  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T04:51:44,724  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T04:51:44,726  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T04:51:44,727  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T04:51:44,729  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f will be shutdown
2024-05-01T04:51:44,730  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 created in the thread with id: 1
2024-05-01T04:51:44,746  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T04:51:44,746  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T04:51:44,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-05-01T04:51:44,813  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T04:51:44,813  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 will be shutdown
2024-05-01T04:51:44,814  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T04:51:44,814  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T04:51:44,815  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665
2024-05-01T04:51:44,818  INFO [main] service.CompositeService: Session opened, SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665], current sessions:1
2024-05-01T04:51:44,824  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T04:51:44,830  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:44,847  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=c289c11b-93cf-4caa-93c0-6289b953c1ed] SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665]
2024-05-01T04:51:44,852  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5.test
2024-05-01T04:51:44,866  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5, startTime=1714564304843, sessionId=b983d77d-bd6b-4cb6-be34-e4852ea35665, createTime=1714564304696, userName=anonymous, ipAddress=null]
2024-05-01T04:51:44,933  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Compiling command(queryId=alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:45,664  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T04:51:45,667  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: null will be shutdown
2024-05-01T04:51:45,667  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 created in the thread with id: 1
2024-05-01T04:51:45,676  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d from thread id: 1
2024-05-01T04:51:45,907  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] reflections.Reflections: Reflections took 195 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T04:51:46,050  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] reflections.Reflections: Reflections took 98 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T04:51:46,172  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] reflections.Reflections: Reflections took 115 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T04:51:46,270  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
2024-05-01T04:51:46,273  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:46,274  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=b983d77d-bd6b-4cb6-be34-e4852ea35665, clientType=HIVESERVER2]
2024-05-01T04:51:46,277  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:46,277  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:46,277  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:46,282  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:46,293  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:47,474  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:48,144  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:48,149  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:48,161  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:48,162  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:48,205  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-44_894_5019417195357972824-1
2024-05-01T04:51:48,247  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:48,333  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:48,356  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:48,429  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:48,436  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:48,436  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:48,436  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:48,437  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:48,437  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:48,437  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:48,440  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:48,440  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
2024-05-01T04:51:48,440  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:48,442  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:48,455  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:48,460  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:48,460  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=98, flushCache_()=13, getAllFunctions_()=66}
2024-05-01T04:51:48,461  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Completed compiling command(queryId=alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5); Time taken: 3.53 seconds
2024-05-01T04:51:48,462  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:48,464  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T04:51:48,473  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:48,477  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Executing command(queryId=alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:48,479  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T04:51:48,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:48,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001
2024-05-01T04:51:48,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001
2024-05-01T04:51:48,482  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
2024-05-01T04:51:48,482  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Query ID = alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
Total jobs = 1
2024-05-01T04:51:48,482  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:48,483  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:48,489  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:48,490  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:48,502  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:48,508  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:48,508  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/dummy_path
2024-05-01T04:51:48,596  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:48,624  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T04:51:48,787  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T04:51:48,809  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T04:51:48,826  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T04:51:48,827  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T04:51:48,849  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:48,903  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:48,914  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:48,917  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:48,918  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-05-01T04:51:48,927  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/dummy_path
2024-05-01T04:51:48,976  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:48,996  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:48,998  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:49,033  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:49,110  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1880017304_0001
2024-05-01T04:51:49,110  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:49,304  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T04:51:49,306  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:49,307  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:49,310  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:49,325  INFO [Thread-61] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:49,330  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1880017304_0001_m_000000_0
2024-05-01T04:51:49,393  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:49,401  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:49,408  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:49,438  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T04:51:49,446  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:49,453  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:49,455  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:49,457  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:49,457  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:49,460  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:49,461  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:49,462  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@29f7824b, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@d48c323, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@4d9ca132
2024-05-01T04:51:49,469  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-44_894_5019417195357972824-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:49,469  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-44_894_5019417195357972824-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:49,469  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-44_894_5019417195357972824-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:49,497  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T04:51:49,498  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T04:51:49,498  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:49,498  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T04:51:49,498  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:49,498  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:49,498  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:49,499  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:49,499  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:49,499  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:49,499  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T04:51:49,501  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T04:51:49,504  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T04:51:49,512  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1880017304_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T04:51:49,513  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T04:51:49,513  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1880017304_0001_m_000000_0' done.
2024-05-01T04:51:49,515  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1880017304_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5586
		FILE: Number of bytes written=1157184
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=916455424
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T04:51:49,515  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1880017304_0001_m_000000_0
2024-05-01T04:51:49,516  INFO [Thread-61] mapred.LocalJobRunner: map task executor complete.
2024-05-01 04:51:50,325 Stage-1 map = 100%,  reduce = 0%
2024-05-01T04:51:50,325  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Task: 2024-05-01 04:51:50,325 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1880017304_0001
2024-05-01T04:51:50,329  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.Task: Ended Job = job_local1880017304_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:50,342  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T04:51:50,342  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:50,342  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001
2024-05-01T04:51:50,342  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1/-mr-10001
2024-05-01T04:51:50,343  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:50,343  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:50,343  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T04:51:50,351  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:50,352  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:50,352  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Completed executing command(queryId=alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5); Time taken: 1.866 seconds
2024-05-01T04:51:50,352  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:50,356  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,357  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=92558afb-7a96-405d-b112-0462146ccb61] SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665]
2024-05-01T04:51:50,357  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2.test
2024-05-01T04:51:50,363  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2, startTime=1714564310356, sessionId=b983d77d-bd6b-4cb6-be34-e4852ea35665, createTime=1714564304696, userName=anonymous, ipAddress=null]
2024-05-01T04:51:50,364  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Compiling command(queryId=alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,367  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2
2024-05-01T04:51:50,367  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:50,368  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:50,368  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,368  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,368  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,368  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:50,383  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,473  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,473  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,476  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,476  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,477  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1
2024-05-01T04:51:50,484  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:50,486  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:50,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:50,499  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:50,499  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:50,499  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:50,499  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:50,499  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:50,499  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:50,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:50,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:50,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2
2024-05-01T04:51:50,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:50,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:50,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:50,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:50,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-05-01T04:51:50,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Completed compiling command(queryId=alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2); Time taken: 0.137 seconds
2024-05-01T04:51:50,502  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:50,503  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,504  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Thread context registration is done.
2024-05-01T04:51:50,504  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=0bdf8bca-eea1-4573-b3bb-2d4139155c27] SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665]
2024-05-01T04:51:50,505  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:50,505  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad.test
2024-05-01T04:51:50,510  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad, startTime=1714564310503, sessionId=b983d77d-bd6b-4cb6-be34-e4852ea35665, createTime=1714564304696, userName=anonymous, ipAddress=null]
2024-05-01T04:51:50,510  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:50,511  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,511  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY2024-05-01T04:51:50,511  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Compiling command(queryId=alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad): select reflect("java.lang.Thread", "sleep", bigint(1000))

2024-05-01T04:51:50,511  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:50,512  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001
2024-05-01T04:51:50,512  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001
2024-05-01T04:51:50,512  WARN [HiveServer2-Background-Pool: Thread-121] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2
2024-05-01T04:51:50,512  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Query ID = alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2
Total jobs = 1
2024-05-01T04:51:50,512  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:50,513  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,514  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:50,516  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,516  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,523  INFO [HiveServer2-Background-Pool: Thread-121] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:50,524  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:50,524  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/dummy_path
2024-05-01T04:51:50,533  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,539  INFO [HiveServer2-Background-Pool: Thread-121] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:50,542  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:50,544  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:50,550  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:50,559  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:50,568  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:50,568  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:50,569  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/dummy_path
2024-05-01T04:51:50,577  INFO [HiveServer2-Background-Pool: Thread-121] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:50,577  INFO [HiveServer2-Background-Pool: Thread-121] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:50,578  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:50,605  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:50,621  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,621  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,624  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,624  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,626  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1
2024-05-01T04:51:50,634  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:50,636  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Submitting tokens for job: job_local960841689_0002
2024-05-01T04:51:50,636  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:50,637  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:50,638  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:50,654  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:50,654  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:50,654  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:50,654  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:50,655  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:50,656  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:50,656  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:50,656  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-05-01T04:51:50,657  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Completed compiling command(queryId=alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad); Time taken: 0.145 seconds
2024-05-01T04:51:50,657  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:50,657  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,659  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=af11e0a7-4522-4beb-b5e4-66eee406c73f] SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665]
2024-05-01T04:51:50,659  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Thread context registration is done.
2024-05-01T04:51:50,658  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5.test
2024-05-01T04:51:50,665  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5, startTime=1714564310657, sessionId=b983d77d-bd6b-4cb6-be34-e4852ea35665, createTime=1714564304696, userName=anonymous, ipAddress=null]
2024-05-01T04:51:50,665  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:50,666  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:50,666  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,667  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Compiling command(queryId=alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,668  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5
2024-05-01T04:51:50,669  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:50,669  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:50,669  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,669  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,669  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,670  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,672  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T04:51:50,672  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:50,672  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001
2024-05-01T04:51:50,672  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001
2024-05-01T04:51:50,673  WARN [HiveServer2-Background-Pool: Thread-156] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad
2024-05-01T04:51:50,673  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Query ID = alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad
Total jobs = 1
2024-05-01T04:51:50,673  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:50,673  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:50,679  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,679  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,689  INFO [HiveServer2-Background-Pool: Thread-156] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:50,690  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:50,690  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/dummy_path
2024-05-01T04:51:50,692  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,708  INFO [HiveServer2-Background-Pool: Thread-156] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:50,710  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:50,711  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:50,719  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:50,729  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:50,737  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:50,737  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:50,739  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/dummy_path
2024-05-01T04:51:50,752  INFO [HiveServer2-Background-Pool: Thread-156] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:50,752  INFO [HiveServer2-Background-Pool: Thread-156] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:50,753  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:50,769  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T04:51:50,770  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T04:51:50,771  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:50,771  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:50,773  INFO [Thread-113] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:50,773  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local960841689_0002_m_000000_0
2024-05-01T04:51:50,775  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:50,776  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:50,777  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:50,781  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:50,782  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:50,783  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:50,784  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:50,784  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,785  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:50,785  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,785  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:50,785  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:50,785  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:50,786  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@348db26f, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@6a14bc49, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@4c76d55c
2024-05-01T04:51:50,787  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:50,787  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,787  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,788  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1
2024-05-01T04:51:50,797  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:50,799  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:50,800  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:50,810  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Submitting tokens for job: job_local1809352174_0003
2024-05-01T04:51:50,811  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:50,814  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:50,815  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:50,815  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:50,815  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-05-01T04:51:50,815  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Completed compiling command(queryId=alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5); Time taken: 0.149 seconds
2024-05-01T04:51:50,816  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:50,816  INFO [HiveServer2-Background-Pool: Thread-197] common.LogUtils: Thread context registration is done.
2024-05-01T04:51:50,816  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,817  INFO [HiveServer2-Background-Pool: Thread-197] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:50,818  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:50,818  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Executing command(queryId=alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,818  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,818  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6f0ad47d-4aeb-4e73-8b1a-70ae3c5e587e] SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665]
PREHOOK: type: QUERY
2024-05-01T04:51:50,818  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table2024-05-01T04:51:50,818  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Thread context registration is done.

2024-05-01T04:51:50,818  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487.test
2024-05-01T04:51:50,824  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487, startTime=1714564310817, sessionId=b983d77d-bd6b-4cb6-be34-e4852ea35665, createTime=1714564304696, userName=anonymous, ipAddress=null]
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001
2024-05-01T04:51:50,824  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001
2024-05-01T04:51:50,824  WARN [HiveServer2-Background-Pool: Thread-197] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5
2024-05-01T04:51:50,825  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Query ID = alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5
Total jobs = 1
2024-05-01T04:51:50,825  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:50,825  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:50,825  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Compiling command(queryId=alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,827  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487
2024-05-01T04:51:50,827  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:50,827  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,828  INFO [HiveServer2-Background-Pool: Thread-197] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,828  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:50,828  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,828  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,828  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,828  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:50,834  INFO [HiveServer2-Background-Pool: Thread-197] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:50,835  INFO [HiveServer2-Background-Pool: Thread-197] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:50,835  INFO [HiveServer2-Background-Pool: Thread-197] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/dummy_path
2024-05-01T04:51:50,844  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,850  INFO [HiveServer2-Background-Pool: Thread-197] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:50,852  INFO [HiveServer2-Background-Pool: Thread-197] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,12KB
2024-05-01T04:51:50,853  WARN [HiveServer2-Background-Pool: Thread-197] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:50,860  WARN [HiveServer2-Background-Pool: Thread-197] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:50,869  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:50,876  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:50,876  INFO [HiveServer2-Background-Pool: Thread-197] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:50,878  INFO [HiveServer2-Background-Pool: Thread-197] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/dummy_path
2024-05-01T04:51:50,883  INFO [HiveServer2-Background-Pool: Thread-197] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:50,883  INFO [HiveServer2-Background-Pool: Thread-197] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:50,884  INFO [HiveServer2-Background-Pool: Thread-197] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:50,906  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T04:51:50,916  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.JobSubmitter: number of splits:1
Job running in-process (local Hadoop)
2024-05-01T04:51:50,916  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:50,917  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:50,917  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:50,926  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1809352174_0003_m_000000_0
2024-05-01T04:51:50,927  INFO [Thread-150] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:50,927  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:50,928  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:50,929  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:50,930  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:50,930  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:50,932  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:50,933  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:50,933  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:50,934  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1
2024-05-01T04:51:50,935  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:50,936  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:50,937  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:50,937  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:50,938  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:50,938  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:50,938  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:50,939  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@72f3d151, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@61b7d025, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@a031d05
2024-05-01T04:51:50,943  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:50,946  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:50,946  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:50,952  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.JobSubmitter: Submitting tokens for job: job_local1413387260_0004
2024-05-01T04:51:50,952  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:50,959  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:50,960  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:50,961  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:50,962  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:50,962  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-05-01T04:51:50,962  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Completed compiling command(queryId=alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487); Time taken: 0.137 seconds
2024-05-01T04:51:50,962  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:50,963  INFO [HiveServer2-Background-Pool: Thread-237] common.LogUtils: Thread context registration is done.
2024-05-01T04:51:50,963  INFO [HiveServer2-Background-Pool: Thread-237] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:50,963  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:50,964  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Executing command(queryId=alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T04:51:50,964  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T04:51:50,964  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:50,964  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001
2024-05-01T04:51:50,964  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001
2024-05-01T04:51:50,964  WARN [HiveServer2-Background-Pool: Thread-237] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487
2024-05-01T04:51:50,964  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Query ID = alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487
Total jobs = 1
2024-05-01T04:51:50,965  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:50,965  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:50,967  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,967  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:50,973  INFO [HiveServer2-Background-Pool: Thread-237] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:50,974  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:50,974  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/dummy_path
2024-05-01T04:51:51,001  INFO [HiveServer2-Background-Pool: Thread-237] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:51,004  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:51,004  WARN [HiveServer2-Background-Pool: Thread-237] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:51,010  WARN [HiveServer2-Background-Pool: Thread-237] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:51,017  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:51,024  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:51,024  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:51,025  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/dummy_path
2024-05-01T04:51:51,031  INFO [HiveServer2-Background-Pool: Thread-237] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:51,031  INFO [HiveServer2-Background-Pool: Thread-237] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:51,031  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:51,056  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:51,057  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T04:51:51,058  INFO [Thread-187] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T04:51:51,058  INFO [HiveServer2-Background-Pool: Thread-197] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:51,058  INFO [Thread-187] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:51,060  INFO [Thread-187] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:51,060  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1413387260_0004_m_000000_0
2024-05-01T04:51:51,061  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:51,061  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:51,062  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:51,064  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,12KB
2024-05-01T04:51:51,065  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:51,065  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:51,066  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:51,066  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:51,066  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:51,066  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:51,066  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:51,067  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@211ea119, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@448d552c, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@706b6d83
2024-05-01T04:51:51,082  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: Submitting tokens for job: job_local1346748838_0005
2024-05-01T04:51:51,082  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:51,154  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T04:51:51,155  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T04:51:51,155  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:51,155  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:51,157  INFO [Thread-218] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:51,157  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1346748838_0005_m_000000_0
2024-05-01T04:51:51,158  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:51,158  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:51,159  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:51,160  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:51,160  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:51,161  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:51,161  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:51,161  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:51,161  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:51,162  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:51,162  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:51,162  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@1ab35fe5, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@6ab1dbb1, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@62c89d31
2024-05-01T04:51:51,478  INFO [main] service.CompositeService: Session closed, SessionHandle [b983d77d-bd6b-4cb6-be34-e4852ea35665], current sessions:0
2024-05-01T04:51:51,478  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=92558afb-7a96-405d-b112-0462146ccb61]
2024-05-01T04:51:51,478  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Removed queryId: alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=92558afb-7a96-405d-b112-0462146ccb61] with tag: null
2024-05-01T04:51:51,478  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2
2024-05-01T04:51:51,479  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T04:51:51,479  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T04:51:51,479  WARN [Thread-113] mapred.LocalJobRunner: job_local960841689_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01 04:51:51,479 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,480  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,480  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: 2024-05-01 04:51:51,479 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-2
2024-05-01T04:51:51,480  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,480  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,480  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T04:51:51,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-2 operation was queued
Ended Job = job_local960841689_0002 with errors
2024-05-01T04:51:51,480 ERROR [HiveServer2-Background-Pool: Thread-121] exec.Task: Ended Job = job_local960841689_0002 with errors
2024-05-01T04:51:51,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1
2024-05-01T04:51:51,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1 operation was queued
2024-05-01T04:51:51,480  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:51,481  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:51,481  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-2
2024-05-01T04:51:51,481  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2 without delay
2024-05-01T04:51:51,481  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=af11e0a7-4522-4beb-b5e4-66eee406c73f]
2024-05-01T04:51:51,481  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Removed queryId: alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=af11e0a7-4522-4beb-b5e4-66eee406c73f] with tag: null
2024-05-01T04:51:51,481  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1
2024-05-01T04:51:51,481  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5
2024-05-01T04:51:51,483  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Shutting down task : Stage-1:MAPRED
Error during job, obtaining debugging information...
2024-05-01T04:51:51,483 ERROR [Thread-223] exec.Task: Error during job, obtaining debugging information...
2024-05-01T04:51:51,483  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 04:51:51,483 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,483  INFO [HiveServer2-Background-Pool: Thread-197] exec.Task: 2024-05-01 04:51:51,483 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,484  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-4
2024-05-01T04:51:51,484  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-4 operation was queued
2024-05-01T04:51:51,484  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1
2024-05-01T04:51:51,484  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1 operation was queued
2024-05-01T04:51:51,484  WARN [Thread-187] mapred.LocalJobRunner: job_local1413387260_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T04:51:51,485  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,485  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1
2024-05-01T04:51:51,485  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,485  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,485  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:51,486  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:51,486  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5 without delay
2024-05-01T04:51:51,486  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=c289c11b-93cf-4caa-93c0-6289b953c1ed]
2024-05-01T04:51:51,486  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Removed queryId: alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=c289c11b-93cf-4caa-93c0-6289b953c1ed] with tag: null
2024-05-01T04:51:51,486  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1 operation was queued
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5 without delay
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=0bdf8bca-eea1-4573-b3bb-2d4139155c27]
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Removed queryId: alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=0bdf8bca-eea1-4573-b3bb-2d4139155c27] with tag: null
2024-05-01T04:51:51,487  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad
2024-05-01T04:51:51,487  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 04:51:51,487 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,488  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: 2024-05-01 04:51:51,487 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,485  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-4
2024-05-01T04:51:51,489  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-44_894_5019417195357972824-1
2024-05-01T04:51:51,490  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T04:51:51,490  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T04:51:51,491  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-3
2024-05-01T04:51:51,491  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-3 operation was queued
2024-05-01T04:51:51,491  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,491  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,491  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_tmp.-ext-10002/000000_0
FAILED: Operation cancelled
2024-05-01T04:51:51,491 ERROR [HiveServer2-Background-Pool: Thread-121] ql.Driver: FAILED: Operation cancelled
2024-05-01T04:51:51,492  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-3
2024-05-01T04:51:51,490  WARN [Thread-150] mapred.LocalJobRunner: job_local1809352174_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T04:51:51,491  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1 operation was queued
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:51,492  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:51,492  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad without delay
2024-05-01T04:51:51,492  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6f0ad47d-4aeb-4e73-8b1a-70ae3c5e587e]
2024-05-01T04:51:51,492  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.OperationManager: Removed queryId: alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6f0ad47d-4aeb-4e73-8b1a-70ae3c5e587e] with tag: null
2024-05-01T04:51:51,492  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487
2024-05-01T04:51:51,493  WARN [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T04:51:51,493  INFO [EventualCleanupService thread 6] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T04:51:51,496  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:51,496  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:51,496  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501045150_309781d5-7ecd-4d47-952f-1efb345148c2) has been interrupted after 0.981 seconds
2024-05-01T04:51:51,498  WARN [HiveServer2-Background-Pool: Thread-121] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T04:51:51,498  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:51,500  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 04:51:51,500 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:51,500  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: 2024-05-01 04:51:51,500 Stage-1 map = 0%,  reduce = 0%
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T04:51:51,500  WARN [Thread-218] mapred.LocalJobRunner: job_local1346748838_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T04:51:51,500  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-5
2024-05-01T04:51:51,500  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,500  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,501  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-5
2024-05-01T04:51:51,500  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-5 operation was queued
2024-05-01T04:51:51,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1
2024-05-01T04:51:51,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1 operation was queued
2024-05-01T04:51:51,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:51,501  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:51,502  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487 without delay
2024-05-01T04:51:51,502  INFO [b983d77d-bd6b-4cb6-be34-e4852ea35665 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665
2024-05-01T04:51:51,503  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/b983d77d-bd6b-4cb6-be34-e4852ea35665 operation was queued
2024-05-01T04:51:51,503  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665 operation was queued
2024-05-01T04:51:51,504  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/b983d77d-bd6b-4cb6-be34-e4852ea35665
2024-05-01T04:51:51,504  INFO [EventualCleanupService thread 8] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1
2024-05-01T04:51:51,504  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665
2024-05-01T04:51:51,516  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T04:51:51,516  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 will be shutdown
2024-05-01T04:51:51,516  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T04:51:51,516  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T04:51:51,517 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T04:51:51,517 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T04:51:51,517  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:51,517  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T04:51:51,517  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:51,517  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:51,518 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:51,518 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:51,517  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:51,518  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T04:51:51,519  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,519  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,519  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_666_897137225765330125-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_666_897137225765330125-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,519  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:51,519  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_511_2762418087574772482-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_511_2762418087574772482-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,519  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:51,520  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_825_3971760180802859726-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_825_3971760180802859726-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,521  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,522  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/b983d77d-bd6b-4cb6-be34-e4852ea35665/hive_2024-05-01_04-51-50_364_7859543281634238998-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-50_364_7859543281634238998-1/_tmp.-ext-10002/000000_0
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="1.822">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T04:51:51,550  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T04:51:51,559  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T04:51:51,559  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T04:51:51,567  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T04:51:51,605  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T04:51:51,606  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T04:51:51,606  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T04:51:51,606  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T04:51:51,606  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T04:51:51,606  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 06cfbbfb-ca7e-4c5b-9e28-2253faf11a81
2024-05-01T04:51:51,607  INFO [main] SessionState: Hive Session ID = 06cfbbfb-ca7e-4c5b-9e28-2253faf11a81
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:51,607  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:51,614  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/06cfbbfb-ca7e-4c5b-9e28-2253faf11a81
2024-05-01T04:51:51,617  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/06cfbbfb-ca7e-4c5b-9e28-2253faf11a81
2024-05-01T04:51:51,620  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/06cfbbfb-ca7e-4c5b-9e28-2253faf11a81/_tmp_space.db
2024-05-01T04:51:51,621  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=06cfbbfb-ca7e-4c5b-9e28-2253faf11a81, clientType=HIVESERVER2]
2024-05-01T04:51:51,622  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T04:51:51,622  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T04:51:51,622  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T04:51:51,623  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: null will be shutdown
2024-05-01T04:51:51,623  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5216532a created in the thread with id: 1
2024-05-01T04:51:51,627  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5 from thread id: 1
2024-05-01T04:51:51,627  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T04:51:51,628  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T04:51:51,628  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T04:51:51,628  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T04:51:51,628  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T04:51:51,628  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T04:51:51,628  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T04:51:51,629  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T04:51:51,632  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T04:51:51,643  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T04:51:51,643  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:51,644  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:51,652  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5cf55d6b-0b7b-4f1d-8063-c01238a3a263
2024-05-01T04:51:51,655  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263
2024-05-01T04:51:51,658  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/_tmp_space.db
2024-05-01T04:51:51,658  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T04:51:51,659  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T04:51:51,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T04:51:51,659  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5216532a will be shutdown
2024-05-01T04:51:51,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T04:51:51,659  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T04:51:51,659  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263
2024-05-01T04:51:51,659  INFO [main] service.CompositeService: Session opened, SessionHandle [5cf55d6b-0b7b-4f1d-8063-c01238a3a263], current sessions:1
2024-05-01T04:51:51,659  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T04:51:51,660  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:51,660  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a66ebef4-7be9-4440-9659-dce764fd501c] SessionHandle [5cf55d6b-0b7b-4f1d-8063-c01238a3a263]
2024-05-01T04:51:51,660  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93.test
2024-05-01T04:51:51,664  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93, startTime=1714564311660, sessionId=5cf55d6b-0b7b-4f1d-8063-c01238a3a263, createTime=1714564311643, userName=anonymous, ipAddress=null]
2024-05-01T04:51:51,665  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Compiling command(queryId=alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:51,666  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T04:51:51,667  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T04:51:51,667  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T04:51:51,668  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: null will be shutdown
2024-05-01T04:51:51,668  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fc40856 created in the thread with id: 1
2024-05-01T04:51:51,672  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016 from thread id: 1
2024-05-01T04:51:51,672  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T04:51:51,673  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T04:51:51,673  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93
2024-05-01T04:51:51,673  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:51,673  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5cf55d6b-0b7b-4f1d-8063-c01238a3a263, clientType=HIVESERVER2]
2024-05-01T04:51:51,674  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:51,674  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:51,674  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:51,674  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:51,674  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:51,688  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:51,740  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:51,741  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:51,742  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:51,742  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:51,743  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-51_665_2240248644196317723-1
2024-05-01T04:51:51,750  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:51,752  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:51,753  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:51,764  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:51,765  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:51,766  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93
2024-05-01T04:51:51,766  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:51,766  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:51,767  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:51,767  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:51,767  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-05-01T04:51:51,767  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Completed compiling command(queryId=alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93); Time taken: 0.102 seconds
2024-05-01T04:51:51,767  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:51,768  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T04:51:51,768  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:51,768  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Executing command(queryId=alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001
2024-05-01T04:51:51,769  WARN [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Query ID = alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93
Total jobs = 1
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:51,769  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:51,773  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:51,773  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:51,777  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:51,777  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:51,777  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/dummy_path
2024-05-01T04:51:51,793  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:51,794  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T04:51:51,795  WARN [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:51,801  WARN [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:51,811  WARN [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:51,818  WARN [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:51,819  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:51,820  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/dummy_path
2024-05-01T04:51:51,824  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:51,824  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:51,825  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:51,848  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:51,879  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1666298144_0006
2024-05-01T04:51:51,879  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:51,958  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T04:51:51,958  INFO [Thread-295] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T04:51:51,959  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:51,959  INFO [Thread-295] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:51,960  INFO [Thread-295] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:51,960  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1666298144_0006_m_000000_0
2024-05-01T04:51:51,964  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:51,965  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:51,969  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:51,970  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T04:51:51,971  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:51,973  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:51,974  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:51,974  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:51,974  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:51,974  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:51,974  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:51,975  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@232766b3, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@28cbdaf7, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@22b99363
2024-05-01T04:51:51,975  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-51_665_2240248644196317723-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,975  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-51_665_2240248644196317723-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:51,976  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-51_665_2240248644196317723-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:51,987  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T04:51:51,988  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T04:51:51,989  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T04:51:51,992  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1666298144_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T04:51:51,992  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T04:51:51,993  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1666298144_0006_m_000000_0' done.
2024-05-01T04:51:51,993  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1666298144_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33474
		FILE: Number of bytes written=6938206
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1012400128
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T04:51:51,993  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1666298144_0006_m_000000_0
2024-05-01T04:51:51,993  INFO [Thread-295] mapred.LocalJobRunner: map task executor complete.
2024-05-01T04:51:52,484  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1413387260_0004 with errors
2024-05-01T04:51:52,485 ERROR [HiveServer2-Background-Pool: Thread-197] exec.Task: Ended Job = job_local1413387260_0004 with errors
Error during job, obtaining debugging information...
2024-05-01T04:51:52,485 ERROR [Thread-302] exec.Task: Error during job, obtaining debugging information...
2024-05-01T04:51:52,486  INFO [HiveServer2-Background-Pool: Thread-197] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T04:51:52,486 ERROR [HiveServer2-Background-Pool: Thread-197] ql.Driver: FAILED: Operation cancelled
2024-05-01T04:51:52,486  INFO [HiveServer2-Background-Pool: Thread-197] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:52,486  INFO [HiveServer2-Background-Pool: Thread-197] metadata.Hive: Total time spent in each metastore function (ms): {close_()=0}
MapReduce Jobs Launched: 
2024-05-01T04:51:52,486  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T04:51:52,486  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T04:51:52,487  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,487  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,487  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Executing command(queryId=alex_20240501045150_2c9de017-fb3e-4ecb-a131-2c6e8a7074f5) has been interrupted after 1.668 seconds
2024-05-01T04:51:52,487  WARN [HiveServer2-Background-Pool: Thread-197] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T04:51:52,487  INFO [HiveServer2-Background-Pool: Thread-197] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:52,488  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1809352174_0003 with errors
2024-05-01T04:51:52,488 ERROR [HiveServer2-Background-Pool: Thread-156] exec.Task: Ended Job = job_local1809352174_0003 with errors
Error during job, obtaining debugging information...
2024-05-01T04:51:52,489 ERROR [Thread-304] exec.Task: Error during job, obtaining debugging information...
2024-05-01T04:51:52,490  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T04:51:52,490 ERROR [HiveServer2-Background-Pool: Thread-156] ql.Driver: FAILED: Operation cancelled
2024-05-01T04:51:52,491  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:52,491  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:52,491  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T04:51:52,491  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T04:51:52,491  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,491  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,491  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501045150_0d210402-24f6-44ad-8b76-d920f30637ad) has been interrupted after 1.825 seconds
2024-05-01T04:51:52,491  WARN [HiveServer2-Background-Pool: Thread-156] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T04:51:52,492  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:52,500  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1346748838_0005 with errors
2024-05-01T04:51:52,501 ERROR [HiveServer2-Background-Pool: Thread-237] exec.Task: Ended Job = job_local1346748838_0005 with errors
Error during job, obtaining debugging information...
2024-05-01T04:51:52,501 ERROR [Thread-306] exec.Task: Error during job, obtaining debugging information...
2024-05-01T04:51:52,502  INFO [HiveServer2-Background-Pool: Thread-237] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T04:51:52,502 ERROR [HiveServer2-Background-Pool: Thread-237] ql.Driver: FAILED: Operation cancelled
2024-05-01T04:51:52,503  INFO [HiveServer2-Background-Pool: Thread-237] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:52,503  INFO [HiveServer2-Background-Pool: Thread-237] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:52,503  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T04:51:52,503  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T04:51:52,503  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,503  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,503  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Executing command(queryId=alex_20240501045150_0e35ff88-2616-4887-9c0a-f1bd5b452487) has been interrupted after 1.539 seconds
2024-05-01T04:51:52,503  WARN [HiveServer2-Background-Pool: Thread-237] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T04:51:52,504  INFO [HiveServer2-Background-Pool: Thread-237] common.LogUtils: Unregistered logging context.
2024-05-01 04:51:52,962 Stage-1 map = 100%,  reduce = 0%
2024-05-01T04:51:52,963  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Task: 2024-05-01 04:51:52,962 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1666298144_0006
2024-05-01T04:51:52,964  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.Task: Ended Job = job_local1666298144_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:52,966  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T04:51:52,966  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:52,966  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001
2024-05-01T04:51:52,966  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1/-mr-10001
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Completed executing command(queryId=alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93); Time taken: 1.199 seconds
2024-05-01T04:51:52,967  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:52,968  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T04:51:52,968  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=67e6ca0e-cfac-4518-b7d2-f958f811b353] SessionHandle [5cf55d6b-0b7b-4f1d-8063-c01238a3a263]
2024-05-01T04:51:52,969  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38.test
2024-05-01T04:51:52,972  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38, startTime=1714564312968, sessionId=5cf55d6b-0b7b-4f1d-8063-c01238a3a263, createTime=1714564311643, userName=anonymous, ipAddress=null]
2024-05-01T04:51:52,973  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Compiling command(queryId=alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T04:51:52,976  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38
2024-05-01T04:51:52,976  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:52,976  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-05-01T04:51:52,978  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-05-01T04:51:53,063  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] reflections.Reflections: Reflections took 74 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T04:51:53,123  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38
2024-05-01T04:51:53,123  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=10, flushCache_()=0}
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Completed compiling command(queryId=alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38); Time taken: 0.151 seconds
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-05-01T04:51:53,124  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Executing command(queryId=alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T04:51:53,125  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-05-01T04:51:53,125  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-05-01T04:51:53,125  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T04:51:53,125  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T04:51:53,125  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-05-01T04:51:53,219  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1714564313, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFiles=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-05-01T04:51:53,226  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/service/target/warehouse/sample_shutdown_hook
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T04:51:53,352  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-05-01T04:51:53,352  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-05-01T04:51:53,352  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T04:51:53,352  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T04:51:53,352  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:53,353  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, createTable_(Table)=134}
2024-05-01T04:51:53,353  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Driver: Completed executing command(queryId=alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38); Time taken: 0.228 seconds
2024-05-01T04:51:53,353  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:53,353  INFO [main] service.CompositeService: Session closed, SessionHandle [5cf55d6b-0b7b-4f1d-8063-c01238a3a263], current sessions:0
2024-05-01T04:51:53,353  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a66ebef4-7be9-4440-9659-dce764fd501c]
2024-05-01T04:51:53,353  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.OperationManager: Removed queryId: alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a66ebef4-7be9-4440-9659-dce764fd501c] with tag: null
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1 operation was queued
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045151_1d242dd1-617f-4dae-b3bf-8da370b53d93 without delay
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=67e6ca0e-cfac-4518-b7d2-f958f811b353]
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.OperationManager: Removed queryId: alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=67e6ca0e-cfac-4518-b7d2-f958f811b353] with tag: null
2024-05-01T04:51:53,354  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/alex_20240501045152_2752e1d4-8c1b-48ea-aa50-898a847dab38 without delay
2024-05-01T04:51:53,355  INFO [5cf55d6b-0b7b-4f1d-8063-c01238a3a263 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/5cf55d6b-0b7b-4f1d-8063-c01238a3a263
2024-05-01T04:51:53,355  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263/hive_2024-05-01_04-51-51_665_2240248644196317723-1
2024-05-01T04:51:53,356  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5cf55d6b-0b7b-4f1d-8063-c01238a3a263 operation was queued
2024-05-01T04:51:53,356  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263 operation was queued
2024-05-01T04:51:53,356  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5cf55d6b-0b7b-4f1d-8063-c01238a3a263
2024-05-01T04:51:53,356  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5cf55d6b-0b7b-4f1d-8063-c01238a3a263
2024-05-01T04:51:53,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T04:51:53,357  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fc40856 will be shutdown
2024-05-01T04:51:53,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T04:51:53,357  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.106">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T04:51:53,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T04:51:53,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T04:51:53,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T04:51:53,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T04:51:53,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T04:51:53,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T04:51:53,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T04:51:53,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T04:51:53,414  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T04:51:53,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T04:51:53,414  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T04:51:53,414  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 71b0b7e1-79b7-47b4-aab0-f9d534eddd79
2024-05-01T04:51:53,415  INFO [main] SessionState: Hive Session ID = 71b0b7e1-79b7-47b4-aab0-f9d534eddd79
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:53,415  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:53,422  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/71b0b7e1-79b7-47b4-aab0-f9d534eddd79
2024-05-01T04:51:53,425  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/71b0b7e1-79b7-47b4-aab0-f9d534eddd79
2024-05-01T04:51:53,429  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/71b0b7e1-79b7-47b4-aab0-f9d534eddd79/_tmp_space.db
2024-05-01T04:51:53,429  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=71b0b7e1-79b7-47b4-aab0-f9d534eddd79, clientType=HIVESERVER2]
2024-05-01T04:51:53,430  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T04:51:53,430  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T04:51:53,430  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T04:51:53,431  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: null will be shutdown
2024-05-01T04:51:53,431  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7097ead6 created in the thread with id: 1
2024-05-01T04:51:53,441  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848 from thread id: 1
2024-05-01T04:51:53,441  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T04:51:53,442  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T04:51:53,442  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T04:51:53,442  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T04:51:53,442  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T04:51:53,442  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T04:51:53,442  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T04:51:53,443  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T04:51:53,446  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T04:51:53,446  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T04:51:53,446  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T04:51:53,446  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T04:51:53,446  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T04:51:53,447  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T04:51:53,447  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T04:51:53,456  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T04:51:53,456  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:53,457  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T04:51:53,464  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/9f4451dc-c19a-48e8-9f92-0337afa74e23
2024-05-01T04:51:53,467  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23
2024-05-01T04:51:53,471  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/9f4451dc-c19a-48e8-9f92-0337afa74e23/_tmp_space.db
2024-05-01T04:51:53,471  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T04:51:53,471  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T04:51:53,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T04:51:53,471  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7097ead6 will be shutdown
2024-05-01T04:51:53,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T04:51:53,471  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T04:51:53,471  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23
2024-05-01T04:51:53,472  INFO [main] service.CompositeService: Session opened, SessionHandle [9f4451dc-c19a-48e8-9f92-0337afa74e23], current sessions:1
2024-05-01T04:51:53,472  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T04:51:53,472  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:53,473  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=47ae0546-f203-4769-8345-30301b258308] SessionHandle [9f4451dc-c19a-48e8-9f92-0337afa74e23]
2024-05-01T04:51:53,473  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2.test
2024-05-01T04:51:53,477  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2, startTime=1714564313472, sessionId=9f4451dc-c19a-48e8-9f92-0337afa74e23, createTime=1714564313456, userName=anonymous, ipAddress=null]
2024-05-01T04:51:53,478  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Compiling command(queryId=alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:53,479  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T04:51:53,479  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T04:51:53,479  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T04:51:53,480  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: null will be shutdown
2024-05-01T04:51:53,480  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@460df441 created in the thread with id: 1
2024-05-01T04:51:53,484  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f from thread id: 1
2024-05-01T04:51:53,484  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T04:51:53,484  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=9f4451dc-c19a-48e8-9f92-0337afa74e23, clientType=HIVESERVER2]
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:53,485  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:53,500  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:53,618  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:53,619  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:53,624  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:53,624  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:53,625  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-53_478_4213754545145267913-1
2024-05-01T04:51:53,632  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:53,634  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:53,634  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:53,646  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:53,647  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:53,647  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2
2024-05-01T04:51:53,647  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:53,647  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=68, flushCache_()=1}
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Completed compiling command(queryId=alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2); Time taken: 0.17 seconds
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:53,648  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Executing command(queryId=alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001
2024-05-01T04:51:53,649  WARN [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Query ID = alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2
Total jobs = 1
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:53,649  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:53,652  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:53,652  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:53,655  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:53,655  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:53,655  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/dummy_path
2024-05-01T04:51:53,668  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:53,669  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T04:51:53,670  WARN [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:53,675  WARN [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:53,682  WARN [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:53,688  WARN [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:53,689  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:53,690  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/dummy_path
2024-05-01T04:51:53,695  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:53,695  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:53,695  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:53,719  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:53,751  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1129444858_0007
2024-05-01T04:51:53,751  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:53,846  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T04:51:53,846  INFO [Thread-349] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T04:51:53,846  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:53,846  INFO [Thread-349] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:53,848  INFO [Thread-349] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:53,849  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1129444858_0007_m_000000_0
2024-05-01T04:51:53,852  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:53,853  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:53,856  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:53,857  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T04:51:53,857  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:53,860  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:53,860  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:53,861  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:53,861  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:53,861  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:53,861  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:53,862  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@488b9aa4, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@663d6255, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@bdd72d0
2024-05-01T04:51:53,862  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-53_478_4213754545145267913-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:53,862  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-53_478_4213754545145267913-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:53,862  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-53_478_4213754545145267913-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:53,874  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T04:51:53,875  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T04:51:53,876  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T04:51:53,877  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T04:51:53,880  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1129444858_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T04:51:53,881  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T04:51:53,881  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1129444858_0007_m_000000_0' done.
2024-05-01T04:51:53,881  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1129444858_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39060
		FILE: Number of bytes written=8095390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1012924416
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T04:51:53,881  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1129444858_0007_m_000000_0
2024-05-01T04:51:53,882  INFO [Thread-349] mapred.LocalJobRunner: map task executor complete.
2024-05-01 04:51:54,850 Stage-1 map = 100%,  reduce = 0%
2024-05-01T04:51:54,850  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Task: 2024-05-01 04:51:54,850 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1129444858_0007
2024-05-01T04:51:54,851  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.Task: Ended Job = job_local1129444858_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1/-mr-10001
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:54,853  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Completed executing command(queryId=alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2); Time taken: 1.205 seconds
2024-05-01T04:51:54,854  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:54,854  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T04:51:54,854  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=11f596e6-f25a-4049-9edb-57ea0061f51c] SessionHandle [9f4451dc-c19a-48e8-9f92-0337afa74e23]
2024-05-01T04:51:54,855  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973.test
2024-05-01T04:51:54,858  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973, startTime=1714564314854, sessionId=9f4451dc-c19a-48e8-9f92-0337afa74e23, createTime=1714564313456, userName=anonymous, ipAddress=null]
2024-05-01T04:51:54,859  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Compiling command(queryId=alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:54,860  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T04:51:54,874  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:54,929  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T04:51:54,930  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T04:51:54,932  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T04:51:54,932  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T04:51:54,933  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-54_859_2248520292101036279-1
2024-05-01T04:51:54,940  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T04:51:54,943  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T04:51:54,944  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map vectorized: false
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T04:51:54,955  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T04:51:54,956  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T04:51:54,956  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973
2024-05-01T04:51:54,956  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T04:51:54,956  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T04:51:54,957  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T04:51:54,957  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T04:51:54,957  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=0}
2024-05-01T04:51:54,957  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Completed compiling command(queryId=alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973); Time taken: 0.098 seconds
2024-05-01T04:51:54,958  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] common.LogUtils: Unregistered logging context.
2024-05-01T04:51:54,958  INFO [HiveServer2-Background-Pool: Thread-442] common.LogUtils: Thread context registration is done.
2024-05-01T04:51:54,958  INFO [HiveServer2-Background-Pool: Thread-442] reexec.ReExecDriver: Execution #1 of query
2024-05-01T04:51:54,959  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T04:51:54,959  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Executing command(queryId=alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T04:51:54,959  INFO [HiveServer2-Background-Pool: Thread-442] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-05-01T04:51:54,959  INFO [HiveServer2-Background-Pool: Thread-442] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T04:51:54,960  INFO [HiveServer2-Background-Pool: Thread-442] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/-mr-10001
2024-05-01T04:51:54,960  INFO [HiveServer2-Background-Pool: Thread-442] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/-mr-10001
2024-05-01T04:51:54,960  WARN [HiveServer2-Background-Pool: Thread-442] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973
2024-05-01T04:51:54,960  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Query ID = alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973
Total jobs = 1
2024-05-01T04:51:54,960  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T04:51:54,960  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Launching Job 1 out of 1
2024-05-01T04:51:54,963  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:54,964  INFO [HiveServer2-Background-Pool: Thread-442] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T04:51:54,970  INFO [HiveServer2-Background-Pool: Thread-442] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T04:51:54,970  INFO [HiveServer2-Background-Pool: Thread-442] exec.Utilities: Processing alias _dummy_table
2024-05-01T04:51:54,970  INFO [HiveServer2-Background-Pool: Thread-442] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/dummy_path
2024-05-01T04:51:54,983  INFO [HiveServer2-Background-Pool: Thread-442] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T04:51:54,984  INFO [HiveServer2-Background-Pool: Thread-442] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:54,985  WARN [HiveServer2-Background-Pool: Thread-442] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:54,990  WARN [HiveServer2-Background-Pool: Thread-442] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T04:51:54,998  WARN [HiveServer2-Background-Pool: Thread-442] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T04:51:55,004  WARN [HiveServer2-Background-Pool: Thread-442] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T04:51:55,004  INFO [HiveServer2-Background-Pool: Thread-442] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T04:51:55,005  INFO [HiveServer2-Background-Pool: Thread-442] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/dummy_path
2024-05-01T04:51:55,009  INFO [HiveServer2-Background-Pool: Thread-442] input.FileInputFormat: Total input files to process : 1
2024-05-01T04:51:55,010  INFO [HiveServer2-Background-Pool: Thread-442] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T04:51:55,010  INFO [HiveServer2-Background-Pool: Thread-442] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T04:51:55,034  INFO [HiveServer2-Background-Pool: Thread-442] mapreduce.JobSubmitter: number of splits:1
2024-05-01T04:51:55,057  INFO [HiveServer2-Background-Pool: Thread-442] mapreduce.JobSubmitter: Submitting tokens for job: job_local604216477_0008
2024-05-01T04:51:55,057  INFO [HiveServer2-Background-Pool: Thread-442] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T04:51:55,126  INFO [HiveServer2-Background-Pool: Thread-442] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T04:51:55,126  INFO [HiveServer2-Background-Pool: Thread-442] exec.Task: Job running in-process (local Hadoop)
2024-05-01T04:51:55,126  INFO [Thread-388] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:55,126  INFO [Thread-388] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T04:51:55,128  INFO [Thread-388] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T04:51:55,128  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local604216477_0008_m_000000_0
2024-05-01T04:51:55,129  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T04:51:55,129  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T04:51:55,130  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T04:51:55,131  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T04:51:55,131  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T04:51:55,132  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T04:51:55,132  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T04:51:55,132  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T04:51:55,132  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T04:51:55,132  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T04:51:55,133  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T04:51:55,133  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@1e89e4d9, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@475020bc, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@51a6c509
DEBUG StatusLogger Removing appender alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
DEBUG StatusLogger Removing appender alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
DEBUG StatusLogger Deleting route with alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5 key 
DEBUG StatusLogger Deleting route with alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5 key 
DEBUG StatusLogger Stopping route with alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5 key
DEBUG StatusLogger Stopping route with alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5 key
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5, all resources released: true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5.test
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/b983d77d-bd6b-4cb6-be34-e4852ea35665/alex_20240501045144_89316a1d-5d56-4487-9a18-c4dc245a5ae5.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-05-01T04:51:55,459  INFO [main] service.CompositeService: Session closed, SessionHandle [9f4451dc-c19a-48e8-9f92-0337afa74e23], current sessions:0
2024-05-01T04:51:55,459  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=11f596e6-f25a-4049-9edb-57ea0061f51c]
2024-05-01T04:51:55,459  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.OperationManager: Removed queryId: alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=11f596e6-f25a-4049-9edb-57ea0061f51c] with tag: null
2024-05-01T04:51:55,459  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973
2024-05-01T04:51:55,459  WARN [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-05-01T04:51:55,460  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-54_859_2248520292101036279-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:55,460  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-6
2024-05-01T04:51:55,460  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-54_859_2248520292101036279-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T04:51:55,460  WARN [HiveServer2-Background-Pool: Thread-442] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T04:51:55,460  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-6 operation was queued
2024-05-01T04:51:55,460  WARN [Thread-388] mapred.LocalJobRunner: job_local604216477_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01 04:51:55,460 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:55,460  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1/-mr-10001/.hive-staging_hive_2024-05-01_04-51-54_859_2248520292101036279-1/_tmp.-ext-10002/000000_0
2024-05-01T04:51:55,460  INFO [HiveServer2-Background-Pool: Thread-442] exec.Task: 2024-05-01 04:51:55,460 Stage-1 map = 0%,  reduce = 0%
2024-05-01T04:51:55,460  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1
2024-05-01T04:51:55,460  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1 operation was queued
2024-05-01T04:51:55,460  WARN [HiveServer2-Background-Pool: Thread-442] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T04:51:55,460  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:55,460  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:55,460  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-6
Ended Job = job_local604216477_0008 with errors
2024-05-01T04:51:55,461  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973 without delay
2024-05-01T04:51:55,461 ERROR [HiveServer2-Background-Pool: Thread-442] exec.Task: Ended Job = job_local604216477_0008 with errors
2024-05-01T04:51:55,461  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=47ae0546-f203-4769-8345-30301b258308]
2024-05-01T04:51:55,461  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.OperationManager: Removed queryId: alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=47ae0546-f203-4769-8345-30301b258308] with tag: null
2024-05-01T04:51:55,461  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-54_859_2248520292101036279-1
2024-05-01T04:51:55,461  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1
Error during job, obtaining debugging information...
2024-05-01T04:51:55,461 ERROR [Thread-393] exec.Task: Error during job, obtaining debugging information...
2024-05-01T04:51:55,461  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1 operation was queued
2024-05-01T04:51:55,462  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T04:51:55,462  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T04:51:55,462  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23/alex_20240501045153_47290fad-9fd3-4339-af16-af0b0aa003b2 without delay
2024-05-01T04:51:55,462  INFO [9f4451dc-c19a-48e8-9f92-0337afa74e23 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/9f4451dc-c19a-48e8-9f92-0337afa74e23
2024-05-01T04:51:55,463  INFO [HiveServer2-Background-Pool: Thread-442] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-05-01T04:51:55,463  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23/hive_2024-05-01_04-51-53_478_4213754545145267913-1
2024-05-01T04:51:55,463  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/9f4451dc-c19a-48e8-9f92-0337afa74e23 operation was queued
2024-05-01T04:51:55,463  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23 operation was queued
2024-05-01T04:51:55,463  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/9f4451dc-c19a-48e8-9f92-0337afa74e23
FAILED: Operation cancelled
2024-05-01T04:51:55,463 ERROR [HiveServer2-Background-Pool: Thread-442] ql.Driver: FAILED: Operation cancelled
2024-05-01T04:51:55,463  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/9f4451dc-c19a-48e8-9f92-0337afa74e23
2024-05-01T04:51:55,464  INFO [HiveServer2-Background-Pool: Thread-442] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T04:51:55,464  INFO [HiveServer2-Background-Pool: Thread-442] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T04:51:55,464  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T04:51:55,464  WARN [HiveServer2-Background-Pool: Thread-442] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL2024-05-01T04:51:55,464  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	

2024-05-01T04:51:55,464  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T04:51:55,464  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@460df441 will be shutdown
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:55,464  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T04:51:55,464  INFO [HiveServer2-Background-Pool: Thread-442] ql.Driver: Executing command(queryId=alex_20240501045154_4e4710c8-5e66-40ab-a09d-f417947b3973) has been interrupted after 0.504 seconds
2024-05-01T04:51:55,464  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T04:51:55,464  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T04:51:55,464  WARN [HiveServer2-Background-Pool: Thread-442] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T04:51:55,465  INFO [HiveServer2-Background-Pool: Thread-442] common.LogUtils: Unregistered logging context.
]]></system-err>
  </testcase>
</testsuite>