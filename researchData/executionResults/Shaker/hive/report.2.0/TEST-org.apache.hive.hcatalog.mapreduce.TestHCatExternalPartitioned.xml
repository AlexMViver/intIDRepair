<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="47.295" tests="8" errors="0" skipped="2" failures="6">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter936805123602972274.jar /home/alex/Repositories/hive/hcatalog/core/target/surefire 2024-05-01T09-25-38_262-jvmRun1 surefire4494941885124591367tmp surefire_9336220974794374215503tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/hcatalog/core/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter936805123602972274.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/hcatalog/core/../../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/hcatalog/core/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/hcatalog/core/../../"/>
  </properties>
  <testcase name="testHCatPartitionedTable[0]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="7.997">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,099454 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@5aa9e4eb
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,029191 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 51818225
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T05:14:55.362-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-05:14:57.025, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-05:14:57.026, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@488d1cd7
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@33d512c1
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1] started OK.
2024-05-01T05:14:57,235  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T05:14:57,349  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/core/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1714565697096/warehouse
2024-05-01T05:14:57,678  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T05:14:57,752  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:14:57,752  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:14:57,753  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:14:57,753  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:14:57,753  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:14:57,754  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:14:57,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:14:57,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:14:57,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:14:57,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:14:57,756  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:14:57,761  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=0 initial-capacity=50 maximum-capacity=50
2024-05-01T05:14:57,818  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:14:58,020  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:14:58,062  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:14:58,078  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T05:14:58,078  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T05:14:58,106  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T05:14:58,113  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T05:14:58,823  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T05:14:58,827  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T05:14:59,515  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T05:14:59,515  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: null will be shutdown
2024-05-01T05:14:59,546  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 created in the thread with id: 1
2024-05-01T05:15:01,982  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T05:15:01,982  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T05:15:01,982  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133 from thread id: 1
2024-05-01T05:15:02,600  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T05:15:02,637  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T05:15:02,664  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T05:15:02,666  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T05:15:02,794  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T05:15:02,804  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T05:15:02,805  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T05:15:02,809  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T05:15:02,839  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T05:15:02,842  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T05:15:02,843  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T05:15:02,844  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T05:15:02,845  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T05:15:02,847  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T05:15:02,849  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T05:15:02,850  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T05:15:02,855  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T05:15:02,856  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T05:15:02,857  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T05:15:02,860  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:03,006  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:03,038  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:03,038  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 will be shutdown
2024-05-01T05:15:03,039  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:03,039  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T05:15:03,039  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:03,041  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:03,043  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: null will be shutdown
2024-05-01T05:15:03,043  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e700eba created in the thread with id: 1
2024-05-01T05:15:03,057  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12 from thread id: 1
2024-05-01T05:15:03,157  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:03,158  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:03,158  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:03,158  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:03,158  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:03,158  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:03,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:03,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:03,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:03,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:03,159  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:03,190  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:03,190  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:03,191  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e700eba will be shutdown
2024-05-01T05:15:03,192  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f238e4f created in the thread with id: 1
2024-05-01T05:15:03,196  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 7658cef7-4227-456b-8f84-3b7ddc0a0ae3
2024-05-01T05:15:03,204  INFO [main] SessionState: Hive Session ID = 7658cef7-4227-456b-8f84-3b7ddc0a0ae3
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:03,218  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:03,274  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/7658cef7-4227-456b-8f84-3b7ddc0a0ae3
2024-05-01T05:15:03,277  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/7658cef7-4227-456b-8f84-3b7ddc0a0ae3
2024-05-01T05:15:03,281  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/7658cef7-4227-456b-8f84-3b7ddc0a0ae3/_tmp_space.db
2024-05-01T05:15:03,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:03,420  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_TEXTFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_TEXTFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T05:15:03,432  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile
2024-05-01T05:15:03,650  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:03,650  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:03,650  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:03,651  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:03,651  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:03,651  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:03,651  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:03,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:03,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:03,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:03,652  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:03,653  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:03,654  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:03,674  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:03,674  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:03,676  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f238e4f will be shutdown
2024-05-01T05:15:03,677  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50211483 created in the thread with id: 1
2024-05-01T05:15:03,683  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:03,684  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:03,684  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:03,684  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58a84a12, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50211483 will be shutdown
2024-05-01T05:15:03,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:03,685  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T05:15:03,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:03,687  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:03,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@450f0235, with PersistenceManager: null will be shutdown
2024-05-01T05:15:03,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@450f0235, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78c262ba created in the thread with id: 1
2024-05-01T05:15:03,694  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@450f0235 from thread id: 1
2024-05-01T05:15:03,700  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:03,763  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:03,963  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T05:15:03,978  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T05:15:03,992  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T05:15:03,992  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:04,047  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:04,048  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:04,048  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:04,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:04,048  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:04,048  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:04,050  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:04,050  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:04,051  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@450f0235, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78c262ba will be shutdown
2024-05-01T05:15:04,051  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@450f0235, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35f7969d created in the thread with id: 1
2024-05-01T05:15:04,055  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:04,055  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:04,055  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:04,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@450f0235, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35f7969d will be shutdown
2024-05-01T05:15:04,056  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:04,056  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T05:15:04,056  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:04,058  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:04,058  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79be91eb, with PersistenceManager: null will be shutdown
2024-05-01T05:15:04,059  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79be91eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@626c569b created in the thread with id: 1
2024-05-01T05:15:04,062  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79be91eb from thread id: 1
2024-05-01T05:15:04,064  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value1,501]	
2024-05-01T05:15:04,134  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:04,144  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:04,178  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:04,235  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:04,278  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local63702042_0001
2024-05-01T05:15:04,278  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:04,401  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:04,403  INFO [main] mapreduce.Job: Running job: job_local63702042_0001
2024-05-01T05:15:04,404  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:04,425  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,425  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,434  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:04,442  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,442  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,464  INFO [Thread-43] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:04,464  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local63702042_0001_m_000000_0
2024-05-01T05:15:04,494  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,494  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,498  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,498  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,515  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:04,520  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T05:15:04,542  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,542  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,610  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:04,618  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local63702042_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:04,618  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,618  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,623  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:04,623  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local63702042_0001_m_000000_0 is allowed to commit now
2024-05-01T05:15:04,623  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:04,623  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:04,636  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local63702042_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5716920356567537/part1=p1value1/part0=501
2024-05-01T05:15:04,637  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:04,638  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local63702042_0001_m_000000_0' done.
2024-05-01T05:15:04,641  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local63702042_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=507715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=704118784
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:04,641  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local63702042_0001_m_000000_0
2024-05-01T05:15:04,642  INFO [Thread-43] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:04,704  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:04,704  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:04,704  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:04,704  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:04,705  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:04,705  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:04,705  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:04,705  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:04,705  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:04,705  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:04,716  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:04,716  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:04,718  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:04,719  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:04,719  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:04,719  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62012eb6, with PersistenceManager: null will be shutdown
2024-05-01T05:15:04,720  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62012eb6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dc119ff created in the thread with id: 69
2024-05-01T05:15:04,725  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62012eb6 from thread id: 69
2024-05-01T05:15:04,725  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:04,726  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:04,726  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:04,726  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62012eb6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dc119ff will be shutdown
2024-05-01T05:15:04,726  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:04,726  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-05-01T05:15:04,726  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:04,727  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:04,728  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1eee9834, with PersistenceManager: null will be shutdown
2024-05-01T05:15:04,728  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1eee9834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ce74fd created in the thread with id: 69
2024-05-01T05:15:04,731  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1eee9834 from thread id: 69
2024-05-01T05:15:04,785  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:04,785  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:04,785  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:04,785  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:04,785  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:04,786  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:04,786  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:04,786  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:04,786  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:04,786  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:04,786  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:04,787  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T05:15:04,819  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5716920356567537/part1=p1value1/part0=501].
2024-05-01T05:15:04,819  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:04,866  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:04,867  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:04,867  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:04,868  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:04,868  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:04,869  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1eee9834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ce74fd will be shutdown
2024-05-01T05:15:04,869  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1eee9834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17fadf8b created in the thread with id: 69
2024-05-01T05:15:04,873  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:04,873  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:04,874  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:04,874  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1eee9834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17fadf8b will be shutdown
2024-05-01T05:15:04,874  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:04,874  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T05:15:04,874  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:04,875  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:04,875  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f547ba4, with PersistenceManager: null will be shutdown
2024-05-01T05:15:04,875  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f547ba4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d50da7d created in the thread with id: 69
2024-05-01T05:15:04,879  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f547ba4 from thread id: 69
2024-05-01T05:15:04,880  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:04,880  WARN [Thread-43] mapred.LocalJobRunner: job_local63702042_0001
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5716920356567537/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:05,411  INFO [main] mapreduce.Job: Job job_local63702042_0001 running in uber mode : false
2024-05-01T05:15:05,412  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:05,414  INFO [main] mapreduce.Job: Job job_local63702042_0001 failed with state FAILED due to: NA
2024-05-01T05:15:05,419  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=507715
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=704118784
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:05,470  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:05,470  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:05,471  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:05,471  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:05,472  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:05,476  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:05,476  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:05,476  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79be91eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@626c569b will be shutdown
2024-05-01T05:15:05,477  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79be91eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32e5af53 created in the thread with id: 1
2024-05-01T05:15:05,481  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:05,481  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:05,481  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:05,481  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79be91eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32e5af53 will be shutdown
2024-05-01T05:15:05,481  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:05,481  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T05:15:05,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:05,483  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:05,483  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ccc1026, with PersistenceManager: null will be shutdown
2024-05-01T05:15:05,483  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ccc1026, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4044589a created in the thread with id: 1
2024-05-01T05:15:05,488  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ccc1026 from thread id: 1
2024-05-01T05:15:05,489  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:05,501  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:05,510  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:05,567  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:05,567  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:05,567  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:05,567  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:05,567  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:05,567  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:05,568  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:05,568  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:05,568  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:05,568  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:05,568  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:05,569  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:05,570  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:05,570  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:05,571  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ccc1026, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4044589a will be shutdown
2024-05-01T05:15:05,571  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ccc1026, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3302035b created in the thread with id: 1
2024-05-01T05:15:05,576  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:05,576  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:05,577  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:05,577  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ccc1026, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3302035b will be shutdown
2024-05-01T05:15:05,577  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:05,577  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-05-01T05:15:05,577  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:05,578  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:05,579  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@577bfadb, with PersistenceManager: null will be shutdown
2024-05-01T05:15:05,579  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@577bfadb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25ae1f80 created in the thread with id: 1
2024-05-01T05:15:05,584  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@577bfadb from thread id: 1
2024-05-01T05:15:05,586  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T05:15:05,620  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:05,626  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:05,627  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:05,650  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:05,669  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1233018406_0002
2024-05-01T05:15:05,669  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:05,742  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:05,743  INFO [main] mapreduce.Job: Running job: job_local1233018406_0002
2024-05-01T05:15:05,743  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:05,747  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,747  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,749  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:05,750  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,750  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,766  INFO [Thread-91] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:05,766  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1233018406_0002_m_000000_0
2024-05-01T05:15:05,771  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,771  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,774  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,774  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,774  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:05,775  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:05,779  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,779  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,796  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:05,796  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1233018406_0002_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:05,796  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,796  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,801  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:05,801  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1233018406_0002_m_000000_0 is allowed to commit now
2024-05-01T05:15:05,801  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:05,801  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:05,812  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1233018406_0002_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,06741132988814869/part1=p1value2/part0=502
2024-05-01T05:15:05,812  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:05,813  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1233018406_0002_m_000000_0' done.
2024-05-01T05:15:05,813  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1233018406_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1020439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=704118784
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:05,813  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1233018406_0002_m_000000_0
2024-05-01T05:15:05,813  INFO [Thread-91] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:05,880  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:05,880  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:05,880  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:05,880  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:05,881  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:05,882  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:05,883  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:05,884  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:05,884  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:05,884  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7dcaf8, with PersistenceManager: null will be shutdown
2024-05-01T05:15:05,884  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7dcaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4949dc54 created in the thread with id: 119
2024-05-01T05:15:05,891  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7dcaf8 from thread id: 119
2024-05-01T05:15:05,891  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:05,891  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:05,891  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:05,891  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7dcaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4949dc54 will be shutdown
2024-05-01T05:15:05,891  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:05,891  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-05-01T05:15:05,892  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:05,892  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:05,893  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1dd2db7e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:05,893  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1dd2db7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34895fb5 created in the thread with id: 119
2024-05-01T05:15:05,897  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1dd2db7e from thread id: 119
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:05,949  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:05,950  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:05,950  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:05,950  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:05,950  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:05,950  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:05,975  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,06741132988814869/part1=p1value2/part0=502].
2024-05-01T05:15:05,975  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:06,023  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:06,023  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:06,023  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:06,023  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:06,023  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:06,023  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:06,024  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:06,024  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:06,024  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:06,024  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:06,024  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:06,024  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:06,025  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:06,026  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:06,026  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1dd2db7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34895fb5 will be shutdown
2024-05-01T05:15:06,026  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1dd2db7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@401f42c6 created in the thread with id: 119
2024-05-01T05:15:06,030  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:06,030  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:06,030  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:06,031  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1dd2db7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@401f42c6 will be shutdown
2024-05-01T05:15:06,031  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:06,031  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -9
2024-05-01T05:15:06,031  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:06,032  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:06,032  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a5c849a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:06,032  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a5c849a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63dbe596 created in the thread with id: 119
2024-05-01T05:15:06,036  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a5c849a from thread id: 119
2024-05-01T05:15:06,037  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:06,037  WARN [Thread-91] mapred.LocalJobRunner: job_local1233018406_0002
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,06741132988814869/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:06,743  INFO [main] mapreduce.Job: Job job_local1233018406_0002 running in uber mode : false
2024-05-01T05:15:06,744  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:06,744  INFO [main] mapreduce.Job: Job job_local1233018406_0002 failed with state FAILED due to: NA
2024-05-01T05:15:06,745  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1020439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=704118784
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:06,822  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:06,823  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:06,823  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:06,824  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:06,827  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:06,827  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:06,827  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@577bfadb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25ae1f80 will be shutdown
2024-05-01T05:15:06,828  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@577bfadb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2084e65a created in the thread with id: 1
2024-05-01T05:15:06,831  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:06,831  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:06,832  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:06,832  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@577bfadb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2084e65a will be shutdown
2024-05-01T05:15:06,832  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:06,832  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -10
2024-05-01T05:15:06,832  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:06,833  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:06,833  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64fdcf99, with PersistenceManager: null will be shutdown
2024-05-01T05:15:06,833  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64fdcf99, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9f0fc36 created in the thread with id: 1
2024-05-01T05:15:06,837  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64fdcf99 from thread id: 1
2024-05-01T05:15:06,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:06,848  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:06,855  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:06,897  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:06,898  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:06,899  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:06,900  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:06,900  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:06,900  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64fdcf99, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9f0fc36 will be shutdown
2024-05-01T05:15:06,900  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64fdcf99, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@671d97bc created in the thread with id: 1
2024-05-01T05:15:06,903  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:06,904  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:06,904  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:06,904  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64fdcf99, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@671d97bc will be shutdown
2024-05-01T05:15:06,904  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:06,904  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -11
2024-05-01T05:15:06,905  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:06,905  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:06,906  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16c5b50a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:06,906  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16c5b50a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f8659d0 created in the thread with id: 1
2024-05-01T05:15:06,909  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16c5b50a from thread id: 1
2024-05-01T05:15:06,910  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T05:15:06,928  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:06,934  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:06,935  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:06,956  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:06,976  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local319705431_0003
2024-05-01T05:15:06,976  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:07,052  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:07,052  INFO [main] mapreduce.Job: Running job: job_local319705431_0003
2024-05-01T05:15:07,053  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:07,055  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,056  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,057  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:07,058  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,058  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,072  INFO [Thread-137] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:07,072  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local319705431_0003_m_000000_0
2024-05-01T05:15:07,075  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,075  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,077  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,077  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,077  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:07,078  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:07,081  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,081  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,096  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:07,097  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local319705431_0003_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:07,097  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,097  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,102  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:07,102  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local319705431_0003_m_000000_0 is allowed to commit now
2024-05-01T05:15:07,103  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:07,103  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:07,114  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local319705431_0003_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5730978494389157/part1=p1value2/part0=502
2024-05-01T05:15:07,115  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:07,115  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local319705431_0003_m_000000_0' done.
2024-05-01T05:15:07,115  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local319705431_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1530768
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=705691648
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:07,115  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local319705431_0003_m_000000_0
2024-05-01T05:15:07,115  INFO [Thread-137] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:07,166  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:07,166  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:07,166  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:07,166  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:07,166  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:07,166  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:07,167  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:07,167  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:07,167  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:07,167  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:07,167  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:07,167  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:07,168  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:07,169  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:07,169  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:07,169  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2177008, with PersistenceManager: null will be shutdown
2024-05-01T05:15:07,169  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2177008, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5589d00f created in the thread with id: 167
2024-05-01T05:15:07,172  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2177008 from thread id: 167
2024-05-01T05:15:07,172  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:07,172  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:07,173  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:07,173  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2177008, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5589d00f will be shutdown
2024-05-01T05:15:07,173  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:07,173  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -12
2024-05-01T05:15:07,173  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:07,174  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:07,174  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b8d2a1, with PersistenceManager: null will be shutdown
2024-05-01T05:15:07,175  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b8d2a1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a7b2410 created in the thread with id: 167
2024-05-01T05:15:07,178  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b8d2a1 from thread id: 167
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:07,233  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:07,234  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:07,234  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:07,234  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:07,234  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:07,234  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:07,258  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5730978494389157/part1=p1value2/part0=502].
2024-05-01T05:15:07,258  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:07,301  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:07,302  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:07,302  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:07,302  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:07,303  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:07,303  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:07,303  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b8d2a1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a7b2410 will be shutdown
2024-05-01T05:15:07,303  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b8d2a1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b5b722a created in the thread with id: 167
2024-05-01T05:15:07,307  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:07,307  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:07,307  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:07,307  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b8d2a1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b5b722a will be shutdown
2024-05-01T05:15:07,307  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:07,308  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -13
2024-05-01T05:15:07,308  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:07,308  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:07,309  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78086f06, with PersistenceManager: null will be shutdown
2024-05-01T05:15:07,309  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78086f06, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d432f11 created in the thread with id: 167
2024-05-01T05:15:07,311  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78086f06 from thread id: 167
2024-05-01T05:15:07,313  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:07,313  WARN [Thread-137] mapred.LocalJobRunner: job_local319705431_0003
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5730978494389157/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:08,053  INFO [main] mapreduce.Job: Job job_local319705431_0003 running in uber mode : false
2024-05-01T05:15:08,053  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:08,054  INFO [main] mapreduce.Job: Job job_local319705431_0003 failed with state FAILED due to: NA
2024-05-01T05:15:08,055  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1530768
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=705691648
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:08,104  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:08,104  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:08,105  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:08,106  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:08,106  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:08,108  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:08,108  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:08,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16c5b50a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f8659d0 will be shutdown
2024-05-01T05:15:08,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16c5b50a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d6f77d7 created in the thread with id: 1
2024-05-01T05:15:08,112  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:08,112  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:08,112  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:08,112  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16c5b50a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d6f77d7 will be shutdown
2024-05-01T05:15:08,112  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:08,112  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -14
2024-05-01T05:15:08,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:08,113  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,114  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee77baf, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,114  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee77baf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@485deee1 created in the thread with id: 1
2024-05-01T05:15:08,116  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee77baf from thread id: 1
2024-05-01T05:15:08,118  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:08,125  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:08,131  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:08,169  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:08,170  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:08,171  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:08,172  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:08,172  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:08,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee77baf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@485deee1 will be shutdown
2024-05-01T05:15:08,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee77baf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47198524 created in the thread with id: 1
2024-05-01T05:15:08,176  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:08,177  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:08,177  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:08,177  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ee77baf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47198524 will be shutdown
2024-05-01T05:15:08,177  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:08,177  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -15
2024-05-01T05:15:08,177  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:08,178  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,179  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29c59b6e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,179  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29c59b6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@483b7dc4 created in the thread with id: 1
2024-05-01T05:15:08,181  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29c59b6e from thread id: 1
2024-05-01T05:15:08,232  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:08,232  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:08,233  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:08,234  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:08,234  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:08,235  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:08,237  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:08,237  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:08,237  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29c59b6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@483b7dc4 will be shutdown
2024-05-01T05:15:08,237  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29c59b6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23469199 created in the thread with id: 1
2024-05-01T05:15:08,240  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:08,240  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:08,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:08,241  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29c59b6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23469199 will be shutdown
2024-05-01T05:15:08,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:08,242  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -16
2024-05-01T05:15:08,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:08,243  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,243  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a51336a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a51336a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d8056bf created in the thread with id: 1
2024-05-01T05:15:08,246  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a51336a from thread id: 1
2024-05-01T05:15:08,248  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:08,257  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:08,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:08,304  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:08,304  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:08,304  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:08,304  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:08,305  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:08,306  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:08,306  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:08,307  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a51336a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d8056bf will be shutdown
2024-05-01T05:15:08,307  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a51336a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c2a903f created in the thread with id: 1
2024-05-01T05:15:08,309  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:08,310  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:08,310  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:08,310  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a51336a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c2a903f will be shutdown
2024-05-01T05:15:08,310  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:08,310  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -17
2024-05-01T05:15:08,310  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:08,311  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,311  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@77ba583, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,311  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@77ba583, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5613247e created in the thread with id: 1
2024-05-01T05:15:08,314  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@77ba583 from thread id: 1
2024-05-01T05:15:08,315  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:08,322  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:08,329  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:08,363  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:08,364  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:08,364  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:08,364  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:08,364  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:08,364  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:08,364  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:08,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:08,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:08,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:08,365  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:08,365  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:08,366  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:08,366  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:08,366  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@77ba583, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5613247e will be shutdown
2024-05-01T05:15:08,367  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@77ba583, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c08c787 created in the thread with id: 1
2024-05-01T05:15:08,369  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:08,369  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:08,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:08,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@77ba583, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c08c787 will be shutdown
2024-05-01T05:15:08,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:08,370  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -18
2024-05-01T05:15:08,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:08,371  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56478522, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56478522, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3caf5c96 created in the thread with id: 1
2024-05-01T05:15:08,374  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56478522 from thread id: 1
2024-05-01T05:15:08,381  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:08,386  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:08,387  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:08,408  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:08,425  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local464014909_0004
2024-05-01T05:15:08,425  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:08,475  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:08,476  INFO [main] mapreduce.Job: Running job: job_local464014909_0004
2024-05-01T05:15:08,476  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:08,479  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:08,480  INFO [Thread-188] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:08,481  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local464014909_0004_m_000000_0
2024-05-01T05:15:08,484  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:08,486  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T05:15:08,497  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local464014909_0004_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.4759384341148363/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T05:15:08,498  INFO [Thread-188] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:08,502  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.4759384341148363].
2024-05-01T05:15:08,503  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:08,547  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:08,547  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:08,547  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:08,547  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:08,548  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:08,548  INFO [Thread-188] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:08,549  INFO [Thread-188] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:08,550  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,550  INFO [Thread-188] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:08,550  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@250c0057, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,550  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@250c0057, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38210509 created in the thread with id: 220
2024-05-01T05:15:08,553  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@250c0057 from thread id: 220
2024-05-01T05:15:08,553  INFO [Thread-188] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:08,553  INFO [Thread-188] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:08,553  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:08,553  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@250c0057, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38210509 will be shutdown
2024-05-01T05:15:08,554  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:08,554  INFO [Thread-188] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -19
2024-05-01T05:15:08,554  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:08,554  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:08,555  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@211989e0, with PersistenceManager: null will be shutdown
2024-05-01T05:15:08,555  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@211989e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@259dc1cc created in the thread with id: 220
2024-05-01T05:15:08,557  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@211989e0 from thread id: 220
2024-05-01T05:15:08,558  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:08,559  WARN [Thread-188] mapred.LocalJobRunner: job_local464014909_0004
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T05:15:09,476  INFO [main] mapreduce.Job: Job job_local464014909_0004 running in uber mode : false
2024-05-01T05:15:09,476  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:09,477  INFO [main] mapreduce.Job: Job job_local464014909_0004 failed with state FAILED due to: NA
2024-05-01T05:15:09,477  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:09,518  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:09,518  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:09,519  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:09,520  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:09,521  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:09,522  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:09,522  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:09,523  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56478522, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3caf5c96 will be shutdown
2024-05-01T05:15:09,523  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56478522, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38cb1606 created in the thread with id: 1
2024-05-01T05:15:09,526  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:09,526  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:09,526  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:09,526  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56478522, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38cb1606 will be shutdown
2024-05-01T05:15:09,526  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:09,526  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -20
2024-05-01T05:15:09,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:09,527  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:09,528  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: null will be shutdown
2024-05-01T05:15:09,528  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@223cbf0d created in the thread with id: 1
2024-05-01T05:15:09,530  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef from thread id: 1
2024-05-01T05:15:09,531  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:09,540  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:09,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:09,558  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:09,565  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:09,570  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:09,593  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T05:15:09,615  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local999628153_0005
2024-05-01T05:15:09,615  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:09,666  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:09,666  INFO [main] mapreduce.Job: Running job: job_local999628153_0005
2024-05-01T05:15:09,667  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:09,668  INFO [Thread-208] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:09,669  INFO [Thread-208] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:09,669  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T05:15:09,678  INFO [Thread-208] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:09,678  INFO [Thread-208] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:10,667  INFO [main] mapreduce.Job: Job job_local999628153_0005 running in uber mode : false
2024-05-01T05:15:10,667  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:10,668  INFO [main] mapreduce.Job: Job job_local999628153_0005 completed successfully
2024-05-01T05:15:10,668  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:10,668  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:10,678  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:10,678  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T05:15:11,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,054  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[1]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.652">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,108  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,109  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:11,110  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:11,110  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:11,111  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@223cbf0d will be shutdown
2024-05-01T05:15:11,111  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a8b9458 created in the thread with id: 1
2024-05-01T05:15:11,118  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 0842af4c-6d9f-4add-8b59-c92bc0c06072
2024-05-01T05:15:11,119  INFO [main] SessionState: Hive Session ID = 0842af4c-6d9f-4add-8b59-c92bc0c06072
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:11,119  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:11,125  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/0842af4c-6d9f-4add-8b59-c92bc0c06072
2024-05-01T05:15:11,128  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/0842af4c-6d9f-4add-8b59-c92bc0c06072
2024-05-01T05:15:11,131  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/0842af4c-6d9f-4add-8b59-c92bc0c06072/_tmp_space.db
2024-05-01T05:15:11,131  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:11,141  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_SEQUENCEFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.mapred.SequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_SEQUENCEFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T05:15:11,146  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,245  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,246  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:11,246  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:11,247  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:11,249  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:11,249  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:11,249  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a8b9458 will be shutdown
2024-05-01T05:15:11,249  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73234691 created in the thread with id: 1
2024-05-01T05:15:11,253  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:11,253  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:11,253  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:11,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac685ef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73234691 will be shutdown
2024-05-01T05:15:11,253  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:11,253  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -21
2024-05-01T05:15:11,254  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:11,254  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:11,255  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: null will be shutdown
2024-05-01T05:15:11,255  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2474df51 created in the thread with id: 1
2024-05-01T05:15:11,258  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373 from thread id: 1
2024-05-01T05:15:11,259  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:11,289  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:11,298  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:11,342  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,343  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:11,343  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:11,344  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:11,344  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:11,344  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2474df51 will be shutdown
2024-05-01T05:15:11,345  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3291d9c2 created in the thread with id: 1
2024-05-01T05:15:11,347  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:11,347  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:11,348  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:11,348  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4654e373, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3291d9c2 will be shutdown
2024-05-01T05:15:11,348  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:11,348  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -22
2024-05-01T05:15:11,348  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:11,349  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:11,349  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:11,349  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79273a4f created in the thread with id: 1
2024-05-01T05:15:11,351  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a from thread id: 1
2024-05-01T05:15:11,353  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value1,501]	
2024-05-01T05:15:11,371  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:11,376  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:11,377  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:11,398  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:11,414  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local867162917_0006
2024-05-01T05:15:11,414  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:11,467  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:11,467  INFO [main] mapreduce.Job: Running job: job_local867162917_0006
2024-05-01T05:15:11,467  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:11,469  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,470  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,471  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:11,471  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,472  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,485  INFO [Thread-242] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:11,485  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local867162917_0006_m_000000_0
2024-05-01T05:15:11,492  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,492  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,494  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,494  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,494  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:11,495  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T05:15:11,501  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,501  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,530  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:11,534  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local867162917_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:11,534  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,534  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,538  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:11,538  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local867162917_0006_m_000000_0 is allowed to commit now
2024-05-01T05:15:11,538  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:11,538  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:11,548  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local867162917_0006_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8243790006768955/part1=p1value1/part0=501
2024-05-01T05:15:11,549  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:11,549  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local867162917_0006_m_000000_0' done.
2024-05-01T05:15:11,549  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local867162917_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3059661
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=775946240
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:11,549  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local867162917_0006_m_000000_0
2024-05-01T05:15:11,549  INFO [Thread-242] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,595  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:11,596  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:11,596  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:11,597  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:11,597  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:11,597  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@118ee000, with PersistenceManager: null will be shutdown
2024-05-01T05:15:11,597  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@118ee000, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1eb4fb2c created in the thread with id: 276
2024-05-01T05:15:11,600  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@118ee000 from thread id: 276
2024-05-01T05:15:11,600  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:11,600  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:11,600  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:11,600  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@118ee000, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1eb4fb2c will be shutdown
2024-05-01T05:15:11,600  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:11,600  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -23
2024-05-01T05:15:11,601  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:11,601  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:11,602  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6961f018, with PersistenceManager: null will be shutdown
2024-05-01T05:15:11,602  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6961f018, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d020695 created in the thread with id: 276
2024-05-01T05:15:11,604  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6961f018 from thread id: 276
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,647  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:11,648  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T05:15:11,670  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8243790006768955/part1=p1value1/part0=501].
2024-05-01T05:15:11,671  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:11,724  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:11,724  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:11,724  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:11,724  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:11,724  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:11,725  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:11,725  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:11,725  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:11,725  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:11,725  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:11,725  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:11,725  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:11,726  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:11,726  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:11,726  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6961f018, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d020695 will be shutdown
2024-05-01T05:15:11,726  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6961f018, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351e84c0 created in the thread with id: 276
2024-05-01T05:15:11,728  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:11,729  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:11,729  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:11,729  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6961f018, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351e84c0 will be shutdown
2024-05-01T05:15:11,729  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:11,729  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -24
2024-05-01T05:15:11,729  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:11,730  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:11,730  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72923941, with PersistenceManager: null will be shutdown
2024-05-01T05:15:11,730  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72923941, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b25ab08 created in the thread with id: 276
2024-05-01T05:15:11,733  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72923941 from thread id: 276
2024-05-01T05:15:11,734  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:11,734  WARN [Thread-242] mapred.LocalJobRunner: job_local867162917_0006
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8243790006768955/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:12,468  INFO [main] mapreduce.Job: Job job_local867162917_0006 running in uber mode : false
2024-05-01T05:15:12,468  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:12,468  INFO [main] mapreduce.Job: Job job_local867162917_0006 failed with state FAILED due to: NA
2024-05-01T05:15:12,469  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3059661
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=775946240
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:12,515  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:12,515  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:12,515  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:12,516  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:12,516  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:12,517  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:12,519  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:12,519  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:12,519  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79273a4f will be shutdown
2024-05-01T05:15:12,520  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6879e983 created in the thread with id: 1
2024-05-01T05:15:12,522  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:12,522  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:12,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:12,522  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4dd4965a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6879e983 will be shutdown
2024-05-01T05:15:12,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:12,522  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -25
2024-05-01T05:15:12,523  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:12,523  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:12,524  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: null will be shutdown
2024-05-01T05:15:12,524  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@673a9db4 created in the thread with id: 1
2024-05-01T05:15:12,526  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4 from thread id: 1
2024-05-01T05:15:12,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:12,536  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:12,543  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:12,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:12,577  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:12,577  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:12,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:12,577  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:12,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:12,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:12,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:12,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:12,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:12,578  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:12,578  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:12,579  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:12,579  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:12,579  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@673a9db4 will be shutdown
2024-05-01T05:15:12,580  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@515940af created in the thread with id: 1
2024-05-01T05:15:12,582  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:12,582  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:12,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:12,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9f7d4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@515940af will be shutdown
2024-05-01T05:15:12,583  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:12,583  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -26
2024-05-01T05:15:12,583  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:12,583  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:12,584  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: null will be shutdown
2024-05-01T05:15:12,584  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e2578ea created in the thread with id: 1
2024-05-01T05:15:12,586  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818 from thread id: 1
2024-05-01T05:15:12,588  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T05:15:12,610  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:12,615  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:12,616  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:12,637  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:12,653  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local850048406_0007
2024-05-01T05:15:12,653  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:12,703  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:12,703  INFO [main] mapreduce.Job: Running job: job_local850048406_0007
2024-05-01T05:15:12,703  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:12,706  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,706  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,707  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:12,708  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,708  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,721  INFO [Thread-288] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:12,722  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local850048406_0007_m_000000_0
2024-05-01T05:15:12,725  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,725  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,727  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,727  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,727  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:12,728  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:12,731  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,731  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,747  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:12,747  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local850048406_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:12,747  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,747  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,751  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:12,751  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local850048406_0007_m_000000_0 is allowed to commit now
2024-05-01T05:15:12,751  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:12,752  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:12,762  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local850048406_0007_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,051474201627937366/part1=p1value2/part0=502
2024-05-01T05:15:12,762  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:12,763  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local850048406_0007_m_000000_0' done.
2024-05-01T05:15:12,763  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local850048406_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3570354
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=775946240
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:12,763  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local850048406_0007_m_000000_0
2024-05-01T05:15:12,763  INFO [Thread-288] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:12,809  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:12,810  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:12,810  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:12,811  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:12,811  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:12,811  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e2fdf0f, with PersistenceManager: null will be shutdown
2024-05-01T05:15:12,811  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e2fdf0f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ce749f2 created in the thread with id: 324
2024-05-01T05:15:12,813  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e2fdf0f from thread id: 324
2024-05-01T05:15:12,813  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:12,813  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:12,814  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:12,814  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e2fdf0f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ce749f2 will be shutdown
2024-05-01T05:15:12,814  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:12,814  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -27
2024-05-01T05:15:12,814  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:12,814  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:12,815  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f1d4dfb, with PersistenceManager: null will be shutdown
2024-05-01T05:15:12,815  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f1d4dfb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20d7cda5 created in the thread with id: 324
2024-05-01T05:15:12,817  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f1d4dfb from thread id: 324
2024-05-01T05:15:12,859  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:12,859  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:12,859  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:12,859  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:12,859  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:12,859  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:12,860  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:12,860  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:12,860  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:12,860  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:12,860  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:12,860  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:12,883  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,051474201627937366/part1=p1value2/part0=502].
2024-05-01T05:15:12,883  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:12,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:12,921  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:12,922  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:12,922  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:12,922  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f1d4dfb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20d7cda5 will be shutdown
2024-05-01T05:15:12,922  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f1d4dfb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f55f7e5 created in the thread with id: 324
2024-05-01T05:15:12,925  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:12,925  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:12,925  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:12,925  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f1d4dfb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f55f7e5 will be shutdown
2024-05-01T05:15:12,925  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:12,925  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -28
2024-05-01T05:15:12,925  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:12,926  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:12,927  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575ceb50, with PersistenceManager: null will be shutdown
2024-05-01T05:15:12,927  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575ceb50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@494f94f created in the thread with id: 324
2024-05-01T05:15:12,928  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@575ceb50 from thread id: 324
2024-05-01T05:15:12,930  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:12,930  WARN [Thread-288] mapred.LocalJobRunner: job_local850048406_0007
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,051474201627937366/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:13,704  INFO [main] mapreduce.Job: Job job_local850048406_0007 running in uber mode : false
2024-05-01T05:15:13,704  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:13,704  INFO [main] mapreduce.Job: Job job_local850048406_0007 failed with state FAILED due to: NA
2024-05-01T05:15:13,705  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3570354
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=775946240
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:13,752  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:13,752  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:13,752  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:13,752  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:13,752  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:13,752  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:13,753  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:13,753  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:13,753  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:13,753  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:13,753  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:13,753  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:13,755  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:13,758  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:13,758  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:13,758  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e2578ea will be shutdown
2024-05-01T05:15:13,759  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ebf776c created in the thread with id: 1
2024-05-01T05:15:13,762  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:13,762  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:13,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:13,762  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@656c5818, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ebf776c will be shutdown
2024-05-01T05:15:13,763  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:13,763  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -29
2024-05-01T05:15:13,763  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:13,764  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:13,765  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: null will be shutdown
2024-05-01T05:15:13,765  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@570299e3 created in the thread with id: 1
2024-05-01T05:15:13,768  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02 from thread id: 1
2024-05-01T05:15:13,769  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:13,779  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:13,787  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:13,838  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:13,838  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:13,838  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:13,838  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:13,839  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:13,839  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:13,840  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:13,840  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:13,841  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@570299e3 will be shutdown
2024-05-01T05:15:13,841  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f430ea8 created in the thread with id: 1
2024-05-01T05:15:13,844  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:13,844  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:13,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:13,844  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ad50b02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f430ea8 will be shutdown
2024-05-01T05:15:13,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:13,844  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -30
2024-05-01T05:15:13,845  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:13,846  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:13,846  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: null will be shutdown
2024-05-01T05:15:13,846  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c6b300a created in the thread with id: 1
2024-05-01T05:15:13,849  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615 from thread id: 1
2024-05-01T05:15:13,850  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T05:15:13,867  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:13,872  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:13,873  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:13,893  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:13,912  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2019761915_0008
2024-05-01T05:15:13,912  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:13,970  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:13,970  INFO [main] mapreduce.Job: Running job: job_local2019761915_0008
2024-05-01T05:15:13,970  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:13,973  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:13,973  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:13,974  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:13,975  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:13,975  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:14,017  INFO [Thread-334] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:14,017  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2019761915_0008_m_000000_0
2024-05-01T05:15:14,020  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:14,020  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:14,021  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:14,021  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:14,021  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:14,022  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:14,025  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:14,025  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:14,038  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:14,038  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2019761915_0008_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:14,038  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:14,038  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:14,043  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:14,043  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2019761915_0008_m_000000_0 is allowed to commit now
2024-05-01T05:15:14,043  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:14,043  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:14,054  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2019761915_0008_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,49483939722765524/part1=p1value2/part0=502
2024-05-01T05:15:14,054  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:14,054  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2019761915_0008_m_000000_0' done.
2024-05-01T05:15:14,054  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2019761915_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4083424
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=778567680
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:14,054  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2019761915_0008_m_000000_0
2024-05-01T05:15:14,054  INFO [Thread-334] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:14,102  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:14,103  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:14,103  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:14,103  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:14,104  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:14,104  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:14,104  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:14,105  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@463c3e8a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:14,105  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@463c3e8a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@584040e8 created in the thread with id: 372
2024-05-01T05:15:14,107  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@463c3e8a from thread id: 372
2024-05-01T05:15:14,107  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:14,107  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:14,107  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:14,107  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@463c3e8a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@584040e8 will be shutdown
2024-05-01T05:15:14,107  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:14,107  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -31
2024-05-01T05:15:14,107  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:14,108  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:14,108  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@532129d, with PersistenceManager: null will be shutdown
2024-05-01T05:15:14,108  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@532129d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ad89f8 created in the thread with id: 372
2024-05-01T05:15:14,111  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@532129d from thread id: 372
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:14,154  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:14,155  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:14,177  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,49483939722765524/part1=p1value2/part0=502].
2024-05-01T05:15:14,177  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:14,215  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:14,216  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:14,216  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:14,217  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:14,217  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:14,217  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@532129d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ad89f8 will be shutdown
2024-05-01T05:15:14,217  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@532129d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27b68137 created in the thread with id: 372
2024-05-01T05:15:14,219  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:14,219  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:14,220  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:14,220  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@532129d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27b68137 will be shutdown
2024-05-01T05:15:14,220  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:14,220  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -32
2024-05-01T05:15:14,220  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:14,221  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:14,221  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d72c8c5, with PersistenceManager: null will be shutdown
2024-05-01T05:15:14,221  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d72c8c5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f2c4072 created in the thread with id: 372
2024-05-01T05:15:14,223  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d72c8c5 from thread id: 372
2024-05-01T05:15:14,224  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:14,224  WARN [Thread-334] mapred.LocalJobRunner: job_local2019761915_0008
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,49483939722765524/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:14,971  INFO [main] mapreduce.Job: Job job_local2019761915_0008 running in uber mode : false
2024-05-01T05:15:14,971  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:14,971  INFO [main] mapreduce.Job: Job job_local2019761915_0008 failed with state FAILED due to: NA
2024-05-01T05:15:14,972  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4083424
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=778567680
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:15,024  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:15,025  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:15,026  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:15,028  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:15,028  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:15,028  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c6b300a will be shutdown
2024-05-01T05:15:15,029  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5340ccb9 created in the thread with id: 1
2024-05-01T05:15:15,031  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:15,031  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:15,031  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:15,031  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b340615, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5340ccb9 will be shutdown
2024-05-01T05:15:15,032  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:15,032  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -33
2024-05-01T05:15:15,032  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:15,033  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,033  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,033  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10e4ee33 created in the thread with id: 1
2024-05-01T05:15:15,035  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320 from thread id: 1
2024-05-01T05:15:15,037  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:15,044  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:15,051  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:15,088  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:15,088  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:15,089  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:15,089  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:15,089  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10e4ee33 will be shutdown
2024-05-01T05:15:15,089  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f9ccd0c created in the thread with id: 1
2024-05-01T05:15:15,091  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:15,091  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:15,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:15,092  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61c58320, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f9ccd0c will be shutdown
2024-05-01T05:15:15,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:15,092  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -34
2024-05-01T05:15:15,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:15,093  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,093  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,093  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e4c4fda created in the thread with id: 1
2024-05-01T05:15:15,095  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f from thread id: 1
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:15,151  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:15,151  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:15,152  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:15,153  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:15,154  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:15,154  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e4c4fda will be shutdown
2024-05-01T05:15:15,154  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77db231c created in the thread with id: 1
2024-05-01T05:15:15,156  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:15,156  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:15,156  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:15,156  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@178ba69f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77db231c will be shutdown
2024-05-01T05:15:15,156  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:15,156  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -35
2024-05-01T05:15:15,156  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:15,157  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,158  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,158  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e617c0e created in the thread with id: 1
2024-05-01T05:15:15,159  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3 from thread id: 1
2024-05-01T05:15:15,160  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:15,167  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:15,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:15,228  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:15,228  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:15,229  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:15,231  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:15,231  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:15,232  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e617c0e will be shutdown
2024-05-01T05:15:15,232  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e73f5e7 created in the thread with id: 1
2024-05-01T05:15:15,234  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:15,234  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:15,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:15,235  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e9dcdd3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e73f5e7 will be shutdown
2024-05-01T05:15:15,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:15,235  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -36
2024-05-01T05:15:15,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:15,236  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,237  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@178c6261 created in the thread with id: 1
2024-05-01T05:15:15,239  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b from thread id: 1
2024-05-01T05:15:15,240  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:15,247  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:15,253  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:15,289  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:15,290  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:15,290  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:15,291  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@178c6261 will be shutdown
2024-05-01T05:15:15,291  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c846d55 created in the thread with id: 1
2024-05-01T05:15:15,293  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:15,293  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:15,293  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:15,293  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4bb10b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c846d55 will be shutdown
2024-05-01T05:15:15,293  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:15,293  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -37
2024-05-01T05:15:15,293  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:15,294  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,294  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,294  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e1b5532 created in the thread with id: 1
2024-05-01T05:15:15,296  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc from thread id: 1
2024-05-01T05:15:15,303  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:15,308  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:15,308  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:15,329  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:15,347  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1089534937_0009
2024-05-01T05:15:15,347  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:15,398  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:15,398  INFO [main] mapreduce.Job: Running job: job_local1089534937_0009
2024-05-01T05:15:15,398  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:15,400  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:15,402  INFO [Thread-385] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:15,402  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1089534937_0009_m_000000_0
2024-05-01T05:15:15,406  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:15,407  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T05:15:15,413  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1089534937_0009_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.613909020465118/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T05:15:15,413  INFO [Thread-385] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:15,415  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.613909020465118].
2024-05-01T05:15:15,415  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:15,463  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:15,464  INFO [Thread-385] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:15,465  INFO [Thread-385] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:15,465  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,465  INFO [Thread-385] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:15,466  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5308a2e3, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,466  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5308a2e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b831b21 created in the thread with id: 425
2024-05-01T05:15:15,468  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5308a2e3 from thread id: 425
2024-05-01T05:15:15,468  INFO [Thread-385] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:15,469  INFO [Thread-385] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:15,469  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:15,469  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5308a2e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b831b21 will be shutdown
2024-05-01T05:15:15,469  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:15,469  INFO [Thread-385] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -38
2024-05-01T05:15:15,469  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:15,470  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:15,470  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@51818222, with PersistenceManager: null will be shutdown
2024-05-01T05:15:15,471  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@51818222, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ef38a1d created in the thread with id: 425
2024-05-01T05:15:15,473  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@51818222 from thread id: 425
2024-05-01T05:15:15,474  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:15,474  WARN [Thread-385] mapred.LocalJobRunner: job_local1089534937_0009
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T05:15:16,398  INFO [main] mapreduce.Job: Job job_local1089534937_0009 running in uber mode : false
2024-05-01T05:15:16,399  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:16,399  INFO [main] mapreduce.Job: Job job_local1089534937_0009 failed with state FAILED due to: NA
2024-05-01T05:15:16,399  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:16,438  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:16,439  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:16,440  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:16,441  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:16,441  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e1b5532 will be shutdown
2024-05-01T05:15:16,441  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61d150af created in the thread with id: 1
2024-05-01T05:15:16,444  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:16,444  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:16,444  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:16,444  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@289da1bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61d150af will be shutdown
2024-05-01T05:15:16,444  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:16,444  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -39
2024-05-01T05:15:16,444  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:16,445  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:16,445  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: null will be shutdown
2024-05-01T05:15:16,446  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dbcee03 created in the thread with id: 1
2024-05-01T05:15:16,447  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39 from thread id: 1
2024-05-01T05:15:16,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:16,456  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:16,457  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:16,467  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:16,473  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:16,478  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:16,500  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T05:15:16,515  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local826001041_0010
2024-05-01T05:15:16,515  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:16,573  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:16,573  INFO [main] mapreduce.Job: Running job: job_local826001041_0010
2024-05-01T05:15:16,574  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:16,574  INFO [Thread-405] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:16,574  INFO [Thread-405] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:16,574  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T05:15:16,583  INFO [Thread-405] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:16,583  INFO [Thread-405] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:17,574  INFO [main] mapreduce.Job: Job job_local826001041_0010 running in uber mode : false
2024-05-01T05:15:17,574  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:17,574  INFO [main] mapreduce.Job: Job job_local826001041_0010 completed successfully
2024-05-01T05:15:17,574  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:17,575  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:17,581  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:17,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:17,716  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[2]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.417">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T05:15:17,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:17,761  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:17,763  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:17,763  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:17,764  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dbcee03 will be shutdown
2024-05-01T05:15:17,764  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b3f62d7 created in the thread with id: 1
2024-05-01T05:15:17,766  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 4f63983c-7b1d-4495-abda-6fea12f11171
2024-05-01T05:15:17,767  INFO [main] SessionState: Hive Session ID = 4f63983c-7b1d-4495-abda-6fea12f11171
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:17,767  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:17,773  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/4f63983c-7b1d-4495-abda-6fea12f11171
2024-05-01T05:15:17,776  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/4f63983c-7b1d-4495-abda-6fea12f11171
2024-05-01T05:15:17,779  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/4f63983c-7b1d-4495-abda-6fea12f11171/_tmp_space.db
2024-05-01T05:15:17,779  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:17,781  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_RCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_RCFILE, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T05:15:17,783  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:17,865  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:17,866  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:17,866  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:17,866  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:17,866  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:17,867  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:17,869  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:17,869  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:17,870  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b3f62d7 will be shutdown
2024-05-01T05:15:17,870  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42012093 created in the thread with id: 1
2024-05-01T05:15:17,872  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:17,873  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:17,873  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:17,873  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47666b39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42012093 will be shutdown
2024-05-01T05:15:17,873  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:17,873  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -40
2024-05-01T05:15:17,873  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:17,874  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:17,874  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: null will be shutdown
2024-05-01T05:15:17,875  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ba27ce6 created in the thread with id: 1
2024-05-01T05:15:17,876  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321 from thread id: 1
2024-05-01T05:15:17,878  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:17,886  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:17,895  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:17,943  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:17,943  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:17,944  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:17,944  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:17,944  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ba27ce6 will be shutdown
2024-05-01T05:15:17,944  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ea45a5b created in the thread with id: 1
2024-05-01T05:15:17,947  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:17,947  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:17,947  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:17,947  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19c24321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ea45a5b will be shutdown
2024-05-01T05:15:17,947  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:17,947  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -41
2024-05-01T05:15:17,947  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:17,948  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:17,949  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: null will be shutdown
2024-05-01T05:15:17,949  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ad6895a created in the thread with id: 1
2024-05-01T05:15:17,951  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73 from thread id: 1
2024-05-01T05:15:17,952  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value1,501]	
2024-05-01T05:15:17,971  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:17,976  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:17,977  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:17,997  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:18,013  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1084230405_0011
2024-05-01T05:15:18,013  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:18,063  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:18,063  INFO [main] mapreduce.Job: Running job: job_local1084230405_0011
2024-05-01T05:15:18,064  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:18,065  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,065  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,066  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:18,067  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,067  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,080  INFO [Thread-439] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:18,080  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1084230405_0011_m_000000_0
2024-05-01T05:15:18,086  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,086  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,088  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,088  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,088  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:18,088  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T05:15:18,095  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,095  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,124  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:18,125  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T05:15:18,125  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T05:15:18,128  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1084230405_0011_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:18,128  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,128  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,132  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:18,132  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1084230405_0011_m_000000_0 is allowed to commit now
2024-05-01T05:15:18,132  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:18,132  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:18,142  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1084230405_0011_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,23362824991309727/part1=p1value1/part0=501
2024-05-01T05:15:18,143  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:18,143  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1084230405_0011_m_000000_0' done.
2024-05-01T05:15:18,143  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1084230405_0011_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5617472
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=778567680
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:18,143  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1084230405_0011_m_000000_0
2024-05-01T05:15:18,143  INFO [Thread-439] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:18,204  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:18,204  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:18,205  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:18,206  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:18,206  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:18,206  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@819f7b6, with PersistenceManager: null will be shutdown
2024-05-01T05:15:18,206  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@819f7b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69185d3f created in the thread with id: 481
2024-05-01T05:15:18,208  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@819f7b6 from thread id: 481
2024-05-01T05:15:18,208  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:18,208  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:18,208  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:18,208  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@819f7b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69185d3f will be shutdown
2024-05-01T05:15:18,208  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:18,208  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -42
2024-05-01T05:15:18,208  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:18,209  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:18,209  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ff0185, with PersistenceManager: null will be shutdown
2024-05-01T05:15:18,210  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ff0185, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ae8cdc5 created in the thread with id: 481
2024-05-01T05:15:18,211  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ff0185 from thread id: 481
2024-05-01T05:15:18,254  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:18,254  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:18,254  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:18,254  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:18,255  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:18,255  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T05:15:18,277  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,23362824991309727/part1=p1value1/part0=501].
2024-05-01T05:15:18,277  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:18,317  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:18,318  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:18,318  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:18,318  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:18,318  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:18,318  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:18,319  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:18,319  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:18,319  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ff0185, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ae8cdc5 will be shutdown
2024-05-01T05:15:18,320  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ff0185, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38d59735 created in the thread with id: 481
2024-05-01T05:15:18,321  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:18,322  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:18,322  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:18,322  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ff0185, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38d59735 will be shutdown
2024-05-01T05:15:18,322  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:18,322  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -43
2024-05-01T05:15:18,322  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:18,324  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:18,324  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c946c03, with PersistenceManager: null will be shutdown
2024-05-01T05:15:18,324  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c946c03, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77853a2b created in the thread with id: 481
2024-05-01T05:15:18,327  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c946c03 from thread id: 481
2024-05-01T05:15:18,328  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:18,328  WARN [Thread-439] mapred.LocalJobRunner: job_local1084230405_0011
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,23362824991309727/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:19,064  INFO [main] mapreduce.Job: Job job_local1084230405_0011 running in uber mode : false
2024-05-01T05:15:19,064  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:19,064  INFO [main] mapreduce.Job: Job job_local1084230405_0011 failed with state FAILED due to: NA
2024-05-01T05:15:19,065  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5617472
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=778567680
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:19,114  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:19,115  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:19,115  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:19,115  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:19,115  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:19,115  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:19,116  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:19,118  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:19,118  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:19,118  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ad6895a will be shutdown
2024-05-01T05:15:19,118  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33f4844b created in the thread with id: 1
2024-05-01T05:15:19,120  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:19,121  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:19,121  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:19,121  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a349a73, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33f4844b will be shutdown
2024-05-01T05:15:19,121  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:19,121  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -44
2024-05-01T05:15:19,121  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:19,122  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:19,122  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: null will be shutdown
2024-05-01T05:15:19,123  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106edde4 created in the thread with id: 1
2024-05-01T05:15:19,124  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be from thread id: 1
2024-05-01T05:15:19,126  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:19,162  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:19,168  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:19,201  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:19,201  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:19,202  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:19,202  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:19,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106edde4 will be shutdown
2024-05-01T05:15:19,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66851aa5 created in the thread with id: 1
2024-05-01T05:15:19,204  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:19,205  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:19,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:19,205  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39fc17be, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66851aa5 will be shutdown
2024-05-01T05:15:19,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:19,205  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -45
2024-05-01T05:15:19,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:19,206  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:19,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e47637c, with PersistenceManager: null will be shutdown
2024-05-01T05:15:19,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e47637c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@606f0f70 created in the thread with id: 1
2024-05-01T05:15:19,209  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e47637c from thread id: 1
2024-05-01T05:15:19,211  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T05:15:19,226  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:19,231  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:19,232  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:19,253  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:19,269  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1048426613_0012
2024-05-01T05:15:19,269  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:19,318  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:19,319  INFO [main] mapreduce.Job: Running job: job_local1048426613_0012
2024-05-01T05:15:19,319  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:19,320  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,320  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,321  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:19,322  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,322  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,335  INFO [Thread-485] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:19,336  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1048426613_0012_m_000000_0
2024-05-01T05:15:19,338  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,338  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,339  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,339  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,339  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:19,340  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:19,342  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,342  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,355  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:19,355  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T05:15:19,355  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T05:15:19,355  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1048426613_0012_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:19,355  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,355  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,359  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:19,359  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1048426613_0012_m_000000_0 is allowed to commit now
2024-05-01T05:15:19,359  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:19,359  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:19,369  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1048426613_0012_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,35571753751701074/part1=p1value2/part0=502
2024-05-01T05:15:19,369  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:19,369  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1048426613_0012_m_000000_0' done.
2024-05-01T05:15:19,370  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1048426613_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6130658
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847773696
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:19,370  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1048426613_0012_m_000000_0
2024-05-01T05:15:19,370  INFO [Thread-485] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:19,414  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:19,415  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:19,415  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:19,416  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:19,416  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:19,416  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:19,417  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d614609, with PersistenceManager: null will be shutdown
2024-05-01T05:15:19,417  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d614609, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12ee51f7 created in the thread with id: 529
2024-05-01T05:15:19,418  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d614609 from thread id: 529
2024-05-01T05:15:19,418  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:19,419  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:19,419  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:19,419  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d614609, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12ee51f7 will be shutdown
2024-05-01T05:15:19,419  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:19,419  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -46
2024-05-01T05:15:19,419  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:19,420  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:19,420  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a8ed0d0, with PersistenceManager: null will be shutdown
2024-05-01T05:15:19,420  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a8ed0d0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c695632 created in the thread with id: 529
2024-05-01T05:15:19,422  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a8ed0d0 from thread id: 529
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:19,466  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:19,466  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:19,489  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,35571753751701074/part1=p1value2/part0=502].
2024-05-01T05:15:19,489  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:19,528  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:19,528  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:19,529  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:19,529  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:19,529  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a8ed0d0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c695632 will be shutdown
2024-05-01T05:15:19,529  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a8ed0d0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b860f9 created in the thread with id: 529
2024-05-01T05:15:19,531  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:19,531  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:19,531  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:19,531  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a8ed0d0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b860f9 will be shutdown
2024-05-01T05:15:19,531  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:19,532  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -47
2024-05-01T05:15:19,532  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:19,532  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:19,533  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1081eb5e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:19,533  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1081eb5e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ffb1c5c created in the thread with id: 529
2024-05-01T05:15:19,534  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1081eb5e from thread id: 529
2024-05-01T05:15:19,535  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:19,535  WARN [Thread-485] mapred.LocalJobRunner: job_local1048426613_0012
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,35571753751701074/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:20,319  INFO [main] mapreduce.Job: Job job_local1048426613_0012 running in uber mode : false
2024-05-01T05:15:20,319  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:20,319  INFO [main] mapreduce.Job: Job job_local1048426613_0012 failed with state FAILED due to: NA
2024-05-01T05:15:20,320  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6130658
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847773696
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:20,366  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:20,366  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:20,367  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:20,368  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:20,368  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:20,369  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e47637c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@606f0f70 will be shutdown
2024-05-01T05:15:20,369  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e47637c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78c23ade created in the thread with id: 1
2024-05-01T05:15:20,371  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:20,371  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:20,371  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:20,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e47637c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78c23ade will be shutdown
2024-05-01T05:15:20,371  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:20,371  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -48
2024-05-01T05:15:20,371  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:20,372  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:20,372  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb1e868, with PersistenceManager: null will be shutdown
2024-05-01T05:15:20,372  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb1e868, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71a7cf7c created in the thread with id: 1
2024-05-01T05:15:20,374  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb1e868 from thread id: 1
2024-05-01T05:15:20,375  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:20,381  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:20,387  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:20,420  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:20,421  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:20,421  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:20,422  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:20,422  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:20,422  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb1e868, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71a7cf7c will be shutdown
2024-05-01T05:15:20,422  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb1e868, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@712594f4 created in the thread with id: 1
2024-05-01T05:15:20,424  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:20,424  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:20,424  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:20,424  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb1e868, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@712594f4 will be shutdown
2024-05-01T05:15:20,424  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:20,424  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -49
2024-05-01T05:15:20,425  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:20,425  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:20,425  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a74c940, with PersistenceManager: null will be shutdown
2024-05-01T05:15:20,426  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a74c940, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66576bd2 created in the thread with id: 1
2024-05-01T05:15:20,427  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a74c940 from thread id: 1
2024-05-01T05:15:20,428  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T05:15:20,440  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:20,445  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:20,445  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:20,467  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:20,483  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T05:15:20,483  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local360044202_0013
2024-05-01T05:15:20,483  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:20,532  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:20,532  INFO [main] mapreduce.Job: Running job: job_local360044202_0013
2024-05-01T05:15:20,533  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:20,534  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,534  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,535  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:20,536  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,536  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,549  INFO [Thread-531] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:20,549  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local360044202_0013_m_000000_0
2024-05-01T05:15:20,551  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,551  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,553  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,553  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,553  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:20,553  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:20,555  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,555  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,568  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:20,568  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T05:15:20,568  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T05:15:20,568  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local360044202_0013_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:20,568  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,568  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,572  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:20,572  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local360044202_0013_m_000000_0 is allowed to commit now
2024-05-01T05:15:20,572  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:20,572  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:20,582  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local360044202_0013_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7636211045245921/part1=p1value2/part0=502
2024-05-01T05:15:20,583  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:20,583  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local360044202_0013_m_000000_0' done.
2024-05-01T05:15:20,583  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local360044202_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6641443
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847773696
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:20,583  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local360044202_0013_m_000000_0
2024-05-01T05:15:20,583  INFO [Thread-531] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:20,628  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:20,628  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:20,629  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:20,630  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:20,630  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:20,630  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56656075, with PersistenceManager: null will be shutdown
2024-05-01T05:15:20,631  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56656075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c6461aa created in the thread with id: 577
2024-05-01T05:15:20,633  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56656075 from thread id: 577
2024-05-01T05:15:20,633  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:20,633  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:20,633  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:20,633  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56656075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c6461aa will be shutdown
2024-05-01T05:15:20,634  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:20,634  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -50
2024-05-01T05:15:20,634  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:20,634  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:20,635  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@505c04a2, with PersistenceManager: null will be shutdown
2024-05-01T05:15:20,635  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@505c04a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@201dec22 created in the thread with id: 577
2024-05-01T05:15:20,636  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@505c04a2 from thread id: 577
2024-05-01T05:15:20,678  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:20,678  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:20,678  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:20,679  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:20,679  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:20,702  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7636211045245921/part1=p1value2/part0=502].
2024-05-01T05:15:20,702  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:20,741  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:20,741  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:20,742  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:20,742  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:20,742  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@505c04a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@201dec22 will be shutdown
2024-05-01T05:15:20,742  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@505c04a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3460fae9 created in the thread with id: 577
2024-05-01T05:15:20,744  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:20,744  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:20,745  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:20,745  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@505c04a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3460fae9 will be shutdown
2024-05-01T05:15:20,745  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:20,745  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -51
2024-05-01T05:15:20,745  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:20,746  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:20,746  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd9c94, with PersistenceManager: null will be shutdown
2024-05-01T05:15:20,746  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd9c94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@574d5a78 created in the thread with id: 577
2024-05-01T05:15:20,748  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd9c94 from thread id: 577
2024-05-01T05:15:20,749  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:20,750  WARN [Thread-531] mapred.LocalJobRunner: job_local360044202_0013
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7636211045245921/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:21,533  INFO [main] mapreduce.Job: Job job_local360044202_0013 running in uber mode : false
2024-05-01T05:15:21,533  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:21,533  INFO [main] mapreduce.Job: Job job_local360044202_0013 failed with state FAILED due to: NA
2024-05-01T05:15:21,534  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6641443
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847773696
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:21,579  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:21,579  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:21,580  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:21,581  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:21,581  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:21,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a74c940, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66576bd2 will be shutdown
2024-05-01T05:15:21,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a74c940, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@391b03b created in the thread with id: 1
2024-05-01T05:15:21,583  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:21,584  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:21,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:21,584  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a74c940, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@391b03b will be shutdown
2024-05-01T05:15:21,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:21,584  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -52
2024-05-01T05:15:21,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:21,585  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,585  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24e79a4d, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,585  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24e79a4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5542418c created in the thread with id: 1
2024-05-01T05:15:21,586  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24e79a4d from thread id: 1
2024-05-01T05:15:21,587  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:21,593  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:21,598  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:21,631  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:21,631  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:21,632  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:21,632  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:21,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24e79a4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5542418c will be shutdown
2024-05-01T05:15:21,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24e79a4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f3a92fd created in the thread with id: 1
2024-05-01T05:15:21,634  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:21,634  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:21,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:21,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24e79a4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f3a92fd will be shutdown
2024-05-01T05:15:21,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:21,634  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -53
2024-05-01T05:15:21,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:21,635  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,635  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26f07261, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,635  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26f07261, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b55ea4d created in the thread with id: 1
2024-05-01T05:15:21,637  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26f07261 from thread id: 1
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:21,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:21,684  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:21,684  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:21,684  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:21,686  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:21,686  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:21,686  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26f07261, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b55ea4d will be shutdown
2024-05-01T05:15:21,686  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26f07261, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ce2c5f6 created in the thread with id: 1
2024-05-01T05:15:21,688  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:21,688  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:21,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:21,688  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26f07261, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ce2c5f6 will be shutdown
2024-05-01T05:15:21,689  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:21,689  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -54
2024-05-01T05:15:21,689  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:21,689  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,690  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25511895, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,690  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25511895, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f569d created in the thread with id: 1
2024-05-01T05:15:21,691  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25511895 from thread id: 1
2024-05-01T05:15:21,692  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:21,698  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:21,743  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:21,743  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:21,744  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:21,745  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:21,745  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:21,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25511895, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f569d will be shutdown
2024-05-01T05:15:21,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25511895, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@643a73fa created in the thread with id: 1
2024-05-01T05:15:21,747  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:21,748  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:21,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:21,748  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25511895, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@643a73fa will be shutdown
2024-05-01T05:15:21,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:21,748  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -55
2024-05-01T05:15:21,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:21,749  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21539796, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21539796, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@215f8d7 created in the thread with id: 1
2024-05-01T05:15:21,750  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21539796 from thread id: 1
2024-05-01T05:15:21,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:21,757  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:21,762  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:21,794  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:21,795  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:21,795  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:21,795  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:21,796  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:21,796  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:21,796  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21539796, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@215f8d7 will be shutdown
2024-05-01T05:15:21,796  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21539796, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55cf5626 created in the thread with id: 1
2024-05-01T05:15:21,798  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:21,798  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:21,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:21,798  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21539796, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55cf5626 will be shutdown
2024-05-01T05:15:21,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:21,798  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -56
2024-05-01T05:15:21,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:21,799  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,799  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3497ecea, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,799  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3497ecea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e487d57 created in the thread with id: 1
2024-05-01T05:15:21,801  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3497ecea from thread id: 1
2024-05-01T05:15:21,808  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:21,813  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:21,814  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:21,834  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:21,849  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local795722893_0014
2024-05-01T05:15:21,849  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:21,899  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:21,899  INFO [main] mapreduce.Job: Running job: job_local795722893_0014
2024-05-01T05:15:21,899  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:21,901  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:21,902  INFO [Thread-582] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:21,903  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local795722893_0014_m_000000_0
2024-05-01T05:15:21,905  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:21,906  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T05:15:21,910  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local795722893_0014_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.7549115397924484/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T05:15:21,910  INFO [Thread-582] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:21,911  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.7549115397924484].
2024-05-01T05:15:21,911  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:21,950  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:21,950  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:21,951  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:21,951  INFO [Thread-582] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:21,952  INFO [Thread-582] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:21,952  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,952  INFO [Thread-582] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:21,952  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc08a98, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,952  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc08a98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69633908 created in the thread with id: 630
2024-05-01T05:15:21,954  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc08a98 from thread id: 630
2024-05-01T05:15:21,955  INFO [Thread-582] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:21,955  INFO [Thread-582] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:21,955  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:21,955  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc08a98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69633908 will be shutdown
2024-05-01T05:15:21,955  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:21,955  INFO [Thread-582] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -57
2024-05-01T05:15:21,955  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:21,956  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:21,956  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1bfdc131, with PersistenceManager: null will be shutdown
2024-05-01T05:15:21,956  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1bfdc131, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f4ccaff created in the thread with id: 630
2024-05-01T05:15:21,958  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1bfdc131 from thread id: 630
2024-05-01T05:15:21,959  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:21,959  WARN [Thread-582] mapred.LocalJobRunner: job_local795722893_0014
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T05:15:22,899  INFO [main] mapreduce.Job: Job job_local795722893_0014 running in uber mode : false
2024-05-01T05:15:22,900  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:22,900  INFO [main] mapreduce.Job: Job job_local795722893_0014 failed with state FAILED due to: NA
2024-05-01T05:15:22,900  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:22,939  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:22,940  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:22,940  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:22,942  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:22,942  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:22,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3497ecea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e487d57 will be shutdown
2024-05-01T05:15:22,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3497ecea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4bd1b07d created in the thread with id: 1
2024-05-01T05:15:22,944  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:22,944  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:22,944  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:22,944  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3497ecea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4bd1b07d will be shutdown
2024-05-01T05:15:22,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:22,945  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -58
2024-05-01T05:15:22,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:22,945  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:22,946  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: null will be shutdown
2024-05-01T05:15:22,946  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e3d6d0 created in the thread with id: 1
2024-05-01T05:15:22,947  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68 from thread id: 1
2024-05-01T05:15:22,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:22,954  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:22,954  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:22,958  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:22,963  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:22,968  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:22,989  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T05:15:23,005  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1869628028_0015
2024-05-01T05:15:23,005  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:23,053  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:23,054  INFO [main] mapreduce.Job: Running job: job_local1869628028_0015
2024-05-01T05:15:23,054  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:23,054  INFO [Thread-602] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:23,054  INFO [Thread-602] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:23,054  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T05:15:23,062  INFO [Thread-602] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:23,062  INFO [Thread-602] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:24,054  INFO [main] mapreduce.Job: Job job_local1869628028_0015 running in uber mode : false
2024-05-01T05:15:24,054  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:24,054  INFO [main] mapreduce.Job: Job job_local1869628028_0015 completed successfully
2024-05-01T05:15:24,054  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:24,055  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:24,060  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:24,060  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,133  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[3]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.383">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,176  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:24,178  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:24,178  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:24,178  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e3d6d0 will be shutdown
2024-05-01T05:15:24,178  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d0acb8f created in the thread with id: 1
2024-05-01T05:15:24,180  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = e0b36e4b-df4e-4a50-b286-08a7fd103073
2024-05-01T05:15:24,180  INFO [main] SessionState: Hive Session ID = e0b36e4b-df4e-4a50-b286-08a7fd103073
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:24,181  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:24,187  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/e0b36e4b-df4e-4a50-b286-08a7fd103073
2024-05-01T05:15:24,189  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/e0b36e4b-df4e-4a50-b286-08a7fd103073
2024-05-01T05:15:24,192  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/e0b36e4b-df4e-4a50-b286-08a7fd103073/_tmp_space.db
2024-05-01T05:15:24,192  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:24,194  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_ORCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_ORCFILE, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T05:15:24,195  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile
2024-05-01T05:15:24,265  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,266  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:24,266  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:24,267  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:24,269  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:24,269  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:24,269  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d0acb8f will be shutdown
2024-05-01T05:15:24,270  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a1689e8 created in the thread with id: 1
2024-05-01T05:15:24,272  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:24,272  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:24,272  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:24,272  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45f70f68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a1689e8 will be shutdown
2024-05-01T05:15:24,273  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:24,273  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -59
2024-05-01T05:15:24,273  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:24,274  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:24,274  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@83bbab, with PersistenceManager: null will be shutdown
2024-05-01T05:15:24,274  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@83bbab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67b2c8bb created in the thread with id: 1
2024-05-01T05:15:24,276  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@83bbab from thread id: 1
2024-05-01T05:15:24,277  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:24,283  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:24,297  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:24,332  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,332  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,333  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,333  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,333  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,333  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,333  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,333  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,366  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,366  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:24,366  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:24,367  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:24,367  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:24,367  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@83bbab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67b2c8bb will be shutdown
2024-05-01T05:15:24,367  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@83bbab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78a0d664 created in the thread with id: 1
2024-05-01T05:15:24,369  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:24,369  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:24,369  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:24,369  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@83bbab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78a0d664 will be shutdown
2024-05-01T05:15:24,369  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:24,369  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -60
2024-05-01T05:15:24,369  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:24,370  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:24,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62966c9f, with PersistenceManager: null will be shutdown
2024-05-01T05:15:24,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62966c9f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4193da4d created in the thread with id: 1
2024-05-01T05:15:24,372  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62966c9f from thread id: 1
2024-05-01T05:15:24,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value1,501]	
2024-05-01T05:15:24,386  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:24,391  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:24,391  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:24,411  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:24,427  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local890803232_0016
2024-05-01T05:15:24,427  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:24,477  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:24,477  INFO [main] mapreduce.Job: Running job: job_local890803232_0016
2024-05-01T05:15:24,478  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:24,479  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,479  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,480  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:24,481  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,481  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,494  INFO [Thread-636] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:24,494  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local890803232_0016_m_000000_0
2024-05-01T05:15:24,498  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,498  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,499  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,500  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,500  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:24,500  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T05:15:24,505  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,505  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,538  INFO [LocalJobRunner Map Task Executor #0] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-05-01T05:15:24,542  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,1141233446701424/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local890803232_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T05:15:24,600  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,1141233446701424/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local890803232_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T05:15:24,606  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:24,649  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local890803232_0016_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:24,649  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,649  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,652  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:24,653  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local890803232_0016_m_000000_0 is allowed to commit now
2024-05-01T05:15:24,653  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:24,653  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:24,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local890803232_0016_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,1141233446701424/part1=p1value1/part0=501
2024-05-01T05:15:24,663  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:24,663  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local890803232_0016_m_000000_0' done.
2024-05-01T05:15:24,663  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local890803232_0016_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8173057
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=852492288
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:24,663  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local890803232_0016_m_000000_0
2024-05-01T05:15:24,663  INFO [Thread-636] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,708  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:24,709  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:24,709  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:24,710  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:24,710  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:24,710  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b495293, with PersistenceManager: null will be shutdown
2024-05-01T05:15:24,710  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b495293, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b1303cb created in the thread with id: 686
2024-05-01T05:15:24,712  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b495293 from thread id: 686
2024-05-01T05:15:24,712  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:24,712  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:24,712  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:24,712  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b495293, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b1303cb will be shutdown
2024-05-01T05:15:24,712  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:24,712  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -61
2024-05-01T05:15:24,712  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:24,713  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:24,713  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35af6eb9, with PersistenceManager: null will be shutdown
2024-05-01T05:15:24,713  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35af6eb9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@610c9259 created in the thread with id: 686
2024-05-01T05:15:24,715  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35af6eb9 from thread id: 686
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,759  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:24,759  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T05:15:24,782  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,1141233446701424/part1=p1value1/part0=501].
2024-05-01T05:15:24,782  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:24,820  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:24,821  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:24,821  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:24,822  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:24,822  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35af6eb9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@610c9259 will be shutdown
2024-05-01T05:15:24,822  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35af6eb9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d311165 created in the thread with id: 686
2024-05-01T05:15:24,824  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:24,824  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:24,824  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:24,825  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35af6eb9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d311165 will be shutdown
2024-05-01T05:15:24,825  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:24,825  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -62
2024-05-01T05:15:24,825  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:24,826  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:24,826  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cb8f6d0, with PersistenceManager: null will be shutdown
2024-05-01T05:15:24,826  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cb8f6d0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49e07fb4 created in the thread with id: 686
2024-05-01T05:15:24,828  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cb8f6d0 from thread id: 686
2024-05-01T05:15:24,829  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:24,829  WARN [Thread-636] mapred.LocalJobRunner: job_local890803232_0016
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,1141233446701424/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:25,478  INFO [main] mapreduce.Job: Job job_local890803232_0016 running in uber mode : false
2024-05-01T05:15:25,478  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:25,478  INFO [main] mapreduce.Job: Job job_local890803232_0016 failed with state FAILED due to: NA
2024-05-01T05:15:25,479  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8173057
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=852492288
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:25,524  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:25,524  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:25,525  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:25,527  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:25,527  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:25,527  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62966c9f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4193da4d will be shutdown
2024-05-01T05:15:25,527  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62966c9f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35d4fecf created in the thread with id: 1
2024-05-01T05:15:25,529  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:25,529  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:25,529  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:25,529  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62966c9f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35d4fecf will be shutdown
2024-05-01T05:15:25,530  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:25,530  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -63
2024-05-01T05:15:25,530  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:25,530  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:25,531  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d96b8fb, with PersistenceManager: null will be shutdown
2024-05-01T05:15:25,531  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d96b8fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d208795 created in the thread with id: 1
2024-05-01T05:15:25,532  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d96b8fb from thread id: 1
2024-05-01T05:15:25,533  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:25,538  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:25,544  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:25,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:25,577  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:25,577  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:25,578  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:25,579  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:25,579  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:25,579  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d96b8fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d208795 will be shutdown
2024-05-01T05:15:25,579  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d96b8fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ac35b17 created in the thread with id: 1
2024-05-01T05:15:25,581  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:25,581  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:25,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:25,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d96b8fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ac35b17 will be shutdown
2024-05-01T05:15:25,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:25,582  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -64
2024-05-01T05:15:25,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:25,583  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:25,583  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26fc464f, with PersistenceManager: null will be shutdown
2024-05-01T05:15:25,583  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26fc464f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1174ff02 created in the thread with id: 1
2024-05-01T05:15:25,585  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26fc464f from thread id: 1
2024-05-01T05:15:25,586  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T05:15:25,597  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:25,602  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:25,603  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:25,623  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:25,639  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1059609485_0017
2024-05-01T05:15:25,639  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:25,688  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:25,688  INFO [main] mapreduce.Job: Running job: job_local1059609485_0017
2024-05-01T05:15:25,689  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:25,690  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,690  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,691  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:25,691  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,691  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,704  INFO [Thread-682] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:25,705  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1059609485_0017_m_000000_0
2024-05-01T05:15:25,707  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,707  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,708  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,708  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,708  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:25,708  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:25,710  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,710  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,712  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,07767222411186736/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1059609485_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T05:15:25,722  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,07767222411186736/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1059609485_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T05:15:25,723  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:25,725  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1059609485_0017_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:25,726  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,726  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,730  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:25,730  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1059609485_0017_m_000000_0 is allowed to commit now
2024-05-01T05:15:25,730  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:25,731  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:25,741  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1059609485_0017_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,07767222411186736/part1=p1value2/part0=502
2024-05-01T05:15:25,741  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:25,741  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1059609485_0017_m_000000_0' done.
2024-05-01T05:15:25,741  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1059609485_0017_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8685805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=852492288
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:25,741  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1059609485_0017_m_000000_0
2024-05-01T05:15:25,741  INFO [Thread-682] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:25,786  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:25,787  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:25,787  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:25,788  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:25,788  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:25,788  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a9c65c, with PersistenceManager: null will be shutdown
2024-05-01T05:15:25,788  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a9c65c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@41811f2b created in the thread with id: 734
2024-05-01T05:15:25,789  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a9c65c from thread id: 734
2024-05-01T05:15:25,790  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:25,790  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:25,790  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:25,790  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a9c65c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@41811f2b will be shutdown
2024-05-01T05:15:25,790  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:25,790  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -65
2024-05-01T05:15:25,790  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:25,791  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:25,791  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@340a5319, with PersistenceManager: null will be shutdown
2024-05-01T05:15:25,791  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@340a5319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e56f0af created in the thread with id: 734
2024-05-01T05:15:25,793  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@340a5319 from thread id: 734
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:25,836  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:25,836  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:25,858  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,07767222411186736/part1=p1value2/part0=502].
2024-05-01T05:15:25,858  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:25,897  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:25,897  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:25,898  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:25,898  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:25,899  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@340a5319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e56f0af will be shutdown
2024-05-01T05:15:25,899  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@340a5319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@767344ae created in the thread with id: 734
2024-05-01T05:15:25,900  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:25,900  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:25,901  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:25,901  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@340a5319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@767344ae will be shutdown
2024-05-01T05:15:25,901  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:25,901  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -66
2024-05-01T05:15:25,901  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:25,902  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:25,902  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ca5a02, with PersistenceManager: null will be shutdown
2024-05-01T05:15:25,902  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ca5a02, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e5db57d created in the thread with id: 734
2024-05-01T05:15:25,903  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ca5a02 from thread id: 734
2024-05-01T05:15:25,904  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:25,904  WARN [Thread-682] mapred.LocalJobRunner: job_local1059609485_0017
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,07767222411186736/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:26,689  INFO [main] mapreduce.Job: Job job_local1059609485_0017 running in uber mode : false
2024-05-01T05:15:26,689  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:26,689  INFO [main] mapreduce.Job: Job job_local1059609485_0017 failed with state FAILED due to: NA
2024-05-01T05:15:26,690  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8685805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=852492288
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:26,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:26,736  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:26,736  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:26,737  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:26,739  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:26,739  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:26,739  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26fc464f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1174ff02 will be shutdown
2024-05-01T05:15:26,739  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26fc464f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7baea18b created in the thread with id: 1
2024-05-01T05:15:26,741  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:26,741  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:26,741  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:26,741  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26fc464f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7baea18b will be shutdown
2024-05-01T05:15:26,741  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:26,741  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -67
2024-05-01T05:15:26,741  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:26,742  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:26,742  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@495598c5, with PersistenceManager: null will be shutdown
2024-05-01T05:15:26,742  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@495598c5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e4ac3f5 created in the thread with id: 1
2024-05-01T05:15:26,744  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@495598c5 from thread id: 1
2024-05-01T05:15:26,745  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:26,750  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:26,755  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:26,787  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:26,787  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:26,788  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:26,788  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:26,788  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@495598c5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e4ac3f5 will be shutdown
2024-05-01T05:15:26,788  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@495598c5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a84beb7 created in the thread with id: 1
2024-05-01T05:15:26,790  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:26,790  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:26,790  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:26,790  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@495598c5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a84beb7 will be shutdown
2024-05-01T05:15:26,790  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:26,790  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -68
2024-05-01T05:15:26,790  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:26,791  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:26,791  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@735dc133, with PersistenceManager: null will be shutdown
2024-05-01T05:15:26,791  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@735dc133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57330423 created in the thread with id: 1
2024-05-01T05:15:26,793  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@735dc133 from thread id: 1
2024-05-01T05:15:26,794  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T05:15:26,807  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:26,812  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:26,812  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:26,832  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:26,848  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1763768356_0018
2024-05-01T05:15:26,848  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:26,896  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:26,896  INFO [main] mapreduce.Job: Running job: job_local1763768356_0018
2024-05-01T05:15:26,896  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:26,898  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,898  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,899  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:26,899  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,899  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,912  INFO [Thread-728] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:26,912  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1763768356_0018_m_000000_0
2024-05-01T05:15:26,914  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,914  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,915  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,915  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,915  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:26,916  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:26,918  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,918  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,920  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6114072413246102/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1763768356_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T05:15:26,930  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6114072413246102/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1763768356_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T05:15:26,931  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:26,934  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1763768356_0018_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:26,934  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,934  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,938  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:26,938  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1763768356_0018_m_000000_0 is allowed to commit now
2024-05-01T05:15:26,938  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:26,938  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:26,948  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1763768356_0018_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6114072413246102/part1=p1value2/part0=502
2024-05-01T05:15:26,948  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:26,948  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1763768356_0018_m_000000_0' done.
2024-05-01T05:15:26,949  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1763768356_0018_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9198548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=852492288
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:26,949  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1763768356_0018_m_000000_0
2024-05-01T05:15:26,949  INFO [Thread-728] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:26,994  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:26,994  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:26,995  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:26,995  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:26,996  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:26,996  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32f66b9a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:26,996  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32f66b9a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@631b0b74 created in the thread with id: 782
2024-05-01T05:15:26,997  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32f66b9a from thread id: 782
2024-05-01T05:15:26,997  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:26,997  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:26,998  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:26,998  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32f66b9a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@631b0b74 will be shutdown
2024-05-01T05:15:26,998  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:26,998  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -69
2024-05-01T05:15:26,998  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:26,999  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:26,999  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac18a96, with PersistenceManager: null will be shutdown
2024-05-01T05:15:26,999  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac18a96, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@291168a7 created in the thread with id: 782
2024-05-01T05:15:27,001  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac18a96 from thread id: 782
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:27,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:27,050  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:27,073  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6114072413246102/part1=p1value2/part0=502].
2024-05-01T05:15:27,073  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:27,112  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:27,113  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:27,113  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:27,113  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:27,114  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac18a96, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@291168a7 will be shutdown
2024-05-01T05:15:27,114  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac18a96, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63989050 created in the thread with id: 782
2024-05-01T05:15:27,115  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:27,115  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:27,116  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:27,116  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac18a96, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63989050 will be shutdown
2024-05-01T05:15:27,116  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:27,116  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -70
2024-05-01T05:15:27,116  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:27,116  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:27,117  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d1518f0, with PersistenceManager: null will be shutdown
2024-05-01T05:15:27,117  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d1518f0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ec6b10b created in the thread with id: 782
2024-05-01T05:15:27,118  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d1518f0 from thread id: 782
2024-05-01T05:15:27,119  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:27,119  WARN [Thread-728] mapred.LocalJobRunner: job_local1763768356_0018
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6114072413246102/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:27,403  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T05:15:27,896  INFO [main] mapreduce.Job: Job job_local1763768356_0018 running in uber mode : false
2024-05-01T05:15:27,897  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:27,897  INFO [main] mapreduce.Job: Job job_local1763768356_0018 failed with state FAILED due to: NA
2024-05-01T05:15:27,898  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9198548
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=852492288
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:27,943  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:27,944  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:27,944  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:27,946  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:27,946  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:27,946  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@735dc133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57330423 will be shutdown
2024-05-01T05:15:27,946  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@735dc133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3599b7e8 created in the thread with id: 1
2024-05-01T05:15:27,948  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:27,948  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:27,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:27,948  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@735dc133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3599b7e8 will be shutdown
2024-05-01T05:15:27,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:27,948  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -71
2024-05-01T05:15:27,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:27,949  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:27,949  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ead6e20, with PersistenceManager: null will be shutdown
2024-05-01T05:15:27,949  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ead6e20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59f56892 created in the thread with id: 1
2024-05-01T05:15:27,951  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ead6e20 from thread id: 1
2024-05-01T05:15:27,951  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:27,957  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:27,962  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:27,995  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:27,996  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:27,996  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:27,996  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:27,997  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ead6e20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59f56892 will be shutdown
2024-05-01T05:15:27,997  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ead6e20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c54d0dc created in the thread with id: 1
2024-05-01T05:15:27,998  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:27,999  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:27,999  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:27,999  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ead6e20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c54d0dc will be shutdown
2024-05-01T05:15:27,999  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:27,999  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -72
2024-05-01T05:15:27,999  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:28,000  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:28,000  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@125ed27, with PersistenceManager: null will be shutdown
2024-05-01T05:15:28,000  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@125ed27, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dedde74 created in the thread with id: 1
2024-05-01T05:15:28,001  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@125ed27 from thread id: 1
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:28,047  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:28,048  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:28,048  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:28,049  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:28,050  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:28,050  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:28,050  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@125ed27, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dedde74 will be shutdown
2024-05-01T05:15:28,050  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@125ed27, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6db59e26 created in the thread with id: 1
2024-05-01T05:15:28,052  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:28,052  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:28,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:28,052  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@125ed27, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6db59e26 will be shutdown
2024-05-01T05:15:28,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:28,052  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -73
2024-05-01T05:15:28,053  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:28,053  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:28,053  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5653429e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:28,054  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5653429e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78c9c38a created in the thread with id: 1
2024-05-01T05:15:28,055  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5653429e from thread id: 1
2024-05-01T05:15:28,056  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:28,060  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:28,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:28,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:28,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:28,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:28,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:28,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:28,107  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:28,107  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:28,107  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:28,107  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:28,107  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:28,107  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:28,108  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:28,109  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:28,109  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:28,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5653429e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78c9c38a will be shutdown
2024-05-01T05:15:28,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5653429e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32cda33c created in the thread with id: 1
2024-05-01T05:15:28,111  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:28,111  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:28,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:28,111  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5653429e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32cda33c will be shutdown
2024-05-01T05:15:28,112  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:28,112  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -74
2024-05-01T05:15:28,112  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:28,112  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:28,112  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f45be42, with PersistenceManager: null will be shutdown
2024-05-01T05:15:28,113  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f45be42, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c7876e1 created in the thread with id: 1
2024-05-01T05:15:28,114  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f45be42 from thread id: 1
2024-05-01T05:15:28,115  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:28,120  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:28,126  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:28,198  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:28,199  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:28,199  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:28,199  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:28,199  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:28,200  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f45be42, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c7876e1 will be shutdown
2024-05-01T05:15:28,200  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f45be42, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ed6e557 created in the thread with id: 1
2024-05-01T05:15:28,201  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:28,202  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:28,202  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:28,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f45be42, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ed6e557 will be shutdown
2024-05-01T05:15:28,202  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:28,202  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -75
2024-05-01T05:15:28,202  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:28,203  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:28,203  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7008b4, with PersistenceManager: null will be shutdown
2024-05-01T05:15:28,203  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7008b4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f54fabc created in the thread with id: 1
2024-05-01T05:15:28,205  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7008b4 from thread id: 1
2024-05-01T05:15:28,211  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:28,216  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:28,216  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:28,236  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:28,251  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local829316184_0019
2024-05-01T05:15:28,251  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:28,301  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:28,301  INFO [main] mapreduce.Job: Running job: job_local829316184_0019
2024-05-01T05:15:28,301  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:28,303  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:28,304  INFO [Thread-779] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:28,304  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local829316184_0019_m_000000_0
2024-05-01T05:15:28,308  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:28,309  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T05:15:28,315  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local829316184_0019_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.6977172213315821/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T05:15:28,315  INFO [Thread-779] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:28,317  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.6977172213315821].
2024-05-01T05:15:28,317  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:28,355  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:28,356  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:28,356  INFO [Thread-779] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:28,357  INFO [Thread-779] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:28,358  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:28,358  INFO [Thread-779] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:28,358  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fe59f28, with PersistenceManager: null will be shutdown
2024-05-01T05:15:28,358  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fe59f28, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d641a46 created in the thread with id: 835
2024-05-01T05:15:28,359  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fe59f28 from thread id: 835
2024-05-01T05:15:28,360  INFO [Thread-779] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:28,360  INFO [Thread-779] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:28,360  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:28,360  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fe59f28, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d641a46 will be shutdown
2024-05-01T05:15:28,360  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:28,360  INFO [Thread-779] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -76
2024-05-01T05:15:28,360  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:28,361  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:28,361  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d9f42f5, with PersistenceManager: null will be shutdown
2024-05-01T05:15:28,361  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d9f42f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a186d48 created in the thread with id: 835
2024-05-01T05:15:28,363  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d9f42f5 from thread id: 835
2024-05-01T05:15:28,364  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:28,364  WARN [Thread-779] mapred.LocalJobRunner: job_local829316184_0019
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T05:15:29,301  INFO [main] mapreduce.Job: Job job_local829316184_0019 running in uber mode : false
2024-05-01T05:15:29,302  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:29,302  INFO [main] mapreduce.Job: Job job_local829316184_0019 failed with state FAILED due to: NA
2024-05-01T05:15:29,302  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:29,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:29,340  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:29,340  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:29,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:29,340  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:29,340  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:29,341  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:29,341  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:29,341  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:29,341  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:29,341  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:29,341  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:29,342  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:29,343  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:29,343  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:29,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7008b4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f54fabc will be shutdown
2024-05-01T05:15:29,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7008b4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@394a7390 created in the thread with id: 1
2024-05-01T05:15:29,345  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:29,345  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:29,345  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:29,345  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c7008b4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@394a7390 will be shutdown
2024-05-01T05:15:29,345  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:29,345  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -77
2024-05-01T05:15:29,346  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:29,346  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:29,346  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: null will be shutdown
2024-05-01T05:15:29,346  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59b8a801 created in the thread with id: 1
2024-05-01T05:15:29,348  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480 from thread id: 1
2024-05-01T05:15:29,349  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:29,354  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:29,354  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:29,358  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:29,363  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:29,369  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:29,390  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T05:15:29,405  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local480533045_0020
2024-05-01T05:15:29,405  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:29,454  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:29,454  INFO [main] mapreduce.Job: Running job: job_local480533045_0020
2024-05-01T05:15:29,455  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:29,455  INFO [Thread-799] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:29,455  INFO [Thread-799] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:29,455  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T05:15:29,464  INFO [Thread-799] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:29,464  INFO [Thread-799] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:30,455  INFO [main] mapreduce.Job: Job job_local480533045_0020 running in uber mode : false
2024-05-01T05:15:30,455  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:30,455  INFO [main] mapreduce.Job: Job job_local480533045_0020 completed successfully
2024-05-01T05:15:30,455  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:30,456  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:30,460  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:30,460  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T05:15:30,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:30,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:30,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:30,517  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[4]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:30,561  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:30,564  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:30,564  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:30,564  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59b8a801 will be shutdown
2024-05-01T05:15:30,564  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5713e35f created in the thread with id: 1
2024-05-01T05:15:30,566  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 98fbdfe0-4f7c-47df-882c-f9c282ad1798
2024-05-01T05:15:30,566  INFO [main] SessionState: Hive Session ID = 98fbdfe0-4f7c-47df-882c-f9c282ad1798
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:30,567  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:30,573  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/98fbdfe0-4f7c-47df-882c-f9c282ad1798
2024-05-01T05:15:30,576  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/98fbdfe0-4f7c-47df-882c-f9c282ad1798
2024-05-01T05:15:30,578  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/98fbdfe0-4f7c-47df-882c-f9c282ad1798/_tmp_space.db
2024-05-01T05:15:30,579  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_PARQUETFILE	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[5]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:30,622  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:30,623  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:30,625  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:30,625  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:30,625  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5713e35f will be shutdown
2024-05-01T05:15:30,625  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17baaf07 created in the thread with id: 1
2024-05-01T05:15:30,627  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = a93eb0b8-136f-4b20-acee-85198cb4f4e3
2024-05-01T05:15:30,627  INFO [main] SessionState: Hive Session ID = a93eb0b8-136f-4b20-acee-85198cb4f4e3
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:30,628  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:30,633  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/a93eb0b8-136f-4b20-acee-85198cb4f4e3
2024-05-01T05:15:30,636  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/a93eb0b8-136f-4b20-acee-85198cb4f4e3
2024-05-01T05:15:30,639  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/a93eb0b8-136f-4b20-acee-85198cb4f4e3/_tmp_space.db
2024-05-01T05:15:30,639  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_AVRO	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[6]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.386">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:30,679  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:30,681  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:30,681  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:30,682  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17baaf07 will be shutdown
2024-05-01T05:15:30,682  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1a4340f2 created in the thread with id: 1
2024-05-01T05:15:30,683  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 833ac3bd-04b4-4987-9c05-b53c3e3fde90
2024-05-01T05:15:30,684  INFO [main] SessionState: Hive Session ID = 833ac3bd-04b4-4987-9c05-b53c3e3fde90
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:30,684  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:30,690  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/833ac3bd-04b4-4987-9c05-b53c3e3fde90
2024-05-01T05:15:30,692  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/833ac3bd-04b4-4987-9c05-b53c3e3fde90
2024-05-01T05:15:30,695  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/833ac3bd-04b4-4987-9c05-b53c3e3fde90/_tmp_space.db
2024-05-01T05:15:30,695  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:30,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_JSONFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_JSONFILE, serializationLib:org.apache.hadoop.hive.serde2.JsonSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T05:15:30,698  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:30,753  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:30,754  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:30,755  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:30,756  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:30,756  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:30,757  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1a4340f2 will be shutdown
2024-05-01T05:15:30,757  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40d0bff1 created in the thread with id: 1
2024-05-01T05:15:30,758  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:30,758  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:30,759  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:30,759  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1252d480, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40d0bff1 will be shutdown
2024-05-01T05:15:30,759  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:30,759  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -78
2024-05-01T05:15:30,759  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:30,760  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:30,760  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e10809f, with PersistenceManager: null will be shutdown
2024-05-01T05:15:30,760  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e10809f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@470c2a7a created in the thread with id: 1
2024-05-01T05:15:30,762  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e10809f from thread id: 1
2024-05-01T05:15:30,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:30,767  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:30,779  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:30,812  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:30,813  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:30,813  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:30,814  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:30,814  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e10809f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@470c2a7a will be shutdown
2024-05-01T05:15:30,814  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e10809f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5afbbf9b created in the thread with id: 1
2024-05-01T05:15:30,815  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:30,815  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:30,816  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:30,816  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e10809f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5afbbf9b will be shutdown
2024-05-01T05:15:30,816  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:30,816  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -79
2024-05-01T05:15:30,816  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:30,817  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:30,817  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@446dc997, with PersistenceManager: null will be shutdown
2024-05-01T05:15:30,817  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@446dc997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32cfd722 created in the thread with id: 1
2024-05-01T05:15:30,818  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@446dc997 from thread id: 1
2024-05-01T05:15:30,819  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value1,501]	
2024-05-01T05:15:30,830  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:30,835  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:30,836  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:30,856  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:30,872  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local103407790_0021
2024-05-01T05:15:30,872  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:30,921  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:30,921  INFO [main] mapreduce.Job: Running job: job_local103407790_0021
2024-05-01T05:15:30,922  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:30,923  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,923  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,924  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:30,925  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,925  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,938  INFO [Thread-841] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:30,938  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local103407790_0021_m_000000_0
2024-05-01T05:15:30,942  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,942  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,943  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,943  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,943  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:30,944  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T05:15:30,949  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,949  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,969  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:30,971  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local103407790_0021_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:30,972  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,972  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,975  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:30,975  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local103407790_0021_m_000000_0 is allowed to commit now
2024-05-01T05:15:30,976  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:30,976  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:30,985  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local103407790_0021_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5340529553887349/part1=p1value1/part0=501
2024-05-01T05:15:30,986  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:30,986  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local103407790_0021_m_000000_0' done.
2024-05-01T05:15:30,986  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local103407790_0021_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10727125
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=902299648
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:30,986  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local103407790_0021_m_000000_0
2024-05-01T05:15:30,986  INFO [Thread-841] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:31,030  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:31,031  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:31,031  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:31,031  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:31,032  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:31,032  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:31,032  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:31,032  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f392a8, with PersistenceManager: null will be shutdown
2024-05-01T05:15:31,032  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f392a8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34e75508 created in the thread with id: 899
2024-05-01T05:15:31,034  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f392a8 from thread id: 899
2024-05-01T05:15:31,034  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:31,034  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:31,034  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:31,034  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f392a8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34e75508 will be shutdown
2024-05-01T05:15:31,034  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:31,034  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -80
2024-05-01T05:15:31,034  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:31,035  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:31,035  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c68745b, with PersistenceManager: null will be shutdown
2024-05-01T05:15:31,035  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c68745b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43325541 created in the thread with id: 899
2024-05-01T05:15:31,037  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c68745b from thread id: 899
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:31,080  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:31,081  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T05:15:31,103  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5340529553887349/part1=p1value1/part0=501].
2024-05-01T05:15:31,103  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:31,140  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:31,141  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:31,141  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:31,142  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:31,142  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:31,142  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c68745b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43325541 will be shutdown
2024-05-01T05:15:31,142  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c68745b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3bae738 created in the thread with id: 899
2024-05-01T05:15:31,144  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:31,144  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:31,144  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:31,144  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c68745b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3bae738 will be shutdown
2024-05-01T05:15:31,144  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:31,144  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -81
2024-05-01T05:15:31,144  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:31,145  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:31,145  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57fc3590, with PersistenceManager: null will be shutdown
2024-05-01T05:15:31,145  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57fc3590, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ba24ac7 created in the thread with id: 899
2024-05-01T05:15:31,147  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57fc3590 from thread id: 899
2024-05-01T05:15:31,147  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:31,147  WARN [Thread-841] mapred.LocalJobRunner: job_local103407790_0021
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5340529553887349/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:31,922  INFO [main] mapreduce.Job: Job job_local103407790_0021 running in uber mode : false
2024-05-01T05:15:31,922  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:31,922  INFO [main] mapreduce.Job: Job job_local103407790_0021 failed with state FAILED due to: NA
2024-05-01T05:15:31,923  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10727125
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=902299648
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:31,969  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:31,969  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:31,970  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:31,971  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:31,971  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:31,972  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@446dc997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32cfd722 will be shutdown
2024-05-01T05:15:31,972  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@446dc997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29e8c09c created in the thread with id: 1
2024-05-01T05:15:31,974  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:31,974  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:31,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:31,974  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@446dc997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29e8c09c will be shutdown
2024-05-01T05:15:31,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:31,974  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -82
2024-05-01T05:15:31,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:31,975  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:31,975  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cc5a38, with PersistenceManager: null will be shutdown
2024-05-01T05:15:31,975  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cc5a38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23b62cc3 created in the thread with id: 1
2024-05-01T05:15:31,977  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cc5a38 from thread id: 1
2024-05-01T05:15:31,978  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:31,983  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:31,990  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:32,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:32,030  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:32,030  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:32,030  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:32,031  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:32,031  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:32,031  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cc5a38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23b62cc3 will be shutdown
2024-05-01T05:15:32,031  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cc5a38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b93a232 created in the thread with id: 1
2024-05-01T05:15:32,033  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:32,033  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:32,033  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:32,033  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cc5a38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b93a232 will be shutdown
2024-05-01T05:15:32,033  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:32,033  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -83
2024-05-01T05:15:32,033  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:32,034  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:32,034  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@674b2703, with PersistenceManager: null will be shutdown
2024-05-01T05:15:32,034  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@674b2703, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67441705 created in the thread with id: 1
2024-05-01T05:15:32,036  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@674b2703 from thread id: 1
2024-05-01T05:15:32,037  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T05:15:32,048  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:32,053  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:32,053  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:32,073  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:32,088  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local403444501_0022
2024-05-01T05:15:32,088  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:32,138  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:32,138  INFO [main] mapreduce.Job: Running job: job_local403444501_0022
2024-05-01T05:15:32,138  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:32,140  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,140  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,141  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:32,142  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,142  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,155  INFO [Thread-887] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:32,156  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local403444501_0022_m_000000_0
2024-05-01T05:15:32,157  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,157  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,159  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,159  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,159  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:32,159  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:32,160  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,160  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,175  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:32,175  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local403444501_0022_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:32,175  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,175  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,178  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:32,178  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local403444501_0022_m_000000_0 is allowed to commit now
2024-05-01T05:15:32,178  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:32,178  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:32,188  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local403444501_0022_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7795543707095536/part1=p1value2/part0=502
2024-05-01T05:15:32,188  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:32,188  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local403444501_0022_m_000000_0' done.
2024-05-01T05:15:32,189  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local403444501_0022_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11237690
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=902299648
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:32,189  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local403444501_0022_m_000000_0
2024-05-01T05:15:32,189  INFO [Thread-887] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:32,234  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:32,235  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:32,235  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:32,235  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:32,235  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:32,235  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:32,235  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:32,236  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:32,236  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:32,236  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1071ef8e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:32,236  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1071ef8e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55c18754 created in the thread with id: 947
2024-05-01T05:15:32,238  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1071ef8e from thread id: 947
2024-05-01T05:15:32,238  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:32,238  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:32,238  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:32,238  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1071ef8e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55c18754 will be shutdown
2024-05-01T05:15:32,238  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:32,238  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -84
2024-05-01T05:15:32,239  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:32,239  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:32,240  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd9afe0, with PersistenceManager: null will be shutdown
2024-05-01T05:15:32,240  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd9afe0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f6aba67 created in the thread with id: 947
2024-05-01T05:15:32,241  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd9afe0 from thread id: 947
2024-05-01T05:15:32,284  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:32,284  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:32,284  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:32,284  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:32,284  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:32,284  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:32,285  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:32,285  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:32,285  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:32,285  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:32,285  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:32,285  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:32,307  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7795543707095536/part1=p1value2/part0=502].
2024-05-01T05:15:32,308  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:32,346  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:32,346  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:32,346  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:32,346  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:32,346  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:32,347  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:32,347  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:32,347  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:32,347  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:32,347  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:32,347  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:32,347  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:32,348  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:32,348  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:32,348  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd9afe0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f6aba67 will be shutdown
2024-05-01T05:15:32,348  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd9afe0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2041a230 created in the thread with id: 947
2024-05-01T05:15:32,350  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:32,350  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:32,350  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:32,350  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd9afe0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2041a230 will be shutdown
2024-05-01T05:15:32,350  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:32,350  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -85
2024-05-01T05:15:32,350  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:32,351  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:32,351  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56e2e850, with PersistenceManager: null will be shutdown
2024-05-01T05:15:32,351  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56e2e850, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73dfa60 created in the thread with id: 947
2024-05-01T05:15:32,353  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56e2e850 from thread id: 947
2024-05-01T05:15:32,353  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:32,353  WARN [Thread-887] mapred.LocalJobRunner: job_local403444501_0022
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7795543707095536/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:33,138  INFO [main] mapreduce.Job: Job job_local403444501_0022 running in uber mode : false
2024-05-01T05:15:33,139  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:33,139  INFO [main] mapreduce.Job: Job job_local403444501_0022 failed with state FAILED due to: NA
2024-05-01T05:15:33,140  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11237690
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=902299648
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:33,185  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:33,185  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:33,185  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:33,185  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:33,185  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:33,185  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:33,186  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:33,186  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:33,186  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:33,186  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:33,186  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:33,186  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:33,187  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:33,189  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:33,189  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:33,190  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@674b2703, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67441705 will be shutdown
2024-05-01T05:15:33,190  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@674b2703, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f63219e created in the thread with id: 1
2024-05-01T05:15:33,192  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:33,192  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:33,192  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:33,192  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@674b2703, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f63219e will be shutdown
2024-05-01T05:15:33,192  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:33,192  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -86
2024-05-01T05:15:33,192  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:33,193  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:33,194  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1201c2f6, with PersistenceManager: null will be shutdown
2024-05-01T05:15:33,194  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1201c2f6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@cbf9cc1 created in the thread with id: 1
2024-05-01T05:15:33,195  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1201c2f6 from thread id: 1
2024-05-01T05:15:33,196  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:33,201  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:33,207  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:33,268  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:33,269  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:33,269  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:33,269  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:33,269  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:33,269  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:33,270  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1201c2f6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@cbf9cc1 will be shutdown
2024-05-01T05:15:33,270  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1201c2f6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106dee26 created in the thread with id: 1
2024-05-01T05:15:33,271  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:33,271  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:33,272  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:33,272  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1201c2f6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106dee26 will be shutdown
2024-05-01T05:15:33,272  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:33,272  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -87
2024-05-01T05:15:33,272  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:33,273  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:33,273  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@adc06b2, with PersistenceManager: null will be shutdown
2024-05-01T05:15:33,273  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@adc06b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@728cf276 created in the thread with id: 1
2024-05-01T05:15:33,275  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@adc06b2 from thread id: 1
2024-05-01T05:15:33,276  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T05:15:33,287  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:33,292  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:33,293  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:33,313  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:33,329  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local350596572_0023
2024-05-01T05:15:33,329  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:33,388  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:33,388  INFO [main] mapreduce.Job: Running job: job_local350596572_0023
2024-05-01T05:15:33,388  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:33,389  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,390  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,390  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:33,391  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,391  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,404  INFO [Thread-933] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:33,404  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local350596572_0023_m_000000_0
2024-05-01T05:15:33,406  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,406  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,407  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,407  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,407  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:33,407  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:33,409  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,409  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,423  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:33,424  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local350596572_0023_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:33,424  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,424  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,427  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:33,427  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local350596572_0023_m_000000_0 is allowed to commit now
2024-05-01T05:15:33,427  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:33,427  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:33,437  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local350596572_0023_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,3509410070676897/part1=p1value2/part0=502
2024-05-01T05:15:33,438  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:33,438  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local350596572_0023_m_000000_0' done.
2024-05-01T05:15:33,438  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local350596572_0023_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11748255
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=905445376
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:33,438  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local350596572_0023_m_000000_0
2024-05-01T05:15:33,438  INFO [Thread-933] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:33,483  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:33,483  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:33,484  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:33,485  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:33,485  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:33,485  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:33,485  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ade14be created in the thread with id: 995
2024-05-01T05:15:33,486  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a from thread id: 995
2024-05-01T05:15:33,486  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:33,487  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:33,487  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:33,487  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ade14be will be shutdown
2024-05-01T05:15:33,487  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:33,487  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -88
2024-05-01T05:15:33,487  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:33,488  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:33,488  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: null will be shutdown
2024-05-01T05:15:33,488  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ae2afaa created in the thread with id: 995
2024-05-01T05:15:33,490  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181 from thread id: 995
2024-05-01T05:15:33,531  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:33,531  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:33,531  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:33,531  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:33,532  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:33,532  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:33,554  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,3509410070676897/part1=p1value2/part0=502].
2024-05-01T05:15:33,554  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:33,592  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:33,592  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:33,592  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:33,592  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:33,592  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:33,592  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:33,593  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:33,593  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:33,593  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:33,593  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:33,593  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:33,593  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:33,594  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:33,594  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:33,594  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ae2afaa will be shutdown
2024-05-01T05:15:33,594  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d9fd547 created in the thread with id: 995
2024-05-01T05:15:33,595  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:33,596  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:33,596  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:33,596  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d9fd547 will be shutdown
2024-05-01T05:15:33,596  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:33,596  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -89
2024-05-01T05:15:33,596  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:33,597  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:33,597  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c9e3015, with PersistenceManager: null will be shutdown
2024-05-01T05:15:33,597  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c9e3015, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f92a1b created in the thread with id: 995
2024-05-01T05:15:33,599  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c9e3015 from thread id: 995
2024-05-01T05:15:33,599  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:33,599  WARN [Thread-933] mapred.LocalJobRunner: job_local350596572_0023
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,3509410070676897/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:33,904  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T05:15:34,388  INFO [main] mapreduce.Job: Job job_local350596572_0023 running in uber mode : false
2024-05-01T05:15:34,388  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:34,389  INFO [main] mapreduce.Job: Job job_local350596572_0023 failed with state FAILED due to: NA
2024-05-01T05:15:34,389  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11748255
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=905445376
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:34,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:34,443  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:34,443  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:34,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:34,444  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:34,444  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:34,445  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:34,446  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:34,446  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:34,446  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@adc06b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@728cf276 will be shutdown
2024-05-01T05:15:34,447  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@adc06b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7aead157 created in the thread with id: 1
2024-05-01T05:15:34,448  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:34,448  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:34,448  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:34,448  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@adc06b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7aead157 will be shutdown
2024-05-01T05:15:34,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:34,449  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -90
2024-05-01T05:15:34,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:34,449  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,450  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e49adfa, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,450  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e49adfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2296926d created in the thread with id: 1
2024-05-01T05:15:34,451  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e49adfa from thread id: 1
2024-05-01T05:15:34,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:34,457  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:34,464  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:34,498  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:34,498  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:34,498  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:34,499  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:34,499  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:34,500  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:34,500  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:34,500  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e49adfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2296926d will be shutdown
2024-05-01T05:15:34,500  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e49adfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a6ae0f0 created in the thread with id: 1
2024-05-01T05:15:34,502  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:34,502  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:34,502  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:34,502  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e49adfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a6ae0f0 will be shutdown
2024-05-01T05:15:34,502  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:34,502  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -91
2024-05-01T05:15:34,502  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:34,503  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,503  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1aa21319, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,503  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1aa21319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3dcf26b5 created in the thread with id: 1
2024-05-01T05:15:34,505  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1aa21319 from thread id: 1
2024-05-01T05:15:34,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:34,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:34,551  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:34,551  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:34,552  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:34,553  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:34,553  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:34,553  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1aa21319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3dcf26b5 will be shutdown
2024-05-01T05:15:34,553  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1aa21319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6baa673d created in the thread with id: 1
2024-05-01T05:15:34,555  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:34,555  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:34,555  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:34,556  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1aa21319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6baa673d will be shutdown
2024-05-01T05:15:34,556  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:34,556  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -92
2024-05-01T05:15:34,556  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:34,557  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,557  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ec9c49, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,557  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ec9c49, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ab2d64c created in the thread with id: 1
2024-05-01T05:15:34,559  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ec9c49 from thread id: 1
2024-05-01T05:15:34,559  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:34,565  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:34,612  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:34,612  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:34,613  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:34,615  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:34,615  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:34,615  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ec9c49, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ab2d64c will be shutdown
2024-05-01T05:15:34,615  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ec9c49, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24c9a52a created in the thread with id: 1
2024-05-01T05:15:34,617  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:34,617  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:34,617  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:34,617  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37ec9c49, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24c9a52a will be shutdown
2024-05-01T05:15:34,617  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:34,617  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -93
2024-05-01T05:15:34,617  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:34,618  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,618  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ffa424d, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,618  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ffa424d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@652cb87d created in the thread with id: 1
2024-05-01T05:15:34,619  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ffa424d from thread id: 1
2024-05-01T05:15:34,620  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:34,625  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:34,632  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:34,665  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:34,666  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:34,666  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:34,666  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:34,667  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ffa424d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@652cb87d will be shutdown
2024-05-01T05:15:34,667  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ffa424d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c902a83 created in the thread with id: 1
2024-05-01T05:15:34,668  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:34,669  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:34,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:34,669  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ffa424d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c902a83 will be shutdown
2024-05-01T05:15:34,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:34,669  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -94
2024-05-01T05:15:34,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:34,670  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a166, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a166, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74f6237 created in the thread with id: 1
2024-05-01T05:15:34,671  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a166 from thread id: 1
2024-05-01T05:15:34,677  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:34,683  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:34,683  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:34,707  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:34,725  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2022944842_0024
2024-05-01T05:15:34,725  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:34,779  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:34,779  INFO [main] mapreduce.Job: Running job: job_local2022944842_0024
2024-05-01T05:15:34,780  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:34,781  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:34,783  INFO [Thread-984] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:34,783  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2022944842_0024_m_000000_0
2024-05-01T05:15:34,785  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:34,785  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T05:15:34,789  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local2022944842_0024_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.42229341770173534/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T05:15:34,789  INFO [Thread-984] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:34,790  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.42229341770173534].
2024-05-01T05:15:34,790  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:34,827  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:34,827  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:34,827  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:34,827  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:34,827  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:34,827  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:34,828  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:34,828  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:34,828  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:34,828  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:34,828  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:34,828  INFO [Thread-984] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:34,828  INFO [Thread-984] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:34,829  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,829  INFO [Thread-984] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:34,829  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5412606d, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,829  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5412606d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b565983 created in the thread with id: 1048
2024-05-01T05:15:34,831  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5412606d from thread id: 1048
2024-05-01T05:15:34,831  INFO [Thread-984] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:34,831  INFO [Thread-984] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:34,831  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:34,831  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5412606d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b565983 will be shutdown
2024-05-01T05:15:34,831  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:34,831  INFO [Thread-984] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -95
2024-05-01T05:15:34,831  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:34,832  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:34,832  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28c1abbf, with PersistenceManager: null will be shutdown
2024-05-01T05:15:34,832  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28c1abbf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@dd5943c created in the thread with id: 1048
2024-05-01T05:15:34,833  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28c1abbf from thread id: 1048
2024-05-01T05:15:34,834  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:34,834  WARN [Thread-984] mapred.LocalJobRunner: job_local2022944842_0024
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T05:15:35,780  INFO [main] mapreduce.Job: Job job_local2022944842_0024 running in uber mode : false
2024-05-01T05:15:35,780  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:35,780  INFO [main] mapreduce.Job: Job job_local2022944842_0024 failed with state FAILED due to: NA
2024-05-01T05:15:35,780  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:35,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:35,824  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:35,824  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:35,825  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:35,826  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:35,826  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:35,827  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a166, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74f6237 will be shutdown
2024-05-01T05:15:35,827  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a166, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34b56a5a created in the thread with id: 1
2024-05-01T05:15:35,829  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:35,829  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:35,829  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:35,829  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a166, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34b56a5a will be shutdown
2024-05-01T05:15:35,829  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:35,829  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -96
2024-05-01T05:15:35,829  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:35,830  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:35,830  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: null will be shutdown
2024-05-01T05:15:35,830  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@230ea983 created in the thread with id: 1
2024-05-01T05:15:35,832  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f from thread id: 1
2024-05-01T05:15:35,833  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:35,839  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:35,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:35,843  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:35,849  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:35,854  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:35,875  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T05:15:35,891  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1242235805_0025
2024-05-01T05:15:35,891  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:35,947  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:35,947  INFO [main] mapreduce.Job: Running job: job_local1242235805_0025
2024-05-01T05:15:35,947  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:35,948  INFO [Thread-1004] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:35,948  INFO [Thread-1004] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:35,948  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T05:15:35,956  INFO [Thread-1004] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:35,956  INFO [Thread-1004] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:36,948  INFO [main] mapreduce.Job: Job job_local1242235805_0025 running in uber mode : false
2024-05-01T05:15:36,948  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:36,948  INFO [main] mapreduce.Job: Job job_local1242235805_0025 completed successfully
2024-05-01T05:15:36,948  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:36,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:36,955  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:36,955  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,020  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[7]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.391">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T05:15:37,076  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,077  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:37,080  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:37,080  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:37,080  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@230ea983 will be shutdown
2024-05-01T05:15:37,080  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@196519dd created in the thread with id: 1
2024-05-01T05:15:37,084  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 3181dc1d-94f3-4586-957c-d5fe8a451bca
2024-05-01T05:15:37,085  INFO [main] SessionState: Hive Session ID = 3181dc1d-94f3-4586-957c-d5fe8a451bca
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:37,085  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T05:15:37,091  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3181dc1d-94f3-4586-957c-d5fe8a451bca
2024-05-01T05:15:37,094  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/3181dc1d-94f3-4586-957c-d5fe8a451bca
2024-05-01T05:15:37,097  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3181dc1d-94f3-4586-957c-d5fe8a451bca/_tmp_space.db
2024-05-01T05:15:37,098  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:37,099  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_rcfile_columnar, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_rcfile_columnar, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T05:15:37,101  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar
2024-05-01T05:15:37,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,162  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,162  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,162  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,163  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,163  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,163  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,163  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:37,163  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:37,164  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:37,166  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:37,166  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:37,166  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@196519dd will be shutdown
2024-05-01T05:15:37,167  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@204d101 created in the thread with id: 1
2024-05-01T05:15:37,169  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:37,169  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:37,169  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:37,169  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4390b78f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@204d101 will be shutdown
2024-05-01T05:15:37,169  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:37,169  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -97
2024-05-01T05:15:37,169  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:37,170  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:37,170  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@759fe679, with PersistenceManager: null will be shutdown
2024-05-01T05:15:37,171  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@759fe679, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7056cda8 created in the thread with id: 1
2024-05-01T05:15:37,172  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@759fe679 from thread id: 1
2024-05-01T05:15:37,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:37,179  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:37,187  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:37,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,230  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:37,230  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:37,231  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:37,231  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:37,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@759fe679, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7056cda8 will be shutdown
2024-05-01T05:15:37,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@759fe679, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@271bbb75 created in the thread with id: 1
2024-05-01T05:15:37,234  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:37,234  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:37,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:37,234  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@759fe679, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@271bbb75 will be shutdown
2024-05-01T05:15:37,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:37,234  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -98
2024-05-01T05:15:37,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:37,235  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:37,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d58136, with PersistenceManager: null will be shutdown
2024-05-01T05:15:37,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d58136, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@173a86ad created in the thread with id: 1
2024-05-01T05:15:37,238  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d58136 from thread id: 1
2024-05-01T05:15:37,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value1,501]	
2024-05-01T05:15:37,255  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:37,260  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:37,261  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:37,284  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:37,303  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local928760612_0026
2024-05-01T05:15:37,303  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:37,363  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:37,363  INFO [main] mapreduce.Job: Running job: job_local928760612_0026
2024-05-01T05:15:37,363  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:37,366  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,366  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,367  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:37,368  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,368  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,381  INFO [Thread-1038] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:37,382  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local928760612_0026_m_000000_0
2024-05-01T05:15:37,387  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,387  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,388  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,388  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,388  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:37,388  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T05:15:37,394  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,394  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,409  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:37,409  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T05:15:37,409  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T05:15:37,411  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local928760612_0026_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:37,411  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,411  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,415  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:37,415  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local928760612_0026_m_000000_0 is allowed to commit now
2024-05-01T05:15:37,415  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:37,415  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:37,425  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local928760612_0026_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,22537162348487527/part1=p1value1/part0=501
2024-05-01T05:15:37,426  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:37,426  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local928760612_0026_m_000000_0' done.
2024-05-01T05:15:37,426  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local928760612_0026_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13282196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=905445376
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:37,426  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local928760612_0026_m_000000_0
2024-05-01T05:15:37,426  INFO [Thread-1038] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,475  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:37,475  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:37,476  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:37,476  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:37,476  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:37,476  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a9e7cfd, with PersistenceManager: null will be shutdown
2024-05-01T05:15:37,477  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a9e7cfd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f617f77 created in the thread with id: 1104
2024-05-01T05:15:37,478  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a9e7cfd from thread id: 1104
2024-05-01T05:15:37,478  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:37,478  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:37,478  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:37,478  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a9e7cfd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f617f77 will be shutdown
2024-05-01T05:15:37,478  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:37,479  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -99
2024-05-01T05:15:37,479  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:37,480  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:37,480  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d80d9d, with PersistenceManager: null will be shutdown
2024-05-01T05:15:37,480  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d80d9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2eaf5fcf created in the thread with id: 1104
2024-05-01T05:15:37,482  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d80d9d from thread id: 1104
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,527  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:37,527  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=501, part1=p1value1}].
2024-05-01T05:15:37,550  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,22537162348487527/part1=p1value1/part0=501].
2024-05-01T05:15:37,551  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:37,591  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:37,591  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:37,592  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:37,592  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:37,592  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d80d9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2eaf5fcf will be shutdown
2024-05-01T05:15:37,592  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d80d9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b2d06e9 created in the thread with id: 1104
2024-05-01T05:15:37,594  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:37,594  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:37,594  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:37,594  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d80d9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b2d06e9 will be shutdown
2024-05-01T05:15:37,594  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:37,594  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -100
2024-05-01T05:15:37,594  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:37,595  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:37,595  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb7f024, with PersistenceManager: null will be shutdown
2024-05-01T05:15:37,595  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb7f024, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37c98853 created in the thread with id: 1104
2024-05-01T05:15:37,596  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@eb7f024 from thread id: 1104
2024-05-01T05:15:37,597  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:37,597  WARN [Thread-1038] mapred.LocalJobRunner: job_local928760612_0026
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,22537162348487527/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:38,363  INFO [main] mapreduce.Job: Job job_local928760612_0026 running in uber mode : false
2024-05-01T05:15:38,364  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:38,364  INFO [main] mapreduce.Job: Job job_local928760612_0026 failed with state FAILED due to: NA
2024-05-01T05:15:38,365  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13282196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=905445376
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:38,413  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:38,414  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:38,414  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:38,416  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:38,416  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:38,416  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d58136, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@173a86ad will be shutdown
2024-05-01T05:15:38,416  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d58136, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e1349cf created in the thread with id: 1
2024-05-01T05:15:38,418  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:38,418  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:38,419  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:38,419  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d58136, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e1349cf will be shutdown
2024-05-01T05:15:38,419  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:38,419  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -101
2024-05-01T05:15:38,419  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:38,420  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:38,420  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5248474e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:38,420  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5248474e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3269ae62 created in the thread with id: 1
2024-05-01T05:15:38,422  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5248474e from thread id: 1
2024-05-01T05:15:38,423  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:38,428  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:38,433  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:38,471  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:38,471  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:38,472  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:38,472  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:38,472  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5248474e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3269ae62 will be shutdown
2024-05-01T05:15:38,473  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5248474e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ffaac1f created in the thread with id: 1
2024-05-01T05:15:38,474  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:38,475  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:38,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:38,475  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5248474e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ffaac1f will be shutdown
2024-05-01T05:15:38,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:38,475  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -102
2024-05-01T05:15:38,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:38,476  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:38,476  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105c253a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:38,476  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105c253a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@156322ce created in the thread with id: 1
2024-05-01T05:15:38,478  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105c253a from thread id: 1
2024-05-01T05:15:38,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T05:15:38,493  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:38,498  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:38,498  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:38,519  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:38,536  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1209358112_0027
2024-05-01T05:15:38,536  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:38,588  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:38,588  INFO [main] mapreduce.Job: Running job: job_local1209358112_0027
2024-05-01T05:15:38,589  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:38,590  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,590  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,591  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:38,591  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,591  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,639  INFO [Thread-1084] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:38,639  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1209358112_0027_m_000000_0
2024-05-01T05:15:38,641  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,641  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,642  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,642  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,642  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:38,643  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:38,644  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,644  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,657  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:38,658  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T05:15:38,658  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T05:15:38,658  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1209358112_0027_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:38,658  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,658  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,661  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:38,662  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1209358112_0027_m_000000_0 is allowed to commit now
2024-05-01T05:15:38,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:38,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:38,672  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1209358112_0027_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,22581636689079398/part1=p1value2/part0=502
2024-05-01T05:15:38,672  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:38,672  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1209358112_0027_m_000000_0' done.
2024-05-01T05:15:38,672  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1209358112_0027_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13795509
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=928514048
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:38,672  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1209358112_0027_m_000000_0
2024-05-01T05:15:38,672  INFO [Thread-1084] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:38,718  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:38,719  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:38,719  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:38,719  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:38,719  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:38,719  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:38,720  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:38,720  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:38,720  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:38,721  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@574014da, with PersistenceManager: null will be shutdown
2024-05-01T05:15:38,721  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@574014da, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77d38293 created in the thread with id: 1152
2024-05-01T05:15:38,722  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@574014da from thread id: 1152
2024-05-01T05:15:38,722  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:38,722  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:38,722  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:38,722  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@574014da, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77d38293 will be shutdown
2024-05-01T05:15:38,723  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:38,723  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -103
2024-05-01T05:15:38,723  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:38,723  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:38,724  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46daa9b9, with PersistenceManager: null will be shutdown
2024-05-01T05:15:38,724  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46daa9b9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60e62a7b created in the thread with id: 1152
2024-05-01T05:15:38,725  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46daa9b9 from thread id: 1152
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:38,770  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:38,771  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:38,793  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,22581636689079398/part1=p1value2/part0=502].
2024-05-01T05:15:38,793  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:38,832  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:38,833  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:38,833  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:38,833  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:38,834  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46daa9b9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60e62a7b will be shutdown
2024-05-01T05:15:38,834  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46daa9b9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ce08128 created in the thread with id: 1152
2024-05-01T05:15:38,836  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:38,836  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:38,836  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:38,836  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46daa9b9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ce08128 will be shutdown
2024-05-01T05:15:38,836  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:38,836  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -104
2024-05-01T05:15:38,836  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:38,837  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:38,837  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73b1e9a6, with PersistenceManager: null will be shutdown
2024-05-01T05:15:38,837  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73b1e9a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2af83a95 created in the thread with id: 1152
2024-05-01T05:15:38,839  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73b1e9a6 from thread id: 1152
2024-05-01T05:15:38,839  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:38,839  WARN [Thread-1084] mapred.LocalJobRunner: job_local1209358112_0027
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,22581636689079398/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:39,589  INFO [main] mapreduce.Job: Job job_local1209358112_0027 running in uber mode : false
2024-05-01T05:15:39,589  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:39,589  INFO [main] mapreduce.Job: Job job_local1209358112_0027 failed with state FAILED due to: NA
2024-05-01T05:15:39,590  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13795509
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=928514048
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:39,648  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:39,649  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:39,650  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:39,652  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:39,652  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:39,652  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105c253a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@156322ce will be shutdown
2024-05-01T05:15:39,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105c253a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a131edc created in the thread with id: 1
2024-05-01T05:15:39,655  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:39,655  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:39,655  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:39,655  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105c253a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a131edc will be shutdown
2024-05-01T05:15:39,655  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:39,655  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -105
2024-05-01T05:15:39,655  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:39,656  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:39,657  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e13e2fc, with PersistenceManager: null will be shutdown
2024-05-01T05:15:39,657  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e13e2fc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13448d2d created in the thread with id: 1
2024-05-01T05:15:39,659  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e13e2fc from thread id: 1
2024-05-01T05:15:39,660  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:39,665  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:39,672  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:39,713  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:39,714  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:39,714  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:39,714  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:39,714  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:39,714  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:39,714  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:39,715  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:39,715  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e13e2fc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13448d2d will be shutdown
2024-05-01T05:15:39,715  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e13e2fc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55b56db3 created in the thread with id: 1
2024-05-01T05:15:39,717  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:39,717  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:39,717  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:39,717  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e13e2fc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55b56db3 will be shutdown
2024-05-01T05:15:39,717  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:39,717  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -106
2024-05-01T05:15:39,717  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:39,718  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:39,718  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b0e903a, with PersistenceManager: null will be shutdown
2024-05-01T05:15:39,718  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b0e903a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ca2fcb5 created in the thread with id: 1
2024-05-01T05:15:39,720  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b0e903a from thread id: 1
2024-05-01T05:15:39,720  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T05:15:39,731  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:39,736  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:39,737  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:39,757  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:39,773  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local701875419_0028
2024-05-01T05:15:39,773  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:39,825  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:39,825  INFO [main] mapreduce.Job: Running job: job_local701875419_0028
2024-05-01T05:15:39,826  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:39,827  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,827  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,828  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:39,828  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,828  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,842  INFO [Thread-1130] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:39,842  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local701875419_0028_m_000000_0
2024-05-01T05:15:39,844  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,844  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,845  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,845  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,845  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:39,846  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T05:15:39,847  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,847  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,860  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:39,860  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T05:15:39,860  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T05:15:39,860  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local701875419_0028_m_000000_0 is done. And is in the process of committing
2024-05-01T05:15:39,860  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,860  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,864  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T05:15:39,864  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local701875419_0028_m_000000_0 is allowed to commit now
2024-05-01T05:15:39,864  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:39,864  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:39,875  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local701875419_0028_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,8328465341676378/part1=p1value2/part0=502
2024-05-01T05:15:39,875  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T05:15:39,875  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local701875419_0028_m_000000_0' done.
2024-05-01T05:15:39,875  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local701875419_0028_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14306421
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=928514048
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:39,875  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local701875419_0028_m_000000_0
2024-05-01T05:15:39,876  INFO [Thread-1130] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:39,935  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:39,935  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:39,936  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:39,936  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:39,936  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:39,936  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2905649c, with PersistenceManager: null will be shutdown
2024-05-01T05:15:39,936  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2905649c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@545fb79e created in the thread with id: 1200
2024-05-01T05:15:39,938  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2905649c from thread id: 1200
2024-05-01T05:15:39,938  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:39,938  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:39,938  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:39,938  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2905649c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@545fb79e will be shutdown
2024-05-01T05:15:39,938  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:39,938  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -107
2024-05-01T05:15:39,938  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:39,939  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:39,939  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cf84dc2, with PersistenceManager: null will be shutdown
2024-05-01T05:15:39,939  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cf84dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77f53e88 created in the thread with id: 1200
2024-05-01T05:15:39,941  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cf84dc2 from thread id: 1200
2024-05-01T05:15:39,986  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:39,986  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:39,986  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:39,986  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:39,986  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:39,986  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:39,987  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:39,987  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:39,987  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:39,987  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:39,987  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:39,987  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T05:15:40,010  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,8328465341676378/part1=p1value2/part0=502].
2024-05-01T05:15:40,010  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:40,048  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:40,049  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:40,049  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:40,049  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:40,049  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:40,050  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:40,050  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:40,050  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cf84dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77f53e88 will be shutdown
2024-05-01T05:15:40,050  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cf84dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b17d11c created in the thread with id: 1200
2024-05-01T05:15:40,052  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:40,052  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:40,052  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:40,052  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cf84dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b17d11c will be shutdown
2024-05-01T05:15:40,052  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:40,052  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -108
2024-05-01T05:15:40,052  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:40,053  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:40,053  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4194444e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:40,053  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4194444e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c7c758d created in the thread with id: 1200
2024-05-01T05:15:40,055  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4194444e from thread id: 1200
2024-05-01T05:15:40,055  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:40,055  WARN [Thread-1130] mapred.LocalJobRunner: job_local701875419_0028
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,8328465341676378/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T05:15:40,306  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T05:15:40,826  INFO [main] mapreduce.Job: Job job_local701875419_0028 running in uber mode : false
2024-05-01T05:15:40,826  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T05:15:40,826  INFO [main] mapreduce.Job: Job job_local701875419_0028 failed with state FAILED due to: NA
2024-05-01T05:15:40,826  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14306421
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=928514048
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T05:15:40,872  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:40,872  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:40,872  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:40,872  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:40,872  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:40,872  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:40,873  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:40,873  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:40,873  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:40,873  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:40,873  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:40,873  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:40,873  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:40,875  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:40,875  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:40,875  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b0e903a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ca2fcb5 will be shutdown
2024-05-01T05:15:40,875  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b0e903a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ff7042c created in the thread with id: 1
2024-05-01T05:15:40,877  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:40,877  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:40,877  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:40,877  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b0e903a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ff7042c will be shutdown
2024-05-01T05:15:40,877  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:40,877  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -109
2024-05-01T05:15:40,877  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:40,878  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:40,878  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@568945a9, with PersistenceManager: null will be shutdown
2024-05-01T05:15:40,878  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@568945a9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4127dcdb created in the thread with id: 1
2024-05-01T05:15:40,879  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@568945a9 from thread id: 1
2024-05-01T05:15:40,880  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:40,884  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:40,889  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:40,923  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:40,923  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:40,924  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:40,924  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:40,924  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@568945a9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4127dcdb will be shutdown
2024-05-01T05:15:40,924  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@568945a9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f774d60 created in the thread with id: 1
2024-05-01T05:15:40,926  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:40,926  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:40,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:40,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@568945a9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f774d60 will be shutdown
2024-05-01T05:15:40,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:40,926  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -110
2024-05-01T05:15:40,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:40,927  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:40,927  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13ea9afc, with PersistenceManager: null will be shutdown
2024-05-01T05:15:40,927  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13ea9afc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f54cdc4 created in the thread with id: 1
2024-05-01T05:15:40,928  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13ea9afc from thread id: 1
2024-05-01T05:15:40,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:40,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:40,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:40,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:40,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:40,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:40,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:40,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:40,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:40,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:40,975  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:40,975  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:40,976  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:40,977  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:40,977  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:40,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13ea9afc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f54cdc4 will be shutdown
2024-05-01T05:15:40,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13ea9afc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@18a129b8 created in the thread with id: 1
2024-05-01T05:15:40,979  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:40,979  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:40,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:40,979  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13ea9afc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@18a129b8 will be shutdown
2024-05-01T05:15:40,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:40,979  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -111
2024-05-01T05:15:40,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:40,980  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:40,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: null will be shutdown
2024-05-01T05:15:40,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1380a19b created in the thread with id: 1
2024-05-01T05:15:40,982  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d from thread id: 1
2024-05-01T05:15:40,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:40,988  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:41,034  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:41,034  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:41,035  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:41,036  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:41,036  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:41,037  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1380a19b will be shutdown
2024-05-01T05:15:41,037  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f0de07 created in the thread with id: 1
2024-05-01T05:15:41,038  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:41,038  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:41,038  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:41,039  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f0de07 will be shutdown
2024-05-01T05:15:41,039  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:41,039  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -112
2024-05-01T05:15:41,039  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:41,039  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:41,040  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: null will be shutdown
2024-05-01T05:15:41,040  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@632cfbc5 created in the thread with id: 1
2024-05-01T05:15:41,041  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47 from thread id: 1
2024-05-01T05:15:41,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:41,046  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:41,051  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:41,084  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:41,085  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:41,085  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:41,085  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:41,086  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@632cfbc5 will be shutdown
2024-05-01T05:15:41,086  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12ce9299 created in the thread with id: 1
2024-05-01T05:15:41,087  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:41,087  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:41,087  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:41,087  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12ce9299 will be shutdown
2024-05-01T05:15:41,087  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:41,087  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -113
2024-05-01T05:15:41,087  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:41,088  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:41,088  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: null will be shutdown
2024-05-01T05:15:41,088  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b517988 created in the thread with id: 1
2024-05-01T05:15:41,090  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71 from thread id: 1
2024-05-01T05:15:41,096  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:41,101  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:41,101  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T05:15:41,121  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T05:15:41,136  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1563695326_0029
2024-05-01T05:15:41,137  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:41,190  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:41,190  INFO [main] mapreduce.Job: Running job: job_local1563695326_0029
2024-05-01T05:15:41,190  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:41,191  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T05:15:41,192  INFO [Thread-1181] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:41,193  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1563695326_0029_m_000000_0
2024-05-01T05:15:41,195  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T05:15:41,195  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T05:15:41,199  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1563695326_0029_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.21790814373206313/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T05:15:41,199  INFO [Thread-1181] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:41,200  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.21790814373206313].
2024-05-01T05:15:41,200  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T05:15:41,238  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:41,238  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:41,238  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:41,238  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:41,238  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:41,238  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:41,239  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:41,239  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:41,239  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:41,239  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:41,239  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:41,239  INFO [Thread-1181] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T05:15:41,240  INFO [Thread-1181] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:41,240  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:41,240  INFO [Thread-1181] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:41,240  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2372abe9, with PersistenceManager: null will be shutdown
2024-05-01T05:15:41,240  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2372abe9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20ae106a created in the thread with id: 1253
2024-05-01T05:15:41,242  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2372abe9 from thread id: 1253
2024-05-01T05:15:41,242  INFO [Thread-1181] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:41,242  INFO [Thread-1181] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:41,243  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:41,243  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2372abe9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20ae106a will be shutdown
2024-05-01T05:15:41,243  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:41,243  INFO [Thread-1181] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -114
2024-05-01T05:15:41,243  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:41,243  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:41,244  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@564a6053, with PersistenceManager: null will be shutdown
2024-05-01T05:15:41,244  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@564a6053, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23d409f1 created in the thread with id: 1253
2024-05-01T05:15:41,245  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@564a6053 from thread id: 1253
2024-05-01T05:15:41,246  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T05:15:41,246  WARN [Thread-1181] mapred.LocalJobRunner: job_local1563695326_0029
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T05:15:42,190  INFO [main] mapreduce.Job: Job job_local1563695326_0029 running in uber mode : false
2024-05-01T05:15:42,190  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:42,190  INFO [main] mapreduce.Job: Job job_local1563695326_0029 failed with state FAILED due to: NA
2024-05-01T05:15:42,190  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:42,230  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:42,230  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:42,230  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:42,230  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:42,230  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:42,230  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:42,231  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:42,231  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:42,231  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:42,231  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:42,231  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T05:15:42,231  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T05:15:42,232  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T05:15:42,233  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T05:15:42,233  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T05:15:42,233  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b517988 will be shutdown
2024-05-01T05:15:42,233  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f1bde96 created in the thread with id: 1
2024-05-01T05:15:42,235  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T05:15:42,235  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T05:15:42,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T05:15:42,235  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f1bde96 will be shutdown
2024-05-01T05:15:42,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T05:15:42,235  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -115
2024-05-01T05:15:42,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T05:15:42,236  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T05:15:42,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c9cd06e, with PersistenceManager: null will be shutdown
2024-05-01T05:15:42,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c9cd06e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4afad6bd created in the thread with id: 1
2024-05-01T05:15:42,238  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c9cd06e from thread id: 1
2024-05-01T05:15:42,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:42,244  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:42,244  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:42,248  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T05:15:42,254  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T05:15:42,259  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T05:15:42,282  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T05:15:42,298  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1065355360_0030
2024-05-01T05:15:42,298  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T05:15:42,350  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T05:15:42,350  INFO [main] mapreduce.Job: Running job: job_local1065355360_0030
2024-05-01T05:15:42,350  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T05:15:42,350  INFO [Thread-1201] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T05:15:42,350  INFO [Thread-1201] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T05:15:42,350  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T05:15:42,358  INFO [Thread-1201] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T05:15:42,359  INFO [Thread-1201] mapred.LocalJobRunner: map task executor complete.
2024-05-01T05:15:43,350  INFO [main] mapreduce.Job: Job job_local1065355360_0030 running in uber mode : false
2024-05-01T05:15:43,350  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T05:15:43,350  INFO [main] mapreduce.Job: Job job_local1065355360_0030 completed successfully
2024-05-01T05:15:43,351  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T05:15:43,351  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:43,355  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T05:15:43,355  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T05:15:43,412  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T05:15:43,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T05:15:43,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T05:15:43,413  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
</testsuite>