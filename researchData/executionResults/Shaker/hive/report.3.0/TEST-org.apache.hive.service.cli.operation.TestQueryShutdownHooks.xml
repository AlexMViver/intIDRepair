<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="19.727" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter8234907003510693771.jar /home/alex/Repositories/hive/service/target/surefire 2024-05-01T13-51-42_861-jvmRun1 surefire986934208932013947tmp surefire_8123889597826566682220tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter8234907003510693771.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="15.688">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,084008 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4b520ea8
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,028380 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 894139
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T09:17:13.436-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-09:17:15.310, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-09:17:15.311, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@157853da...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@157853da OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3a1dd365
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@3de8f619
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619] started OK.
2024-05-01T09:17:15,432  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T09:17:15,948  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T09:17:16,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:17:16,015  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:17:16,015  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:17:16,016  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:17:16,016  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:17:16,016  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:17:16,016  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T09:17:16,017  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:17:16,017  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:17:16,018  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:17:16,018  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:17:16,018  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 564f1f4c-4722-49b7-b873-5519e907c6bb
2024-05-01T09:17:16,055  INFO [main] SessionState: Hive Session ID = 564f1f4c-4722-49b7-b873-5519e907c6bb
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:16,070  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:16,421  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/564f1f4c-4722-49b7-b873-5519e907c6bb
2024-05-01T09:17:16,424  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/564f1f4c-4722-49b7-b873-5519e907c6bb
2024-05-01T09:17:16,428  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/564f1f4c-4722-49b7-b873-5519e907c6bb/_tmp_space.db
2024-05-01T09:17:16,454  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=564f1f4c-4722-49b7-b873-5519e907c6bb, clientType=HIVESERVER2]
2024-05-01T09:17:16,524  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:17:16,762  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:17:16,811  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:17:16,821  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T09:17:16,821  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T09:17:16,851  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T09:17:16,857  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T09:17:17,789  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T09:17:17,794  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T09:17:18,551  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T09:17:18,552  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: null will be shutdown
2024-05-01T09:17:18,577  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f created in the thread with id: 1
2024-05-01T09:17:21,762  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T09:17:21,762  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T09:17:21,762  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64 from thread id: 1
2024-05-01T09:17:21,924  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T09:17:21,965  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T09:17:22,001  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T09:17:22,003  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T09:17:22,123  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T09:17:22,130  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T09:17:22,131  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T09:17:22,135  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T09:17:22,161  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T09:17:22,164  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T09:17:22,166  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T09:17:22,167  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T09:17:22,169  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T09:17:22,171  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T09:17:22,173  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T09:17:22,173  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T09:17:22,180  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T09:17:22,181  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T09:17:22,183  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T09:17:22,187  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:17:22,349  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:17:22,902  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,906  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,911  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,912  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,912  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,913  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,913  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T09:17:22,970  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T09:17:22,972  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T09:17:22,972  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T09:17:22,972  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T09:17:22,973  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T09:17:22,976  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-05-01T09:17:22,984  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-05-01T09:17:22,999  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T09:17:22,999  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T09:17:23,000  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T09:17:23,000  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T09:17:23,001  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T09:17:23,001  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T09:17:23,023  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T09:17:23,030  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:23,036  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:23,046  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8
2024-05-01T09:17:23,051  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8
2024-05-01T09:17:23,055  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/_tmp_space.db
2024-05-01T09:17:23,059  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T09:17:23,059  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T09:17:23,061  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:17:23,062  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:17:23,064  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f will be shutdown
2024-05-01T09:17:23,065  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 created in the thread with id: 1
2024-05-01T09:17:23,082  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:17:23,083  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:17:23,086  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-05-01T09:17:23,151  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:17:23,151  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 will be shutdown
2024-05-01T09:17:23,151  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:17:23,151  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T09:17:23,152  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8
2024-05-01T09:17:23,155  INFO [main] service.CompositeService: Session opened, SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8], current sessions:1
2024-05-01T09:17:23,160  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T09:17:23,167  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:23,184  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=894aa8c3-3542-46db-8b2a-0df059fbc7cf] SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8]
2024-05-01T09:17:23,188  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768.test
2024-05-01T09:17:23,201  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768, startTime=1714580243180, sessionId=91a624f8-b8bd-4d33-9a31-4e92db5c0bc8, createTime=1714580243032, userName=anonymous, ipAddress=null]
2024-05-01T09:17:23,267  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Compiling command(queryId=alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:24,023  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:17:24,026  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: null will be shutdown
2024-05-01T09:17:24,026  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 created in the thread with id: 1
2024-05-01T09:17:24,037  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d from thread id: 1
2024-05-01T09:17:24,258  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] reflections.Reflections: Reflections took 180 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T09:17:24,422  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] reflections.Reflections: Reflections took 110 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T09:17:24,534  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] reflections.Reflections: Reflections took 105 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T09:17:24,639  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
2024-05-01T09:17:24,643  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:24,643  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=91a624f8-b8bd-4d33-9a31-4e92db5c0bc8, clientType=HIVESERVER2]
2024-05-01T09:17:24,647  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:24,647  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:24,647  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:24,653  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:24,667  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:26,028  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:26,708  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:26,712  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:26,727  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:26,727  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:26,775  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-23_227_1863943531076026820-1
2024-05-01T09:17:26,820  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:26,909  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:26,933  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:27,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:27,022  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:27,023  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:27,023  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:27,023  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:27,023  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:27,023  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:27,026  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:27,026  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
2024-05-01T09:17:27,026  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:27,029  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:27,047  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:27,052  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:27,053  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=74, flushCache_()=15, getAllFunctions_()=65}
2024-05-01T09:17:27,053  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Completed compiling command(queryId=alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768); Time taken: 3.788 seconds
2024-05-01T09:17:27,054  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:27,055  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T09:17:27,063  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:27,068  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Executing command(queryId=alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:27,071  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T09:17:27,071  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:27,071  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001
2024-05-01T09:17:27,071  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001
2024-05-01T09:17:27,075  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
2024-05-01T09:17:27,075  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Query ID = alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
Total jobs = 1
2024-05-01T09:17:27,075  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:27,076  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:27,084  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:27,084  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:27,096  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:27,102  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:27,102  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/dummy_path
2024-05-01T09:17:27,228  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:27,258  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T09:17:27,420  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T09:17:27,439  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T09:17:27,462  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T09:17:27,462  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T09:17:27,487  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:27,541  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:27,553  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:27,557  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:27,559  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-05-01T09:17:27,571  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/dummy_path
2024-05-01T09:17:27,620  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:27,647  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:27,649  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:27,683  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:27,748  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local788417204_0001
2024-05-01T09:17:27,748  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:17:27,956  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T09:17:27,958  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:27,958  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:27,960  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:27,978  INFO [Thread-61] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:27,982  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local788417204_0001_m_000000_0
2024-05-01T09:17:28,029  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:28,043  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:28,053  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:28,093  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T09:17:28,103  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:28,114  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:28,116  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:28,120  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:28,120  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:28,125  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:28,126  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:28,127  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@588e071, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@6206685a, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@4f358bb
2024-05-01T09:17:28,140  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-23_227_1863943531076026820-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:28,140  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-23_227_1863943531076026820-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:28,140  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-23_227_1863943531076026820-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:28,185  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T09:17:28,185  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T09:17:28,185  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:28,185  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:28,186  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T09:17:28,189  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T09:17:28,195  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:17:28,208  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local788417204_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T09:17:28,210  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:17:28,210  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local788417204_0001_m_000000_0' done.
2024-05-01T09:17:28,213  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local788417204_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5586
		FILE: Number of bytes written=1152370
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=876085248
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:17:28,213  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local788417204_0001_m_000000_0
2024-05-01T09:17:28,215  INFO [Thread-61] mapred.LocalJobRunner: map task executor complete.
2024-05-01 09:17:28,974 Stage-1 map = 100%,  reduce = 0%
2024-05-01T09:17:28,974  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Task: 2024-05-01 09:17:28,974 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local788417204_0001
2024-05-01T09:17:28,979  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.Task: Ended Job = job_local788417204_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:28,992  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T09:17:28,992  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:28,992  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001
2024-05-01T09:17:28,992  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1/-mr-10001
2024-05-01T09:17:28,993  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:28,993  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:28,993  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T09:17:29,002  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:29,002  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:29,002  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Completed executing command(queryId=alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768); Time taken: 1.925 seconds
2024-05-01T09:17:29,002  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:29,006  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,007  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=f5f4865b-e76f-4e36-a0e6-c7b1358e9dd7] SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8]
2024-05-01T09:17:29,007  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec.test
2024-05-01T09:17:29,012  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec, startTime=1714580249006, sessionId=91a624f8-b8bd-4d33-9a31-4e92db5c0bc8, createTime=1714580243032, userName=anonymous, ipAddress=null]
2024-05-01T09:17:29,013  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Compiling command(queryId=alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec
2024-05-01T09:17:29,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:29,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:29,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,015  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,016  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:29,032  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,134  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,134  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,137  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,137  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,139  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1
2024-05-01T09:17:29,147  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:29,150  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:29,151  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:29,167  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:29,168  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec
2024-05-01T09:17:29,169  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:29,169  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:29,170  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:29,170  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:29,170  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=1}
2024-05-01T09:17:29,171  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Completed compiling command(queryId=alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec); Time taken: 0.157 seconds
2024-05-01T09:17:29,172  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:29,172  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,174  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Thread context registration is done.
2024-05-01T09:17:29,174  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=42b87647-c29d-43ea-9c1f-d2cb867fabbf] SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8]
2024-05-01T09:17:29,174  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:29,174  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f.test
2024-05-01T09:17:29,181  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f, startTime=1714580249172, sessionId=91a624f8-b8bd-4d33-9a31-4e92db5c0bc8, createTime=1714580243032, userName=anonymous, ipAddress=null]
2024-05-01T09:17:29,181  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:29,182  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,182  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Compiling command(queryId=alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,183  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T09:17:29,183  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:29,184  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001
2024-05-01T09:17:29,184  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001
2024-05-01T09:17:29,185  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f
2024-05-01T09:17:29,185  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:29,185  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:29,185  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,185  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,185  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,185  WARN [HiveServer2-Background-Pool: Thread-121] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-05-01T09:17:29,186  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
Query ID = alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec
2024-05-01T09:17:29,186  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Query ID = alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec
Total jobs = 1
2024-05-01T09:17:29,186  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:29,186  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:29,194  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,194  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,227  INFO [HiveServer2-Background-Pool: Thread-121] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:29,228  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:29,228  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/dummy_path
2024-05-01T09:17:29,233  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,246  INFO [HiveServer2-Background-Pool: Thread-121] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:29,249  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,250  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,258  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,268  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:29,279  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:29,280  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:29,281  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/dummy_path
2024-05-01T09:17:29,288  INFO [HiveServer2-Background-Pool: Thread-121] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:29,288  INFO [HiveServer2-Background-Pool: Thread-121] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:29,289  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:29,329  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:29,337  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,338  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,343  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,343  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,345  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1
2024-05-01T09:17:29,359  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:29,362  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:29,364  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:29,369  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Submitting tokens for job: job_local534754408_0002
2024-05-01T09:17:29,369  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:17:29,384  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:29,385  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:29,385  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:29,385  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:29,385  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:29,385  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:29,385  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:29,386  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:29,386  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f
2024-05-01T09:17:29,386  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:29,386  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:29,387  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:29,388  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:29,388  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=8, flushCache_()=0}
2024-05-01T09:17:29,388  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Completed compiling command(queryId=alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f); Time taken: 0.206 seconds
2024-05-01T09:17:29,388  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:29,389  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,390  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=c473f7ef-f9a1-4074-950a-e844c64eda85] SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8]
2024-05-01T09:17:29,390  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236.test
2024-05-01T09:17:29,395  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236, startTime=1714580249389, sessionId=91a624f8-b8bd-4d33-9a31-4e92db5c0bc8, createTime=1714580243032, userName=anonymous, ipAddress=null]
2024-05-01T09:17:29,397  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Compiling command(queryId=alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,399  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236
2024-05-01T09:17:29,400  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:29,400  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:29,400  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,400  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,400  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,400  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:29,404  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Thread context registration is done.
2024-05-01T09:17:29,405  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:29,408  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:29,409  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,409  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T09:17:29,410  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:29,410  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001
2024-05-01T09:17:29,410  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001
2024-05-01T09:17:29,410  WARN [HiveServer2-Background-Pool: Thread-156] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f
2024-05-01T09:17:29,411  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Query ID = alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f
Total jobs = 1
2024-05-01T09:17:29,411  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:29,411  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:29,417  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,418  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,432  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,437  INFO [HiveServer2-Background-Pool: Thread-156] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:29,437  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:29,437  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/dummy_path
2024-05-01T09:17:29,467  INFO [HiveServer2-Background-Pool: Thread-156] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:29,471  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,472  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,480  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,494  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:29,503  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:29,504  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:29,508  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/dummy_path
2024-05-01T09:17:29,515  INFO [HiveServer2-Background-Pool: Thread-156] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:29,515  INFO [HiveServer2-Background-Pool: Thread-156] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:29,516  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:29,520  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:17:29,521  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:29,521  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T09:17:29,522  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:29,524  INFO [Thread-113] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:29,525  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local534754408_0002_m_000000_0
2024-05-01T09:17:29,527  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:29,528  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:29,529  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:29,532  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,533  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:29,534  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:29,535  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:29,535  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:29,536  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:29,537  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:29,538  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:29,538  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@18b2a50f, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7be0cace, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@60d836db
2024-05-01T09:17:29,552  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,552  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:29,552  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,555  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,555  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,557  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1
2024-05-01T09:17:29,566  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:29,568  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:29,569  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:29,583  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:29,583  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:29,583  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:29,583  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:29,583  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:29,584  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:29,584  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:29,584  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:29,584  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236
2024-05-01T09:17:29,584  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:29,584  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:29,585  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:29,586  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:29,586  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=11}
2024-05-01T09:17:29,586  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Completed compiling command(queryId=alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236); Time taken: 0.189 seconds
2024-05-01T09:17:29,586  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:29,587  INFO [HiveServer2-Background-Pool: Thread-196] common.LogUtils: Thread context registration is done.
2024-05-01T09:17:29,587  INFO [HiveServer2-Background-Pool: Thread-196] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:29,587  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,588  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:29,588  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Executing command(queryId=alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,589  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=acadf6d2-4507-4617-a853-84d051b019af] SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8]
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,589  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY2024-05-01T09:17:29,589  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Thread context registration is done.

2024-05-01T09:17:29,589  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: type: QUERY
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
2024-05-01T09:17:29,592  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Submitting tokens for job: job_local264450203_0003
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d.test
2024-05-01T09:17:29,594  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d, startTime=1714580249588, sessionId=91a624f8-b8bd-4d33-9a31-4e92db5c0bc8, createTime=1714580243032, userName=anonymous, ipAddress=null]
PREHOOK: Input: _dummy_database@_dummy_table2024-05-01T09:17:29,594  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Executing with tokens: []

2024-05-01T09:17:29,594  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001
2024-05-01T09:17:29,595  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001
2024-05-01T09:17:29,595  WARN [HiveServer2-Background-Pool: Thread-196] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236
2024-05-01T09:17:29,595  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Query ID = alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236
Total jobs = 1
2024-05-01T09:17:29,595  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:29,595  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:29,596  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Compiling command(queryId=alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,597  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d
2024-05-01T09:17:29,598  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:29,598  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:29,598  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,598  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,598  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,598  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:29,599  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,599  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,606  INFO [HiveServer2-Background-Pool: Thread-196] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:29,607  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:29,607  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/dummy_path
2024-05-01T09:17:29,615  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,621  INFO [HiveServer2-Background-Pool: Thread-196] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:29,623  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,624  WARN [HiveServer2-Background-Pool: Thread-196] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,631  WARN [HiveServer2-Background-Pool: Thread-196] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,653  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:29,660  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:29,660  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:29,662  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/dummy_path
2024-05-01T09:17:29,670  INFO [HiveServer2-Background-Pool: Thread-196] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:29,670  INFO [HiveServer2-Background-Pool: Thread-196] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:29,671  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:29,698  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:29,709  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)2024-05-01T09:17:29,710  INFO [Thread-151] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter

2024-05-01T09:17:29,710  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:29,710  INFO [Thread-151] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:29,713  INFO [Thread-151] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:29,713  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local264450203_0003_m_000000_0
2024-05-01T09:17:29,720  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:29,721  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:29,722  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:29,722  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:29,723  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:29,724  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,725  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:29,725  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:29,725  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:29,726  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:29,726  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:29,727  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:29,727  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:29,727  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:29,727  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:29,728  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1
2024-05-01T09:17:29,728  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@73a81faf, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@d6b27fc, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@b341f60
2024-05-01T09:17:29,730  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: Submitting tokens for job: job_local330532849_0004
2024-05-01T09:17:29,730  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:17:29,738  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:29,740  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:29,741  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:29,758  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:29,758  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:29,758  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:29,758  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:29,758  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:29,758  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:29,759  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:29,759  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:29,759  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d
2024-05-01T09:17:29,759  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:29,759  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:29,760  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:29,760  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:29,760  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=9, flushCache_()=0}
2024-05-01T09:17:29,760  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Completed compiling command(queryId=alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d); Time taken: 0.164 seconds
2024-05-01T09:17:29,761  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:29,761  INFO [HiveServer2-Background-Pool: Thread-237] common.LogUtils: Thread context registration is done.
2024-05-01T09:17:29,761  INFO [HiveServer2-Background-Pool: Thread-237] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:29,762  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:29,763  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Executing command(queryId=alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T09:17:29,763  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T09:17:29,763  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:29,763  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001
2024-05-01T09:17:29,763  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001
2024-05-01T09:17:29,764  WARN [HiveServer2-Background-Pool: Thread-237] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d
2024-05-01T09:17:29,764  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Query ID = alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d
Total jobs = 1
2024-05-01T09:17:29,764  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:29,764  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:29,768  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,768  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:29,775  INFO [HiveServer2-Background-Pool: Thread-237] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:29,775  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:29,775  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/dummy_path
2024-05-01T09:17:29,789  INFO [HiveServer2-Background-Pool: Thread-237] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:29,791  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,792  WARN [HiveServer2-Background-Pool: Thread-237] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,798  WARN [HiveServer2-Background-Pool: Thread-237] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:29,806  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:29,812  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:29,813  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:29,814  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/dummy_path
2024-05-01T09:17:29,818  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:17:29,818  INFO [Thread-185] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T09:17:29,818  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:29,818  INFO [Thread-185] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:29,820  INFO [HiveServer2-Background-Pool: Thread-237] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:29,820  INFO [Thread-185] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:29,820  INFO [HiveServer2-Background-Pool: Thread-237] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:29,820  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local330532849_0004_m_000000_0
2024-05-01T09:17:29,821  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:29,821  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:29,822  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:29,823  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:29,825  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,826  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:29,826  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:29,827  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:29,828  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:29,828  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:29,828  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:29,828  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:29,829  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@44ddbdca, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@72233816, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@15cdb225
2024-05-01T09:17:29,849  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:29,887  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: Submitting tokens for job: job_local512356409_0005
2024-05-01T09:17:29,887  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:17:29,964  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:17:29,965  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:29,965  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T09:17:29,965  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:29,966  INFO [Thread-218] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:29,967  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local512356409_0005_m_000000_0
2024-05-01T09:17:29,967  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:29,968  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:29,969  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:29,970  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:29,971  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:29,971  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:29,972  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:29,972  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:29,973  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:29,973  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:29,973  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:29,973  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@432a7f9c, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@61114b36, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@3b5a15d3
2024-05-01T09:17:30,277  INFO [main] service.CompositeService: Session closed, SessionHandle [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8], current sessions:0
2024-05-01T09:17:30,277  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=894aa8c3-3542-46db-8b2a-0df059fbc7cf]
2024-05-01T09:17:30,277  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Removed queryId: alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=894aa8c3-3542-46db-8b2a-0df059fbc7cf] with tag: null
2024-05-01T09:17:30,278  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1
2024-05-01T09:17:30,279  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1 operation was queued
2024-05-01T09:17:30,279  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T09:17:30,279  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:30,279  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768 without delay
2024-05-01T09:17:30,279  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=f5f4865b-e76f-4e36-a0e6-c7b1358e9dd7]
2024-05-01T09:17:30,279  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Removed queryId: alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=f5f4865b-e76f-4e36-a0e6-c7b1358e9dd7] with tag: null
2024-05-01T09:17:30,280  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec
2024-05-01T09:17:30,280  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T09:17:30,280  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-23_227_1863943531076026820-1
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T09:17:30,280  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T09:17:30,280  WARN [Thread-113] mapred.LocalJobRunner: job_local534754408_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:17:30,281  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-2
2024-05-01 09:17:30,280 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,281  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,281  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: 2024-05-01 09:17:30,280 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,281  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,281  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-2 operation was queued
2024-05-01T09:17:30,281  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,281  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1
2024-05-01T09:17:30,281  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1 operation was queued
2024-05-01T09:17:30,281  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T09:17:30,281  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-2
Ended Job = job_local534754408_0002 with errors
2024-05-01T09:17:30,281 ERROR [HiveServer2-Background-Pool: Thread-121] exec.Task: Ended Job = job_local534754408_0002 with errors
2024-05-01T09:17:30,281  WARN [EventualCleanupService thread 2] fs.FileUtil: Failed to delete file or dir [/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1]: it still exists.
2024-05-01T09:17:30,282  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T09:17:30,282  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1
2024-05-01T09:17:30,282  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:30,282  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec without delay
2024-05-01T09:17:30,282  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=acadf6d2-4507-4617-a853-84d051b019af]
2024-05-01T09:17:30,282  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Removed queryId: alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=acadf6d2-4507-4617-a853-84d051b019af] with tag: null
2024-05-01T09:17:30,282  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d
2024-05-01T09:17:30,283  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T09:17:30,283  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,283  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,283  WARN [Thread-218] mapred.LocalJobRunner: job_local512356409_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:17:30,283  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,283  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 09:17:30,283 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,284  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: 2024-05-01 09:17:30,283 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,284  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-5
2024-05-01T09:17:30,284  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-5 operation was queued
Error during job, obtaining debugging information...
2024-05-01T09:17:30,284 ERROR [Thread-223] exec.Task: Error during job, obtaining debugging information...
2024-05-01T09:17:30,284  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1
2024-05-01T09:17:30,284  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local512356409_0005 with errors
2024-05-01T09:17:30,285  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1 operation was queued
2024-05-01T09:17:30,285 ERROR [HiveServer2-Background-Pool: Thread-237] exec.Task: Ended Job = job_local512356409_0005 with errors
2024-05-01T09:17:30,285  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T09:17:30,285  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:30,284  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-5
2024-05-01T09:17:30,285  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1
2024-05-01T09:17:30,286  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d without delay
Error during job, obtaining debugging information...
2024-05-01T09:17:30,286  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=42b87647-c29d-43ea-9c1f-d2cb867fabbf]
2024-05-01T09:17:30,286 ERROR [Thread-225] exec.Task: Error during job, obtaining debugging information...
2024-05-01T09:17:30,286  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Removed queryId: alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=42b87647-c29d-43ea-9c1f-d2cb867fabbf] with tag: null
2024-05-01T09:17:30,287  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f
2024-05-01T09:17:30,287  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T09:17:30,289  WARN [Thread-151] mapred.LocalJobRunner: job_local264450203_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:17:30,289  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-3
2024-05-01T09:17:30,289  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-05-01T09:17:30,289  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-3
FAILED: Operation cancelled2024-05-01T09:17:30,289  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-3 operation was queued

2024-05-01T09:17:30,290 ERROR [HiveServer2-Background-Pool: Thread-121] ql.Driver: FAILED: Operation cancelled
2024-05-01T09:17:30,290  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1
2024-05-01T09:17:30,290  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:30,290  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:30,290  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: MapReduce Jobs Launched: 
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T09:17:30,290  INFO [EventualCleanupService thread 6] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1
2024-05-01T09:17:30,290  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,290  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1 operation was queued
2024-05-01T09:17:30,290  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,290  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,290  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T09:17:30,291  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:30,291  INFO [HiveServer2-Background-Pool: Thread-237] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T09:17:30,292 ERROR [HiveServer2-Background-Pool: Thread-237] ql.Driver: FAILED: Operation cancelled
2024-05-01T09:17:30,292  INFO [HiveServer2-Background-Pool: Thread-237] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:30,292  INFO [HiveServer2-Background-Pool: Thread-237] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:30,292  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T09:17:30,292  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-05-01T09:17:30,292  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 09:17:30,292 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,292  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: 2024-05-01 09:17:30,292 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,292  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local264450203_0003 with errors2024-05-01T09:17:30,293  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f without delay
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:30,294  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:30,294  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=c473f7ef-f9a1-4074-950a-e844c64eda85]
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:30,294  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:30,294  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.OperationManager: Removed queryId: alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=c473f7ef-f9a1-4074-950a-e844c64eda85] with tag: null
2024-05-01T09:17:30,294  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501091729_86c1c393-bae8-4c66-b4c1-f94003fa14ec) has been interrupted after 1.108 seconds
2024-05-01T09:17:30,296  WARN [HiveServer2-Background-Pool: Thread-121] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T09:17:30,297  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:30,297  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236
2024-05-01T09:17:30,298  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 09:17:30,298 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,298  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: 2024-05-01 09:17:30,298 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:30,299  WARN [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Driver: Shutting down task : Stage-1:MAPRED

2024-05-01T09:17:30,299 ERROR [HiveServer2-Background-Pool: Thread-156] exec.Task: Ended Job = job_local264450203_0003 with errors
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:30,299  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-4
2024-05-01T09:17:30,299  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:30,299  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T09:17:30,299  WARN [Thread-185] mapred.LocalJobRunner: job_local330532849_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:17:30,299  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Executing command(queryId=alex_20240501091729_746a3bb7-11c8-4027-a27c-95253755ef6d) has been interrupted after 0.529 seconds
Error during job, obtaining debugging information...
2024-05-01T09:17:30,299  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,299 ERROR [Thread-231] exec.Task: Error during job, obtaining debugging information...
2024-05-01T09:17:30,299  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,299  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,300  WARN [HiveServer2-Background-Pool: Thread-237] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T09:17:30,300  INFO [HiveServer2-Background-Pool: Thread-237] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:30,301  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T09:17:30,301 ERROR [HiveServer2-Background-Pool: Thread-156] ql.Driver: FAILED: Operation cancelled
2024-05-01T09:17:30,301  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-4 operation was queued
2024-05-01T09:17:30,302  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:30,302  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:30,302  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T09:17:30,302  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-05-01T09:17:30,302  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1
2024-05-01T09:17:30,302  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1 operation was queued
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:30,302  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:30,302  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:30,302  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:30,302  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:30,302  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501091729_45459fb9-89dd-497f-a873-bd715580285f) has been interrupted after 0.892 seconds
2024-05-01T09:17:30,302  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-4
2024-05-01T09:17:30,302  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236 without delay
2024-05-01T09:17:30,303  INFO [91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8
2024-05-01T09:17:30,302  WARN [HiveServer2-Background-Pool: Thread-156] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T09:17:30,303  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1
2024-05-01T09:17:30,303  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:30,304  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 operation was queued
2024-05-01T09:17:30,304  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8 operation was queued
2024-05-01T09:17:30,305  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8
2024-05-01T09:17:30,305  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8
2024-05-01T09:17:30,315  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:17:30,315  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 will be shutdown
2024-05-01T09:17:30,315  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:17:30,315  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T09:17:30,321 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T09:17:30,321 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T09:17:30,321 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:239)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T09:17:30,322  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:30,322  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T09:17:30,322  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:30,321 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T09:17:30,322  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:30,323  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_397_5264474595561732300-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_397_5264474595561732300-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,324  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_013_9120848895107665098-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_013_9120848895107665098-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_596_3866008159168762524-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_596_3866008159168762524-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,325  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,326  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,326  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/hive_2024-05-01_09-17-29_182_7527652981545720168-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-29_182_7527652981545720168-1/_tmp.-ext-10002/000000_0
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="1.918">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T09:17:30,356  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T09:17:30,359  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T09:17:30,359  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T09:17:30,361  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T09:17:30,409  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:17:30,410  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:17:30,410  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:17:30,410  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:17:30,410  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:17:30,410  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:17:30,410  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T09:17:30,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:17:30,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:17:30,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:17:30,411  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:17:30,411  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 98a498d0-0580-4e1e-b04e-a577535e261f
2024-05-01T09:17:30,412  INFO [main] SessionState: Hive Session ID = 98a498d0-0580-4e1e-b04e-a577535e261f
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:30,412  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:30,420  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/98a498d0-0580-4e1e-b04e-a577535e261f
2024-05-01T09:17:30,423  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/98a498d0-0580-4e1e-b04e-a577535e261f
2024-05-01T09:17:30,426  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/98a498d0-0580-4e1e-b04e-a577535e261f/_tmp_space.db
2024-05-01T09:17:30,426  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=98a498d0-0580-4e1e-b04e-a577535e261f, clientType=HIVESERVER2]
2024-05-01T09:17:30,427  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:17:30,428  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:17:30,428  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:17:30,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5216532a, with PersistenceManager: null will be shutdown
2024-05-01T09:17:30,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5216532a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@862624f created in the thread with id: 1
2024-05-01T09:17:30,433  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5216532a from thread id: 1
2024-05-01T09:17:30,433  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:17:30,434  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:17:30,434  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T09:17:30,434  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T09:17:30,434  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T09:17:30,434  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T09:17:30,435  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T09:17:30,436  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T09:17:30,438  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T09:17:30,438  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T09:17:30,438  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T09:17:30,438  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T09:17:30,438  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T09:17:30,439  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T09:17:30,439  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T09:17:30,450  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T09:17:30,450  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:30,451  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:30,459  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/34c88f5c-9638-4de1-bfde-a744354188ad
2024-05-01T09:17:30,462  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad
2024-05-01T09:17:30,465  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/34c88f5c-9638-4de1-bfde-a744354188ad/_tmp_space.db
2024-05-01T09:17:30,466  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T09:17:30,466  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T09:17:30,466  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:17:30,466  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5216532a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@862624f will be shutdown
2024-05-01T09:17:30,466  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:17:30,466  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T09:17:30,467  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad
2024-05-01T09:17:30,467  INFO [main] service.CompositeService: Session opened, SessionHandle [34c88f5c-9638-4de1-bfde-a744354188ad], current sessions:1
2024-05-01T09:17:30,467  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T09:17:30,467  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:30,468  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=d1556836-86f3-4562-984e-2a3cc68ef0b5] SessionHandle [34c88f5c-9638-4de1-bfde-a744354188ad]
2024-05-01T09:17:30,468  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c.test
2024-05-01T09:17:30,472  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c, startTime=1714580250467, sessionId=34c88f5c-9638-4de1-bfde-a744354188ad, createTime=1714580250450, userName=anonymous, ipAddress=null]
2024-05-01T09:17:30,473  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Compiling command(queryId=alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:30,474  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:17:30,475  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:17:30,475  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:17:30,476  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc40856, with PersistenceManager: null will be shutdown
2024-05-01T09:17:30,477  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc40856, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5543d800 created in the thread with id: 1
2024-05-01T09:17:30,482  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc40856 from thread id: 1
2024-05-01T09:17:30,482  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:17:30,483  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:17:30,483  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c
2024-05-01T09:17:30,484  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:30,484  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=34c88f5c-9638-4de1-bfde-a744354188ad, clientType=HIVESERVER2]
2024-05-01T09:17:30,484  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:30,484  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:30,484  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:30,484  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:30,485  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:30,499  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:30,556  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:30,556  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:30,558  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:30,558  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:30,560  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-30_473_7694350919802591869-1
2024-05-01T09:17:30,567  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:30,570  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:30,570  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:30,584  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c
2024-05-01T09:17:30,585  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:30,585  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:30,586  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:30,586  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:30,586  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=0}
2024-05-01T09:17:30,586  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Completed compiling command(queryId=alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c); Time taken: 0.113 seconds
2024-05-01T09:17:30,586  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:30,587  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T09:17:30,587  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:30,587  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Executing command(queryId=alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:30,587  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T09:17:30,588  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:30,588  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001
2024-05-01T09:17:30,588  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001
2024-05-01T09:17:30,588  WARN [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c
2024-05-01T09:17:30,588  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Query ID = alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c
Total jobs = 1
2024-05-01T09:17:30,588  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:30,588  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:30,591  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:30,591  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:30,594  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:30,594  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:30,594  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/dummy_path
2024-05-01T09:17:30,607  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:30,609  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T09:17:30,609  WARN [34c88f5c-9638-4de1-bfde-a744354188ad main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:30,614  WARN [34c88f5c-9638-4de1-bfde-a744354188ad main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:30,622  WARN [34c88f5c-9638-4de1-bfde-a744354188ad main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:30,628  WARN [34c88f5c-9638-4de1-bfde-a744354188ad main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:30,629  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:30,630  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/dummy_path
2024-05-01T09:17:30,635  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:30,635  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:30,635  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:30,660  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:30,684  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] mapreduce.JobSubmitter: Submitting tokens for job: job_local627052655_0006
2024-05-01T09:17:30,684  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:17:30,756  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:17:30,756  INFO [Thread-298] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T09:17:30,756  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:30,757  INFO [Thread-298] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:30,758  INFO [Thread-298] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:30,759  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local627052655_0006_m_000000_0
2024-05-01T09:17:30,762  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:30,763  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:30,766  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:30,767  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T09:17:30,767  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:30,771  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:30,771  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:30,772  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:30,772  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:30,772  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:30,772  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:30,773  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@11d53847, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@4128e4a3, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@18acee25
2024-05-01T09:17:30,774  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-30_473_7694350919802591869-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,774  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-30_473_7694350919802591869-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:30,774  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-30_473_7694350919802591869-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:30,786  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:30,787  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T09:17:30,788  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T09:17:30,788  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:17:30,792  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local627052655_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T09:17:30,793  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:17:30,793  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local627052655_0006_m_000000_0' done.
2024-05-01T09:17:30,793  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local627052655_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33492
		FILE: Number of bytes written=6914156
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=952107008
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:17:30,793  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local627052655_0006_m_000000_0
2024-05-01T09:17:30,793  INFO [Thread-298] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:17:31,298  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local330532849_0004 with errors
2024-05-01T09:17:31,299 ERROR [HiveServer2-Background-Pool: Thread-196] exec.Task: Ended Job = job_local330532849_0004 with errors
Error during job, obtaining debugging information...
2024-05-01T09:17:31,299 ERROR [Thread-305] exec.Task: Error during job, obtaining debugging information...
2024-05-01T09:17:31,300  INFO [HiveServer2-Background-Pool: Thread-196] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T09:17:31,301 ERROR [HiveServer2-Background-Pool: Thread-196] ql.Driver: FAILED: Operation cancelled
2024-05-01T09:17:31,301  INFO [HiveServer2-Background-Pool: Thread-196] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:31,301  INFO [HiveServer2-Background-Pool: Thread-196] metadata.Hive: Total time spent in each metastore function (ms): {close_()=0}
MapReduce Jobs Launched: 
2024-05-01T09:17:31,301  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T09:17:31,301  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:31,301  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:31,301  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:31,301  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Executing command(queryId=alex_20240501091729_a2157425-0acc-4ec2-8563-64e04934e236) has been interrupted after 1.713 seconds
2024-05-01T09:17:31,301  WARN [HiveServer2-Background-Pool: Thread-196] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T09:17:31,302  INFO [HiveServer2-Background-Pool: Thread-196] common.LogUtils: Unregistered logging context.
2024-05-01 09:17:31,760 Stage-1 map = 100%,  reduce = 0%
2024-05-01T09:17:31,760  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Task: 2024-05-01 09:17:31,760 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local627052655_0006
2024-05-01T09:17:31,762  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.Task: Ended Job = job_local627052655_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:31,765  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T09:17:31,765  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:31,765  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001
2024-05-01T09:17:31,765  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1/-mr-10001
2024-05-01T09:17:31,765  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Completed executing command(queryId=alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c); Time taken: 1.178 seconds
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:31,766  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T09:17:31,767  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=57099513-2ad9-454e-bb49-38ebe6b328c6] SessionHandle [34c88f5c-9638-4de1-bfde-a744354188ad]
2024-05-01T09:17:31,767  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af.test
2024-05-01T09:17:31,770  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af, startTime=1714580251766, sessionId=34c88f5c-9638-4de1-bfde-a744354188ad, createTime=1714580250450, userName=anonymous, ipAddress=null]
2024-05-01T09:17:31,771  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Compiling command(queryId=alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T09:17:31,774  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af
2024-05-01T09:17:31,774  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:31,775  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-05-01T09:17:31,776  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-05-01T09:17:31,877  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] reflections.Reflections: Reflections took 90 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T09:17:31,985  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af
2024-05-01T09:17:31,985  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:31,985  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-05-01T09:17:31,986  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:31,986  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=10, flushCache_()=1}
2024-05-01T09:17:31,986  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Completed compiling command(queryId=alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af); Time taken: 0.215 seconds
2024-05-01T09:17:31,986  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:31,986  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-05-01T09:17:31,986  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Executing command(queryId=alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T09:17:31,987  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-05-01T09:17:31,987  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-05-01T09:17:31,987  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T09:17:31,987  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T09:17:31,987  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-05-01T09:17:32,073  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1714580251, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFiles=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-05-01T09:17:32,081  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/service/target/warehouse/sample_shutdown_hook
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T09:17:32,248  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-05-01T09:17:32,248  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-05-01T09:17:32,248  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T09:17:32,249  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T09:17:32,249  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:32,249  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=176}
2024-05-01T09:17:32,249  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Driver: Completed executing command(queryId=alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af); Time taken: 0.263 seconds
2024-05-01T09:17:32,249  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:32,250  INFO [main] service.CompositeService: Session closed, SessionHandle [34c88f5c-9638-4de1-bfde-a744354188ad], current sessions:0
2024-05-01T09:17:32,250  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=d1556836-86f3-4562-984e-2a3cc68ef0b5]
2024-05-01T09:17:32,250  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.OperationManager: Removed queryId: alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=d1556836-86f3-4562-984e-2a3cc68ef0b5] with tag: null
2024-05-01T09:17:32,250  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1
2024-05-01T09:17:32,250  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1 operation was queued
2024-05-01T09:17:32,250  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T09:17:32,250  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:32,251  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091730_1a56b8cc-1088-4b33-b9b7-85dde0ef018c without delay
2024-05-01T09:17:32,251  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=57099513-2ad9-454e-bb49-38ebe6b328c6]
2024-05-01T09:17:32,251  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.OperationManager: Removed queryId: alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=57099513-2ad9-454e-bb49-38ebe6b328c6] with tag: null
2024-05-01T09:17:32,251  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad/alex_20240501091731_22a86363-66e2-445e-8933-f8653c6809af without delay
2024-05-01T09:17:32,251  INFO [34c88f5c-9638-4de1-bfde-a744354188ad main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/34c88f5c-9638-4de1-bfde-a744354188ad
2024-05-01T09:17:32,251  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad/hive_2024-05-01_09-17-30_473_7694350919802591869-1
2024-05-01T09:17:32,252  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/34c88f5c-9638-4de1-bfde-a744354188ad operation was queued
2024-05-01T09:17:32,252  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad operation was queued
2024-05-01T09:17:32,252  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/34c88f5c-9638-4de1-bfde-a744354188ad
2024-05-01T09:17:32,252  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/34c88f5c-9638-4de1-bfde-a744354188ad
2024-05-01T09:17:32,253  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:17:32,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2fc40856, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5543d800 will be shutdown
2024-05-01T09:17:32,253  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:17:32,253  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.099">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T09:17:32,314  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:17:32,314  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:17:32,314  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:17:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:17:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:17:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:17:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T09:17:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:17:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:17:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:17:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:17:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 3445f797-deac-48d1-a0aa-0bbc376c80c8
2024-05-01T09:17:32,317  INFO [main] SessionState: Hive Session ID = 3445f797-deac-48d1-a0aa-0bbc376c80c8
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:32,317  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:32,324  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/3445f797-deac-48d1-a0aa-0bbc376c80c8
2024-05-01T09:17:32,327  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/3445f797-deac-48d1-a0aa-0bbc376c80c8
2024-05-01T09:17:32,330  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/3445f797-deac-48d1-a0aa-0bbc376c80c8/_tmp_space.db
2024-05-01T09:17:32,331  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=3445f797-deac-48d1-a0aa-0bbc376c80c8, clientType=HIVESERVER2]
2024-05-01T09:17:32,332  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:17:32,332  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:17:32,332  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:17:32,333  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7097ead6, with PersistenceManager: null will be shutdown
2024-05-01T09:17:32,333  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7097ead6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c4be9d8 created in the thread with id: 1
2024-05-01T09:17:32,341  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7097ead6 from thread id: 1
2024-05-01T09:17:32,341  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:17:32,341  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:17:32,341  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T09:17:32,341  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T09:17:32,341  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T09:17:32,341  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T09:17:32,341  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T09:17:32,343  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T09:17:32,345  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T09:17:32,355  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T09:17:32,355  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:32,356  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T09:17:32,363  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/e55d24c6-9a64-4b62-a1cc-369fb7228c5c
2024-05-01T09:17:32,366  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c
2024-05-01T09:17:32,369  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/_tmp_space.db
2024-05-01T09:17:32,369  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T09:17:32,369  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T09:17:32,369  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:17:32,369  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7097ead6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c4be9d8 will be shutdown
2024-05-01T09:17:32,369  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:17:32,369  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T09:17:32,370  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c
2024-05-01T09:17:32,370  INFO [main] service.CompositeService: Session opened, SessionHandle [e55d24c6-9a64-4b62-a1cc-369fb7228c5c], current sessions:1
2024-05-01T09:17:32,370  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T09:17:32,370  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:32,371  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=8206f116-0afa-4739-b310-8577da28be37] SessionHandle [e55d24c6-9a64-4b62-a1cc-369fb7228c5c]
2024-05-01T09:17:32,371  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99.test
2024-05-01T09:17:32,375  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99, startTime=1714580252370, sessionId=e55d24c6-9a64-4b62-a1cc-369fb7228c5c, createTime=1714580252355, userName=anonymous, ipAddress=null]
2024-05-01T09:17:32,377  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Compiling command(queryId=alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:32,378  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:17:32,378  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:17:32,378  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:17:32,379  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@460df441, with PersistenceManager: null will be shutdown
2024-05-01T09:17:32,379  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@460df441, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@761f1a28 created in the thread with id: 1
2024-05-01T09:17:32,383  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@460df441 from thread id: 1
2024-05-01T09:17:32,383  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:17:32,383  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=e55d24c6-9a64-4b62-a1cc-369fb7228c5c, clientType=HIVESERVER2]
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:32,384  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:32,385  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:32,398  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:32,522  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:32,522  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:32,527  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:32,527  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:32,528  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-32_377_4103509067727869034-1
2024-05-01T09:17:32,534  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:32,537  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:32,537  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:32,547  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:32,548  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:32,549  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:32,549  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:32,549  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=72, flushCache_()=1}
2024-05-01T09:17:32,549  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Completed compiling command(queryId=alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99); Time taken: 0.172 seconds
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Executing command(queryId=alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:32,550  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001
2024-05-01T09:17:32,551  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001
2024-05-01T09:17:32,551  WARN [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99
2024-05-01T09:17:32,551  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Query ID = alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99
Total jobs = 1
2024-05-01T09:17:32,551  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:32,551  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:32,554  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:32,554  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:32,557  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:32,557  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:32,557  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/dummy_path
2024-05-01T09:17:32,569  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:32,570  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T09:17:32,570  WARN [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:32,574  WARN [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:32,581  WARN [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:32,586  WARN [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:32,587  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:32,588  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/dummy_path
2024-05-01T09:17:32,592  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:32,592  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:32,592  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:32,614  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:32,635  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mapreduce.JobSubmitter: Submitting tokens for job: job_local641201905_0007
2024-05-01T09:17:32,635  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:17:32,713  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:17:32,713  INFO [Thread-348] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T09:17:32,714  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:32,714  INFO [Thread-348] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:32,715  INFO [Thread-348] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:32,716  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local641201905_0007_m_000000_0
2024-05-01T09:17:32,720  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:32,721  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:32,725  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:32,726  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T09:17:32,726  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:32,729  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:32,730  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:32,730  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:32,730  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:32,730  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:32,731  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:32,731  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@488b9aa4, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@663d6255, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@bdd72d0
2024-05-01T09:17:32,731  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-32_377_4103509067727869034-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:32,731  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-32_377_4103509067727869034-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:32,732  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-32_377_4103509067727869034-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:32,743  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T09:17:32,743  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T09:17:32,744  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T09:17:32,745  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:17:32,749  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local641201905_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T09:17:32,749  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:17:32,749  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local641201905_0007_m_000000_0' done.
2024-05-01T09:17:32,750  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local641201905_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39078
		FILE: Number of bytes written=8066526
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=958398464
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:17:32,750  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local641201905_0007_m_000000_0
2024-05-01T09:17:32,750  INFO [Thread-348] mapred.LocalJobRunner: map task executor complete.
2024-05-01 09:17:33,718 Stage-1 map = 100%,  reduce = 0%
2024-05-01T09:17:33,718  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Task: 2024-05-01 09:17:33,718 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local641201905_0007
2024-05-01T09:17:33,719  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.Task: Ended Job = job_local641201905_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T09:17:33,722  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T09:17:33,722  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:33,722  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001
2024-05-01T09:17:33,722  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1/-mr-10001
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Completed executing command(queryId=alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99); Time taken: 1.173 seconds
2024-05-01T09:17:33,723  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:33,724  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T09:17:33,725  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=18fa924f-47c7-4cd7-ab07-11b04f96ffcf] SessionHandle [e55d24c6-9a64-4b62-a1cc-369fb7228c5c]
2024-05-01T09:17:33,725  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9.test
2024-05-01T09:17:33,730  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9, startTime=1714580253724, sessionId=e55d24c6-9a64-4b62-a1cc-369fb7228c5c, createTime=1714580252355, userName=anonymous, ipAddress=null]
2024-05-01T09:17:33,732  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Compiling command(queryId=alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T09:17:33,733  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Starting caching scope for: alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9
2024-05-01T09:17:33,734  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T09:17:33,734  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T09:17:33,734  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:33,734  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:33,734  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:33,734  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T09:17:33,749  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:33,816  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T09:17:33,817  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T09:17:33,819  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T09:17:33,819  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T09:17:33,820  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-33_732_6981944731323312511-1
2024-05-01T09:17:33,826  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T09:17:33,831  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T09:17:33,832  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T09:17:33,842  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T09:17:33,842  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T09:17:33,842  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map vectorized: false
2024-05-01T09:17:33,842  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T09:17:33,842  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T09:17:33,842  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T09:17:33,843  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T09:17:33,843  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Completed plan generation
2024-05-01T09:17:33,843  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] parse.CalcitePlanner: Ending caching scope for: alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9
2024-05-01T09:17:33,843  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T09:17:33,843  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T09:17:33,844  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T09:17:33,844  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T09:17:33,844  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-05-01T09:17:33,844  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Completed compiling command(queryId=alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9); Time taken: 0.112 seconds
2024-05-01T09:17:33,844  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:33,845  INFO [HiveServer2-Background-Pool: Thread-441] common.LogUtils: Thread context registration is done.
2024-05-01T09:17:33,845  INFO [HiveServer2-Background-Pool: Thread-441] reexec.ReExecDriver: Execution #1 of query
2024-05-01T09:17:33,845  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T09:17:33,846  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Executing command(queryId=alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T09:17:33,846  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-05-01T09:17:33,846  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T09:17:33,846  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001
2024-05-01T09:17:33,846  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001
2024-05-01T09:17:33,847  WARN [HiveServer2-Background-Pool: Thread-441] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9
2024-05-01T09:17:33,847  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Query ID = alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9
Total jobs = 1
2024-05-01T09:17:33,847  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T09:17:33,847  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Launching Job 1 out of 1
2024-05-01T09:17:33,850  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:33,850  INFO [HiveServer2-Background-Pool: Thread-441] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T09:17:33,858  INFO [HiveServer2-Background-Pool: Thread-441] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T09:17:33,858  INFO [HiveServer2-Background-Pool: Thread-441] exec.Utilities: Processing alias _dummy_table
2024-05-01T09:17:33,858  INFO [HiveServer2-Background-Pool: Thread-441] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/dummy_path
2024-05-01T09:17:33,870  INFO [HiveServer2-Background-Pool: Thread-441] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T09:17:33,871  INFO [HiveServer2-Background-Pool: Thread-441] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:33,872  WARN [HiveServer2-Background-Pool: Thread-441] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:33,877  WARN [HiveServer2-Background-Pool: Thread-441] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:17:33,884  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:17:33,889  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:17:33,889  INFO [HiveServer2-Background-Pool: Thread-441] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T09:17:33,890  INFO [HiveServer2-Background-Pool: Thread-441] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/dummy_path
2024-05-01T09:17:33,895  INFO [HiveServer2-Background-Pool: Thread-441] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:17:33,895  INFO [HiveServer2-Background-Pool: Thread-441] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T09:17:33,895  INFO [HiveServer2-Background-Pool: Thread-441] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T09:17:33,917  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:17:33,940  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.JobSubmitter: Submitting tokens for job: job_local1120622742_0008
2024-05-01T09:17:33,940  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.JobSubmitter: Executing with tokens: []
DEBUG StatusLogger Removing appender alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
DEBUG StatusLogger Deleting route with alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768 key 
DEBUG StatusLogger Stopping route with alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768 key
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768.test
DEBUG StatusLogger Removing appender alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
DEBUG StatusLogger Deleting route with alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768 key 
DEBUG StatusLogger Stopping route with alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768 key
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/91a624f8-b8bd-4d33-9a31-4e92db5c0bc8/alex_20240501091723_85c2263e-e964-4c6e-a256-7032c1bc4768, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
2024-05-01T09:17:34,019  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T09:17:34,020  INFO [HiveServer2-Background-Pool: Thread-441] exec.Task: Job running in-process (local Hadoop)
2024-05-01T09:17:34,020  INFO [Thread-387] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:34,020  INFO [Thread-387] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T09:17:34,021  INFO [Thread-387] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:17:34,021  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1120622742_0008_m_000000_0
2024-05-01T09:17:34,022  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:17:34,023  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T09:17:34,025  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T09:17:34,027  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T09:17:34,027  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T09:17:34,027  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T09:17:34,028  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T09:17:34,028  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T09:17:34,028  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T09:17:34,028  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T09:17:34,029  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T09:17:34,029  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@49da8b54, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7c1ad74e, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@79a62afc
2024-05-01T09:17:34,346  INFO [main] service.CompositeService: Session closed, SessionHandle [e55d24c6-9a64-4b62-a1cc-369fb7228c5c], current sessions:0
2024-05-01T09:17:34,346  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=18fa924f-47c7-4cd7-ab07-11b04f96ffcf]
2024-05-01T09:17:34,346  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.OperationManager: Removed queryId: alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=18fa924f-47c7-4cd7-ab07-11b04f96ffcf] with tag: null
2024-05-01T09:17:34,346  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9
2024-05-01T09:17:34,346  WARN [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-6
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-6 operation was queued
2024-05-01T09:17:34,347  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-33_732_6981944731323312511-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1
2024-05-01T09:17:34,347  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-33_732_6981944731323312511-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T09:17:34,347  WARN [Thread-387] mapred.LocalJobRunner: job_local1120622742_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:17:34,347  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001/.hive-staging_hive_2024-05-01_09-17-33_732_6981944731323312511-1/_tmp.-ext-10002/000000_0
2024-05-01T09:17:34,347  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1 operation was queued
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:34,347  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-6
2024-05-01 09:17:34,347 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:34,347  INFO [HiveServer2-Background-Pool: Thread-441] exec.Task: 2024-05-01 09:17:34,347 Stage-1 map = 0%,  reduce = 0%
2024-05-01T09:17:34,347  WARN [EventualCleanupService thread 1] fs.FileUtil: Failed to delete file or dir [/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1]: it still exists.
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9 without delay
2024-05-01T09:17:34,347  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1
2024-05-01T09:17:34,347  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=8206f116-0afa-4739-b310-8577da28be37]
2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.OperationManager: Removed queryId: alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=8206f116-0afa-4739-b310-8577da28be37] with tag: null
2024-05-01T09:17:34,348  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1
2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1 operation was queued
Ended Job = job_local1120622742_0008 with errors2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]

2024-05-01T09:17:34,348 ERROR [HiveServer2-Background-Pool: Thread-441] exec.Task: Ended Job = job_local1120622742_0008 with errors
2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/alex_20240501091732_5b5d405f-29d0-4ab7-9d32-b5931de80c99 without delay
Error during job, obtaining debugging information...
2024-05-01T09:17:34,348  INFO [e55d24c6-9a64-4b62-a1cc-369fb7228c5c main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/e55d24c6-9a64-4b62-a1cc-369fb7228c5c
2024-05-01T09:17:34,348 ERROR [Thread-392] exec.Task: Error during job, obtaining debugging information...
2024-05-01T09:17:34,350  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/e55d24c6-9a64-4b62-a1cc-369fb7228c5c operation was queued
2024-05-01T09:17:34,350  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-32_377_4103509067727869034-1
2024-05-01T09:17:34,350  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c operation was queued
2024-05-01T09:17:34,350  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/e55d24c6-9a64-4b62-a1cc-369fb7228c5c
2024-05-01T09:17:34,350  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c
2024-05-01T09:17:34,350  INFO [HiveServer2-Background-Pool: Thread-441] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T09:17:34,350 ERROR [HiveServer2-Background-Pool: Thread-441] ql.Driver: FAILED: Operation cancelled
2024-05-01T09:17:34,350  INFO [HiveServer2-Background-Pool: Thread-441] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T09:17:34,351  INFO [HiveServer2-Background-Pool: Thread-441] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T09:17:34,351  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T09:17:34,351  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T09:17:34,351  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:17:34,351  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec2024-05-01T09:17:34,351  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@460df441, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@761f1a28 will be shutdown

2024-05-01T09:17:34,352  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T09:17:34,352  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Executing command(queryId=alex_20240501091733_1046f564-4e10-4850-9983-469a59dfeed9) has been interrupted after 0.504 seconds
2024-05-01T09:17:34,353  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:17:34,353  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T09:17:34,353 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/e55d24c6-9a64-4b62-a1cc-369fb7228c5c/hive_2024-05-01_09-17-33_732_6981944731323312511-1/-mr-10001': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:561)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:561)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T09:17:34,353  WARN [HiveServer2-Background-Pool: Thread-441] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T09:17:34,353  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T09:17:34,353  INFO [HiveServer2-Background-Pool: Thread-441] common.LogUtils: Unregistered logging context.
2024-05-01T09:17:34,353  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T09:17:34,353  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T09:17:34,353  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
]]></system-err>
  </testcase>
</testsuite>