<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="48.646" tests="8" errors="0" skipped="2" failures="6">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter598268178691707136.jar /home/alex/Repositories/hive/hcatalog/core/target/surefire 2024-05-01T13-51-42_861-jvmRun1 surefire3230988585906905149tmp surefire_9334760894647824656790tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/hcatalog/core/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter598268178691707136.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/hcatalog/core/../../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/hcatalog/core/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/hcatalog/core/../../"/>
  </properties>
  <testcase name="testHCatPartitionedTable[0]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="8.227">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,121725 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@5aa9e4eb
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,022833 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 51827011
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T09:41:06.582-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-09:41:08.410, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-09:41:08.411, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@488d1cd7
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@33d512c1
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1] started OK.
2024-05-01T09:41:08,659  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T09:41:08,802  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/core/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1714581668493/warehouse
2024-05-01T09:41:09,166  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T09:41:09,243  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:09,243  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:09,243  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:09,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:09,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:09,245  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:09,246  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:09,246  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:09,246  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:09,246  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:09,247  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:09,252  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=0 initial-capacity=50 maximum-capacity=50
2024-05-01T09:41:09,314  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:09,570  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:09,616  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:09,636  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T09:41:09,636  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T09:41:09,667  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T09:41:09,673  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T09:41:10,484  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T09:41:10,488  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T09:41:11,220  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T09:41:11,221  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: null will be shutdown
2024-05-01T09:41:11,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 created in the thread with id: 1
2024-05-01T09:41:14,042  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T09:41:14,042  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T09:41:14,042  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133 from thread id: 1
2024-05-01T09:41:14,697  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T09:41:14,734  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T09:41:14,768  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T09:41:14,770  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T09:41:14,895  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T09:41:14,902  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T09:41:14,903  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T09:41:14,907  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T09:41:14,935  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T09:41:14,939  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T09:41:14,941  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T09:41:14,942  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T09:41:14,945  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T09:41:14,948  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T09:41:14,949  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T09:41:14,950  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T09:41:14,957  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T09:41:14,958  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T09:41:14,959  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T09:41:14,963  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:15,125  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:15,157  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:15,157  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 will be shutdown
2024-05-01T09:41:15,157  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:15,158  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T09:41:15,158  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:15,160  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:15,162  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: null will be shutdown
2024-05-01T09:41:15,162  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 created in the thread with id: 1
2024-05-01T09:41:15,183  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff from thread id: 1
2024-05-01T09:41:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:15,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:15,289  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:15,290  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:15,290  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:15,290  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:15,327  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:15,327  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:15,329  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 will be shutdown
2024-05-01T09:41:15,329  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 created in the thread with id: 1
2024-05-01T09:41:15,335  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 623fa5d4-80cc-4598-beea-0e2931cc49ac
2024-05-01T09:41:15,345  INFO [main] SessionState: Hive Session ID = 623fa5d4-80cc-4598-beea-0e2931cc49ac
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:15,359  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:15,419  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/623fa5d4-80cc-4598-beea-0e2931cc49ac
2024-05-01T09:41:15,423  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/623fa5d4-80cc-4598-beea-0e2931cc49ac
2024-05-01T09:41:15,427  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/623fa5d4-80cc-4598-beea-0e2931cc49ac/_tmp_space.db
2024-05-01T09:41:15,433  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:15,589  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_TEXTFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_TEXTFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T09:41:15,602  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile
2024-05-01T09:41:15,849  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:15,849  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:15,849  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:15,849  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:15,849  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:15,850  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:15,850  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:15,850  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:15,850  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:15,850  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:15,850  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:15,851  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:15,853  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:15,872  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:15,872  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:15,873  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 will be shutdown
2024-05-01T09:41:15,874  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d created in the thread with id: 1
2024-05-01T09:41:15,880  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:15,881  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:15,881  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:15,881  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d will be shutdown
2024-05-01T09:41:15,882  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:15,882  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T09:41:15,882  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:15,885  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:15,886  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: null will be shutdown
2024-05-01T09:41:15,886  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 created in the thread with id: 1
2024-05-01T09:41:15,891  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0 from thread id: 1
2024-05-01T09:41:15,895  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:15,955  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:16,142  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T09:41:16,159  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T09:41:16,175  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T09:41:16,175  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T09:41:16,235  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:16,235  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:16,235  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:16,235  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:16,235  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:16,235  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:16,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:16,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:16,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:16,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:16,236  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:16,237  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:16,239  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:16,239  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:16,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 will be shutdown
2024-05-01T09:41:16,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 created in the thread with id: 1
2024-05-01T09:41:16,244  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:16,244  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:16,244  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:16,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 will be shutdown
2024-05-01T09:41:16,245  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:16,245  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T09:41:16,245  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:16,246  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:16,247  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: null will be shutdown
2024-05-01T09:41:16,247  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb created in the thread with id: 1
2024-05-01T09:41:16,251  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933 from thread id: 1
2024-05-01T09:41:16,253  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value1,501]	
2024-05-01T09:41:16,326  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:16,338  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:16,391  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:16,458  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:16,501  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1959331048_0001
2024-05-01T09:41:16,501  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:16,636  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:16,639  INFO [main] mapreduce.Job: Running job: job_local1959331048_0001
2024-05-01T09:41:16,639  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:16,660  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,660  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,668  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:16,676  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,676  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,697  INFO [Thread-43] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:16,698  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1959331048_0001_m_000000_0
2024-05-01T09:41:16,734  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,735  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,740  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,740  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,757  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:16,762  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T09:41:16,782  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,782  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,857  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:16,865  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1959331048_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:16,866  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,866  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,872  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:16,872  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1959331048_0001_m_000000_0 is allowed to commit now
2024-05-01T09:41:16,873  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:16,873  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:16,887  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1959331048_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,18992893115466292/part1=p1value1/part0=501
2024-05-01T09:41:16,888  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:16,888  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1959331048_0001_m_000000_0' done.
2024-05-01T09:41:16,893  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1959331048_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=512500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=670564352
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:16,893  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1959331048_0001_m_000000_0
2024-05-01T09:41:16,894  INFO [Thread-43] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:16,966  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:16,966  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:16,967  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:16,967  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:16,967  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:16,967  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:16,968  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:16,968  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:16,968  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:16,968  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:16,974  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:16,975  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:16,976  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:16,977  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:16,977  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:16,978  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6a8db9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:16,978  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6a8db9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a35b9e2 created in the thread with id: 69
2024-05-01T09:41:16,985  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6a8db9 from thread id: 69
2024-05-01T09:41:16,985  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:16,985  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:16,986  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:16,986  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6a8db9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a35b9e2 will be shutdown
2024-05-01T09:41:16,986  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:16,986  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-05-01T09:41:16,987  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:16,988  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:16,988  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447e637a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:16,988  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447e637a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71ea146c created in the thread with id: 69
2024-05-01T09:41:16,992  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447e637a from thread id: 69
2024-05-01T09:41:17,053  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:17,053  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:17,054  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:17,054  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:17,054  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:17,054  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:17,054  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:17,054  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:17,055  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:17,055  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:17,055  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:17,055  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T09:41:17,094  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,18992893115466292/part1=p1value1/part0=501].
2024-05-01T09:41:17,095  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:17,159  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:17,159  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:17,159  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:17,159  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:17,159  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:17,159  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:17,160  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:17,160  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:17,160  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:17,160  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:17,160  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:17,161  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:17,162  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:17,162  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:17,162  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447e637a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71ea146c will be shutdown
2024-05-01T09:41:17,163  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447e637a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e69f731 created in the thread with id: 69
2024-05-01T09:41:17,167  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:17,168  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:17,168  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:17,168  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447e637a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e69f731 will be shutdown
2024-05-01T09:41:17,169  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:17,169  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T09:41:17,169  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:17,170  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:17,171  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d035674, with PersistenceManager: null will be shutdown
2024-05-01T09:41:17,171  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d035674, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c4b1096 created in the thread with id: 69
2024-05-01T09:41:17,176  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d035674 from thread id: 69
2024-05-01T09:41:17,178  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:17,178  WARN [Thread-43] mapred.LocalJobRunner: job_local1959331048_0001
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,18992893115466292/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:17,646  INFO [main] mapreduce.Job: Job job_local1959331048_0001 running in uber mode : false
2024-05-01T09:41:17,647  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:17,650  INFO [main] mapreduce.Job: Job job_local1959331048_0001 failed with state FAILED due to: NA
2024-05-01T09:41:17,656  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=512500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=670564352
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:17,713  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:17,713  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:17,714  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:17,714  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:17,715  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:17,720  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:17,720  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:17,720  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb will be shutdown
2024-05-01T09:41:17,721  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bfc2f8b created in the thread with id: 1
2024-05-01T09:41:17,725  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:17,725  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:17,725  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:17,725  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bfc2f8b will be shutdown
2024-05-01T09:41:17,725  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:17,725  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T09:41:17,726  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:17,726  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:17,727  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: null will be shutdown
2024-05-01T09:41:17,727  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55c50f52 created in the thread with id: 1
2024-05-01T09:41:17,731  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8 from thread id: 1
2024-05-01T09:41:17,732  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:17,746  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:17,757  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:17,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:17,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:17,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:17,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:17,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:17,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:17,804  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:17,804  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:17,804  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:17,804  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:17,804  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:17,805  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:17,806  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:17,806  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:17,807  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55c50f52 will be shutdown
2024-05-01T09:41:17,807  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52d96367 created in the thread with id: 1
2024-05-01T09:41:17,812  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:17,812  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:17,812  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:17,812  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52d96367 will be shutdown
2024-05-01T09:41:17,813  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:17,813  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-05-01T09:41:17,813  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:17,814  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:17,815  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: null will be shutdown
2024-05-01T09:41:17,815  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64bba0eb created in the thread with id: 1
2024-05-01T09:41:17,820  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5 from thread id: 1
2024-05-01T09:41:17,822  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T09:41:17,858  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:17,863  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:17,864  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:17,888  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:17,912  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1735519876_0002
2024-05-01T09:41:17,912  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:18,016  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:18,016  INFO [main] mapreduce.Job: Running job: job_local1735519876_0002
2024-05-01T09:41:18,017  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:18,022  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,022  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,025  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:18,026  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,026  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,041  INFO [Thread-91] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:18,042  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1735519876_0002_m_000000_0
2024-05-01T09:41:18,047  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,047  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,051  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,051  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,052  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:18,053  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:18,059  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,059  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,078  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:18,078  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1735519876_0002_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:18,079  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,079  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,083  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:18,083  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1735519876_0002_m_000000_0 is allowed to commit now
2024-05-01T09:41:18,084  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:18,084  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:18,095  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1735519876_0002_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,587095989006732/part1=p1value2/part0=502
2024-05-01T09:41:18,096  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:18,096  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1735519876_0002_m_000000_0' done.
2024-05-01T09:41:18,096  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1735519876_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1025206
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=671612928
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:18,097  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1735519876_0002_m_000000_0
2024-05-01T09:41:18,097  INFO [Thread-91] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:18,163  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:18,164  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:18,165  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:18,165  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:18,165  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:18,166  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68ffc1ce, with PersistenceManager: null will be shutdown
2024-05-01T09:41:18,166  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68ffc1ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5bc72604 created in the thread with id: 119
2024-05-01T09:41:18,173  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68ffc1ce from thread id: 119
2024-05-01T09:41:18,173  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:18,173  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:18,173  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:18,173  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68ffc1ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5bc72604 will be shutdown
2024-05-01T09:41:18,174  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:18,174  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-05-01T09:41:18,174  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:18,174  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:18,175  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed92cef, with PersistenceManager: null will be shutdown
2024-05-01T09:41:18,175  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed92cef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ec3a123 created in the thread with id: 119
2024-05-01T09:41:18,179  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed92cef from thread id: 119
2024-05-01T09:41:18,235  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:18,235  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:18,235  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:18,235  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:18,235  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:18,235  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:18,236  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:18,236  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:18,236  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:18,236  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:18,236  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:18,237  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:18,263  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,587095989006732/part1=p1value2/part0=502].
2024-05-01T09:41:18,263  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:18,310  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:18,311  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:18,311  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:18,311  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:18,311  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:18,311  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:18,312  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:18,312  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:18,313  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed92cef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ec3a123 will be shutdown
2024-05-01T09:41:18,313  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed92cef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31c967db created in the thread with id: 119
2024-05-01T09:41:18,317  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:18,318  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:18,318  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:18,318  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed92cef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31c967db will be shutdown
2024-05-01T09:41:18,318  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:18,318  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -9
2024-05-01T09:41:18,318  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:18,320  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:18,320  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56d6e5af, with PersistenceManager: null will be shutdown
2024-05-01T09:41:18,321  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56d6e5af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b120a8a created in the thread with id: 119
2024-05-01T09:41:18,325  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56d6e5af from thread id: 119
2024-05-01T09:41:18,326  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:18,326  WARN [Thread-91] mapred.LocalJobRunner: job_local1735519876_0002
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,587095989006732/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:19,017  INFO [main] mapreduce.Job: Job job_local1735519876_0002 running in uber mode : false
2024-05-01T09:41:19,017  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:19,018  INFO [main] mapreduce.Job: Job job_local1735519876_0002 failed with state FAILED due to: NA
2024-05-01T09:41:19,019  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1025206
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=671612928
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:19,073  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:19,073  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:19,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:19,074  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:19,074  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:19,075  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:19,078  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:19,078  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:19,078  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64bba0eb will be shutdown
2024-05-01T09:41:19,079  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c2ab536 created in the thread with id: 1
2024-05-01T09:41:19,083  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:19,083  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:19,083  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:19,083  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c2ab536 will be shutdown
2024-05-01T09:41:19,083  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:19,083  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -10
2024-05-01T09:41:19,084  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:19,084  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:19,085  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: null will be shutdown
2024-05-01T09:41:19,086  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1805383 created in the thread with id: 1
2024-05-01T09:41:19,089  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300 from thread id: 1
2024-05-01T09:41:19,090  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:19,100  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:19,108  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:19,147  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:19,148  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:19,148  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:19,149  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:19,149  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:19,150  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1805383 will be shutdown
2024-05-01T09:41:19,150  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47eaf55c created in the thread with id: 1
2024-05-01T09:41:19,155  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:19,155  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:19,156  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:19,156  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47eaf55c will be shutdown
2024-05-01T09:41:19,156  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:19,156  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -11
2024-05-01T09:41:19,156  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:19,157  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:19,158  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: null will be shutdown
2024-05-01T09:41:19,158  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@333d44f6 created in the thread with id: 1
2024-05-01T09:41:19,161  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554 from thread id: 1
2024-05-01T09:41:19,162  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T09:41:19,184  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:19,190  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:19,191  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:19,213  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:19,234  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1184847815_0003
2024-05-01T09:41:19,234  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:19,297  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:19,298  INFO [main] mapreduce.Job: Running job: job_local1184847815_0003
2024-05-01T09:41:19,298  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:19,303  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,303  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,305  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:19,307  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,307  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,322  INFO [Thread-137] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:19,322  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1184847815_0003_m_000000_0
2024-05-01T09:41:19,325  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,325  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,328  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,328  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,329  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:19,330  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:19,336  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,336  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,352  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:19,353  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1184847815_0003_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:19,353  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,353  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,358  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:19,358  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1184847815_0003_m_000000_0 is allowed to commit now
2024-05-01T09:41:19,358  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:19,358  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:19,370  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1184847815_0003_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,38744802544035484/part1=p1value2/part0=502
2024-05-01T09:41:19,370  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:19,370  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1184847815_0003_m_000000_0' done.
2024-05-01T09:41:19,371  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1184847815_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1537930
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=671612928
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:19,371  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1184847815_0003_m_000000_0
2024-05-01T09:41:19,371  INFO [Thread-137] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:19,427  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:19,428  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:19,428  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:19,428  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:19,429  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:19,430  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:19,430  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:19,431  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fa07f79, with PersistenceManager: null will be shutdown
2024-05-01T09:41:19,431  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fa07f79, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c802a2e created in the thread with id: 167
2024-05-01T09:41:19,436  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fa07f79 from thread id: 167
2024-05-01T09:41:19,436  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:19,436  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:19,437  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:19,437  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@fa07f79, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c802a2e will be shutdown
2024-05-01T09:41:19,437  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:19,437  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -12
2024-05-01T09:41:19,437  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:19,438  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:19,439  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29340f4e, with PersistenceManager: null will be shutdown
2024-05-01T09:41:19,439  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29340f4e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c89d403 created in the thread with id: 167
2024-05-01T09:41:19,443  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29340f4e from thread id: 167
2024-05-01T09:41:19,493  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:19,493  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:19,493  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:19,494  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:19,495  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:19,523  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,38744802544035484/part1=p1value2/part0=502].
2024-05-01T09:41:19,523  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:19,574  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:19,574  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:19,574  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:19,574  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:19,574  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:19,574  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:19,575  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:19,575  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:19,575  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:19,575  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:19,575  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:19,575  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:19,576  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:19,576  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:19,576  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29340f4e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c89d403 will be shutdown
2024-05-01T09:41:19,577  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29340f4e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b3724b created in the thread with id: 167
2024-05-01T09:41:19,579  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:19,580  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:19,580  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:19,580  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29340f4e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b3724b will be shutdown
2024-05-01T09:41:19,580  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:19,580  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -13
2024-05-01T09:41:19,580  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:19,581  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:19,582  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@486deddf, with PersistenceManager: null will be shutdown
2024-05-01T09:41:19,582  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@486deddf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1763f121 created in the thread with id: 167
2024-05-01T09:41:19,586  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@486deddf from thread id: 167
2024-05-01T09:41:19,587  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:19,587  WARN [Thread-137] mapred.LocalJobRunner: job_local1184847815_0003
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,38744802544035484/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:20,298  INFO [main] mapreduce.Job: Job job_local1184847815_0003 running in uber mode : false
2024-05-01T09:41:20,299  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:20,299  INFO [main] mapreduce.Job: Job job_local1184847815_0003 failed with state FAILED due to: NA
2024-05-01T09:41:20,300  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1537930
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=671612928
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:20,359  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:20,359  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:20,360  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:20,362  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:20,362  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:20,362  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@333d44f6 will be shutdown
2024-05-01T09:41:20,363  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@270f28cf created in the thread with id: 1
2024-05-01T09:41:20,367  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:20,368  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:20,368  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:20,368  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@270f28cf will be shutdown
2024-05-01T09:41:20,368  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:20,368  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -14
2024-05-01T09:41:20,368  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:20,369  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bbdb220 created in the thread with id: 1
2024-05-01T09:41:20,374  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130 from thread id: 1
2024-05-01T09:41:20,376  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:20,387  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:20,394  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:20,436  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:20,436  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:20,436  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:20,436  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:20,436  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:20,436  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:20,438  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:20,438  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:20,439  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bbdb220 will be shutdown
2024-05-01T09:41:20,439  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14e3d439 created in the thread with id: 1
2024-05-01T09:41:20,442  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:20,443  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:20,443  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:20,443  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14e3d439 will be shutdown
2024-05-01T09:41:20,444  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:20,444  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -15
2024-05-01T09:41:20,444  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:20,444  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,445  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,445  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fc1c7e created in the thread with id: 1
2024-05-01T09:41:20,449  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2 from thread id: 1
2024-05-01T09:41:20,505  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:20,505  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:20,505  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:20,505  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:20,505  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:20,505  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:20,506  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:20,506  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:20,506  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:20,506  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:20,506  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:20,506  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:20,507  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:20,509  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:20,509  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:20,510  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fc1c7e will be shutdown
2024-05-01T09:41:20,510  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68f776ee created in the thread with id: 1
2024-05-01T09:41:20,513  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:20,513  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:20,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:20,515  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68f776ee will be shutdown
2024-05-01T09:41:20,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:20,515  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -16
2024-05-01T09:41:20,516  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:20,517  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,518  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,518  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f471037 created in the thread with id: 1
2024-05-01T09:41:20,521  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b from thread id: 1
2024-05-01T09:41:20,523  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:20,533  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:20,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:20,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:20,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:20,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:20,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:20,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:20,585  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:20,585  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:20,585  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:20,585  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:20,586  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:20,586  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:20,587  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:20,588  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:20,588  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:20,589  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f471037 will be shutdown
2024-05-01T09:41:20,589  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15f519f7 created in the thread with id: 1
2024-05-01T09:41:20,592  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:20,592  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:20,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:20,592  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15f519f7 will be shutdown
2024-05-01T09:41:20,593  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:20,593  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -17
2024-05-01T09:41:20,593  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:20,593  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12f8682a created in the thread with id: 1
2024-05-01T09:41:20,597  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc from thread id: 1
2024-05-01T09:41:20,599  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:20,608  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:20,616  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:20,661  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:20,661  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:20,661  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:20,661  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:20,662  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:20,662  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:20,663  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:20,663  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:20,664  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12f8682a will be shutdown
2024-05-01T09:41:20,664  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a047bdb created in the thread with id: 1
2024-05-01T09:41:20,668  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:20,668  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:20,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:20,669  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a047bdb will be shutdown
2024-05-01T09:41:20,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:20,669  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -18
2024-05-01T09:41:20,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:20,670  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@334b392d created in the thread with id: 1
2024-05-01T09:41:20,673  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b from thread id: 1
2024-05-01T09:41:20,681  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:20,686  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:20,687  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:20,709  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:20,728  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local820758929_0004
2024-05-01T09:41:20,728  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:20,811  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:20,811  INFO [main] mapreduce.Job: Running job: job_local820758929_0004
2024-05-01T09:41:20,811  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:20,815  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:20,817  INFO [Thread-188] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:20,817  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local820758929_0004_m_000000_0
2024-05-01T09:41:20,822  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:20,823  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T09:41:20,836  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local820758929_0004_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.1887122597395431/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T09:41:20,836  INFO [Thread-188] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:20,841  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.1887122597395431].
2024-05-01T09:41:20,841  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:20,895  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:20,896  INFO [Thread-188] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:20,897  INFO [Thread-188] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:20,898  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,898  INFO [Thread-188] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:20,898  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bf6c55, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,898  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bf6c55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@463353fe created in the thread with id: 220
2024-05-01T09:41:20,901  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bf6c55 from thread id: 220
2024-05-01T09:41:20,901  INFO [Thread-188] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:20,902  INFO [Thread-188] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:20,902  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:20,902  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@bf6c55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@463353fe will be shutdown
2024-05-01T09:41:20,902  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:20,902  INFO [Thread-188] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -19
2024-05-01T09:41:20,902  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:20,903  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:20,903  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645934b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:20,903  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645934b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e8357f7 created in the thread with id: 220
2024-05-01T09:41:20,907  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645934b from thread id: 220
2024-05-01T09:41:20,908  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:20,908  WARN [Thread-188] mapred.LocalJobRunner: job_local820758929_0004
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T09:41:21,811  INFO [main] mapreduce.Job: Job job_local820758929_0004 running in uber mode : false
2024-05-01T09:41:21,812  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:21,812  INFO [main] mapreduce.Job: Job job_local820758929_0004 failed with state FAILED due to: NA
2024-05-01T09:41:21,812  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:21,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:21,859  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:21,859  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:21,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:21,859  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:21,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:21,860  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:21,860  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:21,860  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:21,860  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:21,860  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:21,860  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:21,861  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:21,863  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:21,863  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:21,864  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@334b392d will be shutdown
2024-05-01T09:41:21,864  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27dfd12b created in the thread with id: 1
2024-05-01T09:41:21,867  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:21,867  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:21,867  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:21,868  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27dfd12b will be shutdown
2024-05-01T09:41:21,868  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:21,868  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -20
2024-05-01T09:41:21,868  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:21,868  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:21,869  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: null will be shutdown
2024-05-01T09:41:21,869  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ab455e2 created in the thread with id: 1
2024-05-01T09:41:21,871  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad from thread id: 1
2024-05-01T09:41:21,872  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:21,883  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:21,883  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:21,902  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:21,909  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:21,914  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:21,939  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T09:41:22,003  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1439091484_0005
2024-05-01T09:41:22,003  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:22,060  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:22,060  INFO [main] mapreduce.Job: Running job: job_local1439091484_0005
2024-05-01T09:41:22,061  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:22,064  INFO [Thread-208] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:22,064  INFO [Thread-208] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:22,064  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T09:41:22,073  INFO [Thread-208] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:22,073  INFO [Thread-208] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:23,061  INFO [main] mapreduce.Job: Job job_local1439091484_0005 running in uber mode : false
2024-05-01T09:41:23,061  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:23,062  INFO [main] mapreduce.Job: Job job_local1439091484_0005 completed successfully
2024-05-01T09:41:23,062  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:23,063  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:23,072  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:23,072  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:23,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:23,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:23,414  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:23,414  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[1]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.968">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T09:41:23,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:23,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:23,472  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:23,475  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:23,475  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:23,475  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ab455e2 will be shutdown
2024-05-01T09:41:23,476  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@615ef20 created in the thread with id: 1
2024-05-01T09:41:23,484  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 891c24d2-6bbf-497e-8d33-a46e899c6151
2024-05-01T09:41:23,485  INFO [main] SessionState: Hive Session ID = 891c24d2-6bbf-497e-8d33-a46e899c6151
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:23,485  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:23,492  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/891c24d2-6bbf-497e-8d33-a46e899c6151
2024-05-01T09:41:23,495  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/891c24d2-6bbf-497e-8d33-a46e899c6151
2024-05-01T09:41:23,498  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/891c24d2-6bbf-497e-8d33-a46e899c6151/_tmp_space.db
2024-05-01T09:41:23,499  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:23,510  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_SEQUENCEFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.mapred.SequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_SEQUENCEFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T09:41:23,514  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile
2024-05-01T09:41:23,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:23,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:23,625  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:23,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:23,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:23,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:23,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:23,626  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:23,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:23,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:23,626  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:23,626  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:23,627  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:23,629  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:23,629  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:23,630  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@615ef20 will be shutdown
2024-05-01T09:41:23,630  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cff5aa3 created in the thread with id: 1
2024-05-01T09:41:23,634  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:23,634  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:23,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:23,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cff5aa3 will be shutdown
2024-05-01T09:41:23,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:23,634  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -21
2024-05-01T09:41:23,635  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:23,635  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:23,636  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: null will be shutdown
2024-05-01T09:41:23,636  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69bca406 created in the thread with id: 1
2024-05-01T09:41:23,638  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e from thread id: 1
2024-05-01T09:41:23,640  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:23,671  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:23,680  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:23,721  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:23,721  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:23,721  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:23,721  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:23,721  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:23,721  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:23,722  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:23,722  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:23,722  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:23,722  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:23,722  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:23,722  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:23,723  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:23,723  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:23,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69bca406 will be shutdown
2024-05-01T09:41:23,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e998033 created in the thread with id: 1
2024-05-01T09:41:23,728  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:23,728  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:23,728  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:23,729  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e998033 will be shutdown
2024-05-01T09:41:23,729  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:23,729  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -22
2024-05-01T09:41:23,729  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:23,730  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:23,730  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: null will be shutdown
2024-05-01T09:41:23,730  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c910acd created in the thread with id: 1
2024-05-01T09:41:23,733  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341 from thread id: 1
2024-05-01T09:41:23,734  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value1,501]	
2024-05-01T09:41:23,757  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:23,762  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:23,763  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:23,785  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:23,804  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1569303955_0006
2024-05-01T09:41:23,804  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:23,859  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:23,859  INFO [main] mapreduce.Job: Running job: job_local1569303955_0006
2024-05-01T09:41:23,860  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:23,863  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,863  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,864  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:23,865  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,865  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,881  INFO [Thread-242] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:23,881  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1569303955_0006_m_000000_0
2024-05-01T09:41:23,887  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,887  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,889  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,889  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,889  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:23,890  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T09:41:23,897  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,898  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,930  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:23,934  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1569303955_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:23,934  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,935  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,938  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:23,938  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1569303955_0006_m_000000_0 is allowed to commit now
2024-05-01T09:41:23,939  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:23,939  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:23,950  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1569303955_0006_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,42506328029781726/part1=p1value1/part0=501
2024-05-01T09:41:23,950  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:23,950  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1569303955_0006_m_000000_0' done.
2024-05-01T09:41:23,951  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1569303955_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3071608
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=733478912
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:23,951  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1569303955_0006_m_000000_0
2024-05-01T09:41:23,951  INFO [Thread-242] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:24,015  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:24,015  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:24,015  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:24,015  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:24,015  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:24,015  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:24,016  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:24,016  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:24,016  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:24,016  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:24,016  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:24,016  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:24,017  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:24,018  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:24,018  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:24,018  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e0ed278, with PersistenceManager: null will be shutdown
2024-05-01T09:41:24,018  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e0ed278, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@774c2df created in the thread with id: 276
2024-05-01T09:41:24,021  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e0ed278 from thread id: 276
2024-05-01T09:41:24,021  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:24,021  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:24,021  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:24,021  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e0ed278, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@774c2df will be shutdown
2024-05-01T09:41:24,022  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:24,022  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -23
2024-05-01T09:41:24,022  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:24,022  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:24,023  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49b74505, with PersistenceManager: null will be shutdown
2024-05-01T09:41:24,023  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49b74505, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f882d5b created in the thread with id: 276
2024-05-01T09:41:24,025  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49b74505 from thread id: 276
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:24,073  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:24,074  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:24,074  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:24,074  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:24,074  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T09:41:24,100  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,42506328029781726/part1=p1value1/part0=501].
2024-05-01T09:41:24,100  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:24,161  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:24,162  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:24,162  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:24,163  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:24,163  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:24,163  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49b74505, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f882d5b will be shutdown
2024-05-01T09:41:24,164  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49b74505, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52c518c4 created in the thread with id: 276
2024-05-01T09:41:24,166  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:24,166  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:24,167  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:24,167  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49b74505, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52c518c4 will be shutdown
2024-05-01T09:41:24,167  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:24,167  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -24
2024-05-01T09:41:24,167  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:24,167  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:24,168  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e3e69e7, with PersistenceManager: null will be shutdown
2024-05-01T09:41:24,168  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e3e69e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58c85c9a created in the thread with id: 276
2024-05-01T09:41:24,171  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e3e69e7 from thread id: 276
2024-05-01T09:41:24,172  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:24,172  WARN [Thread-242] mapred.LocalJobRunner: job_local1569303955_0006
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,42506328029781726/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:24,860  INFO [main] mapreduce.Job: Job job_local1569303955_0006 running in uber mode : false
2024-05-01T09:41:24,860  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:24,860  INFO [main] mapreduce.Job: Job job_local1569303955_0006 failed with state FAILED due to: NA
2024-05-01T09:41:24,862  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3071608
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=733478912
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:24,914  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:24,915  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:24,916  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:24,916  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:24,918  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:24,918  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:24,918  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c910acd will be shutdown
2024-05-01T09:41:24,919  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e4b5da1 created in the thread with id: 1
2024-05-01T09:41:24,920  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:24,921  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:24,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:24,921  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e4b5da1 will be shutdown
2024-05-01T09:41:24,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:24,921  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -25
2024-05-01T09:41:24,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:24,922  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:24,922  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424a152f, with PersistenceManager: null will be shutdown
2024-05-01T09:41:24,923  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424a152f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@408d945b created in the thread with id: 1
2024-05-01T09:41:24,924  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424a152f from thread id: 1
2024-05-01T09:41:24,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:24,935  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:24,942  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:24,979  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:24,980  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:24,980  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:24,981  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:24,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424a152f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@408d945b will be shutdown
2024-05-01T09:41:24,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424a152f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e46a125 created in the thread with id: 1
2024-05-01T09:41:24,984  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:24,984  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:24,984  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:24,984  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424a152f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e46a125 will be shutdown
2024-05-01T09:41:24,984  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:24,984  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -26
2024-05-01T09:41:24,984  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:24,985  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:24,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6684589a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:24,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6684589a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5621a671 created in the thread with id: 1
2024-05-01T09:41:24,988  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6684589a from thread id: 1
2024-05-01T09:41:24,989  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T09:41:25,014  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:25,019  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:25,019  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:25,041  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:25,065  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1170332899_0007
2024-05-01T09:41:25,065  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:25,145  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:25,145  INFO [main] mapreduce.Job: Running job: job_local1170332899_0007
2024-05-01T09:41:25,145  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:25,148  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,148  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,149  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:25,150  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,150  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,165  INFO [Thread-288] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:25,165  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1170332899_0007_m_000000_0
2024-05-01T09:41:25,168  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,168  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,170  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,170  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,170  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:25,171  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:25,174  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,174  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,189  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:25,190  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1170332899_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:25,190  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,190  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,194  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:25,194  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1170332899_0007_m_000000_0 is allowed to commit now
2024-05-01T09:41:25,194  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:25,194  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:25,206  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1170332899_0007_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,9577605088636836/part1=p1value2/part0=502
2024-05-01T09:41:25,206  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:25,206  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1170332899_0007_m_000000_0' done.
2024-05-01T09:41:25,207  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1170332899_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3584673
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=736624640
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:25,207  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1170332899_0007_m_000000_0
2024-05-01T09:41:25,207  INFO [Thread-288] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:25,258  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:25,259  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:25,260  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:25,260  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:25,261  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:25,261  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8677ba, with PersistenceManager: null will be shutdown
2024-05-01T09:41:25,261  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8677ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e52bcd4 created in the thread with id: 324
2024-05-01T09:41:25,264  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8677ba from thread id: 324
2024-05-01T09:41:25,264  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:25,265  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:25,265  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:25,265  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8677ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e52bcd4 will be shutdown
2024-05-01T09:41:25,265  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:25,265  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -27
2024-05-01T09:41:25,265  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:25,266  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:25,266  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@995c02c, with PersistenceManager: null will be shutdown
2024-05-01T09:41:25,267  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@995c02c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@51cbfa2a created in the thread with id: 324
2024-05-01T09:41:25,269  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@995c02c from thread id: 324
2024-05-01T09:41:25,319  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:25,319  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:25,319  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:25,319  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:25,319  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:25,319  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:25,320  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:25,320  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:25,320  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:25,320  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:25,320  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:25,320  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:25,349  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,9577605088636836/part1=p1value2/part0=502].
2024-05-01T09:41:25,349  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:25,396  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:25,396  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:25,397  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:25,398  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:25,398  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@995c02c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@51cbfa2a will be shutdown
2024-05-01T09:41:25,398  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@995c02c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f57d10b created in the thread with id: 324
2024-05-01T09:41:25,402  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:25,402  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:25,402  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:25,402  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@995c02c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f57d10b will be shutdown
2024-05-01T09:41:25,402  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:25,402  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -28
2024-05-01T09:41:25,402  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:25,403  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:25,404  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50b2329, with PersistenceManager: null will be shutdown
2024-05-01T09:41:25,404  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50b2329, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53b1110e created in the thread with id: 324
2024-05-01T09:41:25,407  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50b2329 from thread id: 324
2024-05-01T09:41:25,409  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:25,409  WARN [Thread-288] mapred.LocalJobRunner: job_local1170332899_0007
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,9577605088636836/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:26,146  INFO [main] mapreduce.Job: Job job_local1170332899_0007 running in uber mode : false
2024-05-01T09:41:26,146  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:26,146  INFO [main] mapreduce.Job: Job job_local1170332899_0007 failed with state FAILED due to: NA
2024-05-01T09:41:26,151  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3584673
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=736624640
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:26,220  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:26,221  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:26,222  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:26,222  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:26,224  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:26,224  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:26,224  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6684589a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5621a671 will be shutdown
2024-05-01T09:41:26,225  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6684589a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57eed461 created in the thread with id: 1
2024-05-01T09:41:26,228  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:26,229  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:26,229  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:26,229  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6684589a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57eed461 will be shutdown
2024-05-01T09:41:26,229  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:26,229  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -29
2024-05-01T09:41:26,229  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:26,231  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:26,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: null will be shutdown
2024-05-01T09:41:26,232  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74450c9b created in the thread with id: 1
2024-05-01T09:41:26,234  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8 from thread id: 1
2024-05-01T09:41:26,235  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:26,244  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:26,252  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:26,297  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:26,297  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:26,297  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:26,298  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:26,298  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:26,299  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:26,299  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:26,300  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74450c9b will be shutdown
2024-05-01T09:41:26,300  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d90764a created in the thread with id: 1
2024-05-01T09:41:26,303  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:26,303  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:26,303  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:26,304  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d90764a will be shutdown
2024-05-01T09:41:26,304  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:26,305  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -30
2024-05-01T09:41:26,305  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:26,306  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:26,306  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: null will be shutdown
2024-05-01T09:41:26,307  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db06c50 created in the thread with id: 1
2024-05-01T09:41:26,310  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26 from thread id: 1
2024-05-01T09:41:26,312  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T09:41:26,332  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:26,337  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:26,338  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:26,361  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:26,380  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1191842304_0008
2024-05-01T09:41:26,380  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:26,437  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:26,437  INFO [main] mapreduce.Job: Running job: job_local1191842304_0008
2024-05-01T09:41:26,438  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:26,440  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,440  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,441  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:26,443  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,443  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,457  INFO [Thread-334] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:26,458  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1191842304_0008_m_000000_0
2024-05-01T09:41:26,462  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,462  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,465  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,465  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,465  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:26,466  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:26,469  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,469  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,488  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:26,488  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1191842304_0008_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:26,489  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,489  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,493  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:26,493  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1191842304_0008_m_000000_0 is allowed to commit now
2024-05-01T09:41:26,493  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:26,493  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:26,504  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1191842304_0008_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,6055735608376808/part1=p1value2/part0=502
2024-05-01T09:41:26,504  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:26,505  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1191842304_0008_m_000000_0' done.
2024-05-01T09:41:26,505  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1191842304_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4097738
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=736624640
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:26,505  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1191842304_0008_m_000000_0
2024-05-01T09:41:26,505  INFO [Thread-334] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:26,558  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:26,559  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:26,560  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:26,561  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:26,561  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:26,561  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b41776b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:26,561  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b41776b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bd3011e created in the thread with id: 372
2024-05-01T09:41:26,564  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b41776b from thread id: 372
2024-05-01T09:41:26,564  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:26,565  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:26,565  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:26,565  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b41776b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bd3011e will be shutdown
2024-05-01T09:41:26,565  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:26,565  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -31
2024-05-01T09:41:26,565  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:26,566  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:26,567  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677d10e3, with PersistenceManager: null will be shutdown
2024-05-01T09:41:26,567  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677d10e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5dc4af13 created in the thread with id: 372
2024-05-01T09:41:26,570  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677d10e3 from thread id: 372
2024-05-01T09:41:26,620  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:26,620  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:26,620  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:26,621  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:26,621  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:26,647  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,6055735608376808/part1=p1value2/part0=502].
2024-05-01T09:41:26,647  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:26,694  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:26,694  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:26,695  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:26,695  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:26,696  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677d10e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5dc4af13 will be shutdown
2024-05-01T09:41:26,696  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677d10e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a291a2 created in the thread with id: 372
2024-05-01T09:41:26,698  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:26,698  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:26,698  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:26,698  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677d10e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a291a2 will be shutdown
2024-05-01T09:41:26,699  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:26,699  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -32
2024-05-01T09:41:26,699  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:26,699  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:26,700  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18e654, with PersistenceManager: null will be shutdown
2024-05-01T09:41:26,700  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18e654, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73636972 created in the thread with id: 372
2024-05-01T09:41:26,702  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18e654 from thread id: 372
2024-05-01T09:41:26,704  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:26,704  WARN [Thread-334] mapred.LocalJobRunner: job_local1191842304_0008
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,6055735608376808/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:27,438  INFO [main] mapreduce.Job: Job job_local1191842304_0008 running in uber mode : false
2024-05-01T09:41:27,438  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:27,438  INFO [main] mapreduce.Job: Job job_local1191842304_0008 failed with state FAILED due to: NA
2024-05-01T09:41:27,440  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4097738
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=736624640
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:27,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:27,489  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:27,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:27,490  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:27,490  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:27,491  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:27,493  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:27,493  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:27,494  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db06c50 will be shutdown
2024-05-01T09:41:27,494  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3180aee created in the thread with id: 1
2024-05-01T09:41:27,497  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:27,497  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:27,497  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:27,497  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3180aee will be shutdown
2024-05-01T09:41:27,498  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:27,498  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -33
2024-05-01T09:41:27,498  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:27,499  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,499  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,499  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32d8710a created in the thread with id: 1
2024-05-01T09:41:27,502  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1 from thread id: 1
2024-05-01T09:41:27,503  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:27,513  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:27,520  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:27,560  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:27,561  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:27,561  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:27,562  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:27,562  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32d8710a will be shutdown
2024-05-01T09:41:27,562  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@603b9d4b created in the thread with id: 1
2024-05-01T09:41:27,564  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:27,564  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:27,565  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:27,565  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@603b9d4b will be shutdown
2024-05-01T09:41:27,565  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:27,565  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -34
2024-05-01T09:41:27,565  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:27,566  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,566  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,566  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ca6bd01 created in the thread with id: 1
2024-05-01T09:41:27,567  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba from thread id: 1
2024-05-01T09:41:27,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:27,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:27,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:27,618  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:27,618  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:27,619  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:27,621  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:27,622  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:27,622  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ca6bd01 will be shutdown
2024-05-01T09:41:27,622  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70aa03c0 created in the thread with id: 1
2024-05-01T09:41:27,625  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:27,625  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:27,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:27,626  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70aa03c0 will be shutdown
2024-05-01T09:41:27,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:27,626  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -35
2024-05-01T09:41:27,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:27,627  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e26040f, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e26040f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1782896 created in the thread with id: 1
2024-05-01T09:41:27,631  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e26040f from thread id: 1
2024-05-01T09:41:27,632  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:27,642  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:27,697  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:27,697  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:27,698  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:27,700  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:27,700  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:27,700  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e26040f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1782896 will be shutdown
2024-05-01T09:41:27,700  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e26040f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14293540 created in the thread with id: 1
2024-05-01T09:41:27,702  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:27,702  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:27,702  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:27,702  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e26040f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14293540 will be shutdown
2024-05-01T09:41:27,702  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:27,702  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -36
2024-05-01T09:41:27,702  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:27,703  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,703  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3791af, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,704  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3791af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66fff42f created in the thread with id: 1
2024-05-01T09:41:27,705  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3791af from thread id: 1
2024-05-01T09:41:27,707  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:27,716  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:27,722  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:27,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:27,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:27,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:27,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:27,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:27,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:27,763  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:27,763  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:27,763  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:27,763  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:27,763  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:27,763  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:27,764  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:27,764  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:27,764  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3791af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66fff42f will be shutdown
2024-05-01T09:41:27,764  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3791af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d6a22dd created in the thread with id: 1
2024-05-01T09:41:27,766  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:27,766  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:27,767  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:27,767  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3791af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d6a22dd will be shutdown
2024-05-01T09:41:27,767  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:27,767  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -37
2024-05-01T09:41:27,767  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:27,767  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,768  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@355b53cc, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,768  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@355b53cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2568611c created in the thread with id: 1
2024-05-01T09:41:27,770  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@355b53cc from thread id: 1
2024-05-01T09:41:27,777  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:27,783  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:27,783  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:27,808  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:27,828  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local81678318_0009
2024-05-01T09:41:27,829  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:27,900  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:27,900  INFO [main] mapreduce.Job: Running job: job_local81678318_0009
2024-05-01T09:41:27,901  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:27,903  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:27,904  INFO [Thread-385] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:27,905  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local81678318_0009_m_000000_0
2024-05-01T09:41:27,909  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:27,910  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T09:41:27,919  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local81678318_0009_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.09812407744686058/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T09:41:27,919  INFO [Thread-385] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:27,921  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.09812407744686058].
2024-05-01T09:41:27,921  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:27,972  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:27,972  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:27,972  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:27,972  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:27,972  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:27,972  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:27,973  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:27,973  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:27,973  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:27,973  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:27,973  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:27,973  INFO [Thread-385] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:27,974  INFO [Thread-385] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:27,975  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,975  INFO [Thread-385] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:27,976  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@314e74af, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,976  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@314e74af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16b5f519 created in the thread with id: 425
2024-05-01T09:41:27,980  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@314e74af from thread id: 425
2024-05-01T09:41:27,980  INFO [Thread-385] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:27,980  INFO [Thread-385] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:27,981  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:27,981  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@314e74af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16b5f519 will be shutdown
2024-05-01T09:41:27,981  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:27,981  INFO [Thread-385] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -38
2024-05-01T09:41:27,981  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:27,982  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:27,983  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b75af97, with PersistenceManager: null will be shutdown
2024-05-01T09:41:27,983  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b75af97, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f8e9482 created in the thread with id: 425
2024-05-01T09:41:27,985  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b75af97 from thread id: 425
2024-05-01T09:41:27,987  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:27,987  WARN [Thread-385] mapred.LocalJobRunner: job_local81678318_0009
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T09:41:28,901  INFO [main] mapreduce.Job: Job job_local81678318_0009 running in uber mode : false
2024-05-01T09:41:28,901  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:28,901  INFO [main] mapreduce.Job: Job job_local81678318_0009 failed with state FAILED due to: NA
2024-05-01T09:41:28,901  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:28,955  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:28,956  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:28,957  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:28,958  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:28,962  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:28,962  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:28,962  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@355b53cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2568611c will be shutdown
2024-05-01T09:41:28,963  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@355b53cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f6a2ac8 created in the thread with id: 1
2024-05-01T09:41:28,965  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:28,965  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:28,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:28,966  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@355b53cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f6a2ac8 will be shutdown
2024-05-01T09:41:28,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:28,966  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -39
2024-05-01T09:41:28,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:28,966  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:28,967  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: null will be shutdown
2024-05-01T09:41:28,967  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351be56b created in the thread with id: 1
2024-05-01T09:41:28,969  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d from thread id: 1
2024-05-01T09:41:28,971  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:28,979  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:28,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:28,988  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:28,995  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:29,000  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:29,025  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T09:41:29,050  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local123300899_0010
2024-05-01T09:41:29,050  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:29,150  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:29,151  INFO [main] mapreduce.Job: Running job: job_local123300899_0010
2024-05-01T09:41:29,151  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:29,151  INFO [Thread-405] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:29,151  INFO [Thread-405] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:29,152  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T09:41:29,161  INFO [Thread-405] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:29,161  INFO [Thread-405] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:30,151  INFO [main] mapreduce.Job: Job job_local123300899_0010 running in uber mode : false
2024-05-01T09:41:30,151  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:30,152  INFO [main] mapreduce.Job: Job job_local123300899_0010 completed successfully
2024-05-01T09:41:30,152  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:30,152  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:30,164  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:30,164  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T09:41:30,391  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:30,391  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:30,391  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:30,391  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:30,391  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:30,391  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:30,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:30,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:30,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:30,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:30,392  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[2]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.469">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T09:41:30,443  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:30,444  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:30,446  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:30,446  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:30,446  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351be56b will be shutdown
2024-05-01T09:41:30,446  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6369d01c created in the thread with id: 1
2024-05-01T09:41:30,449  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 7098b985-b2a8-4317-b3e4-8899047fecce
2024-05-01T09:41:30,449  INFO [main] SessionState: Hive Session ID = 7098b985-b2a8-4317-b3e4-8899047fecce
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:30,450  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:30,457  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/7098b985-b2a8-4317-b3e4-8899047fecce
2024-05-01T09:41:30,460  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/7098b985-b2a8-4317-b3e4-8899047fecce
2024-05-01T09:41:30,464  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/7098b985-b2a8-4317-b3e4-8899047fecce/_tmp_space.db
2024-05-01T09:41:30,464  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:30,466  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_RCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_RCFILE, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T09:41:30,468  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:30,546  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:30,547  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:30,548  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:30,550  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:30,550  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:30,551  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6369d01c will be shutdown
2024-05-01T09:41:30,551  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14bd523b created in the thread with id: 1
2024-05-01T09:41:30,554  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:30,554  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:30,554  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:30,554  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cc669d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14bd523b will be shutdown
2024-05-01T09:41:30,554  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:30,554  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -40
2024-05-01T09:41:30,555  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:30,556  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:30,556  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: null will be shutdown
2024-05-01T09:41:30,557  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33563147 created in the thread with id: 1
2024-05-01T09:41:30,560  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631 from thread id: 1
2024-05-01T09:41:30,562  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:30,572  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:30,584  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:30,627  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:30,628  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:30,629  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:30,629  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:30,629  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33563147 will be shutdown
2024-05-01T09:41:30,629  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@759b05d1 created in the thread with id: 1
2024-05-01T09:41:30,632  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:30,632  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:30,632  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:30,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@759b05d1 will be shutdown
2024-05-01T09:41:30,632  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:30,632  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -41
2024-05-01T09:41:30,633  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:30,633  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:30,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bac0be5, with PersistenceManager: null will be shutdown
2024-05-01T09:41:30,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bac0be5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@368d51ca created in the thread with id: 1
2024-05-01T09:41:30,636  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bac0be5 from thread id: 1
2024-05-01T09:41:30,637  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value1,501]	
2024-05-01T09:41:30,660  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:30,666  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:30,667  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:30,692  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:30,711  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local601141321_0011
2024-05-01T09:41:30,711  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:30,768  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:30,768  INFO [main] mapreduce.Job: Running job: job_local601141321_0011
2024-05-01T09:41:30,768  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:30,770  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,770  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,771  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:30,772  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,772  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,786  INFO [Thread-439] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:30,787  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local601141321_0011_m_000000_0
2024-05-01T09:41:30,792  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,792  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,794  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,794  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,794  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:30,795  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T09:41:30,801  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,801  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,838  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:30,838  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T09:41:30,838  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T09:41:30,842  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local601141321_0011_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:30,842  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,842  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,846  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:30,847  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local601141321_0011_m_000000_0 is allowed to commit now
2024-05-01T09:41:30,847  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:30,847  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:30,858  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local601141321_0011_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,542225982487236/part1=p1value1/part0=501
2024-05-01T09:41:30,859  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:30,859  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local601141321_0011_m_000000_0' done.
2024-05-01T09:41:30,859  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local601141321_0011_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5624606
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799014912
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:30,859  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local601141321_0011_m_000000_0
2024-05-01T09:41:30,860  INFO [Thread-439] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:30,909  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:30,910  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:30,910  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:30,911  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:30,911  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:30,911  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6, with PersistenceManager: null will be shutdown
2024-05-01T09:41:30,911  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@536c170b created in the thread with id: 481
2024-05-01T09:41:30,913  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6 from thread id: 481
2024-05-01T09:41:30,913  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:30,914  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:30,914  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:30,914  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@536c170b will be shutdown
2024-05-01T09:41:30,914  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:30,914  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -42
2024-05-01T09:41:30,914  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:30,915  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:30,915  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: null will be shutdown
2024-05-01T09:41:30,915  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a82fdec created in the thread with id: 481
2024-05-01T09:41:30,917  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406 from thread id: 481
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:30,969  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:30,969  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T09:41:30,994  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,542225982487236/part1=p1value1/part0=501].
2024-05-01T09:41:30,994  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:31,039  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:31,040  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:31,040  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:31,040  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:31,040  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:31,040  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:31,040  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:31,041  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:31,041  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a82fdec will be shutdown
2024-05-01T09:41:31,041  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54cd110f created in the thread with id: 481
2024-05-01T09:41:31,043  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:31,043  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:31,043  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:31,043  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54cd110f will be shutdown
2024-05-01T09:41:31,044  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:31,044  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -43
2024-05-01T09:41:31,044  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:31,044  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:31,045  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2503b3f5, with PersistenceManager: null will be shutdown
2024-05-01T09:41:31,045  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2503b3f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c9d569b created in the thread with id: 481
2024-05-01T09:41:31,046  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2503b3f5 from thread id: 481
2024-05-01T09:41:31,047  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:31,047  WARN [Thread-439] mapred.LocalJobRunner: job_local601141321_0011
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,542225982487236/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:31,768  INFO [main] mapreduce.Job: Job job_local601141321_0011 running in uber mode : false
2024-05-01T09:41:31,769  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:31,769  INFO [main] mapreduce.Job: Job job_local601141321_0011 failed with state FAILED due to: NA
2024-05-01T09:41:31,770  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5624606
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799014912
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:31,831  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:31,832  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:31,832  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:31,833  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:31,834  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:31,834  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:31,835  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bac0be5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@368d51ca will be shutdown
2024-05-01T09:41:31,835  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bac0be5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@412440c1 created in the thread with id: 1
2024-05-01T09:41:31,837  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:31,838  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:31,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:31,838  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bac0be5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@412440c1 will be shutdown
2024-05-01T09:41:31,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:31,838  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -44
2024-05-01T09:41:31,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:31,839  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:31,840  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: null will be shutdown
2024-05-01T09:41:31,840  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17d0d3d7 created in the thread with id: 1
2024-05-01T09:41:31,842  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3 from thread id: 1
2024-05-01T09:41:31,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:31,852  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:31,858  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:31,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:31,892  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:31,892  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:31,892  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:31,892  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:31,893  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17d0d3d7 will be shutdown
2024-05-01T09:41:31,893  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3662c887 created in the thread with id: 1
2024-05-01T09:41:31,895  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:31,895  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:31,895  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:31,895  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3662c887 will be shutdown
2024-05-01T09:41:31,895  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:31,895  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -45
2024-05-01T09:41:31,895  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:31,896  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:31,896  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: null will be shutdown
2024-05-01T09:41:31,896  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2059c3ff created in the thread with id: 1
2024-05-01T09:41:31,898  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb from thread id: 1
2024-05-01T09:41:31,899  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T09:41:31,914  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:31,919  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:31,920  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:31,941  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:31,957  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1502425648_0012
2024-05-01T09:41:31,957  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:32,006  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:32,006  INFO [main] mapreduce.Job: Running job: job_local1502425648_0012
2024-05-01T09:41:32,007  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:32,008  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,008  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,009  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:32,010  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,010  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,025  INFO [Thread-485] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:32,025  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1502425648_0012_m_000000_0
2024-05-01T09:41:32,027  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,027  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,028  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,028  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,028  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:32,029  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:32,031  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,031  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,046  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:32,046  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T09:41:32,046  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T09:41:32,047  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1502425648_0012_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:32,047  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,047  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,051  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:32,051  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1502425648_0012_m_000000_0 is allowed to commit now
2024-05-01T09:41:32,051  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:32,051  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:32,065  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1502425648_0012_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,18411586889972442/part1=p1value2/part0=502
2024-05-01T09:41:32,065  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:32,066  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1502425648_0012_m_000000_0' done.
2024-05-01T09:41:32,066  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1502425648_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6137792
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799014912
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:32,066  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1502425648_0012_m_000000_0
2024-05-01T09:41:32,066  INFO [Thread-485] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:32,126  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:32,127  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:32,127  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:32,128  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:32,128  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:32,128  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:32,129  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce05ce, with PersistenceManager: null will be shutdown
2024-05-01T09:41:32,129  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce05ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ae96041 created in the thread with id: 529
2024-05-01T09:41:32,130  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce05ce from thread id: 529
2024-05-01T09:41:32,130  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:32,131  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:32,131  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:32,131  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce05ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ae96041 will be shutdown
2024-05-01T09:41:32,131  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:32,131  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -46
2024-05-01T09:41:32,131  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:32,132  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:32,132  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12e4cc8d, with PersistenceManager: null will be shutdown
2024-05-01T09:41:32,132  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12e4cc8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e8560f7 created in the thread with id: 529
2024-05-01T09:41:32,134  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12e4cc8d from thread id: 529
2024-05-01T09:41:32,209  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:32,210  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:32,211  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:32,277  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,18411586889972442/part1=p1value2/part0=502].
2024-05-01T09:41:32,277  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:32,330  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:32,330  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:32,330  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:32,330  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:32,330  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:32,331  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:32,331  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:32,331  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:32,331  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:32,331  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:32,331  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:32,331  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:32,332  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:32,332  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:32,332  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12e4cc8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e8560f7 will be shutdown
2024-05-01T09:41:32,333  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12e4cc8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ee28497 created in the thread with id: 529
2024-05-01T09:41:32,335  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:32,335  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:32,336  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:32,336  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12e4cc8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ee28497 will be shutdown
2024-05-01T09:41:32,336  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:32,336  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -47
2024-05-01T09:41:32,336  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:32,337  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:32,338  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c69fedc, with PersistenceManager: null will be shutdown
2024-05-01T09:41:32,338  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c69fedc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5787d67 created in the thread with id: 529
2024-05-01T09:41:32,341  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c69fedc from thread id: 529
2024-05-01T09:41:32,343  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:32,343  WARN [Thread-485] mapred.LocalJobRunner: job_local1502425648_0012
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,18411586889972442/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:32,820  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T09:41:33,007  INFO [main] mapreduce.Job: Job job_local1502425648_0012 running in uber mode : false
2024-05-01T09:41:33,007  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:33,007  INFO [main] mapreduce.Job: Job job_local1502425648_0012 failed with state FAILED due to: NA
2024-05-01T09:41:33,009  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6137792
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799014912
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:33,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:33,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:33,058  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:33,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:33,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:33,059  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:33,059  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:33,059  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:33,059  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:33,059  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:33,059  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:33,059  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:33,060  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:33,062  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:33,062  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:33,062  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2059c3ff will be shutdown
2024-05-01T09:41:33,062  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@790f4933 created in the thread with id: 1
2024-05-01T09:41:33,064  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:33,064  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:33,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:33,065  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@790f4933 will be shutdown
2024-05-01T09:41:33,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:33,065  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -48
2024-05-01T09:41:33,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:33,066  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:33,066  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:33,066  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69b80603 created in the thread with id: 1
2024-05-01T09:41:33,068  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9 from thread id: 1
2024-05-01T09:41:33,070  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:33,078  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:33,083  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:33,118  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:33,118  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:33,118  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:33,118  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:33,118  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:33,118  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:33,119  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:33,119  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:33,119  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:33,119  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:33,119  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:33,119  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:33,120  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:33,120  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:33,121  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69b80603 will be shutdown
2024-05-01T09:41:33,121  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65234a9 created in the thread with id: 1
2024-05-01T09:41:33,123  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:33,123  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:33,123  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:33,123  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65234a9 will be shutdown
2024-05-01T09:41:33,123  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:33,123  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -49
2024-05-01T09:41:33,123  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:33,124  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:33,125  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: null will be shutdown
2024-05-01T09:41:33,125  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14580edc created in the thread with id: 1
2024-05-01T09:41:33,127  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016 from thread id: 1
2024-05-01T09:41:33,128  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T09:41:33,141  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:33,146  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:33,147  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:33,169  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:33,186  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1186563677_0013
2024-05-01T09:41:33,186  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:33,241  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:33,241  INFO [main] mapreduce.Job: Running job: job_local1186563677_0013
2024-05-01T09:41:33,266  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:33,268  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,268  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,269  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:33,270  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,270  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,283  INFO [Thread-531] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:33,283  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1186563677_0013_m_000000_0
2024-05-01T09:41:33,285  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,285  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,286  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,286  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,286  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:33,287  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:33,288  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,288  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,302  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:33,302  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T09:41:33,302  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T09:41:33,302  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1186563677_0013_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:33,302  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,302  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,306  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:33,306  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1186563677_0013_m_000000_0 is allowed to commit now
2024-05-01T09:41:33,306  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:33,306  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:33,316  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1186563677_0013_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,010079976434871685/part1=p1value2/part0=502
2024-05-01T09:41:33,316  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:33,316  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1186563677_0013_m_000000_0' done.
2024-05-01T09:41:33,317  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1186563677_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6650983
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802684928
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:33,317  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1186563677_0013_m_000000_0
2024-05-01T09:41:33,317  INFO [Thread-531] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:33,361  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:33,361  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:33,362  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:33,362  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:33,362  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:33,363  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce18417, with PersistenceManager: null will be shutdown
2024-05-01T09:41:33,363  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce18417, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@91c27ee created in the thread with id: 577
2024-05-01T09:41:33,364  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce18417 from thread id: 577
2024-05-01T09:41:33,365  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:33,365  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:33,365  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:33,365  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ce18417, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@91c27ee will be shutdown
2024-05-01T09:41:33,365  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:33,365  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -50
2024-05-01T09:41:33,365  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:33,366  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:33,366  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63e92fca, with PersistenceManager: null will be shutdown
2024-05-01T09:41:33,366  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63e92fca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30db27c2 created in the thread with id: 577
2024-05-01T09:41:33,368  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63e92fca from thread id: 577
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:33,411  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:33,411  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:33,435  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,010079976434871685/part1=p1value2/part0=502].
2024-05-01T09:41:33,436  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:33,473  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:33,474  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:33,474  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:33,474  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:33,474  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:33,474  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:33,474  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:33,475  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:33,475  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63e92fca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30db27c2 will be shutdown
2024-05-01T09:41:33,475  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63e92fca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a574434 created in the thread with id: 577
2024-05-01T09:41:33,477  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:33,477  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:33,477  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:33,477  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63e92fca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a574434 will be shutdown
2024-05-01T09:41:33,477  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:33,477  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -51
2024-05-01T09:41:33,477  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:33,478  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:33,478  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72821520, with PersistenceManager: null will be shutdown
2024-05-01T09:41:33,479  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72821520, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24b4f671 created in the thread with id: 577
2024-05-01T09:41:33,480  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72821520 from thread id: 577
2024-05-01T09:41:33,481  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:33,481  WARN [Thread-531] mapred.LocalJobRunner: job_local1186563677_0013
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,010079976434871685/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:34,267  INFO [main] mapreduce.Job: Job job_local1186563677_0013 running in uber mode : false
2024-05-01T09:41:34,267  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:34,267  INFO [main] mapreduce.Job: Job job_local1186563677_0013 failed with state FAILED due to: NA
2024-05-01T09:41:34,268  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6650983
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802684928
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:34,314  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:34,314  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:34,315  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:34,316  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:34,317  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:34,317  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14580edc will be shutdown
2024-05-01T09:41:34,317  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@451cef67 created in the thread with id: 1
2024-05-01T09:41:34,319  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:34,319  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:34,319  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:34,319  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@451cef67 will be shutdown
2024-05-01T09:41:34,319  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:34,319  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -52
2024-05-01T09:41:34,319  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:34,320  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,320  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3da55998, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,320  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3da55998, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40ebb56 created in the thread with id: 1
2024-05-01T09:41:34,322  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3da55998 from thread id: 1
2024-05-01T09:41:34,323  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:34,330  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:34,335  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:34,369  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:34,369  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:34,370  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:34,370  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:34,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3da55998, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40ebb56 will be shutdown
2024-05-01T09:41:34,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3da55998, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e488e45 created in the thread with id: 1
2024-05-01T09:41:34,372  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:34,372  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:34,372  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:34,372  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3da55998, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e488e45 will be shutdown
2024-05-01T09:41:34,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:34,373  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -53
2024-05-01T09:41:34,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:34,374  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b4f4a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b4f4a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d8a1456 created in the thread with id: 1
2024-05-01T09:41:34,376  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b4f4a from thread id: 1
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:34,422  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:34,423  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:34,423  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:34,425  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:34,425  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:34,425  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b4f4a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d8a1456 will be shutdown
2024-05-01T09:41:34,425  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b4f4a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38d895e8 created in the thread with id: 1
2024-05-01T09:41:34,427  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:34,427  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:34,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:34,427  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b4f4a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38d895e8 will be shutdown
2024-05-01T09:41:34,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:34,427  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -54
2024-05-01T09:41:34,428  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:34,428  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52bcfd10, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52bcfd10, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67683210 created in the thread with id: 1
2024-05-01T09:41:34,430  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52bcfd10 from thread id: 1
2024-05-01T09:41:34,432  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:34,439  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:34,484  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:34,484  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:34,485  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:34,487  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:34,487  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:34,487  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52bcfd10, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67683210 will be shutdown
2024-05-01T09:41:34,487  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52bcfd10, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@263f6e96 created in the thread with id: 1
2024-05-01T09:41:34,490  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:34,490  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:34,490  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:34,490  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@52bcfd10, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@263f6e96 will be shutdown
2024-05-01T09:41:34,490  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:34,491  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -55
2024-05-01T09:41:34,491  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:34,491  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,492  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@206e5183, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,492  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@206e5183, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@325236f5 created in the thread with id: 1
2024-05-01T09:41:34,493  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@206e5183 from thread id: 1
2024-05-01T09:41:34,494  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:34,501  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:34,507  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:34,539  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:34,539  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:34,540  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:34,540  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:34,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@206e5183, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@325236f5 will be shutdown
2024-05-01T09:41:34,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@206e5183, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@96448ee created in the thread with id: 1
2024-05-01T09:41:34,542  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:34,542  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:34,543  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:34,543  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@206e5183, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@96448ee will be shutdown
2024-05-01T09:41:34,543  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:34,543  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -56
2024-05-01T09:41:34,543  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:34,544  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,544  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54c17a2b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,544  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54c17a2b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16279a5d created in the thread with id: 1
2024-05-01T09:41:34,546  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54c17a2b from thread id: 1
2024-05-01T09:41:34,552  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:34,557  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:34,558  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:34,578  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:34,594  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local635882170_0014
2024-05-01T09:41:34,594  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:34,642  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:34,642  INFO [main] mapreduce.Job: Running job: job_local635882170_0014
2024-05-01T09:41:34,643  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:34,645  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:34,646  INFO [Thread-582] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:34,646  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local635882170_0014_m_000000_0
2024-05-01T09:41:34,649  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:34,649  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T09:41:34,655  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local635882170_0014_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.3553561298069676/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T09:41:34,655  INFO [Thread-582] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:34,657  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.3553561298069676].
2024-05-01T09:41:34,657  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:34,694  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:34,695  INFO [Thread-582] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:34,695  INFO [Thread-582] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:34,696  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,696  INFO [Thread-582] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:34,696  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,696  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45da5090 created in the thread with id: 630
2024-05-01T09:41:34,698  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0 from thread id: 630
2024-05-01T09:41:34,698  INFO [Thread-582] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:34,699  INFO [Thread-582] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:34,699  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:34,699  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45da5090 will be shutdown
2024-05-01T09:41:34,699  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:34,699  INFO [Thread-582] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -57
2024-05-01T09:41:34,699  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:34,700  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:34,700  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f6088d5, with PersistenceManager: null will be shutdown
2024-05-01T09:41:34,700  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f6088d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ba4c6f5 created in the thread with id: 630
2024-05-01T09:41:34,702  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f6088d5 from thread id: 630
2024-05-01T09:41:34,703  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:34,703  WARN [Thread-582] mapred.LocalJobRunner: job_local635882170_0014
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T09:41:35,643  INFO [main] mapreduce.Job: Job job_local635882170_0014 running in uber mode : false
2024-05-01T09:41:35,643  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:35,643  INFO [main] mapreduce.Job: Job job_local635882170_0014 failed with state FAILED due to: NA
2024-05-01T09:41:35,643  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:35,683  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:35,684  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:35,684  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:35,685  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:35,686  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:35,686  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54c17a2b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16279a5d will be shutdown
2024-05-01T09:41:35,686  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54c17a2b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52b7c1d9 created in the thread with id: 1
2024-05-01T09:41:35,687  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:35,688  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:35,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:35,688  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54c17a2b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52b7c1d9 will be shutdown
2024-05-01T09:41:35,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:35,688  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -58
2024-05-01T09:41:35,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:35,689  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:35,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: null will be shutdown
2024-05-01T09:41:35,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bf70600 created in the thread with id: 1
2024-05-01T09:41:35,690  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda from thread id: 1
2024-05-01T09:41:35,691  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:35,696  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:35,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:35,700  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:35,706  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:35,712  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:35,734  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T09:41:35,749  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2076394892_0015
2024-05-01T09:41:35,749  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:35,799  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:35,799  INFO [main] mapreduce.Job: Running job: job_local2076394892_0015
2024-05-01T09:41:35,800  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:35,800  INFO [Thread-602] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:35,800  INFO [Thread-602] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:35,800  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T09:41:35,808  INFO [Thread-602] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:35,808  INFO [Thread-602] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:36,800  INFO [main] mapreduce.Job: Job job_local2076394892_0015 running in uber mode : false
2024-05-01T09:41:36,800  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:36,800  INFO [main] mapreduce.Job: Job job_local2076394892_0015 completed successfully
2024-05-01T09:41:36,800  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:36,800  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:36,806  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:36,806  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T09:41:36,861  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:36,861  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:36,862  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[3]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.378">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T09:41:36,904  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:36,904  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:36,904  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:36,905  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:36,906  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:36,906  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:36,906  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bf70600 will be shutdown
2024-05-01T09:41:36,907  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6779af40 created in the thread with id: 1
2024-05-01T09:41:36,909  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 8767703a-e089-4a7a-9954-77040b5a32bd
2024-05-01T09:41:36,909  INFO [main] SessionState: Hive Session ID = 8767703a-e089-4a7a-9954-77040b5a32bd
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:36,910  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:36,916  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/8767703a-e089-4a7a-9954-77040b5a32bd
2024-05-01T09:41:36,919  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/8767703a-e089-4a7a-9954-77040b5a32bd
2024-05-01T09:41:36,922  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/8767703a-e089-4a7a-9954-77040b5a32bd/_tmp_space.db
2024-05-01T09:41:36,923  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:36,924  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_ORCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_ORCFILE, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T09:41:36,925  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile
2024-05-01T09:41:36,981  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:36,981  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:36,981  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:36,982  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:36,982  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:36,983  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:36,984  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:36,984  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:36,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6779af40 will be shutdown
2024-05-01T09:41:36,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@762d2e4c created in the thread with id: 1
2024-05-01T09:41:36,987  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:36,987  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:36,987  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:36,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b332eda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@762d2e4c will be shutdown
2024-05-01T09:41:36,987  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:36,987  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -59
2024-05-01T09:41:36,987  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:36,988  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:36,988  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: null will be shutdown
2024-05-01T09:41:36,989  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f3f0d25 created in the thread with id: 1
2024-05-01T09:41:36,990  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d from thread id: 1
2024-05-01T09:41:36,991  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:36,997  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:37,011  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:37,043  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:37,043  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:37,044  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:37,044  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:37,045  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f3f0d25 will be shutdown
2024-05-01T09:41:37,045  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4131f6db created in the thread with id: 1
2024-05-01T09:41:37,046  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:37,047  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:37,047  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:37,047  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4131f6db will be shutdown
2024-05-01T09:41:37,047  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:37,047  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -60
2024-05-01T09:41:37,047  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:37,048  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:37,048  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ce03a9d, with PersistenceManager: null will be shutdown
2024-05-01T09:41:37,049  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ce03a9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10c67c1c created in the thread with id: 1
2024-05-01T09:41:37,051  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ce03a9d from thread id: 1
2024-05-01T09:41:37,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value1,501]	
2024-05-01T09:41:37,066  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:37,071  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:37,071  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:37,092  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:37,108  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local393043754_0016
2024-05-01T09:41:37,108  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:37,157  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:37,157  INFO [main] mapreduce.Job: Running job: job_local393043754_0016
2024-05-01T09:41:37,158  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:37,159  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,159  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,160  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:37,161  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,161  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,175  INFO [Thread-636] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:37,175  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local393043754_0016_m_000000_0
2024-05-01T09:41:37,179  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,179  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,181  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,181  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,181  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:37,181  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T09:41:37,187  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,187  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,219  INFO [LocalJobRunner Map Task Executor #0] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-05-01T09:41:37,223  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,5696580263097285/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local393043754_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T09:41:37,281  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,5696580263097285/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local393043754_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T09:41:37,287  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:37,338  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local393043754_0016_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:37,338  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,338  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,342  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:37,342  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local393043754_0016_m_000000_0 is allowed to commit now
2024-05-01T09:41:37,342  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:37,342  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:37,352  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local393043754_0016_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,5696580263097285/part1=p1value1/part0=501
2024-05-01T09:41:37,352  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:37,352  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local393043754_0016_m_000000_0' done.
2024-05-01T09:41:37,353  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local393043754_0016_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8182597
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802684928
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:37,353  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local393043754_0016_m_000000_0
2024-05-01T09:41:37,353  INFO [Thread-636] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:37,401  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:37,402  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:37,402  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:37,403  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:37,403  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:37,404  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a0f5f36, with PersistenceManager: null will be shutdown
2024-05-01T09:41:37,404  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a0f5f36, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@498991cc created in the thread with id: 686
2024-05-01T09:41:37,406  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a0f5f36 from thread id: 686
2024-05-01T09:41:37,406  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:37,406  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:37,406  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:37,406  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a0f5f36, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@498991cc will be shutdown
2024-05-01T09:41:37,407  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:37,407  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -61
2024-05-01T09:41:37,407  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:37,408  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:37,408  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@331fbad9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:37,408  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@331fbad9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@634de930 created in the thread with id: 686
2024-05-01T09:41:37,410  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@331fbad9 from thread id: 686
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:37,483  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:37,483  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T09:41:37,506  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,5696580263097285/part1=p1value1/part0=501].
2024-05-01T09:41:37,506  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:37,547  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:37,548  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:37,548  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:37,548  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:37,548  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@331fbad9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@634de930 will be shutdown
2024-05-01T09:41:37,549  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@331fbad9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6367a72a created in the thread with id: 686
2024-05-01T09:41:37,550  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:37,550  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:37,550  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:37,550  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@331fbad9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6367a72a will be shutdown
2024-05-01T09:41:37,551  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:37,551  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -62
2024-05-01T09:41:37,551  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:37,551  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:37,552  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49086cb7, with PersistenceManager: null will be shutdown
2024-05-01T09:41:37,552  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49086cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ef9ba59 created in the thread with id: 686
2024-05-01T09:41:37,554  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49086cb7 from thread id: 686
2024-05-01T09:41:37,555  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:37,555  WARN [Thread-636] mapred.LocalJobRunner: job_local393043754_0016
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,5696580263097285/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:38,158  INFO [main] mapreduce.Job: Job job_local393043754_0016 running in uber mode : false
2024-05-01T09:41:38,158  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:38,158  INFO [main] mapreduce.Job: Job job_local393043754_0016 failed with state FAILED due to: NA
2024-05-01T09:41:38,159  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8182597
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802684928
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:38,205  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:38,205  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:38,206  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:38,207  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:38,207  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:38,208  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ce03a9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10c67c1c will be shutdown
2024-05-01T09:41:38,208  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ce03a9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7fd3c38b created in the thread with id: 1
2024-05-01T09:41:38,209  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:38,210  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:38,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:38,210  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ce03a9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7fd3c38b will be shutdown
2024-05-01T09:41:38,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:38,210  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -63
2024-05-01T09:41:38,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:38,211  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:38,211  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: null will be shutdown
2024-05-01T09:41:38,211  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29612ee2 created in the thread with id: 1
2024-05-01T09:41:38,212  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff from thread id: 1
2024-05-01T09:41:38,213  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:38,219  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:38,226  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:38,262  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:38,262  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:38,262  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:38,263  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:38,263  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:38,264  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:38,264  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:38,264  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29612ee2 will be shutdown
2024-05-01T09:41:38,264  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8aa3013 created in the thread with id: 1
2024-05-01T09:41:38,266  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:38,266  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:38,267  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:38,267  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8aa3013 will be shutdown
2024-05-01T09:41:38,267  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:38,267  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -64
2024-05-01T09:41:38,267  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:38,267  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:38,268  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: null will be shutdown
2024-05-01T09:41:38,268  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bab8290 created in the thread with id: 1
2024-05-01T09:41:38,269  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce from thread id: 1
2024-05-01T09:41:38,270  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T09:41:38,283  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:38,288  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:38,289  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:38,309  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:38,324  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2117792198_0017
2024-05-01T09:41:38,324  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:38,373  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:38,373  INFO [main] mapreduce.Job: Running job: job_local2117792198_0017
2024-05-01T09:41:38,374  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:38,375  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,375  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,376  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:38,377  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,377  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,391  INFO [Thread-682] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:38,391  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2117792198_0017_m_000000_0
2024-05-01T09:41:38,393  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,393  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,395  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,395  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,395  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:38,395  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:38,397  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,397  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,400  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7830613100363685/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local2117792198_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T09:41:38,411  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7830613100363685/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local2117792198_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T09:41:38,411  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:38,414  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2117792198_0017_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:38,414  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,414  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,418  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:38,418  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2117792198_0017_m_000000_0 is allowed to commit now
2024-05-01T09:41:38,418  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:38,418  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:38,428  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2117792198_0017_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7830613100363685/part1=p1value2/part0=502
2024-05-01T09:41:38,429  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:38,429  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2117792198_0017_m_000000_0' done.
2024-05-01T09:41:38,429  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2117792198_0017_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8695340
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847249408
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:38,429  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2117792198_0017_m_000000_0
2024-05-01T09:41:38,429  INFO [Thread-682] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:38,474  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:38,474  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:38,475  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:38,476  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:38,476  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:38,476  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e35a719, with PersistenceManager: null will be shutdown
2024-05-01T09:41:38,476  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e35a719, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c8e0204 created in the thread with id: 734
2024-05-01T09:41:38,478  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e35a719 from thread id: 734
2024-05-01T09:41:38,478  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:38,478  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:38,479  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:38,479  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e35a719, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c8e0204 will be shutdown
2024-05-01T09:41:38,479  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:38,479  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -65
2024-05-01T09:41:38,479  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:38,480  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:38,480  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf2c958, with PersistenceManager: null will be shutdown
2024-05-01T09:41:38,480  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf2c958, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e20b698 created in the thread with id: 734
2024-05-01T09:41:38,483  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf2c958 from thread id: 734
2024-05-01T09:41:38,525  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:38,525  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:38,525  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:38,525  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:38,525  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:38,525  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:38,526  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:38,526  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:38,526  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:38,526  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:38,526  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:38,526  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:38,548  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7830613100363685/part1=p1value2/part0=502].
2024-05-01T09:41:38,548  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:38,588  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:38,589  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:38,589  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:38,589  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:38,589  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:38,589  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:38,590  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:38,590  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf2c958, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e20b698 will be shutdown
2024-05-01T09:41:38,590  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf2c958, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37c65859 created in the thread with id: 734
2024-05-01T09:41:38,593  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:38,593  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:38,593  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:38,593  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf2c958, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37c65859 will be shutdown
2024-05-01T09:41:38,593  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:38,593  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -66
2024-05-01T09:41:38,593  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:38,594  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:38,595  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5741093a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:38,595  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5741093a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d72d9fa created in the thread with id: 734
2024-05-01T09:41:38,597  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5741093a from thread id: 734
2024-05-01T09:41:38,598  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:38,598  WARN [Thread-682] mapred.LocalJobRunner: job_local2117792198_0017
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7830613100363685/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:39,374  INFO [main] mapreduce.Job: Job job_local2117792198_0017 running in uber mode : false
2024-05-01T09:41:39,374  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:39,374  INFO [main] mapreduce.Job: Job job_local2117792198_0017 failed with state FAILED due to: NA
2024-05-01T09:41:39,375  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8695340
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847249408
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:39,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:39,422  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:39,422  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:39,422  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:39,424  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:39,424  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:39,424  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bab8290 will be shutdown
2024-05-01T09:41:39,424  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d50f682 created in the thread with id: 1
2024-05-01T09:41:39,426  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:39,426  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:39,426  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:39,426  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d50f682 will be shutdown
2024-05-01T09:41:39,426  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:39,426  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -67
2024-05-01T09:41:39,426  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:39,427  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:39,427  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: null will be shutdown
2024-05-01T09:41:39,427  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ceb7a60 created in the thread with id: 1
2024-05-01T09:41:39,429  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa from thread id: 1
2024-05-01T09:41:39,430  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:39,435  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:39,440  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:39,472  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:39,472  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:39,473  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:39,473  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:39,473  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ceb7a60 will be shutdown
2024-05-01T09:41:39,473  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6cd8c373 created in the thread with id: 1
2024-05-01T09:41:39,475  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:39,475  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:39,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:39,475  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6cd8c373 will be shutdown
2024-05-01T09:41:39,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:39,475  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -68
2024-05-01T09:41:39,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:39,476  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:39,476  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: null will be shutdown
2024-05-01T09:41:39,476  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a41d17a created in the thread with id: 1
2024-05-01T09:41:39,478  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527 from thread id: 1
2024-05-01T09:41:39,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T09:41:39,490  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:39,495  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:39,496  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:39,517  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:39,533  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2026260055_0018
2024-05-01T09:41:39,533  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:39,582  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:39,582  INFO [main] mapreduce.Job: Running job: job_local2026260055_0018
2024-05-01T09:41:39,583  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:39,584  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,584  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,585  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:39,586  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,586  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,599  INFO [Thread-728] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:39,599  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2026260055_0018_m_000000_0
2024-05-01T09:41:39,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,604  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,604  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,604  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:39,604  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:39,607  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,607  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,610  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8944819706944448/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local2026260055_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T09:41:39,621  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8944819706944448/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local2026260055_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T09:41:39,622  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:39,624  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2026260055_0018_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:39,624  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,624  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,628  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:39,628  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2026260055_0018_m_000000_0 is allowed to commit now
2024-05-01T09:41:39,628  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:39,628  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:39,638  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2026260055_0018_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8944819706944448/part1=p1value2/part0=502
2024-05-01T09:41:39,638  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:39,638  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2026260055_0018_m_000000_0' done.
2024-05-01T09:41:39,638  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2026260055_0018_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9208083
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847249408
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:39,639  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2026260055_0018_m_000000_0
2024-05-01T09:41:39,639  INFO [Thread-728] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:39,683  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:39,683  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:39,684  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:39,685  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:39,685  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:39,685  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6234ebbf, with PersistenceManager: null will be shutdown
2024-05-01T09:41:39,685  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6234ebbf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f94068 created in the thread with id: 782
2024-05-01T09:41:39,686  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6234ebbf from thread id: 782
2024-05-01T09:41:39,686  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:39,686  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:39,687  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:39,687  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6234ebbf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f94068 will be shutdown
2024-05-01T09:41:39,687  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:39,687  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -69
2024-05-01T09:41:39,687  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:39,687  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:39,688  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@133ed4c6, with PersistenceManager: null will be shutdown
2024-05-01T09:41:39,688  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@133ed4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@743aa24e created in the thread with id: 782
2024-05-01T09:41:39,689  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@133ed4c6 from thread id: 782
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:39,732  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:39,732  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:39,754  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8944819706944448/part1=p1value2/part0=502].
2024-05-01T09:41:39,755  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:39,793  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:39,794  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:39,794  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:39,795  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:39,795  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:39,795  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@133ed4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@743aa24e will be shutdown
2024-05-01T09:41:39,796  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@133ed4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56d42a63 created in the thread with id: 782
2024-05-01T09:41:39,798  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:39,798  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:39,798  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:39,798  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@133ed4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56d42a63 will be shutdown
2024-05-01T09:41:39,798  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:39,798  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -70
2024-05-01T09:41:39,798  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:39,799  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:39,800  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41b23206, with PersistenceManager: null will be shutdown
2024-05-01T09:41:39,800  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41b23206, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30138697 created in the thread with id: 782
2024-05-01T09:41:39,801  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41b23206 from thread id: 782
2024-05-01T09:41:39,802  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:39,802  WARN [Thread-728] mapred.LocalJobRunner: job_local2026260055_0018
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8944819706944448/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:39,906  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T09:41:40,583  INFO [main] mapreduce.Job: Job job_local2026260055_0018 running in uber mode : false
2024-05-01T09:41:40,583  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:40,583  INFO [main] mapreduce.Job: Job job_local2026260055_0018 failed with state FAILED due to: NA
2024-05-01T09:41:40,584  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9208083
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=847249408
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:40,629  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:40,629  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:40,630  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:40,631  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:40,631  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:40,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a41d17a will be shutdown
2024-05-01T09:41:40,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c8859b4 created in the thread with id: 1
2024-05-01T09:41:40,633  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:40,634  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:40,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:40,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c8859b4 will be shutdown
2024-05-01T09:41:40,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:40,634  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -71
2024-05-01T09:41:40,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:40,635  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:40,635  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@789d45f7, with PersistenceManager: null will be shutdown
2024-05-01T09:41:40,635  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@789d45f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@240c626d created in the thread with id: 1
2024-05-01T09:41:40,637  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@789d45f7 from thread id: 1
2024-05-01T09:41:40,637  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:40,643  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:40,649  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:40,681  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:40,681  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:40,681  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:40,681  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:40,681  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:40,681  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:40,682  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:40,682  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:40,682  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:40,682  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:40,682  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:40,682  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:40,682  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:40,683  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:40,683  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@789d45f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@240c626d will be shutdown
2024-05-01T09:41:40,683  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@789d45f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39d44217 created in the thread with id: 1
2024-05-01T09:41:40,685  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:40,685  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:40,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:40,686  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@789d45f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39d44217 will be shutdown
2024-05-01T09:41:40,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:40,686  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -72
2024-05-01T09:41:40,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:40,687  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:40,687  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2561d61, with PersistenceManager: null will be shutdown
2024-05-01T09:41:40,687  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2561d61, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6259d7a0 created in the thread with id: 1
2024-05-01T09:41:40,689  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2561d61 from thread id: 1
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:40,735  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:40,735  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:40,736  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:40,738  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:40,738  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:40,738  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2561d61, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6259d7a0 will be shutdown
2024-05-01T09:41:40,738  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2561d61, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@515a2afd created in the thread with id: 1
2024-05-01T09:41:40,740  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:40,740  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:40,740  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:40,740  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2561d61, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@515a2afd will be shutdown
2024-05-01T09:41:40,740  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:40,740  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -73
2024-05-01T09:41:40,740  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:40,741  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:40,741  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bbb59c, with PersistenceManager: null will be shutdown
2024-05-01T09:41:40,741  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bbb59c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@538fb761 created in the thread with id: 1
2024-05-01T09:41:40,743  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bbb59c from thread id: 1
2024-05-01T09:41:40,743  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:40,749  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:40,793  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:40,794  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:40,794  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:40,796  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:40,796  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:40,796  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bbb59c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@538fb761 will be shutdown
2024-05-01T09:41:40,796  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bbb59c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5276330a created in the thread with id: 1
2024-05-01T09:41:40,798  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:40,798  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:40,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:40,798  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bbb59c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5276330a will be shutdown
2024-05-01T09:41:40,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:40,798  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -74
2024-05-01T09:41:40,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:40,799  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:40,799  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ab7e997, with PersistenceManager: null will be shutdown
2024-05-01T09:41:40,799  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ab7e997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2552cb80 created in the thread with id: 1
2024-05-01T09:41:40,801  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ab7e997 from thread id: 1
2024-05-01T09:41:40,802  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:40,807  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:40,813  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:40,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:40,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:40,845  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:40,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:40,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:40,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:40,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:40,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:40,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:40,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:40,846  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:40,846  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:40,846  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:40,847  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:40,847  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ab7e997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2552cb80 will be shutdown
2024-05-01T09:41:40,847  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ab7e997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4be6531a created in the thread with id: 1
2024-05-01T09:41:40,849  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:40,849  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:40,849  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:40,849  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5ab7e997, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4be6531a will be shutdown
2024-05-01T09:41:40,849  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:40,849  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -75
2024-05-01T09:41:40,849  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:40,850  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:40,850  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a0b925a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:40,851  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a0b925a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14b4f462 created in the thread with id: 1
2024-05-01T09:41:40,852  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a0b925a from thread id: 1
2024-05-01T09:41:40,858  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:40,863  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:40,864  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:40,885  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:40,900  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local120026647_0019
2024-05-01T09:41:40,900  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:40,949  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:40,949  INFO [main] mapreduce.Job: Running job: job_local120026647_0019
2024-05-01T09:41:40,950  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:40,952  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:40,952  INFO [Thread-779] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:40,953  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local120026647_0019_m_000000_0
2024-05-01T09:41:40,955  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:40,956  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T09:41:40,960  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local120026647_0019_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.7833325154871696/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T09:41:40,960  INFO [Thread-779] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:40,962  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.7833325154871696].
2024-05-01T09:41:40,962  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:41,020  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:41,021  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:41,021  INFO [Thread-779] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:41,021  INFO [Thread-779] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:41,022  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:41,022  INFO [Thread-779] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:41,022  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@498cde04, with PersistenceManager: null will be shutdown
2024-05-01T09:41:41,022  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@498cde04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@429eff27 created in the thread with id: 835
2024-05-01T09:41:41,024  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@498cde04 from thread id: 835
2024-05-01T09:41:41,024  INFO [Thread-779] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:41,024  INFO [Thread-779] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:41,024  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:41,024  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@498cde04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@429eff27 will be shutdown
2024-05-01T09:41:41,024  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:41,024  INFO [Thread-779] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -76
2024-05-01T09:41:41,024  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:41,025  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:41,025  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@522e89e3, with PersistenceManager: null will be shutdown
2024-05-01T09:41:41,025  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@522e89e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f1caa3 created in the thread with id: 835
2024-05-01T09:41:41,027  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@522e89e3 from thread id: 835
2024-05-01T09:41:41,028  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:41,028  WARN [Thread-779] mapred.LocalJobRunner: job_local120026647_0019
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T09:41:41,950  INFO [main] mapreduce.Job: Job job_local120026647_0019 running in uber mode : false
2024-05-01T09:41:41,950  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:41,950  INFO [main] mapreduce.Job: Job job_local120026647_0019 failed with state FAILED due to: NA
2024-05-01T09:41:41,950  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:41,999  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:41,999  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:42,000  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:42,001  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:42,002  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:42,002  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a0b925a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14b4f462 will be shutdown
2024-05-01T09:41:42,002  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a0b925a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e6c703a created in the thread with id: 1
2024-05-01T09:41:42,004  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:42,004  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:42,004  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:42,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a0b925a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e6c703a will be shutdown
2024-05-01T09:41:42,004  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:42,004  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -77
2024-05-01T09:41:42,004  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:42,005  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:42,005  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: null will be shutdown
2024-05-01T09:41:42,005  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79e3f444 created in the thread with id: 1
2024-05-01T09:41:42,007  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40 from thread id: 1
2024-05-01T09:41:42,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:42,013  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:42,013  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:42,017  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:42,023  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:42,028  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:42,049  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T09:41:42,066  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1227779311_0020
2024-05-01T09:41:42,066  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:42,158  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:42,158  INFO [main] mapreduce.Job: Running job: job_local1227779311_0020
2024-05-01T09:41:42,158  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:42,159  INFO [Thread-799] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:42,159  INFO [Thread-799] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:42,159  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T09:41:42,167  INFO [Thread-799] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:42,167  INFO [Thread-799] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:43,158  INFO [main] mapreduce.Job: Job job_local1227779311_0020 running in uber mode : false
2024-05-01T09:41:43,159  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:43,159  INFO [main] mapreduce.Job: Job job_local1227779311_0020 completed successfully
2024-05-01T09:41:43,159  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:43,159  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:43,164  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:43,164  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,240  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[4]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,285  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,287  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,287  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,288  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79e3f444 will be shutdown
2024-05-01T09:41:43,288  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d2413e created in the thread with id: 1
2024-05-01T09:41:43,290  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = a099f549-b02b-464c-97aa-c6f330776d63
2024-05-01T09:41:43,290  INFO [main] SessionState: Hive Session ID = a099f549-b02b-464c-97aa-c6f330776d63
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:43,290  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:43,296  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/a099f549-b02b-464c-97aa-c6f330776d63
2024-05-01T09:41:43,299  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/a099f549-b02b-464c-97aa-c6f330776d63
2024-05-01T09:41:43,301  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/a099f549-b02b-464c-97aa-c6f330776d63/_tmp_space.db
2024-05-01T09:41:43,302  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_PARQUETFILE	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[5]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,345  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,347  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,348  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,348  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d2413e will be shutdown
2024-05-01T09:41:43,348  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c020e58 created in the thread with id: 1
2024-05-01T09:41:43,349  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 0968f6ed-1695-4ad2-8eb9-6e625f595d81
2024-05-01T09:41:43,350  INFO [main] SessionState: Hive Session ID = 0968f6ed-1695-4ad2-8eb9-6e625f595d81
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:43,350  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:43,356  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/0968f6ed-1695-4ad2-8eb9-6e625f595d81
2024-05-01T09:41:43,359  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/0968f6ed-1695-4ad2-8eb9-6e625f595d81
2024-05-01T09:41:43,361  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/0968f6ed-1695-4ad2-8eb9-6e625f595d81/_tmp_space.db
2024-05-01T09:41:43,362  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_AVRO	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[6]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.332">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T09:41:43,402  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,402  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,402  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,402  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,402  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,402  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,403  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,403  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,403  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,403  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,403  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,405  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,405  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,405  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c020e58 will be shutdown
2024-05-01T09:41:43,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47bcd95a created in the thread with id: 1
2024-05-01T09:41:43,407  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 4e6c67b8-e155-4997-a8ed-cba20560d651
2024-05-01T09:41:43,407  INFO [main] SessionState: Hive Session ID = 4e6c67b8-e155-4997-a8ed-cba20560d651
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:43,408  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:43,414  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/4e6c67b8-e155-4997-a8ed-cba20560d651
2024-05-01T09:41:43,416  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/4e6c67b8-e155-4997-a8ed-cba20560d651
2024-05-01T09:41:43,419  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/4e6c67b8-e155-4997-a8ed-cba20560d651/_tmp_space.db
2024-05-01T09:41:43,420  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:43,421  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_JSONFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_JSONFILE, serializationLib:org.apache.hadoop.hive.serde2.JsonSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T09:41:43,423  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,478  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,478  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:43,479  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:43,481  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,481  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,481  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47bcd95a will be shutdown
2024-05-01T09:41:43,481  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64dc0a5f created in the thread with id: 1
2024-05-01T09:41:43,483  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:43,483  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:43,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:43,483  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c1d9c40, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64dc0a5f will be shutdown
2024-05-01T09:41:43,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:43,483  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -78
2024-05-01T09:41:43,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:43,484  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:43,484  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: null will be shutdown
2024-05-01T09:41:43,484  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50e336d9 created in the thread with id: 1
2024-05-01T09:41:43,486  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368 from thread id: 1
2024-05-01T09:41:43,487  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:43,492  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:43,504  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,536  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,537  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:43,537  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,537  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,538  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50e336d9 will be shutdown
2024-05-01T09:41:43,538  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d95100f created in the thread with id: 1
2024-05-01T09:41:43,540  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:43,540  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:43,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:43,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d95100f will be shutdown
2024-05-01T09:41:43,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:43,540  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -79
2024-05-01T09:41:43,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:43,541  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:43,541  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac7927a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:43,541  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac7927a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25bfc558 created in the thread with id: 1
2024-05-01T09:41:43,543  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac7927a from thread id: 1
2024-05-01T09:41:43,544  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value1,501]	
2024-05-01T09:41:43,557  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:43,562  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:43,562  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:43,582  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:43,598  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local160946667_0021
2024-05-01T09:41:43,598  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:43,647  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:43,647  INFO [main] mapreduce.Job: Running job: job_local160946667_0021
2024-05-01T09:41:43,647  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:43,649  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,649  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,650  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:43,650  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,650  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,664  INFO [Thread-841] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:43,664  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local160946667_0021_m_000000_0
2024-05-01T09:41:43,669  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,669  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,670  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,670  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,670  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:43,671  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T09:41:43,677  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,677  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,702  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:43,706  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local160946667_0021_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:43,706  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,706  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,710  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:43,710  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local160946667_0021_m_000000_0 is allowed to commit now
2024-05-01T09:41:43,710  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:43,710  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:43,720  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local160946667_0021_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,4745303619341319/part1=p1value1/part0=501
2024-05-01T09:41:43,720  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:43,720  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local160946667_0021_m_000000_0' done.
2024-05-01T09:41:43,720  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local160946667_0021_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10739046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=850919424
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:43,720  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local160946667_0021_m_000000_0
2024-05-01T09:41:43,721  INFO [Thread-841] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,764  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,764  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:43,765  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,766  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:43,766  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,766  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5aaccedc, with PersistenceManager: null will be shutdown
2024-05-01T09:41:43,766  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5aaccedc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32ee4936 created in the thread with id: 899
2024-05-01T09:41:43,767  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5aaccedc from thread id: 899
2024-05-01T09:41:43,767  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:43,768  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:43,768  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:43,768  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5aaccedc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32ee4936 will be shutdown
2024-05-01T09:41:43,768  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:43,768  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -80
2024-05-01T09:41:43,768  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:43,769  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:43,769  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e9fef13, with PersistenceManager: null will be shutdown
2024-05-01T09:41:43,769  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e9fef13, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3018970e created in the thread with id: 899
2024-05-01T09:41:43,770  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e9fef13 from thread id: 899
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,812  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,813  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T09:41:43,835  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,4745303619341319/part1=p1value1/part0=501].
2024-05-01T09:41:43,835  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:43,873  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:43,874  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:43,874  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:43,874  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:43,874  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:43,875  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e9fef13, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3018970e will be shutdown
2024-05-01T09:41:43,875  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e9fef13, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22e73752 created in the thread with id: 899
2024-05-01T09:41:43,876  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:43,876  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:43,876  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:43,877  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e9fef13, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22e73752 will be shutdown
2024-05-01T09:41:43,877  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:43,877  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -81
2024-05-01T09:41:43,877  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:43,877  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:43,878  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9669, with PersistenceManager: null will be shutdown
2024-05-01T09:41:43,878  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9669, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@165fb354 created in the thread with id: 899
2024-05-01T09:41:43,879  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bb9669 from thread id: 899
2024-05-01T09:41:43,880  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:43,880  WARN [Thread-841] mapred.LocalJobRunner: job_local160946667_0021
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,4745303619341319/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:44,647  INFO [main] mapreduce.Job: Job job_local160946667_0021 running in uber mode : false
2024-05-01T09:41:44,648  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:44,648  INFO [main] mapreduce.Job: Job job_local160946667_0021 failed with state FAILED due to: NA
2024-05-01T09:41:44,649  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10739046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=850919424
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:44,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:44,693  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:44,693  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:44,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:44,693  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:44,694  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:44,694  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:44,694  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:44,694  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:44,694  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:44,694  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:44,694  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:44,695  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:44,696  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:44,697  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:44,697  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac7927a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25bfc558 will be shutdown
2024-05-01T09:41:44,697  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac7927a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@297bbd41 created in the thread with id: 1
2024-05-01T09:41:44,699  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:44,699  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:44,699  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:44,699  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac7927a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@297bbd41 will be shutdown
2024-05-01T09:41:44,699  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:44,699  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -82
2024-05-01T09:41:44,699  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:44,700  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:44,700  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: null will be shutdown
2024-05-01T09:41:44,700  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@472d7f34 created in the thread with id: 1
2024-05-01T09:41:44,702  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6 from thread id: 1
2024-05-01T09:41:44,703  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:44,708  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:44,714  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:44,747  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:44,748  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:44,748  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:44,748  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:44,749  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:44,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@472d7f34 will be shutdown
2024-05-01T09:41:44,749  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16263fb2 created in the thread with id: 1
2024-05-01T09:41:44,750  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:44,750  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:44,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:44,751  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16263fb2 will be shutdown
2024-05-01T09:41:44,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:44,751  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -83
2024-05-01T09:41:44,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:44,752  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:44,752  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: null will be shutdown
2024-05-01T09:41:44,752  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62857555 created in the thread with id: 1
2024-05-01T09:41:44,753  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc from thread id: 1
2024-05-01T09:41:44,754  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T09:41:44,765  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:44,770  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:44,771  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:44,791  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:44,807  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local723023237_0022
2024-05-01T09:41:44,807  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:44,855  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:44,855  INFO [main] mapreduce.Job: Running job: job_local723023237_0022
2024-05-01T09:41:44,855  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:44,857  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,857  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,858  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:44,859  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,859  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,872  INFO [Thread-887] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:44,872  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local723023237_0022_m_000000_0
2024-05-01T09:41:44,874  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,874  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,875  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,875  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,875  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:44,876  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:44,877  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,877  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,891  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:44,891  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local723023237_0022_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:44,891  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,891  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,895  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:44,895  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local723023237_0022_m_000000_0 is allowed to commit now
2024-05-01T09:41:44,895  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:44,895  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:44,905  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local723023237_0022_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7804158913531887/part1=p1value2/part0=502
2024-05-01T09:41:44,905  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:44,905  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local723023237_0022_m_000000_0' done.
2024-05-01T09:41:44,905  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local723023237_0022_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11249611
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=850919424
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:44,905  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local723023237_0022_m_000000_0
2024-05-01T09:41:44,906  INFO [Thread-887] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:44,954  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:44,954  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:44,954  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:44,954  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:44,955  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:44,955  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:44,956  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:44,956  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:44,956  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:44,956  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31861fbd, with PersistenceManager: null will be shutdown
2024-05-01T09:41:44,957  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31861fbd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25a0efaf created in the thread with id: 947
2024-05-01T09:41:44,958  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31861fbd from thread id: 947
2024-05-01T09:41:44,958  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:44,958  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:44,958  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:44,958  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31861fbd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25a0efaf will be shutdown
2024-05-01T09:41:44,959  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:44,959  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -84
2024-05-01T09:41:44,959  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:44,959  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:44,960  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@288d483d, with PersistenceManager: null will be shutdown
2024-05-01T09:41:44,960  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@288d483d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@771e5ad9 created in the thread with id: 947
2024-05-01T09:41:44,961  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@288d483d from thread id: 947
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:45,004  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:45,004  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:45,026  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7804158913531887/part1=p1value2/part0=502].
2024-05-01T09:41:45,027  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:45,065  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:45,065  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:45,066  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:45,066  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:45,066  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@288d483d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@771e5ad9 will be shutdown
2024-05-01T09:41:45,066  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@288d483d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@277c5b3f created in the thread with id: 947
2024-05-01T09:41:45,068  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:45,068  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:45,068  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:45,068  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@288d483d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@277c5b3f will be shutdown
2024-05-01T09:41:45,068  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:45,068  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -85
2024-05-01T09:41:45,068  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:45,069  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:45,069  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6aa418b9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:45,069  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6aa418b9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3209cb7c created in the thread with id: 947
2024-05-01T09:41:45,070  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6aa418b9 from thread id: 947
2024-05-01T09:41:45,071  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:45,071  WARN [Thread-887] mapred.LocalJobRunner: job_local723023237_0022
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7804158913531887/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:45,856  INFO [main] mapreduce.Job: Job job_local723023237_0022 running in uber mode : false
2024-05-01T09:41:45,856  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:45,856  INFO [main] mapreduce.Job: Job job_local723023237_0022 failed with state FAILED due to: NA
2024-05-01T09:41:45,857  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11249611
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=850919424
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:45,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:45,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:45,901  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:45,902  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:45,902  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:45,903  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:45,904  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:45,904  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:45,905  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62857555 will be shutdown
2024-05-01T09:41:45,905  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ac9742e created in the thread with id: 1
2024-05-01T09:41:45,906  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:45,906  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:45,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:45,907  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ac9742e will be shutdown
2024-05-01T09:41:45,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:45,907  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -86
2024-05-01T09:41:45,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:45,907  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:45,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:45,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14ca4b4d created in the thread with id: 1
2024-05-01T09:41:45,909  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b from thread id: 1
2024-05-01T09:41:45,910  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:45,914  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:45,920  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:45,959  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:45,960  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:45,960  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:45,960  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14ca4b4d will be shutdown
2024-05-01T09:41:45,960  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73611fbb created in the thread with id: 1
2024-05-01T09:41:45,962  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:45,962  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:45,962  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:45,962  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73611fbb will be shutdown
2024-05-01T09:41:45,962  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:45,962  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -87
2024-05-01T09:41:45,962  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:45,963  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:45,963  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: null will be shutdown
2024-05-01T09:41:45,963  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c61011b created in the thread with id: 1
2024-05-01T09:41:45,965  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2 from thread id: 1
2024-05-01T09:41:45,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T09:41:45,977  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:45,982  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:45,983  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:46,003  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:46,018  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1060396445_0023
2024-05-01T09:41:46,018  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:46,067  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:46,067  INFO [main] mapreduce.Job: Running job: job_local1060396445_0023
2024-05-01T09:41:46,068  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:46,069  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,069  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,070  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:46,070  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,070  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,084  INFO [Thread-933] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:46,084  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1060396445_0023_m_000000_0
2024-05-01T09:41:46,086  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,086  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,087  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,087  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,087  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:46,087  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:46,089  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,089  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,103  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:46,104  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1060396445_0023_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:46,104  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,104  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,107  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:46,107  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1060396445_0023_m_000000_0 is allowed to commit now
2024-05-01T09:41:46,107  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:46,107  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:46,118  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1060396445_0023_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,27440124745467187/part1=p1value2/part0=502
2024-05-01T09:41:46,118  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:46,118  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1060396445_0023_m_000000_0' done.
2024-05-01T09:41:46,118  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1060396445_0023_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11762571
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=850919424
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:46,118  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1060396445_0023_m_000000_0
2024-05-01T09:41:46,118  INFO [Thread-933] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:46,164  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:46,165  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:46,165  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:46,165  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:46,165  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:46,165  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:46,165  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:46,166  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:46,166  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:46,166  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2eb7553a, with PersistenceManager: null will be shutdown
2024-05-01T09:41:46,166  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2eb7553a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e5e7c27 created in the thread with id: 995
2024-05-01T09:41:46,167  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2eb7553a from thread id: 995
2024-05-01T09:41:46,168  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:46,168  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:46,168  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:46,168  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2eb7553a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e5e7c27 will be shutdown
2024-05-01T09:41:46,168  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:46,168  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -88
2024-05-01T09:41:46,168  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:46,169  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:46,169  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105f4c20, with PersistenceManager: null will be shutdown
2024-05-01T09:41:46,169  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105f4c20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f74630 created in the thread with id: 995
2024-05-01T09:41:46,170  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105f4c20 from thread id: 995
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:46,212  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:46,213  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:46,235  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,27440124745467187/part1=p1value2/part0=502].
2024-05-01T09:41:46,235  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:46,285  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:46,285  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:46,286  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:46,286  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:46,286  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105f4c20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f74630 will be shutdown
2024-05-01T09:41:46,287  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105f4c20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4373d9cd created in the thread with id: 995
2024-05-01T09:41:46,288  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:46,288  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:46,288  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:46,288  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@105f4c20, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4373d9cd will be shutdown
2024-05-01T09:41:46,288  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:46,288  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -89
2024-05-01T09:41:46,288  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:46,289  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:46,289  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@700f1fbe, with PersistenceManager: null will be shutdown
2024-05-01T09:41:46,290  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@700f1fbe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67f9b45f created in the thread with id: 995
2024-05-01T09:41:46,291  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@700f1fbe from thread id: 995
2024-05-01T09:41:46,292  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:46,292  WARN [Thread-933] mapred.LocalJobRunner: job_local1060396445_0023
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,27440124745467187/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:46,648  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T09:41:47,068  INFO [main] mapreduce.Job: Job job_local1060396445_0023 running in uber mode : false
2024-05-01T09:41:47,068  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:47,068  INFO [main] mapreduce.Job: Job job_local1060396445_0023 failed with state FAILED due to: NA
2024-05-01T09:41:47,069  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11762571
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=850919424
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:47,118  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:47,118  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:47,118  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:47,118  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:47,118  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:47,118  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:47,119  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:47,119  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:47,119  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:47,119  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:47,119  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:47,119  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:47,120  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:47,122  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:47,122  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:47,122  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c61011b will be shutdown
2024-05-01T09:41:47,122  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78ba0a57 created in the thread with id: 1
2024-05-01T09:41:47,124  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:47,124  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:47,124  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:47,124  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78ba0a57 will be shutdown
2024-05-01T09:41:47,125  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:47,125  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -90
2024-05-01T09:41:47,125  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:47,125  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,126  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,126  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eef8498 created in the thread with id: 1
2024-05-01T09:41:47,127  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325 from thread id: 1
2024-05-01T09:41:47,129  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:47,135  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:47,142  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:47,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:47,180  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:47,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:47,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:47,181  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:47,181  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:47,182  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:47,182  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:47,182  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eef8498 will be shutdown
2024-05-01T09:41:47,182  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cb3c9e6 created in the thread with id: 1
2024-05-01T09:41:47,184  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:47,184  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:47,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:47,185  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cb3c9e6 will be shutdown
2024-05-01T09:41:47,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:47,185  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -91
2024-05-01T09:41:47,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:47,186  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,186  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,186  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@165634aa created in the thread with id: 1
2024-05-01T09:41:47,187  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04 from thread id: 1
2024-05-01T09:41:47,232  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:47,233  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:47,233  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:47,234  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:47,235  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:47,235  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:47,235  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@165634aa will be shutdown
2024-05-01T09:41:47,235  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e92f150 created in the thread with id: 1
2024-05-01T09:41:47,237  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:47,237  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:47,237  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:47,238  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e92f150 will be shutdown
2024-05-01T09:41:47,238  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:47,238  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -92
2024-05-01T09:41:47,238  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:47,239  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,239  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,239  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fa35f7e created in the thread with id: 1
2024-05-01T09:41:47,240  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777 from thread id: 1
2024-05-01T09:41:47,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:47,247  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:47,292  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:47,292  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:47,293  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:47,295  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:47,295  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:47,295  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fa35f7e will be shutdown
2024-05-01T09:41:47,295  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71b01319 created in the thread with id: 1
2024-05-01T09:41:47,297  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:47,297  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:47,297  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:47,297  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71b01319 will be shutdown
2024-05-01T09:41:47,297  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:47,297  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -93
2024-05-01T09:41:47,297  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:47,298  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,298  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,299  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ea3b20d created in the thread with id: 1
2024-05-01T09:41:47,300  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e from thread id: 1
2024-05-01T09:41:47,301  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:47,307  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:47,313  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:47,346  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:47,347  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:47,347  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:47,347  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:47,348  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:47,348  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:47,348  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ea3b20d will be shutdown
2024-05-01T09:41:47,348  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c581e65 created in the thread with id: 1
2024-05-01T09:41:47,350  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:47,350  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:47,350  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:47,350  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c581e65 will be shutdown
2024-05-01T09:41:47,350  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:47,350  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -94
2024-05-01T09:41:47,350  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:47,351  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,351  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,352  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@445265b0 created in the thread with id: 1
2024-05-01T09:41:47,353  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04 from thread id: 1
2024-05-01T09:41:47,360  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:47,365  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:47,366  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:47,390  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:47,405  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1221029434_0024
2024-05-01T09:41:47,406  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:47,458  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:47,458  INFO [main] mapreduce.Job: Running job: job_local1221029434_0024
2024-05-01T09:41:47,458  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:47,460  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:47,461  INFO [Thread-984] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:47,461  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1221029434_0024_m_000000_0
2024-05-01T09:41:47,464  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:47,464  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T09:41:47,469  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1221029434_0024_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.15874379055213084/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T09:41:47,469  INFO [Thread-984] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:47,471  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.15874379055213084].
2024-05-01T09:41:47,471  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:47,510  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:47,511  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:47,511  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:47,511  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:47,511  INFO [Thread-984] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:47,511  INFO [Thread-984] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:47,512  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,512  INFO [Thread-984] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:47,512  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4da607f9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,512  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4da607f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fdbe26f created in the thread with id: 1048
2024-05-01T09:41:47,514  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4da607f9 from thread id: 1048
2024-05-01T09:41:47,514  INFO [Thread-984] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:47,514  INFO [Thread-984] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:47,514  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:47,514  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4da607f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fdbe26f will be shutdown
2024-05-01T09:41:47,514  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:47,514  INFO [Thread-984] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -95
2024-05-01T09:41:47,514  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:47,515  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:47,515  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5df6a920, with PersistenceManager: null will be shutdown
2024-05-01T09:41:47,515  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5df6a920, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21dc67a1 created in the thread with id: 1048
2024-05-01T09:41:47,516  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5df6a920 from thread id: 1048
2024-05-01T09:41:47,518  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:47,518  WARN [Thread-984] mapred.LocalJobRunner: job_local1221029434_0024
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T09:41:48,458  INFO [main] mapreduce.Job: Job job_local1221029434_0024 running in uber mode : false
2024-05-01T09:41:48,458  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:48,459  INFO [main] mapreduce.Job: Job job_local1221029434_0024 failed with state FAILED due to: NA
2024-05-01T09:41:48,459  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:48,508  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:48,509  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:48,510  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:48,511  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:48,511  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@445265b0 will be shutdown
2024-05-01T09:41:48,511  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70c6860 created in the thread with id: 1
2024-05-01T09:41:48,512  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:48,512  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:48,513  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:48,513  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70c6860 will be shutdown
2024-05-01T09:41:48,513  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:48,513  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -96
2024-05-01T09:41:48,513  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:48,514  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:48,514  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: null will be shutdown
2024-05-01T09:41:48,514  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cae7d5 created in the thread with id: 1
2024-05-01T09:41:48,515  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816 from thread id: 1
2024-05-01T09:41:48,516  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:48,521  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:48,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:48,525  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:48,531  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:48,536  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:48,557  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T09:41:48,573  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local589114491_0025
2024-05-01T09:41:48,573  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:48,624  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:48,624  INFO [main] mapreduce.Job: Running job: job_local589114491_0025
2024-05-01T09:41:48,624  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:48,625  INFO [Thread-1004] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:48,625  INFO [Thread-1004] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:48,625  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T09:41:48,633  INFO [Thread-1004] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:48,633  INFO [Thread-1004] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:49,625  INFO [main] mapreduce.Job: Job job_local589114491_0025 running in uber mode : false
2024-05-01T09:41:49,625  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:49,625  INFO [main] mapreduce.Job: Job job_local589114491_0025 completed successfully
2024-05-01T09:41:49,625  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:49,625  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:49,632  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:49,632  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:49,691  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[7]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.32">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:49,736  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:49,737  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:49,737  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:49,738  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cae7d5 will be shutdown
2024-05-01T09:41:49,738  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fdb338e created in the thread with id: 1
2024-05-01T09:41:49,739  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = e7f421c0-713a-4a9b-aba7-fe2376027a6c
2024-05-01T09:41:49,739  INFO [main] SessionState: Hive Session ID = e7f421c0-713a-4a9b-aba7-fe2376027a6c
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:49,740  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T09:41:49,746  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/e7f421c0-713a-4a9b-aba7-fe2376027a6c
2024-05-01T09:41:49,749  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/e7f421c0-713a-4a9b-aba7-fe2376027a6c
2024-05-01T09:41:49,751  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/e7f421c0-713a-4a9b-aba7-fe2376027a6c/_tmp_space.db
2024-05-01T09:41:49,752  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:49,753  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_rcfile_columnar, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_rcfile_columnar, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T09:41:49,755  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar
2024-05-01T09:41:49,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:49,818  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:49,818  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:49,819  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:49,821  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:49,821  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:49,821  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fdb338e will be shutdown
2024-05-01T09:41:49,821  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@51a4472d created in the thread with id: 1
2024-05-01T09:41:49,824  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:49,824  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:49,824  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:49,824  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16bed816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@51a4472d will be shutdown
2024-05-01T09:41:49,824  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:49,824  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -97
2024-05-01T09:41:49,824  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:49,825  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:49,825  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: null will be shutdown
2024-05-01T09:41:49,826  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d91e9c9 created in the thread with id: 1
2024-05-01T09:41:49,827  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b from thread id: 1
2024-05-01T09:41:49,828  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:49,835  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:49,841  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:49,877  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:49,878  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:49,878  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:49,879  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:49,879  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:49,879  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d91e9c9 will be shutdown
2024-05-01T09:41:49,879  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16d4757f created in the thread with id: 1
2024-05-01T09:41:49,881  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:49,881  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:49,881  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:49,881  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16d4757f will be shutdown
2024-05-01T09:41:49,881  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:49,881  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -98
2024-05-01T09:41:49,881  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:49,882  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:49,882  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d170dac, with PersistenceManager: null will be shutdown
2024-05-01T09:41:49,882  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d170dac, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@139e291e created in the thread with id: 1
2024-05-01T09:41:49,884  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d170dac from thread id: 1
2024-05-01T09:41:49,885  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value1,501]	
2024-05-01T09:41:49,896  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:49,901  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:49,902  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:49,922  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:49,937  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local128146104_0026
2024-05-01T09:41:49,937  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:49,986  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:49,986  INFO [main] mapreduce.Job: Running job: job_local128146104_0026
2024-05-01T09:41:49,987  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:49,989  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:49,989  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:49,990  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:49,990  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:49,990  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:50,004  INFO [Thread-1038] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:50,004  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local128146104_0026_m_000000_0
2024-05-01T09:41:50,008  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:50,008  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:50,009  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:50,009  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:50,009  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:50,010  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T09:41:50,018  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:50,018  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:50,032  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:50,032  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T09:41:50,032  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T09:41:50,035  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local128146104_0026_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:50,035  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:50,035  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:50,039  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:50,039  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local128146104_0026_m_000000_0 is allowed to commit now
2024-05-01T09:41:50,039  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:50,040  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:50,049  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local128146104_0026_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,2489356989502799/part1=p1value1/part0=501
2024-05-01T09:41:50,050  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:50,050  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local128146104_0026_m_000000_0' done.
2024-05-01T09:41:50,050  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local128146104_0026_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13294111
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=900726784
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:50,050  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local128146104_0026_m_000000_0
2024-05-01T09:41:50,050  INFO [Thread-1038] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:50,094  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:50,095  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:50,095  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:50,096  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:50,096  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:50,096  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:50,097  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6cc42d, with PersistenceManager: null will be shutdown
2024-05-01T09:41:50,097  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6cc42d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4089348f created in the thread with id: 1104
2024-05-01T09:41:50,098  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6cc42d from thread id: 1104
2024-05-01T09:41:50,098  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:50,098  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:50,098  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:50,098  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6cc42d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4089348f will be shutdown
2024-05-01T09:41:50,098  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:50,099  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -99
2024-05-01T09:41:50,099  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:50,099  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:50,100  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59b8e11e, with PersistenceManager: null will be shutdown
2024-05-01T09:41:50,100  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59b8e11e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21504e9a created in the thread with id: 1104
2024-05-01T09:41:50,101  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59b8e11e from thread id: 1104
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:50,143  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:50,144  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=501, part1=p1value1}].
2024-05-01T09:41:50,165  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,2489356989502799/part1=p1value1/part0=501].
2024-05-01T09:41:50,166  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:50,204  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:50,204  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:50,205  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:50,205  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:50,206  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:50,206  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:50,206  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59b8e11e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21504e9a will be shutdown
2024-05-01T09:41:50,206  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59b8e11e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@760c9263 created in the thread with id: 1104
2024-05-01T09:41:50,207  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:50,208  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:50,208  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:50,208  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59b8e11e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@760c9263 will be shutdown
2024-05-01T09:41:50,208  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:50,208  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -100
2024-05-01T09:41:50,208  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:50,209  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:50,209  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d6bb528, with PersistenceManager: null will be shutdown
2024-05-01T09:41:50,209  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d6bb528, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54a2300 created in the thread with id: 1104
2024-05-01T09:41:50,210  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d6bb528 from thread id: 1104
2024-05-01T09:41:50,211  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:50,211  WARN [Thread-1038] mapred.LocalJobRunner: job_local128146104_0026
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,2489356989502799/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:50,987  INFO [main] mapreduce.Job: Job job_local128146104_0026 running in uber mode : false
2024-05-01T09:41:50,987  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:50,987  INFO [main] mapreduce.Job: Job job_local128146104_0026 failed with state FAILED due to: NA
2024-05-01T09:41:50,988  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13294111
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=900726784
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:51,033  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:51,033  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:51,034  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:51,035  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:51,035  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:51,035  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d170dac, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@139e291e will be shutdown
2024-05-01T09:41:51,036  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d170dac, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1088b120 created in the thread with id: 1
2024-05-01T09:41:51,037  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:51,037  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:51,037  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:51,037  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d170dac, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1088b120 will be shutdown
2024-05-01T09:41:51,037  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:51,038  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -101
2024-05-01T09:41:51,038  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:51,038  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:51,039  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78131a47, with PersistenceManager: null will be shutdown
2024-05-01T09:41:51,039  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78131a47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5869f15f created in the thread with id: 1
2024-05-01T09:41:51,040  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78131a47 from thread id: 1
2024-05-01T09:41:51,041  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:51,045  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:51,051  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:51,084  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:51,085  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:51,085  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:51,085  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:51,085  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78131a47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5869f15f will be shutdown
2024-05-01T09:41:51,086  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78131a47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60ee1a29 created in the thread with id: 1
2024-05-01T09:41:51,087  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:51,087  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:51,087  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:51,087  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@78131a47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60ee1a29 will be shutdown
2024-05-01T09:41:51,087  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:51,087  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -102
2024-05-01T09:41:51,088  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:51,088  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:51,088  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c02f50, with PersistenceManager: null will be shutdown
2024-05-01T09:41:51,089  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c02f50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35852b6 created in the thread with id: 1
2024-05-01T09:41:51,090  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c02f50 from thread id: 1
2024-05-01T09:41:51,091  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T09:41:51,101  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:51,106  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:51,107  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:51,126  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:51,141  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local535271393_0027
2024-05-01T09:41:51,141  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:51,191  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:51,191  INFO [main] mapreduce.Job: Running job: job_local535271393_0027
2024-05-01T09:41:51,191  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:51,192  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,192  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,193  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:51,194  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,194  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,207  INFO [Thread-1084] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:51,207  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local535271393_0027_m_000000_0
2024-05-01T09:41:51,209  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,209  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,210  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,210  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,210  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:51,211  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:51,212  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,212  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,225  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:51,225  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T09:41:51,225  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T09:41:51,226  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local535271393_0027_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:51,226  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,226  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,229  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:51,230  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local535271393_0027_m_000000_0 is allowed to commit now
2024-05-01T09:41:51,230  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:51,230  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:51,240  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local535271393_0027_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9339037014978213/part1=p1value2/part0=502
2024-05-01T09:41:51,240  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:51,240  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local535271393_0027_m_000000_0' done.
2024-05-01T09:41:51,240  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local535271393_0027_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13805023
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=900726784
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:51,240  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local535271393_0027_m_000000_0
2024-05-01T09:41:51,240  INFO [Thread-1084] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:51,284  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:51,284  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:51,284  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:51,284  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:51,284  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:51,284  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:51,285  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:51,285  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:51,285  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:51,285  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:51,285  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:51,285  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:51,285  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:51,286  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:51,286  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:51,286  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d45fd80, with PersistenceManager: null will be shutdown
2024-05-01T09:41:51,286  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d45fd80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@134b1000 created in the thread with id: 1152
2024-05-01T09:41:51,288  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d45fd80 from thread id: 1152
2024-05-01T09:41:51,288  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:51,288  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:51,288  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:51,288  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d45fd80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@134b1000 will be shutdown
2024-05-01T09:41:51,288  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:51,288  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -103
2024-05-01T09:41:51,288  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:51,289  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:51,289  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d045a2e, with PersistenceManager: null will be shutdown
2024-05-01T09:41:51,289  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d045a2e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17a1d410 created in the thread with id: 1152
2024-05-01T09:41:51,291  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d045a2e from thread id: 1152
2024-05-01T09:41:51,332  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:51,332  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:51,332  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:51,332  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:51,332  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:51,332  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:51,333  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:51,333  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:51,333  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:51,333  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:51,333  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:51,333  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:51,354  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9339037014978213/part1=p1value2/part0=502].
2024-05-01T09:41:51,355  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:51,393  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:51,393  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:51,394  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:51,394  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:51,394  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d045a2e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17a1d410 will be shutdown
2024-05-01T09:41:51,395  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d045a2e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@552256f7 created in the thread with id: 1152
2024-05-01T09:41:51,396  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:51,396  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:51,396  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:51,396  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d045a2e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@552256f7 will be shutdown
2024-05-01T09:41:51,396  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:51,396  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -104
2024-05-01T09:41:51,396  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:51,397  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:51,397  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@267eea80, with PersistenceManager: null will be shutdown
2024-05-01T09:41:51,397  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@267eea80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d0bf746 created in the thread with id: 1152
2024-05-01T09:41:51,399  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@267eea80 from thread id: 1152
2024-05-01T09:41:51,400  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:51,400  WARN [Thread-1084] mapred.LocalJobRunner: job_local535271393_0027
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9339037014978213/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:52,191  INFO [main] mapreduce.Job: Job job_local535271393_0027 running in uber mode : false
2024-05-01T09:41:52,191  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:52,192  INFO [main] mapreduce.Job: Job job_local535271393_0027 failed with state FAILED due to: NA
2024-05-01T09:41:52,192  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13805023
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=900726784
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:52,237  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:52,237  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:52,238  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:52,239  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:52,239  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:52,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c02f50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35852b6 will be shutdown
2024-05-01T09:41:52,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c02f50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1dd17c0c created in the thread with id: 1
2024-05-01T09:41:52,242  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:52,242  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:52,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:52,242  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c02f50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1dd17c0c will be shutdown
2024-05-01T09:41:52,243  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:52,243  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -105
2024-05-01T09:41:52,243  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:52,243  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:52,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@470ce6e7, with PersistenceManager: null will be shutdown
2024-05-01T09:41:52,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@470ce6e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39a8905b created in the thread with id: 1
2024-05-01T09:41:52,245  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@470ce6e7 from thread id: 1
2024-05-01T09:41:52,246  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:52,250  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:52,255  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:52,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:52,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:52,288  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:52,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:52,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:52,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:52,289  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:52,289  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:52,289  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:52,289  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:52,289  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:52,289  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:52,290  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:52,290  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:52,290  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@470ce6e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39a8905b will be shutdown
2024-05-01T09:41:52,290  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@470ce6e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d3a3738 created in the thread with id: 1
2024-05-01T09:41:52,291  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:52,292  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:52,292  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:52,292  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@470ce6e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d3a3738 will be shutdown
2024-05-01T09:41:52,292  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:52,292  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -106
2024-05-01T09:41:52,292  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:52,293  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:52,293  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@dd3d0a6, with PersistenceManager: null will be shutdown
2024-05-01T09:41:52,293  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@dd3d0a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5abfb698 created in the thread with id: 1
2024-05-01T09:41:52,294  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@dd3d0a6 from thread id: 1
2024-05-01T09:41:52,295  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T09:41:52,305  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:52,310  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:52,311  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:52,330  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:52,387  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1585754369_0028
2024-05-01T09:41:52,387  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:52,443  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:52,444  INFO [main] mapreduce.Job: Running job: job_local1585754369_0028
2024-05-01T09:41:52,444  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:52,445  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,445  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,446  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:52,447  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,447  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,460  INFO [Thread-1130] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:52,460  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1585754369_0028_m_000000_0
2024-05-01T09:41:52,462  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,462  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,463  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,463  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,463  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:52,463  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T09:41:52,465  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,465  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,478  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:52,478  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T09:41:52,478  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T09:41:52,478  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1585754369_0028_m_000000_0 is done. And is in the process of committing
2024-05-01T09:41:52,478  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,478  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,482  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T09:41:52,482  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1585754369_0028_m_000000_0 is allowed to commit now
2024-05-01T09:41:52,482  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:52,482  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:52,492  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1585754369_0028_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,04821077391930784/part1=p1value2/part0=502
2024-05-01T09:41:52,493  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T09:41:52,493  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1585754369_0028_m_000000_0' done.
2024-05-01T09:41:52,493  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1585754369_0028_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14318336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=902299648
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:52,493  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1585754369_0028_m_000000_0
2024-05-01T09:41:52,493  INFO [Thread-1130] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:52,545  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:52,545  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:52,546  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:52,546  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:52,547  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:52,547  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@253c5bb9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:52,547  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@253c5bb9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f4cce1a created in the thread with id: 1200
2024-05-01T09:41:52,548  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@253c5bb9 from thread id: 1200
2024-05-01T09:41:52,548  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:52,549  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:52,549  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:52,549  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@253c5bb9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f4cce1a will be shutdown
2024-05-01T09:41:52,549  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:52,549  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -107
2024-05-01T09:41:52,549  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:52,549  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:52,550  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3652e0c9, with PersistenceManager: null will be shutdown
2024-05-01T09:41:52,550  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3652e0c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@242768cd created in the thread with id: 1200
2024-05-01T09:41:52,551  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3652e0c9 from thread id: 1200
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:52,595  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:52,596  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T09:41:52,618  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,04821077391930784/part1=p1value2/part0=502].
2024-05-01T09:41:52,618  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:52,656  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:52,656  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:52,657  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:52,657  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:52,657  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3652e0c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@242768cd will be shutdown
2024-05-01T09:41:52,657  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3652e0c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e3eb0c6 created in the thread with id: 1200
2024-05-01T09:41:52,659  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:52,659  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:52,659  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:52,659  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3652e0c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e3eb0c6 will be shutdown
2024-05-01T09:41:52,659  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:52,659  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -108
2024-05-01T09:41:52,659  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:52,660  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:52,660  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62a1588c, with PersistenceManager: null will be shutdown
2024-05-01T09:41:52,660  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62a1588c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cac8a81 created in the thread with id: 1200
2024-05-01T09:41:52,661  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62a1588c from thread id: 1200
2024-05-01T09:41:52,662  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:52,662  WARN [Thread-1130] mapred.LocalJobRunner: job_local1585754369_0028
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,04821077391930784/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T09:41:52,986  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T09:41:53,444  INFO [main] mapreduce.Job: Job job_local1585754369_0028 running in uber mode : false
2024-05-01T09:41:53,444  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T09:41:53,444  INFO [main] mapreduce.Job: Job job_local1585754369_0028 failed with state FAILED due to: NA
2024-05-01T09:41:53,444  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14318336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=902299648
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:53,488  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:53,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:53,489  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:53,489  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:53,490  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:53,491  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:53,491  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:53,491  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@dd3d0a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5abfb698 will be shutdown
2024-05-01T09:41:53,491  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@dd3d0a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14021c10 created in the thread with id: 1
2024-05-01T09:41:53,493  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:53,493  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:53,493  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:53,493  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@dd3d0a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14021c10 will be shutdown
2024-05-01T09:41:53,493  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:53,493  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -109
2024-05-01T09:41:53,493  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:53,494  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,494  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,494  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5655d64 created in the thread with id: 1
2024-05-01T09:41:53,495  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289 from thread id: 1
2024-05-01T09:41:53,496  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:53,500  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:53,506  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:53,537  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:53,537  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:53,538  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:53,538  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:53,539  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5655d64 will be shutdown
2024-05-01T09:41:53,539  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b24fcba created in the thread with id: 1
2024-05-01T09:41:53,540  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:53,540  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:53,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:53,541  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b24fcba will be shutdown
2024-05-01T09:41:53,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:53,541  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -110
2024-05-01T09:41:53,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:53,542  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,542  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,542  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54353bb1 created in the thread with id: 1
2024-05-01T09:41:53,544  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2 from thread id: 1
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:53,591  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:53,591  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:53,592  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:53,594  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:53,594  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:53,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54353bb1 will be shutdown
2024-05-01T09:41:53,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2627da4c created in the thread with id: 1
2024-05-01T09:41:53,596  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:53,596  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:53,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:53,596  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2627da4c will be shutdown
2024-05-01T09:41:53,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:53,596  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -111
2024-05-01T09:41:53,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:53,597  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,597  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,597  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@228f15de created in the thread with id: 1
2024-05-01T09:41:53,598  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770 from thread id: 1
2024-05-01T09:41:53,599  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:53,603  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:53,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:53,647  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:53,647  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:53,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:53,647  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:53,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:53,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:53,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:53,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:53,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:53,648  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:53,648  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:53,648  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:53,650  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:53,650  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:53,650  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@228f15de will be shutdown
2024-05-01T09:41:53,650  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14c5d220 created in the thread with id: 1
2024-05-01T09:41:53,652  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:53,652  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:53,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:53,652  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14c5d220 will be shutdown
2024-05-01T09:41:53,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:53,652  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -112
2024-05-01T09:41:53,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:53,653  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ea4abef created in the thread with id: 1
2024-05-01T09:41:53,655  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3 from thread id: 1
2024-05-01T09:41:53,655  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:53,659  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:53,664  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:53,696  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:53,697  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:53,697  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:53,697  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:53,698  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ea4abef will be shutdown
2024-05-01T09:41:53,698  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@721e5f57 created in the thread with id: 1
2024-05-01T09:41:53,699  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:53,699  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:53,699  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:53,699  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@721e5f57 will be shutdown
2024-05-01T09:41:53,700  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:53,700  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -113
2024-05-01T09:41:53,700  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:53,700  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,701  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,701  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@bcf8bd7 created in the thread with id: 1
2024-05-01T09:41:53,702  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2 from thread id: 1
2024-05-01T09:41:53,708  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:53,713  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:53,714  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T09:41:53,733  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T09:41:53,748  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local102650500_0029
2024-05-01T09:41:53,748  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:53,799  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:53,799  INFO [main] mapreduce.Job: Running job: job_local102650500_0029
2024-05-01T09:41:53,800  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:53,802  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T09:41:53,803  INFO [Thread-1181] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:53,803  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local102650500_0029_m_000000_0
2024-05-01T09:41:53,805  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T09:41:53,805  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T09:41:53,809  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local102650500_0029_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.02505961111710331/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T09:41:53,809  INFO [Thread-1181] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:53,811  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.02505961111710331].
2024-05-01T09:41:53,811  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:53,848  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:53,848  INFO [Thread-1181] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T09:41:53,849  INFO [Thread-1181] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:53,849  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,849  INFO [Thread-1181] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:53,850  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216c9e98, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,850  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216c9e98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b5fca93 created in the thread with id: 1253
2024-05-01T09:41:53,851  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216c9e98 from thread id: 1253
2024-05-01T09:41:53,851  INFO [Thread-1181] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:53,851  INFO [Thread-1181] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:53,852  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:53,852  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@216c9e98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b5fca93 will be shutdown
2024-05-01T09:41:53,852  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:53,852  INFO [Thread-1181] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -114
2024-05-01T09:41:53,852  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:53,852  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:53,853  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@152b9c47, with PersistenceManager: null will be shutdown
2024-05-01T09:41:53,853  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@152b9c47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f3337d6 created in the thread with id: 1253
2024-05-01T09:41:53,854  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@152b9c47 from thread id: 1253
2024-05-01T09:41:53,855  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T09:41:53,855  WARN [Thread-1181] mapred.LocalJobRunner: job_local102650500_0029
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T09:41:54,800  INFO [main] mapreduce.Job: Job job_local102650500_0029 running in uber mode : false
2024-05-01T09:41:54,800  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:54,800  INFO [main] mapreduce.Job: Job job_local102650500_0029 failed with state FAILED due to: NA
2024-05-01T09:41:54,800  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:54,839  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:54,840  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:54,840  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:54,840  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:54,840  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T09:41:54,840  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T09:41:54,840  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T09:41:54,842  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T09:41:54,842  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T09:41:54,842  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@bcf8bd7 will be shutdown
2024-05-01T09:41:54,842  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@660dcd17 created in the thread with id: 1
2024-05-01T09:41:54,844  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T09:41:54,844  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T09:41:54,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T09:41:54,844  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@660dcd17 will be shutdown
2024-05-01T09:41:54,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T09:41:54,844  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -115
2024-05-01T09:41:54,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T09:41:54,845  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T09:41:54,845  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a5b8f77, with PersistenceManager: null will be shutdown
2024-05-01T09:41:54,845  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a5b8f77, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@385ff04e created in the thread with id: 1
2024-05-01T09:41:54,846  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a5b8f77 from thread id: 1
2024-05-01T09:41:54,847  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:54,851  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:54,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:54,856  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T09:41:54,862  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T09:41:54,867  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T09:41:54,888  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T09:41:54,904  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local369119729_0030
2024-05-01T09:41:54,904  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T09:41:54,954  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T09:41:54,954  INFO [main] mapreduce.Job: Running job: job_local369119729_0030
2024-05-01T09:41:54,954  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T09:41:54,954  INFO [Thread-1201] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T09:41:54,955  INFO [Thread-1201] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T09:41:54,955  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T09:41:54,963  INFO [Thread-1201] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T09:41:54,963  INFO [Thread-1201] mapred.LocalJobRunner: map task executor complete.
2024-05-01T09:41:55,954  INFO [main] mapreduce.Job: Job job_local369119729_0030 running in uber mode : false
2024-05-01T09:41:55,955  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T09:41:55,955  INFO [main] mapreduce.Job: Job job_local369119729_0030 completed successfully
2024-05-01T09:41:55,955  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T09:41:55,955  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:55,959  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T09:41:55,959  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T09:41:56,010  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T09:41:56,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T09:41:56,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T09:41:56,011  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
</testsuite>