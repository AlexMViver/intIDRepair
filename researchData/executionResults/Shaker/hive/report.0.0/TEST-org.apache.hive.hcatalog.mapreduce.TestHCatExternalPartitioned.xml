<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="46.46" tests="8" errors="0" skipped="2" failures="6">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter5334347772632942326.jar /home/alex/Repositories/hive/hcatalog/core/target/surefire 2024-05-01T00-40-33_663-jvmRun1 surefire7660654083579214734tmp surefire_9337957251576812153675tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/hcatalog/core/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter5334347772632942326.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/hcatalog/core/../../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/hcatalog/core/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/hcatalog/core/../../"/>
  </properties>
  <testcase name="testHCatPartitionedTable[0]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="7.881">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,101048 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@5aa9e4eb
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,026694 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 51822328
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-30T20:25:12.043-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/01-00:00:00.000, nextFileTime=2024/04/30-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/30-20:25:13.654, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/01-00:00:00.000, nextFileTime=2024/04/30-00:00:00.000, prevFileTime=2024/04/30-00:00:00.000, current=2024/04/30-20:25:13.655, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@488d1cd7
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@33d512c1
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1] started OK.
2024-04-30T20:25:13,859  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-30T20:25:13,962  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/core/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1714533913724/warehouse
2024-04-30T20:25:14,250  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-30T20:25:14,311  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:14,311  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:14,311  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:14,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:14,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:14,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:14,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:14,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:14,313  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:14,313  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:14,313  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:14,316  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=0 initial-capacity=50 maximum-capacity=50
2024-04-30T20:25:14,372  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:14,569  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:14,608  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:14,623  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-30T20:25:14,623  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-30T20:25:14,651  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-30T20:25:14,655  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-30T20:25:15,313  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-30T20:25:15,317  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-30T20:25:15,935  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-30T20:25:15,935  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: null will be shutdown
2024-04-30T20:25:15,964  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 created in the thread with id: 1
2024-04-30T20:25:18,248  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-30T20:25:18,248  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-30T20:25:18,248  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133 from thread id: 1
2024-04-30T20:25:18,849  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-30T20:25:18,890  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-30T20:25:18,927  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-30T20:25:18,929  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-30T20:25:19,057  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-30T20:25:19,064  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-30T20:25:19,066  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-30T20:25:19,069  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-30T20:25:19,096  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-30T20:25:19,099  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-30T20:25:19,101  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-30T20:25:19,101  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-30T20:25:19,104  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-30T20:25:19,107  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-30T20:25:19,109  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-30T20:25:19,109  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-30T20:25:19,116  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-30T20:25:19,117  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-30T20:25:19,118  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-30T20:25:19,121  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:19,264  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:19,292  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:19,292  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 will be shutdown
2024-04-30T20:25:19,292  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:19,292  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-30T20:25:19,293  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:19,295  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:19,296  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: null will be shutdown
2024-04-30T20:25:19,297  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 created in the thread with id: 1
2024-04-30T20:25:19,311  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff from thread id: 1
2024-04-30T20:25:19,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:19,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:19,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:19,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:19,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:19,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:19,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:19,414  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:19,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:19,414  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:19,414  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:19,446  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:19,446  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:19,447  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 will be shutdown
2024-04-30T20:25:19,448  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 created in the thread with id: 1
2024-04-30T20:25:19,452  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = c7f2c32c-1164-4a8f-b9b7-d99809a953cc
2024-04-30T20:25:19,460  INFO [main] SessionState: Hive Session ID = c7f2c32c-1164-4a8f-b9b7-d99809a953cc
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:19,474  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:19,530  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/c7f2c32c-1164-4a8f-b9b7-d99809a953cc
2024-04-30T20:25:19,534  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/c7f2c32c-1164-4a8f-b9b7-d99809a953cc
2024-04-30T20:25:19,537  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/c7f2c32c-1164-4a8f-b9b7-d99809a953cc/_tmp_space.db
2024-04-30T20:25:19,544  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:19,663  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_TEXTFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_TEXTFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-30T20:25:19,673  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile
2024-04-30T20:25:19,895  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:19,896  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:19,897  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:19,897  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:19,898  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:19,899  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:19,915  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:19,915  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:19,917  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 will be shutdown
2024-04-30T20:25:19,917  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d created in the thread with id: 1
2024-04-30T20:25:19,922  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:19,922  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:19,923  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:19,923  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d will be shutdown
2024-04-30T20:25:19,923  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:19,923  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-30T20:25:19,923  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:19,924  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:19,925  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: null will be shutdown
2024-04-30T20:25:19,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 created in the thread with id: 1
2024-04-30T20:25:19,929  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0 from thread id: 1
2024-04-30T20:25:19,934  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:19,988  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:20,165  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-30T20:25:20,179  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-30T20:25:20,193  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-30T20:25:20,193  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-30T20:25:20,248  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:20,248  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:20,248  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:20,248  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:20,248  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:20,248  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:20,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:20,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:20,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:20,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:20,249  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:20,249  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:20,251  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:20,252  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:20,252  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 will be shutdown
2024-04-30T20:25:20,252  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 created in the thread with id: 1
2024-04-30T20:25:20,257  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:20,258  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:20,258  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:20,258  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 will be shutdown
2024-04-30T20:25:20,258  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:20,258  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-30T20:25:20,258  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:20,260  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:20,261  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: null will be shutdown
2024-04-30T20:25:20,262  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb created in the thread with id: 1
2024-04-30T20:25:20,267  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933 from thread id: 1
2024-04-30T20:25:20,269  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value1,501]	
2024-04-30T20:25:20,337  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:20,347  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:20,379  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:20,440  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:20,478  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local584083415_0001
2024-04-30T20:25:20,478  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:20,590  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:20,591  INFO [main] mapreduce.Job: Running job: job_local584083415_0001
2024-04-30T20:25:20,592  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:20,609  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,609  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,616  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:20,623  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,623  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,644  INFO [Thread-43] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:20,645  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local584083415_0001_m_000000_0
2024-04-30T20:25:20,675  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,676  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,679  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,680  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,693  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:20,698  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-30T20:25:20,716  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,716  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,783  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:20,790  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local584083415_0001_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:20,790  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,790  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,796  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:20,796  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local584083415_0001_m_000000_0 is allowed to commit now
2024-04-30T20:25:20,796  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:20,796  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:20,809  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local584083415_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,8291795320316342/part1=p1value1/part0=501
2024-04-30T20:25:20,809  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:20,809  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local584083415_0001_m_000000_0' done.
2024-04-30T20:25:20,813  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local584083415_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=510105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=682622976
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:20,813  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local584083415_0001_m_000000_0
2024-04-30T20:25:20,814  INFO [Thread-43] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:20,873  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:20,873  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:20,873  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:20,873  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:20,873  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:20,873  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:20,874  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:20,874  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:20,874  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:20,874  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:20,874  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:20,880  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:20,881  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:20,882  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:20,882  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:20,883  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b303a0, with PersistenceManager: null will be shutdown
2024-04-30T20:25:20,883  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b303a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f692174 created in the thread with id: 69
2024-04-30T20:25:20,889  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b303a0 from thread id: 69
2024-04-30T20:25:20,889  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:20,890  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:20,890  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:20,890  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b303a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f692174 will be shutdown
2024-04-30T20:25:20,890  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:20,890  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-04-30T20:25:20,891  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:20,891  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:20,892  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13f91602, with PersistenceManager: null will be shutdown
2024-04-30T20:25:20,892  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13f91602, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d67d5f7 created in the thread with id: 69
2024-04-30T20:25:20,895  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13f91602 from thread id: 69
2024-04-30T20:25:20,947  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:20,948  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:20,949  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:20,949  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:20,949  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=501, part1=p1value1}].
2024-04-30T20:25:20,981  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,8291795320316342/part1=p1value1/part0=501].
2024-04-30T20:25:20,981  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:21,034  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:21,034  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:21,034  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:21,034  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:21,035  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:21,036  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:21,037  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:21,037  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:21,037  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13f91602, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d67d5f7 will be shutdown
2024-04-30T20:25:21,037  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13f91602, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@276aa720 created in the thread with id: 69
2024-04-30T20:25:21,042  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:21,042  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:21,042  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:21,042  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13f91602, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@276aa720 will be shutdown
2024-04-30T20:25:21,042  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:21,042  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-30T20:25:21,043  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:21,043  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:21,044  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@617d15de, with PersistenceManager: null will be shutdown
2024-04-30T20:25:21,044  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@617d15de, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@28e675d3 created in the thread with id: 69
2024-04-30T20:25:21,047  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@617d15de from thread id: 69
2024-04-30T20:25:21,049  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:21,049  WARN [Thread-43] mapred.LocalJobRunner: job_local584083415_0001
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,8291795320316342/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:21,597  INFO [main] mapreduce.Job: Job job_local584083415_0001 running in uber mode : false
2024-04-30T20:25:21,597  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:21,600  INFO [main] mapreduce.Job: Job job_local584083415_0001 failed with state FAILED due to: NA
2024-04-30T20:25:21,606  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=510105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=682622976
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:21,658  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:21,658  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:21,658  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:21,658  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:21,658  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:21,659  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:21,659  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:21,659  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:21,659  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:21,659  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:21,659  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:21,659  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:21,660  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:21,663  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:21,664  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:21,664  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb will be shutdown
2024-04-30T20:25:21,665  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bfc2f8b created in the thread with id: 1
2024-04-30T20:25:21,669  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:21,670  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:21,670  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:21,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bfc2f8b will be shutdown
2024-04-30T20:25:21,670  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:21,670  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-04-30T20:25:21,671  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:21,672  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:21,672  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: null will be shutdown
2024-04-30T20:25:21,673  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55c50f52 created in the thread with id: 1
2024-04-30T20:25:21,677  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8 from thread id: 1
2024-04-30T20:25:21,678  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:21,690  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:21,698  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:21,754  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:21,755  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:21,756  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:21,757  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:21,757  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:21,758  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55c50f52 will be shutdown
2024-04-30T20:25:21,758  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52d96367 created in the thread with id: 1
2024-04-30T20:25:21,763  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:21,763  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:21,764  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:21,764  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53cddaf8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52d96367 will be shutdown
2024-04-30T20:25:21,764  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:21,764  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-04-30T20:25:21,764  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:21,765  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:21,766  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: null will be shutdown
2024-04-30T20:25:21,766  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64bba0eb created in the thread with id: 1
2024-04-30T20:25:21,771  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5 from thread id: 1
2024-04-30T20:25:21,773  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-04-30T20:25:21,808  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:21,814  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:21,815  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:21,837  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:21,857  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local776274734_0002
2024-04-30T20:25:21,857  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:21,924  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:21,924  INFO [main] mapreduce.Job: Running job: job_local776274734_0002
2024-04-30T20:25:21,925  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:21,931  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,931  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,933  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:21,935  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,935  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,949  INFO [Thread-91] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:21,949  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local776274734_0002_m_000000_0
2024-04-30T20:25:21,954  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,954  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,957  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,957  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,957  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:21,958  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:21,964  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,964  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,981  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:21,981  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local776274734_0002_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:21,981  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,981  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,986  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:21,986  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local776274734_0002_m_000000_0 is allowed to commit now
2024-04-30T20:25:21,986  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:21,986  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:21,997  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local776274734_0002_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5378018684141268/part1=p1value2/part0=502
2024-04-30T20:25:21,998  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:21,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local776274734_0002_m_000000_0' done.
2024-04-30T20:25:21,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local776274734_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1020434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=682622976
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:21,998  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local776274734_0002_m_000000_0
2024-04-30T20:25:21,999  INFO [Thread-91] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:22,077  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:22,078  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:22,078  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:22,078  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:22,078  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:22,079  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:22,079  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:22,079  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:22,080  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2c692218, with PersistenceManager: null will be shutdown
2024-04-30T20:25:22,080  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2c692218, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49371383 created in the thread with id: 119
2024-04-30T20:25:22,085  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2c692218 from thread id: 119
2024-04-30T20:25:22,085  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:22,085  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:22,086  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:22,086  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2c692218, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49371383 will be shutdown
2024-04-30T20:25:22,086  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:22,086  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-04-30T20:25:22,086  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:22,087  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:22,087  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69c3a9d7, with PersistenceManager: null will be shutdown
2024-04-30T20:25:22,087  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69c3a9d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62d95f09 created in the thread with id: 119
2024-04-30T20:25:22,091  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69c3a9d7 from thread id: 119
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:22,140  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:22,141  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:22,164  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5378018684141268/part1=p1value2/part0=502].
2024-04-30T20:25:22,165  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:22,207  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:22,208  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:22,209  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:22,209  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:22,209  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69c3a9d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62d95f09 will be shutdown
2024-04-30T20:25:22,209  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69c3a9d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f719211 created in the thread with id: 119
2024-04-30T20:25:22,213  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:22,213  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:22,214  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:22,214  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69c3a9d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f719211 will be shutdown
2024-04-30T20:25:22,214  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:22,214  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -9
2024-04-30T20:25:22,214  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:22,215  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:22,215  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1facf40a, with PersistenceManager: null will be shutdown
2024-04-30T20:25:22,215  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1facf40a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19c8e173 created in the thread with id: 119
2024-04-30T20:25:22,218  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1facf40a from thread id: 119
2024-04-30T20:25:22,220  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:22,220  WARN [Thread-91] mapred.LocalJobRunner: job_local776274734_0002
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,5378018684141268/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:22,925  INFO [main] mapreduce.Job: Job job_local776274734_0002 running in uber mode : false
2024-04-30T20:25:22,925  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:22,925  INFO [main] mapreduce.Job: Job job_local776274734_0002 failed with state FAILED due to: NA
2024-04-30T20:25:22,927  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1020434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=682622976
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:22,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:22,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:22,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:22,975  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:22,976  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:22,976  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:22,979  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:22,979  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:22,979  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64bba0eb will be shutdown
2024-04-30T20:25:22,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c2ab536 created in the thread with id: 1
2024-04-30T20:25:22,984  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:22,985  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:22,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:22,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@632241f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c2ab536 will be shutdown
2024-04-30T20:25:22,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:22,985  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -10
2024-04-30T20:25:22,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:22,986  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:22,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: null will be shutdown
2024-04-30T20:25:22,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1805383 created in the thread with id: 1
2024-04-30T20:25:22,992  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300 from thread id: 1
2024-04-30T20:25:22,993  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:23,002  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:23,009  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:23,044  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:23,045  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:23,046  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:23,047  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:23,047  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:23,047  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1805383 will be shutdown
2024-04-30T20:25:23,048  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47eaf55c created in the thread with id: 1
2024-04-30T20:25:23,051  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:23,051  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:23,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:23,052  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47eaf55c will be shutdown
2024-04-30T20:25:23,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:23,052  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -11
2024-04-30T20:25:23,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:23,053  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:23,053  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: null will be shutdown
2024-04-30T20:25:23,053  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@333d44f6 created in the thread with id: 1
2024-04-30T20:25:23,056  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554 from thread id: 1
2024-04-30T20:25:23,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-04-30T20:25:23,076  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:23,082  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:23,083  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:23,105  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:23,121  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local801521960_0003
2024-04-30T20:25:23,121  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:23,174  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:23,174  INFO [main] mapreduce.Job: Running job: job_local801521960_0003
2024-04-30T20:25:23,175  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:23,177  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,177  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,178  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:23,180  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,180  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,193  INFO [Thread-137] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:23,193  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local801521960_0003_m_000000_0
2024-04-30T20:25:23,197  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,197  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,198  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,199  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,199  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:23,200  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:23,202  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,202  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,219  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:23,219  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local801521960_0003_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:23,219  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,219  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,224  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:23,224  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local801521960_0003_m_000000_0 is allowed to commit now
2024-04-30T20:25:23,224  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:23,224  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:23,235  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local801521960_0003_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9457992539685081/part1=p1value2/part0=502
2024-04-30T20:25:23,236  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:23,236  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local801521960_0003_m_000000_0' done.
2024-04-30T20:25:23,237  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local801521960_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1530763
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=688914432
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:23,237  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local801521960_0003_m_000000_0
2024-04-30T20:25:23,237  INFO [Thread-137] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:23,288  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:23,289  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:23,289  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:23,289  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:23,289  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:23,289  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:23,290  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:23,291  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:23,291  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:23,291  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63759297, with PersistenceManager: null will be shutdown
2024-04-30T20:25:23,291  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63759297, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1726c11b created in the thread with id: 167
2024-04-30T20:25:23,294  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63759297 from thread id: 167
2024-04-30T20:25:23,294  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:23,294  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:23,295  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:23,295  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63759297, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1726c11b will be shutdown
2024-04-30T20:25:23,295  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:23,295  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -12
2024-04-30T20:25:23,295  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:23,296  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:23,297  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50228f89, with PersistenceManager: null will be shutdown
2024-04-30T20:25:23,297  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50228f89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39254508 created in the thread with id: 167
2024-04-30T20:25:23,300  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50228f89 from thread id: 167
2024-04-30T20:25:23,346  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:23,347  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:23,348  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:23,373  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9457992539685081/part1=p1value2/part0=502].
2024-04-30T20:25:23,374  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:23,423  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:23,424  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:23,424  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:23,425  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:23,425  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:23,425  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50228f89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39254508 will be shutdown
2024-04-30T20:25:23,425  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50228f89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@314a22dc created in the thread with id: 167
2024-04-30T20:25:23,428  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:23,428  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:23,429  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:23,429  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50228f89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@314a22dc will be shutdown
2024-04-30T20:25:23,429  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:23,429  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -13
2024-04-30T20:25:23,429  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:23,430  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:23,431  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@586ce44b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:23,431  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@586ce44b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8347d6e created in the thread with id: 167
2024-04-30T20:25:23,434  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@586ce44b from thread id: 167
2024-04-30T20:25:23,436  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:23,436  WARN [Thread-137] mapred.LocalJobRunner: job_local801521960_0003
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9457992539685081/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:24,175  INFO [main] mapreduce.Job: Job job_local801521960_0003 running in uber mode : false
2024-04-30T20:25:24,175  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:24,176  INFO [main] mapreduce.Job: Job job_local801521960_0003 failed with state FAILED due to: NA
2024-04-30T20:25:24,177  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1530763
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=688914432
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:24,226  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:24,226  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:24,226  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:24,226  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:24,227  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:24,227  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:24,228  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:24,230  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:24,230  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:24,230  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@333d44f6 will be shutdown
2024-04-30T20:25:24,230  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@270f28cf created in the thread with id: 1
2024-04-30T20:25:24,233  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:24,233  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:24,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:24,234  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@270f28cf will be shutdown
2024-04-30T20:25:24,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:24,234  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -14
2024-04-30T20:25:24,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:24,235  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,235  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bbdb220 created in the thread with id: 1
2024-04-30T20:25:24,240  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130 from thread id: 1
2024-04-30T20:25:24,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:24,250  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:24,257  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:24,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:24,313  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:24,313  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:24,313  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:24,314  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:24,315  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:24,315  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bbdb220 will be shutdown
2024-04-30T20:25:24,316  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14e3d439 created in the thread with id: 1
2024-04-30T20:25:24,320  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:24,320  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:24,321  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:24,321  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d2fc130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14e3d439 will be shutdown
2024-04-30T20:25:24,321  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:24,321  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -15
2024-04-30T20:25:24,321  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:24,322  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,323  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,323  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fc1c7e created in the thread with id: 1
2024-04-30T20:25:24,326  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2 from thread id: 1
2024-04-30T20:25:24,386  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:24,386  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:24,387  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:24,388  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:24,388  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:24,389  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:24,391  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:24,391  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:24,391  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fc1c7e will be shutdown
2024-04-30T20:25:24,391  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68f776ee created in the thread with id: 1
2024-04-30T20:25:24,395  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:24,395  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:24,396  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:24,397  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@278de2b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68f776ee will be shutdown
2024-04-30T20:25:24,397  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:24,397  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -16
2024-04-30T20:25:24,398  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:24,398  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,399  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,399  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f471037 created in the thread with id: 1
2024-04-30T20:25:24,402  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b from thread id: 1
2024-04-30T20:25:24,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:24,414  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:24,462  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:24,462  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:24,463  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:24,464  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:24,465  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:24,467  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:24,467  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:24,468  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f471037 will be shutdown
2024-04-30T20:25:24,468  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15f519f7 created in the thread with id: 1
2024-04-30T20:25:24,471  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:24,472  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:24,472  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:24,472  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cc9bd9b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15f519f7 will be shutdown
2024-04-30T20:25:24,472  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:24,472  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -17
2024-04-30T20:25:24,473  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:24,474  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,474  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,474  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12f8682a created in the thread with id: 1
2024-04-30T20:25:24,478  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc from thread id: 1
2024-04-30T20:25:24,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:24,490  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:24,498  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:24,532  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:24,533  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:24,533  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:24,534  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:24,534  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12f8682a will be shutdown
2024-04-30T20:25:24,534  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a047bdb created in the thread with id: 1
2024-04-30T20:25:24,537  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:24,537  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:24,537  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:24,537  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ccd2bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a047bdb will be shutdown
2024-04-30T20:25:24,537  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:24,537  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -18
2024-04-30T20:25:24,537  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:24,538  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,538  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,539  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@334b392d created in the thread with id: 1
2024-04-30T20:25:24,541  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b from thread id: 1
2024-04-30T20:25:24,548  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:24,554  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:24,555  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:24,575  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:24,592  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2028194530_0004
2024-04-30T20:25:24,592  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:24,642  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:24,642  INFO [main] mapreduce.Job: Running job: job_local2028194530_0004
2024-04-30T20:25:24,643  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:24,646  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:24,647  INFO [Thread-188] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:24,647  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2028194530_0004_m_000000_0
2024-04-30T20:25:24,651  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:24,652  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-30T20:25:24,660  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local2028194530_0004_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.2758131484786005/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-30T20:25:24,660  INFO [Thread-188] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:24,665  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.2758131484786005].
2024-04-30T20:25:24,665  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:24,708  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:24,708  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:24,708  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:24,708  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:24,708  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:24,708  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:24,709  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:24,709  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:24,709  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:24,709  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:24,709  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:24,709  INFO [Thread-188] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:24,710  INFO [Thread-188] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:24,710  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,711  INFO [Thread-188] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:24,711  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40b9d23e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,711  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40b9d23e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44b9eeb1 created in the thread with id: 220
2024-04-30T20:25:24,713  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40b9d23e from thread id: 220
2024-04-30T20:25:24,713  INFO [Thread-188] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:24,714  INFO [Thread-188] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:24,714  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:24,714  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40b9d23e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44b9eeb1 will be shutdown
2024-04-30T20:25:24,714  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:24,714  INFO [Thread-188] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -19
2024-04-30T20:25:24,714  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:24,715  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:24,715  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bdb236f, with PersistenceManager: null will be shutdown
2024-04-30T20:25:24,715  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bdb236f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16a2cace created in the thread with id: 220
2024-04-30T20:25:24,717  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bdb236f from thread id: 220
2024-04-30T20:25:24,718  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:24,719  WARN [Thread-188] mapred.LocalJobRunner: job_local2028194530_0004
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-30T20:25:25,643  INFO [main] mapreduce.Job: Job job_local2028194530_0004 running in uber mode : false
2024-04-30T20:25:25,643  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:25,643  INFO [main] mapreduce.Job: Job job_local2028194530_0004 failed with state FAILED due to: NA
2024-04-30T20:25:25,643  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:25,684  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:25,685  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:25,686  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:25,686  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:25,686  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:25,686  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:25,687  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:25,688  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:25,689  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:25,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@334b392d will be shutdown
2024-04-30T20:25:25,689  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c0e4262 created in the thread with id: 1
2024-04-30T20:25:25,692  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:25,693  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:25,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:25,693  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@279c4e3b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c0e4262 will be shutdown
2024-04-30T20:25:25,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:25,693  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -20
2024-04-30T20:25:25,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:25,694  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:25,695  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: null will be shutdown
2024-04-30T20:25:25,695  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23df7fad created in the thread with id: 1
2024-04-30T20:25:25,697  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea from thread id: 1
2024-04-30T20:25:25,698  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:25,707  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:25,707  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:25,725  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:25,732  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:25,737  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:25,759  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-30T20:25:25,783  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local985288963_0005
2024-04-30T20:25:25,783  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:25,866  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:25,866  INFO [main] mapreduce.Job: Running job: job_local985288963_0005
2024-04-30T20:25:25,867  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:25,869  INFO [Thread-208] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:25,869  INFO [Thread-208] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:25,869  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-30T20:25:25,878  INFO [Thread-208] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:25,878  INFO [Thread-208] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:26,867  INFO [main] mapreduce.Job: Job job_local985288963_0005 running in uber mode : false
2024-04-30T20:25:26,867  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:26,867  INFO [main] mapreduce.Job: Job job_local985288963_0005 completed successfully
2024-04-30T20:25:26,867  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:26,868  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:26,876  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:26,876  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,194  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[1]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.6">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-30T20:25:27,248  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,248  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,248  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,249  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:27,252  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:27,252  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:27,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23df7fad will be shutdown
2024-04-30T20:25:27,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57b33c29 created in the thread with id: 1
2024-04-30T20:25:27,261  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = b2f43737-774f-40ba-a452-73159b76ec6e
2024-04-30T20:25:27,261  INFO [main] SessionState: Hive Session ID = b2f43737-774f-40ba-a452-73159b76ec6e
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:27,262  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:27,269  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/b2f43737-774f-40ba-a452-73159b76ec6e
2024-04-30T20:25:27,272  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/b2f43737-774f-40ba-a452-73159b76ec6e
2024-04-30T20:25:27,275  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/b2f43737-774f-40ba-a452-73159b76ec6e/_tmp_space.db
2024-04-30T20:25:27,275  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:27,286  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_SEQUENCEFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.mapred.SequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_SEQUENCEFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-30T20:25:27,290  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile
2024-04-30T20:25:27,387  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,387  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,387  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,387  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,387  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,387  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,388  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,388  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,388  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,388  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,388  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:27,388  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:27,389  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:27,391  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:27,391  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:27,391  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57b33c29 will be shutdown
2024-04-30T20:25:27,391  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cff5aa3 created in the thread with id: 1
2024-04-30T20:25:27,394  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:27,394  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:27,394  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:27,394  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@391d28ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cff5aa3 will be shutdown
2024-04-30T20:25:27,394  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:27,394  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -21
2024-04-30T20:25:27,395  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:27,395  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:27,396  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:27,396  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69bca406 created in the thread with id: 1
2024-04-30T20:25:27,398  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e from thread id: 1
2024-04-30T20:25:27,399  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:27,422  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:27,428  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:27,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,463  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,464  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:27,465  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:27,466  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:27,466  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:27,466  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69bca406 will be shutdown
2024-04-30T20:25:27,466  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e1a150c created in the thread with id: 1
2024-04-30T20:25:27,470  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:27,471  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:27,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:27,471  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e1a150c will be shutdown
2024-04-30T20:25:27,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:27,471  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -22
2024-04-30T20:25:27,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:27,472  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:27,473  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c910acd, with PersistenceManager: null will be shutdown
2024-04-30T20:25:27,473  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c910acd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@612ac38b created in the thread with id: 1
2024-04-30T20:25:27,475  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c910acd from thread id: 1
2024-04-30T20:25:27,476  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value1,501]	
2024-04-30T20:25:27,499  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:27,504  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:27,504  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:27,525  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:27,541  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local74946413_0006
2024-04-30T20:25:27,541  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:27,594  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:27,594  INFO [main] mapreduce.Job: Running job: job_local74946413_0006
2024-04-30T20:25:27,594  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:27,596  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,596  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,598  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:27,599  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,599  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,614  INFO [Thread-242] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:27,614  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local74946413_0006_m_000000_0
2024-04-30T20:25:27,620  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,620  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,622  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,622  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,622  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:27,622  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-30T20:25:27,629  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,629  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,658  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:27,662  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local74946413_0006_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:27,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,662  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,666  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:27,666  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local74946413_0006_m_000000_0 is allowed to commit now
2024-04-30T20:25:27,666  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:27,666  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:27,676  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local74946413_0006_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5720189163854348/part1=p1value1/part0=501
2024-04-30T20:25:27,677  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:27,677  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local74946413_0006_m_000000_0' done.
2024-04-30T20:25:27,677  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local74946413_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3059656
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=742391808
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:27,677  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local74946413_0006_m_000000_0
2024-04-30T20:25:27,678  INFO [Thread-242] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:27,722  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,722  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,722  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,722  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,722  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,723  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,723  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,723  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,723  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,723  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,723  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:27,723  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:27,724  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:27,725  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:27,725  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:27,725  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27cb5d1e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:27,725  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27cb5d1e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65495a6d created in the thread with id: 276
2024-04-30T20:25:27,728  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27cb5d1e from thread id: 276
2024-04-30T20:25:27,728  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:27,728  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:27,728  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:27,728  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27cb5d1e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65495a6d will be shutdown
2024-04-30T20:25:27,728  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:27,728  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -23
2024-04-30T20:25:27,729  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:27,729  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:27,730  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45a61081, with PersistenceManager: null will be shutdown
2024-04-30T20:25:27,730  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45a61081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f861a2d created in the thread with id: 276
2024-04-30T20:25:27,732  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45a61081 from thread id: 276
2024-04-30T20:25:27,774  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,774  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,775  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:27,775  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=501, part1=p1value1}].
2024-04-30T20:25:27,800  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5720189163854348/part1=p1value1/part0=501].
2024-04-30T20:25:27,800  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:27,858  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:27,858  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:27,858  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:27,859  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:27,859  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:27,860  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:27,860  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:27,861  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45a61081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f861a2d will be shutdown
2024-04-30T20:25:27,861  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45a61081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cfe6977 created in the thread with id: 276
2024-04-30T20:25:27,864  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:27,864  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:27,865  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:27,865  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@45a61081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cfe6977 will be shutdown
2024-04-30T20:25:27,865  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:27,865  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -24
2024-04-30T20:25:27,865  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:27,866  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:27,867  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c2b7f80, with PersistenceManager: null will be shutdown
2024-04-30T20:25:27,867  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c2b7f80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e4b7470 created in the thread with id: 276
2024-04-30T20:25:27,869  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c2b7f80 from thread id: 276
2024-04-30T20:25:27,871  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:27,871  WARN [Thread-242] mapred.LocalJobRunner: job_local74946413_0006
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5720189163854348/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:28,594  INFO [main] mapreduce.Job: Job job_local74946413_0006 running in uber mode : false
2024-04-30T20:25:28,595  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:28,595  INFO [main] mapreduce.Job: Job job_local74946413_0006 failed with state FAILED due to: NA
2024-04-30T20:25:28,596  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3059656
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=742391808
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:28,641  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:28,642  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:28,643  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:28,644  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:28,644  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:28,645  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c910acd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@612ac38b will be shutdown
2024-04-30T20:25:28,645  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c910acd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@312819ae created in the thread with id: 1
2024-04-30T20:25:28,647  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:28,647  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:28,648  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:28,648  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c910acd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@312819ae will be shutdown
2024-04-30T20:25:28,648  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:28,648  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -25
2024-04-30T20:25:28,648  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:28,648  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:28,649  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:28,649  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15ad5acb created in the thread with id: 1
2024-04-30T20:25:28,652  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b from thread id: 1
2024-04-30T20:25:28,653  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:28,663  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:28,670  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:28,707  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:28,707  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:28,708  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:28,708  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:28,709  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:28,709  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:28,709  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15ad5acb will be shutdown
2024-04-30T20:25:28,710  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5831989d created in the thread with id: 1
2024-04-30T20:25:28,712  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:28,712  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:28,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:28,712  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5831989d will be shutdown
2024-04-30T20:25:28,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:28,712  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -26
2024-04-30T20:25:28,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:28,713  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:28,713  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: null will be shutdown
2024-04-30T20:25:28,714  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2006fdaa created in the thread with id: 1
2024-04-30T20:25:28,716  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671 from thread id: 1
2024-04-30T20:25:28,718  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-04-30T20:25:28,742  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:28,747  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:28,748  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:28,770  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:28,786  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1850672128_0007
2024-04-30T20:25:28,786  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:28,835  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:28,835  INFO [main] mapreduce.Job: Running job: job_local1850672128_0007
2024-04-30T20:25:28,836  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:28,839  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,839  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,840  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:28,842  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,842  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,855  INFO [Thread-288] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:28,855  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1850672128_0007_m_000000_0
2024-04-30T20:25:28,858  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,858  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,860  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,860  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,860  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:28,861  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:28,863  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,863  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,877  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:28,878  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1850672128_0007_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:28,878  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,878  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,882  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:28,882  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1850672128_0007_m_000000_0 is allowed to commit now
2024-04-30T20:25:28,882  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:28,882  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:28,892  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1850672128_0007_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5345137731503432/part1=p1value2/part0=502
2024-04-30T20:25:28,893  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:28,893  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1850672128_0007_m_000000_0' done.
2024-04-30T20:25:28,894  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1850672128_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3572721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=742391808
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:28,894  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1850672128_0007_m_000000_0
2024-04-30T20:25:28,894  INFO [Thread-288] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:28,940  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:28,941  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:28,941  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:28,942  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:28,943  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:28,943  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:28,943  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b98f8d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:28,943  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b98f8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@396f631c created in the thread with id: 324
2024-04-30T20:25:28,945  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b98f8d from thread id: 324
2024-04-30T20:25:28,945  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:28,945  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:28,946  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:28,946  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44b98f8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@396f631c will be shutdown
2024-04-30T20:25:28,946  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:28,946  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -27
2024-04-30T20:25:28,946  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:28,947  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:28,948  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6128d7cf, with PersistenceManager: null will be shutdown
2024-04-30T20:25:28,948  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6128d7cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b59fc79 created in the thread with id: 324
2024-04-30T20:25:28,951  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6128d7cf from thread id: 324
2024-04-30T20:25:28,996  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:28,997  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:28,997  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:29,021  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5345137731503432/part1=p1value2/part0=502].
2024-04-30T20:25:29,021  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:29,061  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:29,061  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:29,061  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:29,061  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:29,061  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:29,061  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:29,062  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:29,062  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:29,062  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:29,062  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:29,062  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:29,062  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:29,063  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:29,063  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:29,063  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6128d7cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b59fc79 will be shutdown
2024-04-30T20:25:29,063  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6128d7cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35a5829 created in the thread with id: 324
2024-04-30T20:25:29,066  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:29,067  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:29,067  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:29,067  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6128d7cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35a5829 will be shutdown
2024-04-30T20:25:29,067  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:29,067  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -28
2024-04-30T20:25:29,067  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:29,068  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:29,069  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dbb3431, with PersistenceManager: null will be shutdown
2024-04-30T20:25:29,069  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dbb3431, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b70f25b created in the thread with id: 324
2024-04-30T20:25:29,071  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dbb3431 from thread id: 324
2024-04-30T20:25:29,073  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:29,073  WARN [Thread-288] mapred.LocalJobRunner: job_local1850672128_0007
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,5345137731503432/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:29,836  INFO [main] mapreduce.Job: Job job_local1850672128_0007 running in uber mode : false
2024-04-30T20:25:29,836  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:29,836  INFO [main] mapreduce.Job: Job job_local1850672128_0007 failed with state FAILED due to: NA
2024-04-30T20:25:29,838  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3572721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=742391808
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:29,884  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:29,885  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:29,885  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:29,885  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:29,885  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:29,886  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:29,888  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:29,888  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:29,889  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2006fdaa will be shutdown
2024-04-30T20:25:29,889  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57eed461 created in the thread with id: 1
2024-04-30T20:25:29,892  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:29,892  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:29,893  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:29,893  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57eed461 will be shutdown
2024-04-30T20:25:29,893  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:29,893  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -29
2024-04-30T20:25:29,893  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:29,894  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:29,894  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: null will be shutdown
2024-04-30T20:25:29,895  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74450c9b created in the thread with id: 1
2024-04-30T20:25:29,897  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8 from thread id: 1
2024-04-30T20:25:29,899  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:29,908  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:29,915  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:29,967  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:29,967  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:29,968  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:29,969  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:29,970  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:29,970  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:29,971  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74450c9b will be shutdown
2024-04-30T20:25:29,971  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d90764a created in the thread with id: 1
2024-04-30T20:25:29,974  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:29,974  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:29,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:29,975  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d90764a will be shutdown
2024-04-30T20:25:29,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:29,975  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -30
2024-04-30T20:25:29,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:29,976  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:29,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: null will be shutdown
2024-04-30T20:25:29,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db06c50 created in the thread with id: 1
2024-04-30T20:25:29,980  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26 from thread id: 1
2024-04-30T20:25:29,982  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-04-30T20:25:30,000  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:30,034  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:30,035  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:30,056  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:30,072  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1202092341_0008
2024-04-30T20:25:30,072  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:30,120  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:30,120  INFO [main] mapreduce.Job: Running job: job_local1202092341_0008
2024-04-30T20:25:30,121  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:30,123  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,123  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,125  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:30,126  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,126  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,140  INFO [Thread-334] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:30,140  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1202092341_0008_m_000000_0
2024-04-30T20:25:30,142  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,143  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,144  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,144  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,144  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:30,145  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:30,147  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,147  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,161  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:30,162  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1202092341_0008_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:30,162  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,162  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,166  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:30,166  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1202092341_0008_m_000000_0 is allowed to commit now
2024-04-30T20:25:30,166  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:30,166  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:30,176  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1202092341_0008_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8530049732165018/part1=p1value2/part0=502
2024-04-30T20:25:30,177  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:30,177  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1202092341_0008_m_000000_0' done.
2024-04-30T20:25:30,177  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1202092341_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4085786
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=746061824
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:30,177  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1202092341_0008_m_000000_0
2024-04-30T20:25:30,177  INFO [Thread-334] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:30,221  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:30,222  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:30,222  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:30,222  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:30,222  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:30,222  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:30,223  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:30,223  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:30,224  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:30,224  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35fc9046, with PersistenceManager: null will be shutdown
2024-04-30T20:25:30,224  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35fc9046, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53f7c580 created in the thread with id: 372
2024-04-30T20:25:30,227  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35fc9046 from thread id: 372
2024-04-30T20:25:30,227  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:30,227  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:30,228  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:30,228  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35fc9046, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53f7c580 will be shutdown
2024-04-30T20:25:30,228  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:30,228  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -31
2024-04-30T20:25:30,228  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:30,229  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:30,230  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@584ba9c, with PersistenceManager: null will be shutdown
2024-04-30T20:25:30,230  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@584ba9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a1d1f87 created in the thread with id: 372
2024-04-30T20:25:30,232  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@584ba9c from thread id: 372
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:30,278  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:30,278  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:30,301  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8530049732165018/part1=p1value2/part0=502].
2024-04-30T20:25:30,301  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:30,338  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:30,339  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:30,339  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:30,340  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:30,340  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@584ba9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a1d1f87 will be shutdown
2024-04-30T20:25:30,340  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@584ba9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@133c5cb created in the thread with id: 372
2024-04-30T20:25:30,342  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:30,342  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:30,342  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:30,342  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@584ba9c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@133c5cb will be shutdown
2024-04-30T20:25:30,343  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:30,343  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -32
2024-04-30T20:25:30,343  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:30,344  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:30,344  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34b4b8a3, with PersistenceManager: null will be shutdown
2024-04-30T20:25:30,345  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34b4b8a3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d4453d8 created in the thread with id: 372
2024-04-30T20:25:30,347  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34b4b8a3 from thread id: 372
2024-04-30T20:25:30,348  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:30,348  WARN [Thread-334] mapred.LocalJobRunner: job_local1202092341_0008
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8530049732165018/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:31,121  INFO [main] mapreduce.Job: Job job_local1202092341_0008 running in uber mode : false
2024-04-30T20:25:31,121  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:31,121  INFO [main] mapreduce.Job: Job job_local1202092341_0008 failed with state FAILED due to: NA
2024-04-30T20:25:31,123  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4085786
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=746061824
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:31,167  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:31,168  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:31,169  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:31,170  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:31,170  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:31,170  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db06c50 will be shutdown
2024-04-30T20:25:31,171  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d94ac8a created in the thread with id: 1
2024-04-30T20:25:31,173  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:31,173  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:31,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:31,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d94ac8a will be shutdown
2024-04-30T20:25:31,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:31,173  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -33
2024-04-30T20:25:31,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:31,174  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,174  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32d8710a, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,174  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32d8710a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@180cc0df created in the thread with id: 1
2024-04-30T20:25:31,176  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32d8710a from thread id: 1
2024-04-30T20:25:31,177  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:31,184  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:31,190  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:31,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:31,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:31,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:31,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:31,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:31,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:31,222  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:31,222  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:31,222  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:31,222  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:31,222  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:31,222  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:31,223  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:31,223  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:31,223  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32d8710a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@180cc0df will be shutdown
2024-04-30T20:25:31,223  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32d8710a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42cf5a6f created in the thread with id: 1
2024-04-30T20:25:31,226  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:31,226  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:31,226  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:31,226  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@32d8710a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42cf5a6f will be shutdown
2024-04-30T20:25:31,226  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:31,226  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -34
2024-04-30T20:25:31,226  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:31,227  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,227  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca6bd01, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,228  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca6bd01, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5acd7d1c created in the thread with id: 1
2024-04-30T20:25:31,229  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca6bd01 from thread id: 1
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:31,274  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:31,274  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:31,275  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:31,277  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:31,277  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:31,277  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca6bd01, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5acd7d1c will be shutdown
2024-04-30T20:25:31,277  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca6bd01, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44da745f created in the thread with id: 1
2024-04-30T20:25:31,279  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:31,279  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:31,280  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:31,280  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3ca6bd01, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44da745f will be shutdown
2024-04-30T20:25:31,280  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:31,280  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -35
2024-04-30T20:25:31,280  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:31,281  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,281  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,281  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8bde368 created in the thread with id: 1
2024-04-30T20:25:31,283  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896 from thread id: 1
2024-04-30T20:25:31,284  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:31,291  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:31,336  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:31,336  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:31,337  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:31,339  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:31,339  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:31,339  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8bde368 will be shutdown
2024-04-30T20:25:31,339  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6fe243a created in the thread with id: 1
2024-04-30T20:25:31,341  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:31,341  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:31,342  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:31,342  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6fe243a will be shutdown
2024-04-30T20:25:31,342  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:31,342  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -36
2024-04-30T20:25:31,342  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:31,343  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@308be1a3 created in the thread with id: 1
2024-04-30T20:25:31,344  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f from thread id: 1
2024-04-30T20:25:31,346  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:31,352  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:31,358  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:31,392  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:31,393  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:31,393  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:31,393  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:31,393  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:31,394  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:31,394  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:31,394  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@308be1a3 will be shutdown
2024-04-30T20:25:31,394  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67671db1 created in the thread with id: 1
2024-04-30T20:25:31,396  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:31,396  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:31,396  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:31,396  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67671db1 will be shutdown
2024-04-30T20:25:31,397  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:31,397  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -37
2024-04-30T20:25:31,397  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:31,397  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2568611c, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2568611c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bda7a5b created in the thread with id: 1
2024-04-30T20:25:31,399  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2568611c from thread id: 1
2024-04-30T20:25:31,406  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:31,411  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:31,411  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:31,433  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:31,450  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1161845498_0009
2024-04-30T20:25:31,450  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:31,503  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:31,503  INFO [main] mapreduce.Job: Running job: job_local1161845498_0009
2024-04-30T20:25:31,504  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:31,506  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:31,507  INFO [Thread-385] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:31,507  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1161845498_0009_m_000000_0
2024-04-30T20:25:31,510  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:31,511  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-30T20:25:31,516  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1161845498_0009_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.3892982205952046/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-30T20:25:31,516  INFO [Thread-385] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:31,518  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.3892982205952046].
2024-04-30T20:25:31,518  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:31,559  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:31,559  INFO [Thread-385] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:31,560  INFO [Thread-385] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:31,561  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,561  INFO [Thread-385] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:31,561  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dd55885, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,561  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dd55885, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30a68079 created in the thread with id: 425
2024-04-30T20:25:31,563  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dd55885 from thread id: 425
2024-04-30T20:25:31,563  INFO [Thread-385] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:31,563  INFO [Thread-385] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:31,564  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:31,564  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dd55885, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30a68079 will be shutdown
2024-04-30T20:25:31,564  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:31,564  INFO [Thread-385] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -38
2024-04-30T20:25:31,564  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:31,565  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:31,565  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a70d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:31,565  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a70d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47a9f2a7 created in the thread with id: 425
2024-04-30T20:25:31,567  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1440a70d from thread id: 425
2024-04-30T20:25:31,568  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:31,568  WARN [Thread-385] mapred.LocalJobRunner: job_local1161845498_0009
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-30T20:25:32,504  INFO [main] mapreduce.Job: Job job_local1161845498_0009 running in uber mode : false
2024-04-30T20:25:32,504  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:32,504  INFO [main] mapreduce.Job: Job job_local1161845498_0009 failed with state FAILED due to: NA
2024-04-30T20:25:32,504  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:32,542  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:32,542  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:32,542  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:32,542  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:32,542  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:32,542  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:32,543  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:32,543  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:32,543  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:32,543  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:32,543  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:32,543  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:32,544  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:32,545  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:32,545  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:32,546  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2568611c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bda7a5b will be shutdown
2024-04-30T20:25:32,546  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2568611c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49809275 created in the thread with id: 1
2024-04-30T20:25:32,548  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:32,549  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:32,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:32,549  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2568611c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49809275 will be shutdown
2024-04-30T20:25:32,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:32,549  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -39
2024-04-30T20:25:32,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:32,550  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:32,550  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:32,551  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@212c0aff created in the thread with id: 1
2024-04-30T20:25:32,552  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b from thread id: 1
2024-04-30T20:25:32,554  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:32,560  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:32,561  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:32,569  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:32,575  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:32,580  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:32,601  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-30T20:25:32,616  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1204865431_0010
2024-04-30T20:25:32,616  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:32,665  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:32,665  INFO [main] mapreduce.Job: Running job: job_local1204865431_0010
2024-04-30T20:25:32,665  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:32,666  INFO [Thread-405] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:32,666  INFO [Thread-405] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:32,666  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-30T20:25:32,674  INFO [Thread-405] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:32,674  INFO [Thread-405] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:33,666  INFO [main] mapreduce.Job: Job job_local1204865431_0010 running in uber mode : false
2024-04-30T20:25:33,666  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:33,666  INFO [main] mapreduce.Job: Job job_local1204865431_0010 completed successfully
2024-04-30T20:25:33,666  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:33,666  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:33,672  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:33,673  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:33,803  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[2]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.406">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-30T20:25:33,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:33,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:33,845  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:33,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:33,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:33,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:33,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:33,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:33,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:33,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:33,846  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:33,848  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:33,848  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:33,849  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@212c0aff will be shutdown
2024-04-30T20:25:33,849  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54e680fe created in the thread with id: 1
2024-04-30T20:25:33,851  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 3faba972-3485-4278-87e2-d3a685f31b49
2024-04-30T20:25:33,852  INFO [main] SessionState: Hive Session ID = 3faba972-3485-4278-87e2-d3a685f31b49
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:33,852  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:33,859  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3faba972-3485-4278-87e2-d3a685f31b49
2024-04-30T20:25:33,862  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/3faba972-3485-4278-87e2-d3a685f31b49
2024-04-30T20:25:33,865  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3faba972-3485-4278-87e2-d3a685f31b49/_tmp_space.db
2024-04-30T20:25:33,865  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:33,866  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_RCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_RCFILE, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-30T20:25:33,869  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:33,944  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:33,945  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:33,946  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:33,947  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:33,948  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:33,948  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54e680fe will be shutdown
2024-04-30T20:25:33,948  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14bd523b created in the thread with id: 1
2024-04-30T20:25:33,950  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:33,950  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:33,950  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:33,950  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@351be56b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14bd523b will be shutdown
2024-04-30T20:25:33,951  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:33,951  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -40
2024-04-30T20:25:33,951  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:33,951  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:33,952  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: null will be shutdown
2024-04-30T20:25:33,952  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33563147 created in the thread with id: 1
2024-04-30T20:25:33,954  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631 from thread id: 1
2024-04-30T20:25:33,955  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:33,964  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:33,973  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:34,009  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:34,010  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:34,010  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:34,010  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:34,011  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@33563147 will be shutdown
2024-04-30T20:25:34,011  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69d61a6f created in the thread with id: 1
2024-04-30T20:25:34,013  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:34,013  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:34,014  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:34,014  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8c34631, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69d61a6f will be shutdown
2024-04-30T20:25:34,014  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:34,014  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -41
2024-04-30T20:25:34,014  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:34,015  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:34,015  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3506bc8b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:34,015  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3506bc8b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4bac0be5 created in the thread with id: 1
2024-04-30T20:25:34,017  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3506bc8b from thread id: 1
2024-04-30T20:25:34,018  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value1,501]	
2024-04-30T20:25:34,038  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:34,043  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:34,044  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:34,065  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:34,084  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local185865125_0011
2024-04-30T20:25:34,084  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:34,133  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:34,133  INFO [main] mapreduce.Job: Running job: job_local185865125_0011
2024-04-30T20:25:34,133  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:34,135  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,135  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,137  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:34,137  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,137  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,151  INFO [Thread-439] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:34,151  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local185865125_0011_m_000000_0
2024-04-30T20:25:34,181  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,181  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,183  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,183  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,183  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:34,184  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-30T20:25:34,191  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,191  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,220  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:34,220  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-04-30T20:25:34,220  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-04-30T20:25:34,224  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local185865125_0011_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:34,224  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,224  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,227  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:34,228  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local185865125_0011_m_000000_0 is allowed to commit now
2024-04-30T20:25:34,228  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:34,228  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:34,238  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local185865125_0011_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7867239869428193/part1=p1value1/part0=501
2024-04-30T20:25:34,238  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:34,238  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local185865125_0011_m_000000_0' done.
2024-04-30T20:25:34,238  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local185865125_0011_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5619821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=799539200
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:34,238  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local185865125_0011_m_000000_0
2024-04-30T20:25:34,239  INFO [Thread-439] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:34,284  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:34,284  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:34,284  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:34,284  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:34,284  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:34,284  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:34,285  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:34,285  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:34,285  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:34,285  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:34,285  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:34,285  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:34,285  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:34,286  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:34,286  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:34,286  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6, with PersistenceManager: null will be shutdown
2024-04-30T20:25:34,286  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@536c170b created in the thread with id: 481
2024-04-30T20:25:34,288  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6 from thread id: 481
2024-04-30T20:25:34,288  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:34,288  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:34,288  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:34,289  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@864e4c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@536c170b will be shutdown
2024-04-30T20:25:34,289  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:34,289  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -42
2024-04-30T20:25:34,289  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:34,289  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:34,290  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: null will be shutdown
2024-04-30T20:25:34,290  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a82fdec created in the thread with id: 481
2024-04-30T20:25:34,291  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406 from thread id: 481
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:34,334  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:34,334  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=501, part1=p1value1}].
2024-04-30T20:25:34,356  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7867239869428193/part1=p1value1/part0=501].
2024-04-30T20:25:34,357  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:34,394  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:34,394  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:34,395  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:34,395  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:34,395  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a82fdec will be shutdown
2024-04-30T20:25:34,395  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54cd110f created in the thread with id: 481
2024-04-30T20:25:34,397  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:34,397  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:34,397  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:34,397  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@694c4406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54cd110f will be shutdown
2024-04-30T20:25:34,398  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:34,398  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -43
2024-04-30T20:25:34,398  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:34,398  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:34,399  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2503b3f5, with PersistenceManager: null will be shutdown
2024-04-30T20:25:34,399  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2503b3f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c9d569b created in the thread with id: 481
2024-04-30T20:25:34,400  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2503b3f5 from thread id: 481
2024-04-30T20:25:34,401  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:34,401  WARN [Thread-439] mapred.LocalJobRunner: job_local185865125_0011
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7867239869428193/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:35,134  INFO [main] mapreduce.Job: Job job_local185865125_0011 running in uber mode : false
2024-04-30T20:25:35,134  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:35,134  INFO [main] mapreduce.Job: Job job_local185865125_0011 failed with state FAILED due to: NA
2024-04-30T20:25:35,135  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5619821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=799539200
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:35,180  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:35,180  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:35,181  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:35,182  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:35,182  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:35,183  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3506bc8b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4bac0be5 will be shutdown
2024-04-30T20:25:35,183  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3506bc8b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@412440c1 created in the thread with id: 1
2024-04-30T20:25:35,184  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:35,185  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:35,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:35,185  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3506bc8b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@412440c1 will be shutdown
2024-04-30T20:25:35,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:35,185  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -44
2024-04-30T20:25:35,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:35,186  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:35,186  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: null will be shutdown
2024-04-30T20:25:35,187  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17d0d3d7 created in the thread with id: 1
2024-04-30T20:25:35,188  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3 from thread id: 1
2024-04-30T20:25:35,189  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:35,198  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:35,204  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:35,236  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:35,236  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:35,237  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:35,237  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:35,237  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17d0d3d7 will be shutdown
2024-04-30T20:25:35,238  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3662c887 created in the thread with id: 1
2024-04-30T20:25:35,240  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:35,240  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:35,240  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:35,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59d09ff3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3662c887 will be shutdown
2024-04-30T20:25:35,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:35,241  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -45
2024-04-30T20:25:35,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:35,242  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:35,242  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: null will be shutdown
2024-04-30T20:25:35,242  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2059c3ff created in the thread with id: 1
2024-04-30T20:25:35,244  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb from thread id: 1
2024-04-30T20:25:35,246  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-04-30T20:25:35,262  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:35,267  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:35,267  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:35,288  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:35,303  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1201035270_0012
2024-04-30T20:25:35,303  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:35,352  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:35,352  INFO [main] mapreduce.Job: Running job: job_local1201035270_0012
2024-04-30T20:25:35,352  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:35,354  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,354  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,355  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:35,355  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,355  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,369  INFO [Thread-485] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:35,369  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1201035270_0012_m_000000_0
2024-04-30T20:25:35,371  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,371  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,372  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,372  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,372  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:35,373  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:35,375  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,375  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,391  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:35,391  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-04-30T20:25:35,391  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-30T20:25:35,391  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1201035270_0012_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:35,392  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,392  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,396  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:35,396  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1201035270_0012_m_000000_0 is allowed to commit now
2024-04-30T20:25:35,396  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:35,396  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:35,407  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1201035270_0012_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7718823916875291/part1=p1value2/part0=502
2024-04-30T20:25:35,407  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:35,407  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1201035270_0012_m_000000_0' done.
2024-04-30T20:25:35,407  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1201035270_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6132994
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799539200
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:35,408  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1201035270_0012_m_000000_0
2024-04-30T20:25:35,408  INFO [Thread-485] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:35,454  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:35,454  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:35,454  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:35,454  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:35,454  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:35,454  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:35,455  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:35,455  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:35,455  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:35,455  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:35,455  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:35,455  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:35,455  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:35,456  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:35,456  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:35,456  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236a3e68, with PersistenceManager: null will be shutdown
2024-04-30T20:25:35,456  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236a3e68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ad615c7 created in the thread with id: 529
2024-04-30T20:25:35,458  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236a3e68 from thread id: 529
2024-04-30T20:25:35,458  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:35,458  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:35,459  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:35,459  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236a3e68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ad615c7 will be shutdown
2024-04-30T20:25:35,459  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:35,459  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -46
2024-04-30T20:25:35,459  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:35,459  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:35,460  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d1493e1, with PersistenceManager: null will be shutdown
2024-04-30T20:25:35,460  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d1493e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@733a006d created in the thread with id: 529
2024-04-30T20:25:35,461  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d1493e1 from thread id: 529
2024-04-30T20:25:35,505  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:35,505  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:35,505  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:35,506  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:35,506  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:35,529  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7718823916875291/part1=p1value2/part0=502].
2024-04-30T20:25:35,529  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:35,566  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:35,566  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:35,567  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:35,567  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:35,568  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d1493e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@733a006d will be shutdown
2024-04-30T20:25:35,568  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d1493e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ee6f0f5 created in the thread with id: 529
2024-04-30T20:25:35,569  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:35,570  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:35,570  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:35,570  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d1493e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ee6f0f5 will be shutdown
2024-04-30T20:25:35,570  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:35,570  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -47
2024-04-30T20:25:35,570  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:35,571  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:35,571  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60de3150, with PersistenceManager: null will be shutdown
2024-04-30T20:25:35,571  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60de3150, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ad3bfc0 created in the thread with id: 529
2024-04-30T20:25:35,573  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60de3150 from thread id: 529
2024-04-30T20:25:35,574  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:35,574  WARN [Thread-485] mapred.LocalJobRunner: job_local1201035270_0012
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,7718823916875291/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:36,352  INFO [main] mapreduce.Job: Job job_local1201035270_0012 running in uber mode : false
2024-04-30T20:25:36,352  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:36,353  INFO [main] mapreduce.Job: Job job_local1201035270_0012 failed with state FAILED due to: NA
2024-04-30T20:25:36,354  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6132994
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799539200
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:36,399  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:36,399  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:36,400  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:36,401  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:36,402  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:36,402  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2059c3ff will be shutdown
2024-04-30T20:25:36,402  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@790f4933 created in the thread with id: 1
2024-04-30T20:25:36,404  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:36,404  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:36,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:36,404  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60251ddb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@790f4933 will be shutdown
2024-04-30T20:25:36,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:36,405  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -48
2024-04-30T20:25:36,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:36,405  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:36,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: null will be shutdown
2024-04-30T20:25:36,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69b80603 created in the thread with id: 1
2024-04-30T20:25:36,407  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9 from thread id: 1
2024-04-30T20:25:36,408  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:36,415  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:36,420  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:36,453  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:36,454  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:36,454  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:36,454  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:36,454  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:36,454  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:36,454  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:36,454  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:36,455  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69b80603 will be shutdown
2024-04-30T20:25:36,455  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65234a9 created in the thread with id: 1
2024-04-30T20:25:36,456  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:36,457  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:36,457  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:36,457  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6318ff9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65234a9 will be shutdown
2024-04-30T20:25:36,457  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:36,457  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -49
2024-04-30T20:25:36,457  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:36,458  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:36,458  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: null will be shutdown
2024-04-30T20:25:36,458  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14580edc created in the thread with id: 1
2024-04-30T20:25:36,460  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016 from thread id: 1
2024-04-30T20:25:36,461  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-04-30T20:25:36,472  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:36,477  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:36,478  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:36,498  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:36,514  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2008246979_0013
2024-04-30T20:25:36,514  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:36,562  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:36,563  INFO [main] mapreduce.Job: Running job: job_local2008246979_0013
2024-04-30T20:25:36,563  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:36,565  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,565  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,565  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:36,566  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,566  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,579  INFO [Thread-531] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:36,580  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2008246979_0013_m_000000_0
2024-04-30T20:25:36,582  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,582  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,584  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,584  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,584  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:36,584  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:36,587  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,587  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,602  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:36,602  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-04-30T20:25:36,602  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-30T20:25:36,602  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2008246979_0013_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:36,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,606  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:36,606  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2008246979_0013_m_000000_0 is allowed to commit now
2024-04-30T20:25:36,606  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:36,606  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:36,617  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2008246979_0013_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,35984835669162596/part1=p1value2/part0=502
2024-04-30T20:25:36,618  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:36,618  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2008246979_0013_m_000000_0' done.
2024-04-30T20:25:36,618  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2008246979_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6646180
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799539200
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:36,618  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2008246979_0013_m_000000_0
2024-04-30T20:25:36,618  INFO [Thread-531] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:36,650  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:36,664  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:36,664  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:36,665  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:36,665  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:36,665  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:36,666  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f706ed, with PersistenceManager: null will be shutdown
2024-04-30T20:25:36,666  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f706ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74bb8892 created in the thread with id: 577
2024-04-30T20:25:36,667  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f706ed from thread id: 577
2024-04-30T20:25:36,667  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:36,668  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:36,668  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:36,668  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f706ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74bb8892 will be shutdown
2024-04-30T20:25:36,668  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:36,668  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -50
2024-04-30T20:25:36,668  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:36,669  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:36,669  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f2b9c26, with PersistenceManager: null will be shutdown
2024-04-30T20:25:36,669  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f2b9c26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d3ef528 created in the thread with id: 577
2024-04-30T20:25:36,671  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f2b9c26 from thread id: 577
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:36,712  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:36,713  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:36,713  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:36,713  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:36,736  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,35984835669162596/part1=p1value2/part0=502].
2024-04-30T20:25:36,736  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:36,777  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:36,778  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:36,778  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:36,779  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:36,779  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:36,780  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f2b9c26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d3ef528 will be shutdown
2024-04-30T20:25:36,780  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f2b9c26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@573bbe5b created in the thread with id: 577
2024-04-30T20:25:36,782  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:36,782  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:36,782  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:36,782  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f2b9c26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@573bbe5b will be shutdown
2024-04-30T20:25:36,783  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:36,783  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -51
2024-04-30T20:25:36,783  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:36,784  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:36,784  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f9bd28e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:36,784  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f9bd28e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7dc4d55d created in the thread with id: 577
2024-04-30T20:25:36,786  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f9bd28e from thread id: 577
2024-04-30T20:25:36,787  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:36,787  WARN [Thread-531] mapred.LocalJobRunner: job_local2008246979_0013
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,35984835669162596/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:37,563  INFO [main] mapreduce.Job: Job job_local2008246979_0013 running in uber mode : false
2024-04-30T20:25:37,563  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:37,564  INFO [main] mapreduce.Job: Job job_local2008246979_0013 failed with state FAILED due to: NA
2024-04-30T20:25:37,565  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6646180
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=799539200
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:37,609  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:37,609  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:37,609  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:37,610  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:37,610  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:37,611  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:37,612  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:37,612  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:37,612  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14580edc will be shutdown
2024-04-30T20:25:37,613  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d527346 created in the thread with id: 1
2024-04-30T20:25:37,614  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:37,614  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:37,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:37,615  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7091a016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d527346 will be shutdown
2024-04-30T20:25:37,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:37,615  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -52
2024-04-30T20:25:37,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:37,615  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,616  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c163e1, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,616  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c163e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3da55998 created in the thread with id: 1
2024-04-30T20:25:37,617  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c163e1 from thread id: 1
2024-04-30T20:25:37,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:37,625  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:37,630  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:37,661  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:37,661  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:37,661  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:37,661  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:37,662  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:37,662  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:37,663  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:37,663  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:37,663  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c163e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3da55998 will be shutdown
2024-04-30T20:25:37,663  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c163e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17635531 created in the thread with id: 1
2024-04-30T20:25:37,664  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:37,665  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:37,665  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:37,665  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c163e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17635531 will be shutdown
2024-04-30T20:25:37,665  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:37,665  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -53
2024-04-30T20:25:37,665  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:37,666  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,666  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60256d1b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,666  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60256d1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24b4f4a created in the thread with id: 1
2024-04-30T20:25:37,668  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60256d1b from thread id: 1
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:37,716  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:37,717  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:37,717  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:37,719  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:37,719  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:37,720  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60256d1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24b4f4a will be shutdown
2024-04-30T20:25:37,720  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60256d1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70cdbd18 created in the thread with id: 1
2024-04-30T20:25:37,722  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:37,722  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:37,723  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:37,723  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60256d1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70cdbd18 will be shutdown
2024-04-30T20:25:37,723  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:37,723  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -54
2024-04-30T20:25:37,723  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:37,724  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab717f3, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab717f3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52bcfd10 created in the thread with id: 1
2024-04-30T20:25:37,726  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab717f3 from thread id: 1
2024-04-30T20:25:37,727  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:37,732  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:37,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:37,777  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:37,777  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:37,777  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:37,777  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:37,779  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:37,779  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:37,779  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab717f3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52bcfd10 will be shutdown
2024-04-30T20:25:37,779  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab717f3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2caa9666 created in the thread with id: 1
2024-04-30T20:25:37,781  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:37,781  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:37,781  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:37,781  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ab717f3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2caa9666 will be shutdown
2024-04-30T20:25:37,781  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:37,781  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -55
2024-04-30T20:25:37,782  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:37,782  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,782  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ca7bddd, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,783  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ca7bddd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@206e5183 created in the thread with id: 1
2024-04-30T20:25:37,784  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ca7bddd from thread id: 1
2024-04-30T20:25:37,785  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:37,790  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:37,796  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:37,828  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:37,828  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:37,829  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:37,829  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:37,829  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ca7bddd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@206e5183 will be shutdown
2024-04-30T20:25:37,829  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ca7bddd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@345af277 created in the thread with id: 1
2024-04-30T20:25:37,831  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:37,831  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:37,831  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:37,831  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ca7bddd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@345af277 will be shutdown
2024-04-30T20:25:37,831  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:37,831  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -56
2024-04-30T20:25:37,831  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:37,832  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,832  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677274e7, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,832  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677274e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54c17a2b created in the thread with id: 1
2024-04-30T20:25:37,834  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677274e7 from thread id: 1
2024-04-30T20:25:37,840  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:37,845  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:37,846  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:37,866  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:37,884  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2006493528_0014
2024-04-30T20:25:37,884  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:37,934  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:37,934  INFO [main] mapreduce.Job: Running job: job_local2006493528_0014
2024-04-30T20:25:37,935  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:37,937  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:37,938  INFO [Thread-582] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:37,938  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2006493528_0014_m_000000_0
2024-04-30T20:25:37,941  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:37,941  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-30T20:25:37,946  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local2006493528_0014_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.47074198257619715/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-30T20:25:37,946  INFO [Thread-582] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:37,947  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.47074198257619715].
2024-04-30T20:25:37,947  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:37,984  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:37,985  INFO [Thread-582] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:37,985  INFO [Thread-582] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:37,986  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,986  INFO [Thread-582] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:37,986  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,986  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45da5090 created in the thread with id: 630
2024-04-30T20:25:37,989  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0 from thread id: 630
2024-04-30T20:25:37,989  INFO [Thread-582] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:37,989  INFO [Thread-582] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:37,989  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:37,989  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28a9cdb0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45da5090 will be shutdown
2024-04-30T20:25:37,989  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:37,989  INFO [Thread-582] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -57
2024-04-30T20:25:37,989  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:37,990  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:37,991  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f6088d5, with PersistenceManager: null will be shutdown
2024-04-30T20:25:37,991  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f6088d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ba4c6f5 created in the thread with id: 630
2024-04-30T20:25:37,992  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f6088d5 from thread id: 630
2024-04-30T20:25:37,993  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:37,994  WARN [Thread-582] mapred.LocalJobRunner: job_local2006493528_0014
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-30T20:25:38,935  INFO [main] mapreduce.Job: Job job_local2006493528_0014 running in uber mode : false
2024-04-30T20:25:38,935  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:38,935  INFO [main] mapreduce.Job: Job job_local2006493528_0014 failed with state FAILED due to: NA
2024-04-30T20:25:38,935  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:38,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:38,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:38,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:38,976  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:38,976  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:38,977  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:38,979  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:38,979  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:38,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677274e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54c17a2b will be shutdown
2024-04-30T20:25:38,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677274e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35c9f527 created in the thread with id: 1
2024-04-30T20:25:38,982  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:38,982  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:38,982  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:38,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677274e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35c9f527 will be shutdown
2024-04-30T20:25:38,982  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:38,982  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -58
2024-04-30T20:25:38,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:38,983  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:38,984  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: null will be shutdown
2024-04-30T20:25:38,984  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b332eda created in the thread with id: 1
2024-04-30T20:25:38,986  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575 from thread id: 1
2024-04-30T20:25:38,987  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:39,026  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:39,026  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:39,030  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:39,036  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:39,041  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:39,062  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-30T20:25:39,077  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1970919929_0015
2024-04-30T20:25:39,077  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:39,125  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:39,126  INFO [main] mapreduce.Job: Running job: job_local1970919929_0015
2024-04-30T20:25:39,126  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:39,126  INFO [Thread-602] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:39,126  INFO [Thread-602] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:39,126  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-30T20:25:39,134  INFO [Thread-602] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:39,134  INFO [Thread-602] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:40,126  INFO [main] mapreduce.Job: Job job_local1970919929_0015 running in uber mode : false
2024-04-30T20:25:40,126  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:40,127  INFO [main] mapreduce.Job: Job job_local1970919929_0015 completed successfully
2024-04-30T20:25:40,127  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:40,127  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:40,133  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:40,133  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,209  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[3]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.316">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,251  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:40,253  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:40,253  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:40,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b332eda will be shutdown
2024-04-30T20:25:40,253  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1259b2a5 created in the thread with id: 1
2024-04-30T20:25:40,255  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 30222537-1579-4bac-bb9c-a659252bcd29
2024-04-30T20:25:40,256  INFO [main] SessionState: Hive Session ID = 30222537-1579-4bac-bb9c-a659252bcd29
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:40,256  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:40,262  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/30222537-1579-4bac-bb9c-a659252bcd29
2024-04-30T20:25:40,265  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/30222537-1579-4bac-bb9c-a659252bcd29
2024-04-30T20:25:40,267  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/30222537-1579-4bac-bb9c-a659252bcd29/_tmp_space.db
2024-04-30T20:25:40,268  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:40,269  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_ORCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_ORCFILE, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-30T20:25:40,271  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,346  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:40,346  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:40,347  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:40,349  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:40,349  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:40,349  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1259b2a5 will be shutdown
2024-04-30T20:25:40,350  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@762d2e4c created in the thread with id: 1
2024-04-30T20:25:40,352  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:40,352  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:40,352  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:40,352  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4645a575, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@762d2e4c will be shutdown
2024-04-30T20:25:40,352  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:40,352  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -59
2024-04-30T20:25:40,352  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:40,353  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:40,353  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:40,353  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f3f0d25 created in the thread with id: 1
2024-04-30T20:25:40,355  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d from thread id: 1
2024-04-30T20:25:40,356  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:40,361  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:40,374  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,407  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,408  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,408  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,408  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,408  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:40,408  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:40,409  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:40,409  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:40,409  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f3f0d25 will be shutdown
2024-04-30T20:25:40,409  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cdf61d created in the thread with id: 1
2024-04-30T20:25:40,411  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:40,411  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:40,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:40,411  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60e5db1d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cdf61d will be shutdown
2024-04-30T20:25:40,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:40,411  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -60
2024-04-30T20:25:40,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:40,412  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:40,412  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: null will be shutdown
2024-04-30T20:25:40,412  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1067192a created in the thread with id: 1
2024-04-30T20:25:40,414  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c from thread id: 1
2024-04-30T20:25:40,415  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value1,501]	
2024-04-30T20:25:40,427  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:40,432  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:40,433  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:40,453  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:40,468  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1278070902_0016
2024-04-30T20:25:40,468  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:40,516  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:40,516  INFO [main] mapreduce.Job: Running job: job_local1278070902_0016
2024-04-30T20:25:40,516  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:40,518  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,518  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,519  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:40,520  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,520  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,533  INFO [Thread-636] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:40,533  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1278070902_0016_m_000000_0
2024-04-30T20:25:40,538  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,538  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,539  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,539  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,539  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:40,540  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-30T20:25:40,545  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,545  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,576  INFO [LocalJobRunner Map Task Executor #0] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-30T20:25:40,581  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,25845245001737205/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1278070902_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-30T20:25:40,638  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,25845245001737205/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1278070902_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-30T20:25:40,644  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:40,686  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1278070902_0016_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:40,686  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,686  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,690  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:40,690  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1278070902_0016_m_000000_0 is allowed to commit now
2024-04-30T20:25:40,690  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:40,690  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:40,700  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1278070902_0016_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,25845245001737205/part1=p1value1/part0=501
2024-04-30T20:25:40,701  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:40,701  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1278070902_0016_m_000000_0' done.
2024-04-30T20:25:40,701  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1278070902_0016_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8182593
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802160640
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:40,701  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1278070902_0016_m_000000_0
2024-04-30T20:25:40,701  INFO [Thread-636] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,745  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:40,745  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:40,746  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:40,747  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:40,747  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:40,747  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@743bae50, with PersistenceManager: null will be shutdown
2024-04-30T20:25:40,747  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@743bae50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b86f62b created in the thread with id: 686
2024-04-30T20:25:40,749  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@743bae50 from thread id: 686
2024-04-30T20:25:40,749  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:40,749  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:40,749  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:40,749  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@743bae50, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b86f62b will be shutdown
2024-04-30T20:25:40,749  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:40,749  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -61
2024-04-30T20:25:40,749  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:40,750  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:40,750  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd41e76, with PersistenceManager: null will be shutdown
2024-04-30T20:25:40,750  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd41e76, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c945c3c created in the thread with id: 686
2024-04-30T20:25:40,752  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd41e76 from thread id: 686
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,794  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:40,794  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=501, part1=p1value1}].
2024-04-30T20:25:40,816  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,25845245001737205/part1=p1value1/part0=501].
2024-04-30T20:25:40,817  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:40,853  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:40,853  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:40,853  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:40,854  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:40,854  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:40,855  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:40,855  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:40,855  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd41e76, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c945c3c will be shutdown
2024-04-30T20:25:40,855  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd41e76, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dd70194 created in the thread with id: 686
2024-04-30T20:25:40,857  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:40,857  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:40,857  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:40,857  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd41e76, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dd70194 will be shutdown
2024-04-30T20:25:40,857  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:40,857  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -62
2024-04-30T20:25:40,857  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:40,858  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:40,858  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b9ba084, with PersistenceManager: null will be shutdown
2024-04-30T20:25:40,859  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b9ba084, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29096f89 created in the thread with id: 686
2024-04-30T20:25:40,860  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b9ba084 from thread id: 686
2024-04-30T20:25:40,861  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:40,861  WARN [Thread-636] mapred.LocalJobRunner: job_local1278070902_0016
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,25845245001737205/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:41,517  INFO [main] mapreduce.Job: Job job_local1278070902_0016 running in uber mode : false
2024-04-30T20:25:41,517  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:41,517  INFO [main] mapreduce.Job: Job job_local1278070902_0016 failed with state FAILED due to: NA
2024-04-30T20:25:41,518  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8182593
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802160640
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:41,562  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:41,562  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:41,563  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:41,565  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:41,565  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:41,565  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1067192a will be shutdown
2024-04-30T20:25:41,565  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7fd3c38b created in the thread with id: 1
2024-04-30T20:25:41,567  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:41,567  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:41,567  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:41,568  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7fd3c38b will be shutdown
2024-04-30T20:25:41,568  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:41,568  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -63
2024-04-30T20:25:41,568  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:41,568  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:41,569  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: null will be shutdown
2024-04-30T20:25:41,569  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29612ee2 created in the thread with id: 1
2024-04-30T20:25:41,570  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff from thread id: 1
2024-04-30T20:25:41,571  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:41,576  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:41,582  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:41,614  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:41,614  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:41,615  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:41,615  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:41,615  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@29612ee2 will be shutdown
2024-04-30T20:25:41,616  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8aa3013 created in the thread with id: 1
2024-04-30T20:25:41,617  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:41,617  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:41,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:41,618  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54a5eff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8aa3013 will be shutdown
2024-04-30T20:25:41,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:41,618  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -64
2024-04-30T20:25:41,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:41,619  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:41,619  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: null will be shutdown
2024-04-30T20:25:41,619  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bab8290 created in the thread with id: 1
2024-04-30T20:25:41,620  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce from thread id: 1
2024-04-30T20:25:41,621  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-04-30T20:25:41,633  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:41,638  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:41,638  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:41,659  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:41,674  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2074609658_0017
2024-04-30T20:25:41,674  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:41,722  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:41,722  INFO [main] mapreduce.Job: Running job: job_local2074609658_0017
2024-04-30T20:25:41,722  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:41,724  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,724  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,724  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:41,725  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,725  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,738  INFO [Thread-682] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:41,738  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2074609658_0017_m_000000_0
2024-04-30T20:25:41,740  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,740  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,741  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,741  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,742  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:41,742  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:41,744  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,744  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,746  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8391795739900856/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local2074609658_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-30T20:25:41,756  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8391795739900856/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local2074609658_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-30T20:25:41,757  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:41,759  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2074609658_0017_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:41,760  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,760  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,763  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:41,763  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2074609658_0017_m_000000_0 is allowed to commit now
2024-04-30T20:25:41,763  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:41,763  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:41,773  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2074609658_0017_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8391795739900856/part1=p1value2/part0=502
2024-04-30T20:25:41,774  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:41,774  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2074609658_0017_m_000000_0' done.
2024-04-30T20:25:41,774  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2074609658_0017_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8695336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802160640
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:41,774  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2074609658_0017_m_000000_0
2024-04-30T20:25:41,774  INFO [Thread-682] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:41,817  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:41,817  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:41,818  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:41,818  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:41,819  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:41,819  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:41,819  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:41,820  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd89d58, with PersistenceManager: null will be shutdown
2024-04-30T20:25:41,820  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd89d58, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25bda657 created in the thread with id: 734
2024-04-30T20:25:41,822  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd89d58 from thread id: 734
2024-04-30T20:25:41,822  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:41,822  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:41,822  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:41,822  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bd89d58, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25bda657 will be shutdown
2024-04-30T20:25:41,822  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:41,822  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -65
2024-04-30T20:25:41,822  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:41,823  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:41,824  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46c326bf, with PersistenceManager: null will be shutdown
2024-04-30T20:25:41,824  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46c326bf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c457b9f created in the thread with id: 734
2024-04-30T20:25:41,826  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46c326bf from thread id: 734
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:41,870  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:41,870  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:41,893  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8391795739900856/part1=p1value2/part0=502].
2024-04-30T20:25:41,893  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:41,929  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:41,929  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:41,929  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:41,929  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:41,929  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:41,930  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:41,930  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:41,930  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:41,930  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:41,930  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:41,930  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:41,930  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:41,931  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:41,931  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:41,931  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46c326bf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c457b9f will be shutdown
2024-04-30T20:25:41,931  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46c326bf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351ec6b3 created in the thread with id: 734
2024-04-30T20:25:41,933  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:41,933  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:41,934  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:41,934  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@46c326bf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351ec6b3 will be shutdown
2024-04-30T20:25:41,934  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:41,934  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -66
2024-04-30T20:25:41,934  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:41,934  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:41,935  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ee9e11a, with PersistenceManager: null will be shutdown
2024-04-30T20:25:41,935  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ee9e11a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56aa84d0 created in the thread with id: 734
2024-04-30T20:25:41,936  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ee9e11a from thread id: 734
2024-04-30T20:25:41,937  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:41,937  WARN [Thread-682] mapred.LocalJobRunner: job_local2074609658_0017
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,8391795739900856/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:42,723  INFO [main] mapreduce.Job: Job job_local2074609658_0017 running in uber mode : false
2024-04-30T20:25:42,723  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:42,723  INFO [main] mapreduce.Job: Job job_local2074609658_0017 failed with state FAILED due to: NA
2024-04-30T20:25:42,724  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8695336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=802160640
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:42,770  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:42,770  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:42,770  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:42,770  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:42,770  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:42,770  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:42,771  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:42,771  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:42,771  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:42,771  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:42,771  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:42,771  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:42,772  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:42,773  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:42,774  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:42,774  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bab8290 will be shutdown
2024-04-30T20:25:42,774  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d50f682 created in the thread with id: 1
2024-04-30T20:25:42,775  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:42,776  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:42,776  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:42,776  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b2114ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d50f682 will be shutdown
2024-04-30T20:25:42,776  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:42,776  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -67
2024-04-30T20:25:42,776  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:42,777  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:42,777  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: null will be shutdown
2024-04-30T20:25:42,777  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ceb7a60 created in the thread with id: 1
2024-04-30T20:25:42,779  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa from thread id: 1
2024-04-30T20:25:42,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:42,785  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:42,790  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:42,821  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:42,822  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:42,822  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:42,823  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:42,823  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ceb7a60 will be shutdown
2024-04-30T20:25:42,823  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6cd8c373 created in the thread with id: 1
2024-04-30T20:25:42,824  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:42,824  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:42,825  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:42,825  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53ce27fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6cd8c373 will be shutdown
2024-04-30T20:25:42,825  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:42,825  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -68
2024-04-30T20:25:42,825  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:42,826  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:42,826  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: null will be shutdown
2024-04-30T20:25:42,826  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a41d17a created in the thread with id: 1
2024-04-30T20:25:42,828  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527 from thread id: 1
2024-04-30T20:25:42,829  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-04-30T20:25:42,840  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:42,845  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:42,845  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:42,865  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:42,881  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1613844457_0018
2024-04-30T20:25:42,881  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:42,955  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:42,955  INFO [main] mapreduce.Job: Running job: job_local1613844457_0018
2024-04-30T20:25:42,955  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:42,956  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,957  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:42,957  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:42,958  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,958  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:42,971  INFO [Thread-728] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:42,971  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1613844457_0018_m_000000_0
2024-04-30T20:25:42,973  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,973  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:42,974  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,974  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:42,974  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:42,975  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:42,976  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,976  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:42,978  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7121889605571099/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1613844457_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-30T20:25:42,989  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7121889605571099/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1613844457_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-30T20:25:42,990  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:42,992  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1613844457_0018_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:42,992  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,992  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:42,996  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:42,996  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1613844457_0018_m_000000_0 is allowed to commit now
2024-04-30T20:25:42,996  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:42,996  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:43,006  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1613844457_0018_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7121889605571099/part1=p1value2/part0=502
2024-04-30T20:25:43,007  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:43,007  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1613844457_0018_m_000000_0' done.
2024-04-30T20:25:43,007  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1613844457_0018_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9208079
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=842006528
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:43,007  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1613844457_0018_m_000000_0
2024-04-30T20:25:43,007  INFO [Thread-728] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:43,051  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:43,051  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:43,051  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:43,051  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:43,051  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:43,052  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:43,052  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:43,052  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:43,052  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:43,052  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:43,052  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:43,052  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:43,053  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:43,053  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:43,053  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:43,054  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3473b1e5, with PersistenceManager: null will be shutdown
2024-04-30T20:25:43,054  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3473b1e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78ee88f0 created in the thread with id: 782
2024-04-30T20:25:43,055  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3473b1e5 from thread id: 782
2024-04-30T20:25:43,055  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:43,055  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:43,056  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:43,056  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3473b1e5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78ee88f0 will be shutdown
2024-04-30T20:25:43,056  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:43,056  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -69
2024-04-30T20:25:43,056  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:43,056  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:43,057  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a669bec, with PersistenceManager: null will be shutdown
2024-04-30T20:25:43,057  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a669bec, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5885d2a0 created in the thread with id: 782
2024-04-30T20:25:43,058  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a669bec from thread id: 782
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:43,100  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:43,100  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:43,122  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7121889605571099/part1=p1value2/part0=502].
2024-04-30T20:25:43,123  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:43,160  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:43,160  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:43,161  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:43,161  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:43,161  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a669bec, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5885d2a0 will be shutdown
2024-04-30T20:25:43,162  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a669bec, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4aa60706 created in the thread with id: 782
2024-04-30T20:25:43,163  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:43,163  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:43,163  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:43,163  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a669bec, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4aa60706 will be shutdown
2024-04-30T20:25:43,164  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:43,164  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -70
2024-04-30T20:25:43,164  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:43,164  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:43,165  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56528159, with PersistenceManager: null will be shutdown
2024-04-30T20:25:43,165  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56528159, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a3724b created in the thread with id: 782
2024-04-30T20:25:43,166  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@56528159 from thread id: 782
2024-04-30T20:25:43,167  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:43,167  WARN [Thread-728] mapred.LocalJobRunner: job_local1613844457_0018
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,7121889605571099/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:43,509  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-30T20:25:43,955  INFO [main] mapreduce.Job: Job job_local1613844457_0018 running in uber mode : false
2024-04-30T20:25:43,955  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:43,956  INFO [main] mapreduce.Job: Job job_local1613844457_0018 failed with state FAILED due to: NA
2024-04-30T20:25:43,957  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9208079
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=842006528
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:44,002  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:44,002  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:44,003  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:44,004  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:44,004  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:44,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a41d17a will be shutdown
2024-04-30T20:25:44,005  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56897de0 created in the thread with id: 1
2024-04-30T20:25:44,006  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:44,006  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:44,006  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:44,006  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f9ee527, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56897de0 will be shutdown
2024-04-30T20:25:44,006  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:44,006  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -71
2024-04-30T20:25:44,007  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:44,007  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,007  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,007  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53a645a2 created in the thread with id: 1
2024-04-30T20:25:44,009  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d from thread id: 1
2024-04-30T20:25:44,010  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:44,016  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:44,021  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:44,053  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:44,054  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:44,054  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:44,055  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:44,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53a645a2 will be shutdown
2024-04-30T20:25:44,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3280a79a created in the thread with id: 1
2024-04-30T20:25:44,057  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:44,057  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:44,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:44,057  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3280a79a will be shutdown
2024-04-30T20:25:44,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:44,057  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -72
2024-04-30T20:25:44,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:44,058  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,059  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,059  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@374712f8 created in the thread with id: 1
2024-04-30T20:25:44,061  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0 from thread id: 1
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:44,106  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:44,106  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:44,107  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:44,108  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:44,108  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:44,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@374712f8 will be shutdown
2024-04-30T20:25:44,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4822fc53 created in the thread with id: 1
2024-04-30T20:25:44,110  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:44,110  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:44,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:44,111  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4822fc53 will be shutdown
2024-04-30T20:25:44,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:44,111  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -73
2024-04-30T20:25:44,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:44,111  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,112  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,112  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@163cd4a6 created in the thread with id: 1
2024-04-30T20:25:44,113  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761 from thread id: 1
2024-04-30T20:25:44,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:44,119  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:44,163  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:44,163  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:44,164  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:44,165  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:44,165  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:44,166  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@163cd4a6 will be shutdown
2024-04-30T20:25:44,166  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@221961f2 created in the thread with id: 1
2024-04-30T20:25:44,167  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:44,167  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:44,168  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:44,168  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@221961f2 will be shutdown
2024-04-30T20:25:44,168  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:44,168  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -74
2024-04-30T20:25:44,168  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:44,168  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,169  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,169  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b3b5252 created in the thread with id: 1
2024-04-30T20:25:44,170  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80 from thread id: 1
2024-04-30T20:25:44,171  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:44,177  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:44,183  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:44,215  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:44,215  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:44,216  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:44,216  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:44,216  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b3b5252 will be shutdown
2024-04-30T20:25:44,216  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21553c3a created in the thread with id: 1
2024-04-30T20:25:44,218  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:44,218  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:44,218  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:44,218  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21553c3a will be shutdown
2024-04-30T20:25:44,219  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:44,219  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -75
2024-04-30T20:25:44,219  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:44,220  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,220  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,220  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42718ebf created in the thread with id: 1
2024-04-30T20:25:44,222  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462 from thread id: 1
2024-04-30T20:25:44,228  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:44,233  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:44,233  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:44,254  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:44,269  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local856801264_0019
2024-04-30T20:25:44,269  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:44,318  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:44,318  INFO [main] mapreduce.Job: Running job: job_local856801264_0019
2024-04-30T20:25:44,318  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:44,320  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:44,321  INFO [Thread-779] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:44,321  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local856801264_0019_m_000000_0
2024-04-30T20:25:44,324  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:44,325  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-30T20:25:44,328  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local856801264_0019_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.25950620611653685/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-30T20:25:44,329  INFO [Thread-779] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:44,330  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.25950620611653685].
2024-04-30T20:25:44,330  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:44,368  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:44,368  INFO [Thread-779] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:44,369  INFO [Thread-779] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:44,369  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,370  INFO [Thread-779] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:44,370  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f2f5d2b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,370  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f2f5d2b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4dd13f6b created in the thread with id: 835
2024-04-30T20:25:44,371  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f2f5d2b from thread id: 835
2024-04-30T20:25:44,371  INFO [Thread-779] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:44,372  INFO [Thread-779] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:44,372  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:44,372  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f2f5d2b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4dd13f6b will be shutdown
2024-04-30T20:25:44,372  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:44,372  INFO [Thread-779] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -76
2024-04-30T20:25:44,372  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:44,373  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:44,373  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f39e36f, with PersistenceManager: null will be shutdown
2024-04-30T20:25:44,373  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f39e36f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e05937c created in the thread with id: 835
2024-04-30T20:25:44,375  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f39e36f from thread id: 835
2024-04-30T20:25:44,376  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:44,376  WARN [Thread-779] mapred.LocalJobRunner: job_local856801264_0019
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-30T20:25:45,318  INFO [main] mapreduce.Job: Job job_local856801264_0019 running in uber mode : false
2024-04-30T20:25:45,319  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:45,319  INFO [main] mapreduce.Job: Job job_local856801264_0019 failed with state FAILED due to: NA
2024-04-30T20:25:45,319  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:45,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:45,356  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:45,356  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:45,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:45,356  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:45,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:45,357  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:45,357  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:45,357  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:45,357  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:45,357  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:45,357  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:45,358  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:45,359  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:45,359  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:45,359  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42718ebf will be shutdown
2024-04-30T20:25:45,360  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58d635de created in the thread with id: 1
2024-04-30T20:25:45,361  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:45,361  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:45,362  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:45,362  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58d635de will be shutdown
2024-04-30T20:25:45,362  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:45,362  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -77
2024-04-30T20:25:45,362  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:45,362  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:45,363  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: null will be shutdown
2024-04-30T20:25:45,363  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@205d6f84 created in the thread with id: 1
2024-04-30T20:25:45,365  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444 from thread id: 1
2024-04-30T20:25:45,366  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:45,372  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:45,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:45,376  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:45,382  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:45,387  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:45,408  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-30T20:25:45,423  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local35218136_0020
2024-04-30T20:25:45,423  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:45,471  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:45,471  INFO [main] mapreduce.Job: Running job: job_local35218136_0020
2024-04-30T20:25:45,471  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:45,472  INFO [Thread-799] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:45,472  INFO [Thread-799] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:45,472  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-30T20:25:45,480  INFO [Thread-799] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:45,480  INFO [Thread-799] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:46,472  INFO [main] mapreduce.Job: Job job_local35218136_0020 running in uber mode : false
2024-04-30T20:25:46,472  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:46,472  INFO [main] mapreduce.Job: Job job_local35218136_0020 completed successfully
2024-04-30T20:25:46,472  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:46,472  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:46,477  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:46,477  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-30T20:25:46,525  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,525  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,525  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,525  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,525  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,526  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[4]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-04-30T20:25:46,565  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,565  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,565  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,565  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,565  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,565  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,566  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,566  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,566  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,566  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,566  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:46,568  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:46,568  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:46,568  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@205d6f84 will be shutdown
2024-04-30T20:25:46,568  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d4b09c7 created in the thread with id: 1
2024-04-30T20:25:46,571  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 68528f15-ccea-4c22-b985-1d60549106c8
2024-04-30T20:25:46,571  INFO [main] SessionState: Hive Session ID = 68528f15-ccea-4c22-b985-1d60549106c8
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:46,571  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:46,578  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/68528f15-ccea-4c22-b985-1d60549106c8
2024-04-30T20:25:46,580  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/68528f15-ccea-4c22-b985-1d60549106c8
2024-04-30T20:25:46,583  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/68528f15-ccea-4c22-b985-1d60549106c8/_tmp_space.db
2024-04-30T20:25:46,583  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_PARQUETFILE	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[5]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-04-30T20:25:46,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,621  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:46,622  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:46,622  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:46,622  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d4b09c7 will be shutdown
2024-04-30T20:25:46,623  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67887bf2 created in the thread with id: 1
2024-04-30T20:25:46,624  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = cb8c9c5e-24fd-42b5-b991-3fe6aced9f31
2024-04-30T20:25:46,624  INFO [main] SessionState: Hive Session ID = cb8c9c5e-24fd-42b5-b991-3fe6aced9f31
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:46,625  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:46,630  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/cb8c9c5e-24fd-42b5-b991-3fe6aced9f31
2024-04-30T20:25:46,633  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/cb8c9c5e-24fd-42b5-b991-3fe6aced9f31
2024-04-30T20:25:46,635  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/cb8c9c5e-24fd-42b5-b991-3fe6aced9f31/_tmp_space.db
2024-04-30T20:25:46,635  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_AVRO	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[6]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.283">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,672  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:46,673  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:46,674  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:46,674  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67887bf2 will be shutdown
2024-04-30T20:25:46,674  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fae1ec9 created in the thread with id: 1
2024-04-30T20:25:46,676  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = c51ed6e6-0e31-4b88-a867-1e192e66d642
2024-04-30T20:25:46,676  INFO [main] SessionState: Hive Session ID = c51ed6e6-0e31-4b88-a867-1e192e66d642
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:46,676  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:46,682  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/c51ed6e6-0e31-4b88-a867-1e192e66d642
2024-04-30T20:25:46,684  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/c51ed6e6-0e31-4b88-a867-1e192e66d642
2024-04-30T20:25:46,687  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/c51ed6e6-0e31-4b88-a867-1e192e66d642/_tmp_space.db
2024-04-30T20:25:46,687  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:46,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_JSONFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_JSONFILE, serializationLib:org.apache.hadoop.hive.serde2.JsonSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-30T20:25:46,690  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile
2024-04-30T20:25:46,738  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,738  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,739  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:46,739  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:46,740  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:46,741  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:46,741  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:46,741  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fae1ec9 will be shutdown
2024-04-30T20:25:46,741  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64dc0a5f created in the thread with id: 1
2024-04-30T20:25:46,743  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:46,743  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:46,743  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:46,743  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64dc0a5f will be shutdown
2024-04-30T20:25:46,743  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:46,743  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -78
2024-04-30T20:25:46,744  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:46,744  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:46,744  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: null will be shutdown
2024-04-30T20:25:46,745  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50e336d9 created in the thread with id: 1
2024-04-30T20:25:46,746  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368 from thread id: 1
2024-04-30T20:25:46,747  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:46,752  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:46,763  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:46,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,790  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,791  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:46,791  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:46,792  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:46,792  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:46,792  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50e336d9 will be shutdown
2024-04-30T20:25:46,792  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7baf7a9d created in the thread with id: 1
2024-04-30T20:25:46,794  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:46,794  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:46,794  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:46,794  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2812368, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7baf7a9d will be shutdown
2024-04-30T20:25:46,794  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:46,794  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -79
2024-04-30T20:25:46,794  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:46,795  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:46,795  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c48bbf3, with PersistenceManager: null will be shutdown
2024-04-30T20:25:46,795  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c48bbf3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ac7927a created in the thread with id: 1
2024-04-30T20:25:46,796  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c48bbf3 from thread id: 1
2024-04-30T20:25:46,797  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value1,501]	
2024-04-30T20:25:46,808  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:46,812  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:46,813  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:46,831  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:46,846  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local718667670_0021
2024-04-30T20:25:46,846  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:46,892  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:46,892  INFO [main] mapreduce.Job: Running job: job_local718667670_0021
2024-04-30T20:25:46,893  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:46,894  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,894  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,895  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:46,895  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,895  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,907  INFO [Thread-841] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:46,907  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local718667670_0021_m_000000_0
2024-04-30T20:25:46,911  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,911  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,912  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,912  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,912  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:46,913  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-30T20:25:46,918  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,918  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,936  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:46,938  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local718667670_0021_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:46,938  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,938  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,942  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:46,942  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local718667670_0021_m_000000_0 is allowed to commit now
2024-04-30T20:25:46,942  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:46,942  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:46,951  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local718667670_0021_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,18207795779025637/part1=p1value1/part0=501
2024-04-30T20:25:46,952  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:46,952  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local718667670_0021_m_000000_0' done.
2024-04-30T20:25:46,952  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local718667670_0021_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10734277
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=842006528
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:46,952  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local718667670_0021_m_000000_0
2024-04-30T20:25:46,952  INFO [Thread-841] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:46,993  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:46,993  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:46,994  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:46,994  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:46,994  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:46,995  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38b81b2d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:46,995  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38b81b2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36141a96 created in the thread with id: 899
2024-04-30T20:25:46,997  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38b81b2d from thread id: 899
2024-04-30T20:25:46,997  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:46,997  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:46,997  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:46,997  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38b81b2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36141a96 will be shutdown
2024-04-30T20:25:46,997  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:46,997  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -80
2024-04-30T20:25:46,998  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:46,998  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:46,999  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55b34e68, with PersistenceManager: null will be shutdown
2024-04-30T20:25:46,999  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55b34e68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@684dd8bb created in the thread with id: 899
2024-04-30T20:25:47,001  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55b34e68 from thread id: 899
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:47,040  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:47,041  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:47,041  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:47,041  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=501, part1=p1value1}].
2024-04-30T20:25:47,062  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,18207795779025637/part1=p1value1/part0=501].
2024-04-30T20:25:47,062  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:47,120  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:47,120  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:47,121  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:47,121  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:47,121  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55b34e68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@684dd8bb will be shutdown
2024-04-30T20:25:47,121  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55b34e68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a50dab9 created in the thread with id: 899
2024-04-30T20:25:47,123  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:47,123  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:47,123  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:47,123  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55b34e68, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a50dab9 will be shutdown
2024-04-30T20:25:47,123  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:47,123  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -81
2024-04-30T20:25:47,123  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:47,124  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:47,124  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f725f1a, with PersistenceManager: null will be shutdown
2024-04-30T20:25:47,124  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f725f1a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b2e10e9 created in the thread with id: 899
2024-04-30T20:25:47,125  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f725f1a from thread id: 899
2024-04-30T20:25:47,126  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:47,126  WARN [Thread-841] mapred.LocalJobRunner: job_local718667670_0021
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,18207795779025637/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:47,893  INFO [main] mapreduce.Job: Job job_local718667670_0021 running in uber mode : false
2024-04-30T20:25:47,893  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:47,893  INFO [main] mapreduce.Job: Job job_local718667670_0021 failed with state FAILED due to: NA
2024-04-30T20:25:47,894  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10734277
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=842006528
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:47,937  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:47,938  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:47,938  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:47,939  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:47,941  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:47,941  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:47,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c48bbf3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ac7927a will be shutdown
2024-04-30T20:25:47,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c48bbf3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@297bbd41 created in the thread with id: 1
2024-04-30T20:25:47,944  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:47,944  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:47,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:47,945  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c48bbf3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@297bbd41 will be shutdown
2024-04-30T20:25:47,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:47,945  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -82
2024-04-30T20:25:47,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:47,946  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:47,946  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: null will be shutdown
2024-04-30T20:25:47,946  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@472d7f34 created in the thread with id: 1
2024-04-30T20:25:47,948  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6 from thread id: 1
2024-04-30T20:25:47,950  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:47,956  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:47,965  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:48,006  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:48,007  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:48,007  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:48,007  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:48,008  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@472d7f34 will be shutdown
2024-04-30T20:25:48,008  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16263fb2 created in the thread with id: 1
2024-04-30T20:25:48,009  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:48,009  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:48,010  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:48,010  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79864d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16263fb2 will be shutdown
2024-04-30T20:25:48,010  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:48,010  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -83
2024-04-30T20:25:48,010  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:48,011  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:48,011  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: null will be shutdown
2024-04-30T20:25:48,011  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62857555 created in the thread with id: 1
2024-04-30T20:25:48,012  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc from thread id: 1
2024-04-30T20:25:48,013  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-04-30T20:25:48,024  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:48,029  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:48,029  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:48,049  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:48,064  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1738357011_0022
2024-04-30T20:25:48,064  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:48,113  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:48,113  INFO [main] mapreduce.Job: Running job: job_local1738357011_0022
2024-04-30T20:25:48,113  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:48,115  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,115  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,116  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:48,116  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,116  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,130  INFO [Thread-887] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:48,130  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1738357011_0022_m_000000_0
2024-04-30T20:25:48,132  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,132  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,133  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,133  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,133  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:48,134  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:48,135  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,135  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,149  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:48,150  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1738357011_0022_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:48,150  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,150  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,153  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:48,153  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1738357011_0022_m_000000_0 is allowed to commit now
2024-04-30T20:25:48,153  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:48,154  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:48,163  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1738357011_0022_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5772417858373633/part1=p1value2/part0=502
2024-04-30T20:25:48,164  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:48,164  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1738357011_0022_m_000000_0' done.
2024-04-30T20:25:48,164  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1738357011_0022_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11247232
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:48,164  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1738357011_0022_m_000000_0
2024-04-30T20:25:48,164  INFO [Thread-887] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:48,213  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:48,213  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:48,214  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:48,214  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:48,214  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:48,214  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4302f9cd, with PersistenceManager: null will be shutdown
2024-04-30T20:25:48,215  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4302f9cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ecafa78 created in the thread with id: 947
2024-04-30T20:25:48,216  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4302f9cd from thread id: 947
2024-04-30T20:25:48,216  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:48,216  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:48,217  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:48,217  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4302f9cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ecafa78 will be shutdown
2024-04-30T20:25:48,217  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:48,217  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -84
2024-04-30T20:25:48,217  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:48,218  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:48,218  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d58204a, with PersistenceManager: null will be shutdown
2024-04-30T20:25:48,218  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d58204a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@72add6ec created in the thread with id: 947
2024-04-30T20:25:48,219  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d58204a from thread id: 947
2024-04-30T20:25:48,261  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:48,261  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:48,261  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:48,261  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:48,261  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:48,261  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:48,262  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:48,262  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:48,262  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:48,262  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:48,262  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:48,262  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:48,284  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5772417858373633/part1=p1value2/part0=502].
2024-04-30T20:25:48,284  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:48,322  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:48,322  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:48,323  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:48,323  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:48,323  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d58204a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@72add6ec will be shutdown
2024-04-30T20:25:48,323  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d58204a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@651a5af5 created in the thread with id: 947
2024-04-30T20:25:48,325  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:48,325  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:48,325  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:48,325  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d58204a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@651a5af5 will be shutdown
2024-04-30T20:25:48,325  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:48,325  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -85
2024-04-30T20:25:48,325  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:48,326  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:48,326  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@437a60d1, with PersistenceManager: null will be shutdown
2024-04-30T20:25:48,326  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@437a60d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d1a97b6 created in the thread with id: 947
2024-04-30T20:25:48,328  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@437a60d1 from thread id: 947
2024-04-30T20:25:48,328  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:48,328  WARN [Thread-887] mapred.LocalJobRunner: job_local1738357011_0022
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5772417858373633/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:49,113  INFO [main] mapreduce.Job: Job job_local1738357011_0022 running in uber mode : false
2024-04-30T20:25:49,114  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:49,114  INFO [main] mapreduce.Job: Job job_local1738357011_0022 failed with state FAILED due to: NA
2024-04-30T20:25:49,115  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11247232
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:49,159  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:49,159  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:49,160  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:49,162  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:49,162  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:49,163  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62857555 will be shutdown
2024-04-30T20:25:49,163  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ac9742e created in the thread with id: 1
2024-04-30T20:25:49,165  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:49,165  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:49,165  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:49,165  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a1143cc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ac9742e will be shutdown
2024-04-30T20:25:49,165  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:49,165  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -86
2024-04-30T20:25:49,165  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:49,166  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:49,167  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:49,167  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14ca4b4d created in the thread with id: 1
2024-04-30T20:25:49,168  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b from thread id: 1
2024-04-30T20:25:49,169  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:49,174  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:49,180  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:49,211  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:49,211  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:49,211  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:49,211  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:49,211  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:49,211  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:49,212  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:49,212  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:49,212  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:49,212  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:49,212  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:49,212  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:49,213  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:49,213  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:49,213  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14ca4b4d will be shutdown
2024-04-30T20:25:49,213  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73611fbb created in the thread with id: 1
2024-04-30T20:25:49,215  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:49,215  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:49,215  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:49,215  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f04349b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73611fbb will be shutdown
2024-04-30T20:25:49,215  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:49,215  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -87
2024-04-30T20:25:49,215  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:49,216  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:49,216  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: null will be shutdown
2024-04-30T20:25:49,216  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c61011b created in the thread with id: 1
2024-04-30T20:25:49,218  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2 from thread id: 1
2024-04-30T20:25:49,219  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-04-30T20:25:49,230  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:49,235  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:49,235  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:49,255  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:49,271  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local866958821_0023
2024-04-30T20:25:49,271  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:49,320  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:49,320  INFO [main] mapreduce.Job: Running job: job_local866958821_0023
2024-04-30T20:25:49,320  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:49,322  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,322  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,322  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:49,323  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,323  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,336  INFO [Thread-933] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:49,337  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local866958821_0023_m_000000_0
2024-04-30T20:25:49,338  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,339  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,340  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,340  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,340  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:49,340  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:49,342  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,342  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,356  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:49,356  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local866958821_0023_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:49,356  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,356  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,360  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:49,360  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local866958821_0023_m_000000_0 is allowed to commit now
2024-04-30T20:25:49,360  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:49,360  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:49,370  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local866958821_0023_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,09381414368408447/part1=p1value2/part0=502
2024-04-30T20:25:49,370  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:49,370  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local866958821_0023_m_000000_0' done.
2024-04-30T20:25:49,371  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local866958821_0023_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11757802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:49,371  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local866958821_0023_m_000000_0
2024-04-30T20:25:49,371  INFO [Thread-933] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:49,415  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:49,415  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:49,416  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:49,416  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:49,416  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:49,417  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30266fc2, with PersistenceManager: null will be shutdown
2024-04-30T20:25:49,417  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30266fc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c6fe297 created in the thread with id: 995
2024-04-30T20:25:49,418  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30266fc2 from thread id: 995
2024-04-30T20:25:49,418  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:49,418  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:49,418  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:49,419  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30266fc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c6fe297 will be shutdown
2024-04-30T20:25:49,419  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:49,419  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -88
2024-04-30T20:25:49,419  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:49,419  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:49,420  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3914d86e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:49,420  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3914d86e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ddd274f created in the thread with id: 995
2024-04-30T20:25:49,421  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3914d86e from thread id: 995
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:49,462  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:49,463  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:49,485  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,09381414368408447/part1=p1value2/part0=502].
2024-04-30T20:25:49,485  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:49,522  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:49,522  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:49,523  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:49,523  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:49,523  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3914d86e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@ddd274f will be shutdown
2024-04-30T20:25:49,523  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3914d86e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27e40d1 created in the thread with id: 995
2024-04-30T20:25:49,525  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:49,525  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:49,525  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:49,525  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3914d86e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27e40d1 will be shutdown
2024-04-30T20:25:49,525  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:49,525  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -89
2024-04-30T20:25:49,525  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:49,526  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:49,526  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@818982d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:49,526  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@818982d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c912762 created in the thread with id: 995
2024-04-30T20:25:49,528  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@818982d from thread id: 995
2024-04-30T20:25:49,528  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:49,528  WARN [Thread-933] mapred.LocalJobRunner: job_local866958821_0023
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,09381414368408447/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:49,940  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-30T20:25:50,320  INFO [main] mapreduce.Job: Job job_local866958821_0023 running in uber mode : false
2024-04-30T20:25:50,321  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:50,321  INFO [main] mapreduce.Job: Job job_local866958821_0023 failed with state FAILED due to: NA
2024-04-30T20:25:50,322  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11757802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=843055104
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:50,365  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:50,365  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:50,366  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:50,368  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:50,368  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:50,368  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c61011b will be shutdown
2024-04-30T20:25:50,368  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@cc81cb3 created in the thread with id: 1
2024-04-30T20:25:50,369  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:50,370  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:50,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:50,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac64dc2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@cc81cb3 will be shutdown
2024-04-30T20:25:50,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:50,370  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -90
2024-04-30T20:25:50,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:50,370  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e756b8d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e756b8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eda5325 created in the thread with id: 1
2024-04-30T20:25:50,372  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e756b8d from thread id: 1
2024-04-30T20:25:50,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:50,379  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:50,387  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:50,428  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:50,428  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:50,429  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:50,429  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:50,430  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e756b8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eda5325 will be shutdown
2024-04-30T20:25:50,430  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e756b8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d2d7a85 created in the thread with id: 1
2024-04-30T20:25:50,431  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:50,431  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:50,431  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:50,431  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e756b8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d2d7a85 will be shutdown
2024-04-30T20:25:50,432  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:50,432  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -91
2024-04-30T20:25:50,432  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:50,432  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,433  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d577add, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,433  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d577add, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@712adc04 created in the thread with id: 1
2024-04-30T20:25:50,434  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d577add from thread id: 1
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:50,478  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:50,479  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:50,479  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:50,479  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:50,479  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:50,479  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:50,480  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:50,481  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:50,481  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:50,481  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d577add, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@712adc04 will be shutdown
2024-04-30T20:25:50,481  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d577add, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b42eb0f created in the thread with id: 1
2024-04-30T20:25:50,483  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:50,483  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:50,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:50,483  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d577add, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b42eb0f will be shutdown
2024-04-30T20:25:50,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:50,483  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -92
2024-04-30T20:25:50,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:50,484  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,484  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2de3ac17, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,484  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2de3ac17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c683777 created in the thread with id: 1
2024-04-30T20:25:50,486  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2de3ac17 from thread id: 1
2024-04-30T20:25:50,486  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:50,491  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:50,536  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:50,536  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:50,537  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:50,539  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:50,539  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:50,539  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2de3ac17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c683777 will be shutdown
2024-04-30T20:25:50,539  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2de3ac17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f8c6694 created in the thread with id: 1
2024-04-30T20:25:50,541  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:50,542  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:50,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:50,542  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2de3ac17, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f8c6694 will be shutdown
2024-04-30T20:25:50,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:50,542  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -93
2024-04-30T20:25:50,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:50,543  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,543  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71f9f8ba, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,544  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71f9f8ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7685912e created in the thread with id: 1
2024-04-30T20:25:50,545  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71f9f8ba from thread id: 1
2024-04-30T20:25:50,546  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:50,553  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:50,559  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:50,591  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:50,592  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:50,592  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:50,592  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:50,593  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71f9f8ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7685912e will be shutdown
2024-04-30T20:25:50,593  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71f9f8ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f2a13c7 created in the thread with id: 1
2024-04-30T20:25:50,595  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:50,595  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:50,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:50,595  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71f9f8ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f2a13c7 will be shutdown
2024-04-30T20:25:50,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:50,595  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -94
2024-04-30T20:25:50,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:50,596  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,597  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62d10834, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,597  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62d10834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34f4fd04 created in the thread with id: 1
2024-04-30T20:25:50,599  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62d10834 from thread id: 1
2024-04-30T20:25:50,605  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:50,610  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:50,611  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:50,631  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:50,646  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2132560653_0024
2024-04-30T20:25:50,646  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:50,696  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:50,696  INFO [main] mapreduce.Job: Running job: job_local2132560653_0024
2024-04-30T20:25:50,696  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:50,698  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:50,700  INFO [Thread-984] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:50,700  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2132560653_0024_m_000000_0
2024-04-30T20:25:50,702  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:50,703  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-30T20:25:50,707  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local2132560653_0024_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.3275066012013029/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-30T20:25:50,707  INFO [Thread-984] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:50,709  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.3275066012013029].
2024-04-30T20:25:50,709  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:50,757  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:50,757  INFO [Thread-984] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:50,758  INFO [Thread-984] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:50,758  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,758  INFO [Thread-984] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:50,759  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a94265e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,759  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a94265e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f1f4bb8 created in the thread with id: 1048
2024-04-30T20:25:50,760  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a94265e from thread id: 1048
2024-04-30T20:25:50,760  INFO [Thread-984] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:50,760  INFO [Thread-984] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:50,760  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:50,761  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a94265e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f1f4bb8 will be shutdown
2024-04-30T20:25:50,761  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:50,761  INFO [Thread-984] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -95
2024-04-30T20:25:50,761  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:50,761  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:50,762  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cbc1075, with PersistenceManager: null will be shutdown
2024-04-30T20:25:50,762  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cbc1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c84135e created in the thread with id: 1048
2024-04-30T20:25:50,763  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cbc1075 from thread id: 1048
2024-04-30T20:25:50,764  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:50,764  WARN [Thread-984] mapred.LocalJobRunner: job_local2132560653_0024
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-30T20:25:51,696  INFO [main] mapreduce.Job: Job job_local2132560653_0024 running in uber mode : false
2024-04-30T20:25:51,697  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:51,697  INFO [main] mapreduce.Job: Job job_local2132560653_0024 failed with state FAILED due to: NA
2024-04-30T20:25:51,697  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:51,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:51,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:51,735  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:51,735  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:51,736  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:51,737  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:51,737  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:51,737  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62d10834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34f4fd04 will be shutdown
2024-04-30T20:25:51,737  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62d10834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32f35739 created in the thread with id: 1
2024-04-30T20:25:51,739  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:51,739  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:51,739  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:51,739  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62d10834, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32f35739 will be shutdown
2024-04-30T20:25:51,739  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:51,739  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -96
2024-04-30T20:25:51,739  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:51,740  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:51,740  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: null will be shutdown
2024-04-30T20:25:51,741  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16bed816 created in the thread with id: 1
2024-04-30T20:25:51,742  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6 from thread id: 1
2024-04-30T20:25:51,743  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:51,747  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:51,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:51,751  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:51,757  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:51,762  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:51,783  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-30T20:25:51,798  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local890946836_0025
2024-04-30T20:25:51,798  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:51,846  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:51,846  INFO [main] mapreduce.Job: Running job: job_local890946836_0025
2024-04-30T20:25:51,846  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:51,846  INFO [Thread-1004] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:51,846  INFO [Thread-1004] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:51,847  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-30T20:25:51,855  INFO [Thread-1004] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:51,855  INFO [Thread-1004] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:52,846  INFO [main] mapreduce.Job: Job job_local890946836_0025 running in uber mode : false
2024-04-30T20:25:52,847  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:52,847  INFO [main] mapreduce.Job: Job job_local890946836_0025 completed successfully
2024-04-30T20:25:52,847  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:52,847  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:52,853  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:52,853  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:52,915  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[7]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.328">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:52,959  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:52,960  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:52,960  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:52,961  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16bed816 will be shutdown
2024-04-30T20:25:52,961  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37905236 created in the thread with id: 1
2024-04-30T20:25:52,962  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = aa40b380-49f1-4808-91f6-0c69a5b3667d
2024-04-30T20:25:52,962  INFO [main] SessionState: Hive Session ID = aa40b380-49f1-4808-91f6-0c69a5b3667d
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:52,963  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-30T20:25:52,969  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/aa40b380-49f1-4808-91f6-0c69a5b3667d
2024-04-30T20:25:52,971  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/aa40b380-49f1-4808-91f6-0c69a5b3667d
2024-04-30T20:25:52,974  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/aa40b380-49f1-4808-91f6-0c69a5b3667d/_tmp_space.db
2024-04-30T20:25:52,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:52,976  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_rcfile_columnar, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_rcfile_columnar, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-30T20:25:52,978  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:53,071  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:53,072  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:53,072  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:53,074  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:53,074  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:53,074  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37905236 will be shutdown
2024-04-30T20:25:53,074  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@51a4472d created in the thread with id: 1
2024-04-30T20:25:53,076  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:53,076  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:53,076  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:53,076  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b6a9ef6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@51a4472d will be shutdown
2024-04-30T20:25:53,076  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:53,076  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -97
2024-04-30T20:25:53,076  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:53,077  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:53,077  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:53,077  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d91e9c9 created in the thread with id: 1
2024-04-30T20:25:53,078  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b from thread id: 1
2024-04-30T20:25:53,079  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:53,083  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:53,089  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:53,122  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:53,122  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:53,123  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:53,123  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:53,123  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d91e9c9 will be shutdown
2024-04-30T20:25:53,123  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6aa16117 created in the thread with id: 1
2024-04-30T20:25:53,124  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:53,125  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:53,125  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:53,125  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2044a11b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6aa16117 will be shutdown
2024-04-30T20:25:53,125  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:53,125  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -98
2024-04-30T20:25:53,125  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:53,126  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:53,126  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: null will be shutdown
2024-04-30T20:25:53,126  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56b4951a created in the thread with id: 1
2024-04-30T20:25:53,127  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e from thread id: 1
2024-04-30T20:25:53,128  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value1,501]	
2024-04-30T20:25:53,140  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:53,145  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:53,145  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:53,165  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:53,182  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local902620174_0026
2024-04-30T20:25:53,182  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:53,230  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:53,231  INFO [main] mapreduce.Job: Running job: job_local902620174_0026
2024-04-30T20:25:53,231  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:53,233  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,233  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,233  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:53,234  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,234  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,247  INFO [Thread-1038] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:53,247  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local902620174_0026_m_000000_0
2024-04-30T20:25:53,252  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,252  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,253  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,253  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,253  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:53,253  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-30T20:25:53,259  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,259  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,272  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:53,272  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-04-30T20:25:53,272  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-04-30T20:25:53,274  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local902620174_0026_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:53,274  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,274  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,278  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:53,278  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local902620174_0026_m_000000_0 is allowed to commit now
2024-04-30T20:25:53,278  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:53,278  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:53,289  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local902620174_0026_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7959477094539501/part1=p1value1/part0=501
2024-04-30T20:25:53,289  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:53,289  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local902620174_0026_m_000000_0' done.
2024-04-30T20:25:53,289  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local902620174_0026_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13289344
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879230976
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:53,289  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local902620174_0026_m_000000_0
2024-04-30T20:25:53,289  INFO [Thread-1038] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:53,333  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:53,333  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:53,334  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:53,335  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:53,335  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:53,335  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cf7581a, with PersistenceManager: null will be shutdown
2024-04-30T20:25:53,335  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cf7581a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@348fa8b9 created in the thread with id: 1104
2024-04-30T20:25:53,338  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cf7581a from thread id: 1104
2024-04-30T20:25:53,338  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:53,338  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:53,338  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:53,338  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cf7581a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@348fa8b9 will be shutdown
2024-04-30T20:25:53,338  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:53,339  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -99
2024-04-30T20:25:53,339  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:53,340  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:53,340  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bbf0a04, with PersistenceManager: null will be shutdown
2024-04-30T20:25:53,340  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bbf0a04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15f3e0c2 created in the thread with id: 1104
2024-04-30T20:25:53,342  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bbf0a04 from thread id: 1104
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:53,384  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:53,384  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=501, part1=p1value1}].
2024-04-30T20:25:53,406  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7959477094539501/part1=p1value1/part0=501].
2024-04-30T20:25:53,407  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:53,442  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:53,443  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:53,443  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:53,443  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:53,443  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:53,443  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:53,444  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bbf0a04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15f3e0c2 will be shutdown
2024-04-30T20:25:53,444  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bbf0a04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4070a98e created in the thread with id: 1104
2024-04-30T20:25:53,445  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:53,446  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:53,446  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:53,446  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bbf0a04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4070a98e will be shutdown
2024-04-30T20:25:53,446  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:53,446  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -100
2024-04-30T20:25:53,446  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:53,447  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:53,447  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47ef3f2, with PersistenceManager: null will be shutdown
2024-04-30T20:25:53,447  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47ef3f2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77a2434 created in the thread with id: 1104
2024-04-30T20:25:53,448  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47ef3f2 from thread id: 1104
2024-04-30T20:25:53,449  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:53,449  WARN [Thread-1038] mapred.LocalJobRunner: job_local902620174_0026
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7959477094539501/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:54,231  INFO [main] mapreduce.Job: Job job_local902620174_0026 running in uber mode : false
2024-04-30T20:25:54,231  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:54,231  INFO [main] mapreduce.Job: Job job_local902620174_0026 failed with state FAILED due to: NA
2024-04-30T20:25:54,232  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13289344
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879230976
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:54,278  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:54,279  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:54,279  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:54,280  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:54,281  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:54,281  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56b4951a will be shutdown
2024-04-30T20:25:54,281  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b4133d0 created in the thread with id: 1
2024-04-30T20:25:54,282  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:54,283  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:54,283  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:54,283  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b4133d0 will be shutdown
2024-04-30T20:25:54,283  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:54,283  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -101
2024-04-30T20:25:54,283  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:54,284  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:54,284  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: null will be shutdown
2024-04-30T20:25:54,284  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c8ab21f created in the thread with id: 1
2024-04-30T20:25:54,286  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f from thread id: 1
2024-04-30T20:25:54,286  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:54,291  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:54,296  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:54,329  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:54,330  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:54,330  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:54,330  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:54,330  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:54,330  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:54,330  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:54,331  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:54,331  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c8ab21f will be shutdown
2024-04-30T20:25:54,331  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6142b9dd created in the thread with id: 1
2024-04-30T20:25:54,332  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:54,332  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:54,333  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:54,333  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6142b9dd will be shutdown
2024-04-30T20:25:54,333  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:54,333  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -102
2024-04-30T20:25:54,333  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:54,334  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:54,334  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: null will be shutdown
2024-04-30T20:25:54,334  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27d6ff8c created in the thread with id: 1
2024-04-30T20:25:54,336  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6 from thread id: 1
2024-04-30T20:25:54,337  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-04-30T20:25:54,347  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:54,352  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:54,352  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:54,373  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:54,389  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local96674696_0027
2024-04-30T20:25:54,389  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:54,436  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:54,437  INFO [main] mapreduce.Job: Running job: job_local96674696_0027
2024-04-30T20:25:54,437  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:54,438  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,438  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,439  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:54,439  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,439  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,452  INFO [Thread-1084] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:54,453  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local96674696_0027_m_000000_0
2024-04-30T20:25:54,454  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,454  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,455  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,455  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,456  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:54,456  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:54,457  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,458  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,471  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:54,471  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-04-30T20:25:54,471  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-30T20:25:54,471  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local96674696_0027_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:54,471  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,471  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,475  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:54,475  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local96674696_0027_m_000000_0 is allowed to commit now
2024-04-30T20:25:54,475  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:54,475  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:54,485  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local96674696_0027_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,542136759179/part1=p1value2/part0=502
2024-04-30T20:25:54,486  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:54,486  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local96674696_0027_m_000000_0' done.
2024-04-30T20:25:54,486  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local96674696_0027_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13797836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879230976
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:54,486  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local96674696_0027_m_000000_0
2024-04-30T20:25:54,486  INFO [Thread-1084] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:54,529  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:54,530  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:54,530  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:54,531  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:54,531  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:54,531  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2962bde7, with PersistenceManager: null will be shutdown
2024-04-30T20:25:54,531  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2962bde7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8ad809 created in the thread with id: 1152
2024-04-30T20:25:54,532  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2962bde7 from thread id: 1152
2024-04-30T20:25:54,532  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:54,533  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:54,533  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:54,533  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2962bde7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8ad809 will be shutdown
2024-04-30T20:25:54,533  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:54,533  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -103
2024-04-30T20:25:54,533  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:54,534  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:54,534  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@723399e7, with PersistenceManager: null will be shutdown
2024-04-30T20:25:54,534  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@723399e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ef4a272 created in the thread with id: 1152
2024-04-30T20:25:54,536  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@723399e7 from thread id: 1152
2024-04-30T20:25:54,577  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:54,577  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:54,577  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:54,577  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:54,577  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:54,577  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:54,578  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:54,578  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:54,578  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:54,578  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:54,578  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:54,578  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:54,599  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,542136759179/part1=p1value2/part0=502].
2024-04-30T20:25:54,600  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:54,636  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:54,637  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:54,637  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:54,638  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:54,638  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:54,638  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@723399e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ef4a272 will be shutdown
2024-04-30T20:25:54,638  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@723399e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21e0e5be created in the thread with id: 1152
2024-04-30T20:25:54,640  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:54,640  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:54,640  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:54,640  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@723399e7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21e0e5be will be shutdown
2024-04-30T20:25:54,640  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:54,640  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -104
2024-04-30T20:25:54,640  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:54,641  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:54,641  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b2497ae, with PersistenceManager: null will be shutdown
2024-04-30T20:25:54,641  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b2497ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d21117f created in the thread with id: 1152
2024-04-30T20:25:54,643  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b2497ae from thread id: 1152
2024-04-30T20:25:54,643  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:54,644  WARN [Thread-1084] mapred.LocalJobRunner: job_local96674696_0027
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,542136759179/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:55,437  INFO [main] mapreduce.Job: Job job_local96674696_0027 running in uber mode : false
2024-04-30T20:25:55,437  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:55,437  INFO [main] mapreduce.Job: Job job_local96674696_0027 failed with state FAILED due to: NA
2024-04-30T20:25:55,438  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13797836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879230976
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:55,482  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:55,482  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:55,483  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:55,485  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:55,485  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:55,485  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27d6ff8c will be shutdown
2024-04-30T20:25:55,485  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@441e789e created in the thread with id: 1
2024-04-30T20:25:55,487  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:55,487  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:55,487  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:55,487  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@441e789e will be shutdown
2024-04-30T20:25:55,487  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:55,487  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -105
2024-04-30T20:25:55,488  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:55,488  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:55,489  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: null will be shutdown
2024-04-30T20:25:55,489  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8174ce created in the thread with id: 1
2024-04-30T20:25:55,491  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b from thread id: 1
2024-04-30T20:25:55,492  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:55,497  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:55,503  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:55,543  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:55,544  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:55,544  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:55,544  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:55,544  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:55,544  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:55,544  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:55,544  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:55,545  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8174ce will be shutdown
2024-04-30T20:25:55,545  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ba056ab created in the thread with id: 1
2024-04-30T20:25:55,546  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:55,546  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:55,546  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:55,546  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ba056ab will be shutdown
2024-04-30T20:25:55,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:55,547  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -106
2024-04-30T20:25:55,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:55,547  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:55,547  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: null will be shutdown
2024-04-30T20:25:55,548  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61ce2d47 created in the thread with id: 1
2024-04-30T20:25:55,549  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698 from thread id: 1
2024-04-30T20:25:55,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-04-30T20:25:55,560  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:55,565  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:55,565  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:55,585  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:55,600  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local893426966_0028
2024-04-30T20:25:55,601  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:55,648  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:55,648  INFO [main] mapreduce.Job: Running job: job_local893426966_0028
2024-04-30T20:25:55,648  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:55,650  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,650  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,650  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:55,651  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,651  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,665  INFO [Thread-1130] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:55,665  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local893426966_0028_m_000000_0
2024-04-30T20:25:55,667  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,667  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,668  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,668  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,668  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:55,669  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-30T20:25:55,670  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,670  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,683  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:55,683  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-04-30T20:25:55,683  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-30T20:25:55,683  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local893426966_0028_m_000000_0 is done. And is in the process of committing
2024-04-30T20:25:55,683  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,683  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,687  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:25:55,687  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local893426966_0028_m_000000_0 is allowed to commit now
2024-04-30T20:25:55,688  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:55,688  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:55,698  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local893426966_0028_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,6592938447826774/part1=p1value2/part0=502
2024-04-30T20:25:55,698  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:25:55,698  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local893426966_0028_m_000000_0' done.
2024-04-30T20:25:55,698  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local893426966_0028_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14308748
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879230976
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:55,698  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local893426966_0028_m_000000_0
2024-04-30T20:25:55,698  INFO [Thread-1130] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:55,741  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:55,742  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:55,742  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:55,743  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:55,743  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:55,743  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:55,743  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49ba5b8f, with PersistenceManager: null will be shutdown
2024-04-30T20:25:55,743  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49ba5b8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b884d3e created in the thread with id: 1200
2024-04-30T20:25:55,745  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49ba5b8f from thread id: 1200
2024-04-30T20:25:55,745  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:55,745  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:55,745  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:55,745  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@49ba5b8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b884d3e will be shutdown
2024-04-30T20:25:55,745  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:55,745  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -107
2024-04-30T20:25:55,745  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:55,746  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:55,746  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b3cc2d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:55,746  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b3cc2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c8054d0 created in the thread with id: 1200
2024-04-30T20:25:55,747  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b3cc2d from thread id: 1200
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:55,788  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:55,789  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-04-30T20:25:55,810  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,6592938447826774/part1=p1value2/part0=502].
2024-04-30T20:25:55,811  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:55,847  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:55,847  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:55,847  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:55,847  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:55,847  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:55,847  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:55,848  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:55,848  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:55,848  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:55,848  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:55,848  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:55,848  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:55,848  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:55,848  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:55,849  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b3cc2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c8054d0 will be shutdown
2024-04-30T20:25:55,849  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b3cc2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10c62d89 created in the thread with id: 1200
2024-04-30T20:25:55,850  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:55,850  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:55,850  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:55,850  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24b3cc2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10c62d89 will be shutdown
2024-04-30T20:25:55,851  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:55,851  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -108
2024-04-30T20:25:55,851  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:55,851  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:55,852  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55101a6d, with PersistenceManager: null will be shutdown
2024-04-30T20:25:55,852  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55101a6d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10f97b69 created in the thread with id: 1200
2024-04-30T20:25:55,853  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55101a6d from thread id: 1200
2024-04-30T20:25:55,854  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:55,854  WARN [Thread-1130] mapred.LocalJobRunner: job_local893426966_0028
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,6592938447826774/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:25:56,323  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-30T20:25:56,649  INFO [main] mapreduce.Job: Job job_local893426966_0028 running in uber mode : false
2024-04-30T20:25:56,649  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-30T20:25:56,649  INFO [main] mapreduce.Job: Job job_local893426966_0028 failed with state FAILED due to: NA
2024-04-30T20:25:56,649  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14308748
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=879230976
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:56,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:56,693  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:56,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:56,693  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:56,693  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:56,694  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:56,695  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:56,695  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:56,695  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61ce2d47 will be shutdown
2024-04-30T20:25:56,695  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14021c10 created in the thread with id: 1
2024-04-30T20:25:56,697  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:56,697  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:56,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:56,697  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14021c10 will be shutdown
2024-04-30T20:25:56,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:56,697  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -109
2024-04-30T20:25:56,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:56,698  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:56,698  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: null will be shutdown
2024-04-30T20:25:56,698  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5655d64 created in the thread with id: 1
2024-04-30T20:25:56,699  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289 from thread id: 1
2024-04-30T20:25:56,700  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:56,704  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:56,709  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:56,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:56,741  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:56,741  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:56,742  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:56,742  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:56,742  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5655d64 will be shutdown
2024-04-30T20:25:56,742  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b24fcba created in the thread with id: 1
2024-04-30T20:25:56,744  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:56,744  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:56,744  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:56,744  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b24fcba will be shutdown
2024-04-30T20:25:56,744  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:56,744  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -110
2024-04-30T20:25:56,744  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:56,745  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:56,745  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: null will be shutdown
2024-04-30T20:25:56,745  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54353bb1 created in the thread with id: 1
2024-04-30T20:25:56,746  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2 from thread id: 1
2024-04-30T20:25:56,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:56,790  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:56,790  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:56,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:56,790  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:56,790  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:56,791  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:56,791  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:56,791  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:56,791  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:56,791  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:56,791  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:56,792  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:56,793  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:56,793  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:56,794  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54353bb1 will be shutdown
2024-04-30T20:25:56,794  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2627da4c created in the thread with id: 1
2024-04-30T20:25:56,795  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:56,795  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:56,795  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:56,795  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@631ff7a2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2627da4c will be shutdown
2024-04-30T20:25:56,796  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:56,796  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -111
2024-04-30T20:25:56,796  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:56,796  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:56,797  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: null will be shutdown
2024-04-30T20:25:56,797  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@228f15de created in the thread with id: 1
2024-04-30T20:25:56,798  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770 from thread id: 1
2024-04-30T20:25:56,799  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:56,804  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:56,847  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:56,848  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:56,848  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:56,850  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:56,850  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:56,850  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@228f15de will be shutdown
2024-04-30T20:25:56,851  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14c5d220 created in the thread with id: 1
2024-04-30T20:25:56,852  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:56,852  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:56,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:56,852  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c4ef770, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14c5d220 will be shutdown
2024-04-30T20:25:56,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:56,852  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -112
2024-04-30T20:25:56,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:56,853  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:56,853  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: null will be shutdown
2024-04-30T20:25:56,854  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ea4abef created in the thread with id: 1
2024-04-30T20:25:56,855  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3 from thread id: 1
2024-04-30T20:25:56,856  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:56,859  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:56,864  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:56,895  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:56,895  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:56,895  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:56,895  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:56,895  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:56,895  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:56,896  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:56,896  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:56,896  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:56,896  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:56,896  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:56,896  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:56,897  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:56,897  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:56,897  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ea4abef will be shutdown
2024-04-30T20:25:56,897  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@721e5f57 created in the thread with id: 1
2024-04-30T20:25:56,899  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:56,899  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:56,899  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:56,899  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a080ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@721e5f57 will be shutdown
2024-04-30T20:25:56,899  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:56,899  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -113
2024-04-30T20:25:56,899  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:56,900  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:56,900  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: null will be shutdown
2024-04-30T20:25:56,900  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@bcf8bd7 created in the thread with id: 1
2024-04-30T20:25:56,902  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2 from thread id: 1
2024-04-30T20:25:56,907  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:56,912  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:56,913  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:25:56,933  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:25:56,948  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2019430067_0029
2024-04-30T20:25:56,948  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:56,997  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:56,997  INFO [main] mapreduce.Job: Running job: job_local2019430067_0029
2024-04-30T20:25:56,997  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:56,999  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-30T20:25:57,000  INFO [Thread-1181] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:57,000  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2019430067_0029_m_000000_0
2024-04-30T20:25:57,002  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:25:57,002  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-30T20:25:57,006  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local2019430067_0029_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.5101858079463654/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-30T20:25:57,006  INFO [Thread-1181] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:57,008  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.5101858079463654].
2024-04-30T20:25:57,008  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:57,046  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:57,046  INFO [Thread-1181] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-30T20:25:57,047  INFO [Thread-1181] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:57,047  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:57,047  INFO [Thread-1181] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:57,048  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4590ac16, with PersistenceManager: null will be shutdown
2024-04-30T20:25:57,048  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4590ac16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44eeb00d created in the thread with id: 1253
2024-04-30T20:25:57,049  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4590ac16 from thread id: 1253
2024-04-30T20:25:57,049  INFO [Thread-1181] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:57,049  INFO [Thread-1181] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:57,050  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:57,050  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4590ac16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44eeb00d will be shutdown
2024-04-30T20:25:57,050  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:57,050  INFO [Thread-1181] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -114
2024-04-30T20:25:57,050  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:57,050  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:57,051  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b8c14c, with PersistenceManager: null will be shutdown
2024-04-30T20:25:57,051  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b8c14c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c2f94e6 created in the thread with id: 1253
2024-04-30T20:25:57,052  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b8c14c from thread id: 1253
2024-04-30T20:25:57,053  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-30T20:25:57,053  WARN [Thread-1181] mapred.LocalJobRunner: job_local2019430067_0029
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-30T20:25:57,997  INFO [main] mapreduce.Job: Job job_local2019430067_0029 running in uber mode : false
2024-04-30T20:25:57,997  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:57,998  INFO [main] mapreduce.Job: Job job_local2019430067_0029 failed with state FAILED due to: NA
2024-04-30T20:25:57,998  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:58,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:58,037  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:58,037  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-30T20:25:58,037  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-30T20:25:58,038  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-30T20:25:58,040  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:25:58,040  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:25:58,040  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@bcf8bd7 will be shutdown
2024-04-30T20:25:58,040  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@660dcd17 created in the thread with id: 1
2024-04-30T20:25:58,042  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:25:58,042  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:25:58,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:25:58,042  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@15d844b2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@660dcd17 will be shutdown
2024-04-30T20:25:58,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:25:58,042  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -115
2024-04-30T20:25:58,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-30T20:25:58,043  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:25:58,044  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a5b8f77, with PersistenceManager: null will be shutdown
2024-04-30T20:25:58,044  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a5b8f77, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@385ff04e created in the thread with id: 1
2024-04-30T20:25:58,045  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1a5b8f77 from thread id: 1
2024-04-30T20:25:58,046  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:58,050  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:58,050  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:58,054  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:25:58,059  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:25:58,065  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:25:58,117  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-30T20:25:58,134  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1755601787_0030
2024-04-30T20:25:58,134  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:25:58,185  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:25:58,185  INFO [main] mapreduce.Job: Running job: job_local1755601787_0030
2024-04-30T20:25:58,185  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-30T20:25:58,185  INFO [Thread-1201] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-30T20:25:58,185  INFO [Thread-1201] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-30T20:25:58,185  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-30T20:25:58,193  INFO [Thread-1201] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:25:58,193  INFO [Thread-1201] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:25:59,185  INFO [main] mapreduce.Job: Job job_local1755601787_0030 running in uber mode : false
2024-04-30T20:25:59,185  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-30T20:25:59,185  INFO [main] mapreduce.Job: Job job_local1755601787_0030 completed successfully
2024-04-30T20:25:59,186  INFO [main] mapreduce.Job: Counters: 0
2024-04-30T20:25:59,186  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:59,190  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-30T20:25:59,190  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:25:59,242  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:25:59,243  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:25:59,243  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:25:59,243  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
</testsuite>