<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="18.178" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter3906107295944006842.jar /home/alex/Repositories/hive/service/target/surefire 2024-05-01T00-40-33_663-jvmRun1 surefire4854260135569878773tmp surefire_8122299708880721938099tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter3906107295944006842.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="14.229">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,076323 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4b520ea8
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,028469 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 894101
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-30T20:02:50.932-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/01-00:00:00.000, nextFileTime=2024/04/30-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/30-20:02:52.748, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/01-00:00:00.000, nextFileTime=2024/04/30-00:00:00.000, prevFileTime=2024/04/30-00:00:00.000, current=2024/04/30-20:02:52.749, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@157853da...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@157853da OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3a1dd365
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@3de8f619
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619] started OK.
2024-04-30T20:02:52,850  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-30T20:02:53,302  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-30T20:02:53,380  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:02:53,380  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:02:53,381  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:02:53,381  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:02:53,381  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:02:53,381  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:02:53,382  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-30T20:02:53,383  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:02:53,383  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:02:53,383  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:02:53,383  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:02:53,384  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 4ab9325d-c374-42b9-8336-caa82ed3387e
2024-04-30T20:02:53,420  INFO [main] SessionState: Hive Session ID = 4ab9325d-c374-42b9-8336-caa82ed3387e
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:02:53,433  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:02:53,777  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/4ab9325d-c374-42b9-8336-caa82ed3387e
2024-04-30T20:02:53,781  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/4ab9325d-c374-42b9-8336-caa82ed3387e
2024-04-30T20:02:53,784  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/4ab9325d-c374-42b9-8336-caa82ed3387e/_tmp_space.db
2024-04-30T20:02:53,807  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4ab9325d-c374-42b9-8336-caa82ed3387e, clientType=HIVESERVER2]
2024-04-30T20:02:53,863  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:02:54,079  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:02:54,115  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:02:54,123  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-30T20:02:54,123  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-30T20:02:54,146  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-30T20:02:54,150  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-30T20:02:54,848  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-30T20:02:54,852  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-30T20:02:55,538  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-30T20:02:55,538  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: null will be shutdown
2024-04-30T20:02:55,563  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f created in the thread with id: 1
2024-04-30T20:02:58,385  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-30T20:02:58,385  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-30T20:02:58,385  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64 from thread id: 1
2024-04-30T20:02:58,531  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-30T20:02:58,567  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-30T20:02:58,597  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-30T20:02:58,598  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-30T20:02:58,697  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-30T20:02:58,703  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-30T20:02:58,704  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-30T20:02:58,707  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-30T20:02:58,732  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-30T20:02:58,734  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-30T20:02:58,736  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-30T20:02:58,737  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-30T20:02:58,738  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-30T20:02:58,740  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-30T20:02:58,742  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-30T20:02:58,743  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-30T20:02:58,749  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-30T20:02:58,750  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-30T20:02:58,751  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-30T20:02:58,755  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:02:58,904  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:02:59,431  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,436  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,440  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,441  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,441  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,442  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,443  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-30T20:02:59,492  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-30T20:02:59,493  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-30T20:02:59,493  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-30T20:02:59,494  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-30T20:02:59,495  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-30T20:02:59,497  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-04-30T20:02:59,504  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-04-30T20:02:59,518  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-30T20:02:59,518  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-30T20:02:59,519  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-30T20:02:59,519  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-30T20:02:59,519  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-30T20:02:59,520  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-30T20:02:59,543  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-30T20:02:59,548  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:02:59,554  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:02:59,565  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/acb24ed1-3bbd-4b8a-a58c-680a3715469b
2024-04-30T20:02:59,569  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b
2024-04-30T20:02:59,574  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/acb24ed1-3bbd-4b8a-a58c-680a3715469b/_tmp_space.db
2024-04-30T20:02:59,577  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-30T20:02:59,577  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-30T20:02:59,579  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:02:59,579  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:02:59,581  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f will be shutdown
2024-04-30T20:02:59,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 created in the thread with id: 1
2024-04-30T20:02:59,596  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:02:59,597  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:02:59,599  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-30T20:02:59,654  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:02:59,654  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4faf1f4 will be shutdown
2024-04-30T20:02:59,654  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:02:59,655  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-30T20:02:59,656  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b
2024-04-30T20:02:59,658  INFO [main] service.CompositeService: Session opened, SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b], current sessions:1
2024-04-30T20:02:59,664  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-30T20:02:59,670  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:02:59,688  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b378f5e8-6cd0-45f6-82c6-7ff33cfd1f1a] SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b]
2024-04-30T20:02:59,692  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08.test
2024-04-30T20:02:59,704  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08, startTime=1714532579684, sessionId=acb24ed1-3bbd-4b8a-a58c-680a3715469b, createTime=1714532579551, userName=anonymous, ipAddress=null]
2024-04-30T20:02:59,761  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Compiling command(queryId=alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08): select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:00,464  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:03:00,466  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: null will be shutdown
2024-04-30T20:03:00,467  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 created in the thread with id: 1
2024-04-30T20:03:00,475  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d from thread id: 1
2024-04-30T20:03:00,675  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] reflections.Reflections: Reflections took 164 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-30T20:03:00,815  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] reflections.Reflections: Reflections took 99 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-30T20:03:00,927  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] reflections.Reflections: Reflections took 104 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-30T20:03:01,017  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
2024-04-30T20:03:01,020  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:01,020  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=acb24ed1-3bbd-4b8a-a58c-680a3715469b, clientType=HIVESERVER2]
2024-04-30T20:03:01,023  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:01,023  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:01,023  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:01,028  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:01,038  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:02,321  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:02,921  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:02,925  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:02,936  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:02,936  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:02,978  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001/.hive-staging_hive_2024-04-30_20-02-59_727_233255231666187559-1
2024-04-30T20:03:03,020  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:03,096  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:03,116  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:03,185  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:03,192  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:03,192  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:03,192  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:03,192  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:03,192  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:03,192  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:03,195  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:03,195  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
2024-04-30T20:03:03,196  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:03,198  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:03,209  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:03,214  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:03,215  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=73, flushCache_()=13, getAllFunctions_()=55}
2024-04-30T20:03:03,215  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Completed compiling command(queryId=alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08); Time taken: 3.456 seconds
2024-04-30T20:03:03,216  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:03,217  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-30T20:03:03,223  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:03,227  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Executing command(queryId=alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:03,230  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-30T20:03:03,230  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:03,230  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001
2024-04-30T20:03:03,230  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001
2024-04-30T20:03:03,233  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
2024-04-30T20:03:03,233  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Query ID = alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
Total jobs = 1
2024-04-30T20:03:03,233  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:03,234  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:03,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:03,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:03,250  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:03,254  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:03,254  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/dummy_path
2024-04-30T20:03:03,341  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:03,367  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:03,510  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-30T20:03:03,528  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-30T20:03:03,543  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-30T20:03:03,543  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-30T20:03:03,567  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:03,618  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:03,627  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:03,631  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:03,632  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-30T20:03:03,640  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/dummy_path
2024-04-30T20:03:03,679  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:03,702  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:03,703  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:03,737  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:03,803  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1679779736_0001
2024-04-30T20:03:03,803  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:04,024  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:03:04,027  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-30T20:03:04,027  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:04,029  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:04,041  INFO [Thread-61] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:04,045  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1679779736_0001_m_000000_0
2024-04-30T20:03:04,088  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:04,097  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:04,103  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:04,128  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:04,136  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:04,143  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:04,145  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:04,148  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:04,148  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:04,151  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:04,152  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:04,153  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@a2d409, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@1f0d5e7c, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@29fdfa22
2024-04-30T20:03:04,160  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001/.hive-staging_hive_2024-04-30_20-02-59_727_233255231666187559-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:04,160  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001/.hive-staging_hive_2024-04-30_20-02-59_727_233255231666187559-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:04,160  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001/.hive-staging_hive_2024-04-30_20-02-59_727_233255231666187559-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:04,190  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-30T20:03:04,191  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-30T20:03:04,191  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:04,191  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-30T20:03:04,191  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:04,191  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:04,191  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:04,192  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:04,192  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:04,192  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:04,192  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-30T20:03:04,194  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-30T20:03:04,198  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:03:04,205  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1679779736_0001_m_000000_0 is done. And is in the process of committing
2024-04-30T20:03:04,206  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:03:04,207  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1679779736_0001_m_000000_0' done.
2024-04-30T20:03:04,208  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1679779736_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5576
		FILE: Number of bytes written=1157168
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=340
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=906493952
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:03:04,209  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1679779736_0001_m_000000_0
2024-04-30T20:03:04,209  INFO [Thread-61] mapred.LocalJobRunner: map task executor complete.
2024-04-30 20:03:05,042 Stage-1 map = 100%,  reduce = 0%
2024-04-30T20:03:05,042  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Task: 2024-04-30 20:03:05,042 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1679779736_0001
2024-04-30T20:03:05,046  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.Task: Ended Job = job_local1679779736_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:05,061  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-30T20:03:05,061  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:05,061  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001
2024-04-30T20:03:05,062  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1/-mr-10001
2024-04-30T20:03:05,062  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:05,062  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-30T20:03:05,063  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-30T20:03:05,071  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:05,071  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:05,071  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Completed executing command(queryId=alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08); Time taken: 1.835 seconds
2024-04-30T20:03:05,072  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:05,075  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,076  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=0d7172bc-5acf-49a4-9634-58db39e9b1c2] SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b]
2024-04-30T20:03:05,077  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37.test
2024-04-30T20:03:05,083  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37, startTime=1714532585076, sessionId=acb24ed1-3bbd-4b8a-a58c-680a3715469b, createTime=1714532579551, userName=anonymous, ipAddress=null]
2024-04-30T20:03:05,084  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Compiling command(queryId=alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,086  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37
2024-04-30T20:03:05,086  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:05,087  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:05,087  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,087  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,087  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,087  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:05,103  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,206  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,207  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,209  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,209  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,211  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1
2024-04-30T20:03:05,218  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:05,221  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:05,223  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:05,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:05,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:05,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:05,242  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:05,242  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:05,242  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-04-30T20:03:05,242  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Completed compiling command(queryId=alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37); Time taken: 0.158 seconds
2024-04-30T20:03:05,244  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:05,244  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,246  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Thread context registration is done.
2024-04-30T20:03:05,246  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=29799042-15c2-4aea-bd0e-199890275188] SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b]
2024-04-30T20:03:05,247  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:05,247  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd.test
2024-04-30T20:03:05,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd, startTime=1714532585245, sessionId=acb24ed1-3bbd-4b8a-a58c-680a3715469b, createTime=1714532579551, userName=anonymous, ipAddress=null]
2024-04-30T20:03:05,252  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:05,253  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,253  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-30T20:03:05,253  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:05,253  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:05,253  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Compiling command(queryId=alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001
2024-04-30T20:03:05,254  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001
2024-04-30T20:03:05,254  WARN [HiveServer2-Background-Pool: Thread-121] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37
2024-04-30T20:03:05,254  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Query ID = alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37
Total jobs = 1
2024-04-30T20:03:05,254  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:05,254  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,256  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:05,257  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,257  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,265  INFO [HiveServer2-Background-Pool: Thread-121] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:05,266  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:05,266  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/dummy_path
2024-04-30T20:03:05,273  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,280  INFO [HiveServer2-Background-Pool: Thread-121] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:05,284  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,286  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,291  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,299  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:05,307  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:05,308  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:05,309  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/dummy_path
2024-04-30T20:03:05,315  INFO [HiveServer2-Background-Pool: Thread-121] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:05,316  INFO [HiveServer2-Background-Pool: Thread-121] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:05,316  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:05,342  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:05,365  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,366  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,367  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Submitting tokens for job: job_local251267886_0002
2024-04-30T20:03:05,367  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:05,368  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,368  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,370  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1
2024-04-30T20:03:05,379  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:05,382  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:05,383  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:05,401  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:05,402  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:05,402  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd
2024-04-30T20:03:05,402  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:05,402  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:05,403  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:05,404  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:05,404  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-04-30T20:03:05,404  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Completed compiling command(queryId=alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd); Time taken: 0.15 seconds
2024-04-30T20:03:05,404  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:05,405  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Thread context registration is done.
2024-04-30T20:03:05,405  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,406  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:05,409  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:05,410  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,410  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=84999181-c8d8-4863-ba80-ae3fee57c3c3] SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b]
2024-04-30T20:03:05,410  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486.test
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))2024-04-30T20:03:05,414  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486, startTime=1714532585408, sessionId=acb24ed1-3bbd-4b8a-a58c-680a3715469b, createTime=1714532579551, userName=anonymous, ipAddress=null]

2024-04-30T20:03:05,414  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-30T20:03:05,415  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:05,415  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001
2024-04-30T20:03:05,415  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001
2024-04-30T20:03:05,415  WARN [HiveServer2-Background-Pool: Thread-156] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd2024-04-30T20:03:05,416  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Compiling command(queryId=alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486): select reflect("java.lang.Thread", "sleep", bigint(1000))

2024-04-30T20:03:05,416  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Query ID = alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd
Total jobs = 1
2024-04-30T20:03:05,416  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:05,416  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:05,419  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486
2024-04-30T20:03:05,419  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:05,419  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:05,420  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,420  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,420  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,420  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:05,421  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,421  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,430  INFO [HiveServer2-Background-Pool: Thread-156] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:05,431  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:05,431  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/dummy_path
2024-04-30T20:03:05,444  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,449  INFO [HiveServer2-Background-Pool: Thread-156] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:05,451  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,452  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,459  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,470  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:05,479  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:05,480  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:05,481  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/dummy_path
2024-04-30T20:03:05,488  INFO [HiveServer2-Background-Pool: Thread-156] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:05,488  INFO [HiveServer2-Background-Pool: Thread-156] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:05,488  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:05,493  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-30T20:03:05,494  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:05,494  INFO [Thread-111] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,495  INFO [Thread-111] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,498  INFO [Thread-111] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:05,501  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local251267886_0002_m_000000_0
2024-04-30T20:03:05,503  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:05,504  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:05,505  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:05,507  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,508  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:05,509  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:05,510  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:05,511  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:05,511  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:05,511  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:05,511  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:05,512  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@19798dd2, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5972610b, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@61319c8f
2024-04-30T20:03:05,520  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:05,532  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,532  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,534  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,534  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,536  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1
2024-04-30T20:03:05,543  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:05,545  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:05,545  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:05,549  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Submitting tokens for job: job_local1320099443_0003
2024-04-30T20:03:05,550  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:05,557  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:05,558  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:05,558  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486
2024-04-30T20:03:05,558  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:05,558  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:05,559  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:05,559  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:05,559  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-04-30T20:03:05,559  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Completed compiling command(queryId=alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486); Time taken: 0.143 seconds
2024-04-30T20:03:05,560  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:05,560  INFO [HiveServer2-Background-Pool: Thread-196] common.LogUtils: Thread context registration is done.
2024-04-30T20:03:05,561  INFO [HiveServer2-Background-Pool: Thread-196] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:05,561  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,561  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:05,562  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Executing command(queryId=alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,562  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=114a1ad4-b70a-4e2e-ab53-f72f1361fa84] SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b]
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,562  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY2024-04-30T20:03:05,563  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Thread context registration is done.

2024-04-30T20:03:05,563  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: type: QUERY
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f.test
2024-04-30T20:03:05,568  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f, startTime=1714532585561, sessionId=acb24ed1-3bbd-4b8a-a58c-680a3715469b, createTime=1714532579551, userName=anonymous, ipAddress=null]
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:05,568  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001
2024-04-30T20:03:05,568  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001
2024-04-30T20:03:05,569  WARN [HiveServer2-Background-Pool: Thread-196] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486
2024-04-30T20:03:05,569  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Query ID = alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486
Total jobs = 1
2024-04-30T20:03:05,569  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:05,569  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:05,570  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Compiling command(queryId=alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,571  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f
2024-04-30T20:03:05,572  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:05,572  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:05,572  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,572  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,572  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,572  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:05,573  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,573  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,580  INFO [HiveServer2-Background-Pool: Thread-196] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:05,581  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:05,581  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/dummy_path
2024-04-30T20:03:05,588  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,596  INFO [HiveServer2-Background-Pool: Thread-196] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:05,598  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,598  WARN [HiveServer2-Background-Pool: Thread-196] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,604  WARN [HiveServer2-Background-Pool: Thread-196] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,612  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:05,618  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:05,619  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:05,620  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/dummy_path
2024-04-30T20:03:05,627  INFO [HiveServer2-Background-Pool: Thread-196] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:05,627  INFO [HiveServer2-Background-Pool: Thread-196] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:05,628  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:05,659  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:03:05,660  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,660  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-30T20:03:05,661  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:05,665  INFO [Thread-150] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:05,665  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1320099443_0003_m_000000_0
2024-04-30T20:03:05,665  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:05,666  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:05,667  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:05,667  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:05,671  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,671  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:05,672  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:05,673  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:05,673  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:05,674  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:05,674  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:05,674  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:05,675  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@1be5d5e0, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@17dc9c60, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@63e36a0e
2024-04-30T20:03:05,689  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:05,689  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:05,692  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:05,692  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:05,693  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1
2024-04-30T20:03:05,699  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: Submitting tokens for job: job_local1463583598_0004
2024-04-30T20:03:05,699  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:05,702  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:05,705  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:05,706  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:05,718  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:05,718  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:05,719  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:05,720  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:05,720  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:05,720  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-04-30T20:03:05,720  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Completed compiling command(queryId=alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f); Time taken: 0.151 seconds
2024-04-30T20:03:05,720  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:05,720  INFO [HiveServer2-Background-Pool: Thread-236] common.LogUtils: Thread context registration is done.
2024-04-30T20:03:05,720  INFO [HiveServer2-Background-Pool: Thread-236] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:05,721  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:05,721  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Executing command(queryId=alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-30T20:03:05,722  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-30T20:03:05,722  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:05,722  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001
2024-04-30T20:03:05,722  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001
2024-04-30T20:03:05,722  WARN [HiveServer2-Background-Pool: Thread-236] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f
2024-04-30T20:03:05,722  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Query ID = alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f
Total jobs = 1
2024-04-30T20:03:05,723  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:05,723  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:05,726  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,726  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:05,732  INFO [HiveServer2-Background-Pool: Thread-236] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:05,733  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:05,733  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/dummy_path
2024-04-30T20:03:05,746  INFO [HiveServer2-Background-Pool: Thread-236] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:05,747  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,747  WARN [HiveServer2-Background-Pool: Thread-236] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,752  WARN [HiveServer2-Background-Pool: Thread-236] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:05,760  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:05,766  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:05,767  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:05,768  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/dummy_path
2024-04-30T20:03:05,773  INFO [HiveServer2-Background-Pool: Thread-236] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:05,773  INFO [HiveServer2-Background-Pool: Thread-236] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:05,774  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:05,793  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-30T20:03:05,794  INFO [Thread-186] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,794  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:05,794  INFO [Thread-186] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,796  INFO [Thread-186] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:05,796  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1463583598_0004_m_000000_0
2024-04-30T20:03:05,796  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:05,797  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:05,798  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:05,798  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:05,800  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,800  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:05,801  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:05,801  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:05,802  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:05,802  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:05,802  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:05,802  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:05,802  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@5a25d8a9, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@46e1e8cb, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@b2b2f3e
2024-04-30T20:03:05,821  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: Submitting tokens for job: job_local1989692915_0005
2024-04-30T20:03:05,821  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:05,891  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-30T20:03:05,892  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,892  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:05,892  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:05,894  INFO [Thread-218] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:05,894  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1989692915_0005_m_000000_0
2024-04-30T20:03:05,895  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:05,895  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:05,896  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:05,898  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:05,898  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:05,898  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:05,899  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:05,899  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:05,899  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:05,899  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:05,900  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:05,900  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@3088b6ad, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7fd1f9a9, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@48e6044e
2024-04-30T20:03:06,236  INFO [main] service.CompositeService: Session closed, SessionHandle [acb24ed1-3bbd-4b8a-a58c-680a3715469b], current sessions:0
2024-04-30T20:03:06,236  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=0d7172bc-5acf-49a4-9634-58db39e9b1c2]
2024-04-30T20:03:06,236  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Removed queryId: alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=0d7172bc-5acf-49a4-9634-58db39e9b1c2] with tag: null
2024-04-30T20:03:06,237  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37
2024-04-30T20:03:06,237  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-30T20:03:06,237  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-30 20:03:06,237 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,237  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: 2024-04-30 20:03:06,237 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,237  WARN [Thread-111] mapred.LocalJobRunner: job_local251267886_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:03:06,238  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,238  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-2
2024-04-30T20:03:06,238  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,238  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,238  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30T20:03:06,238  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-2 operation was queued
2024-04-30T20:03:06,238  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1
Ended Job = job_local251267886_0002 with errors
2024-04-30T20:03:06,238 ERROR [HiveServer2-Background-Pool: Thread-121] exec.Task: Ended Job = job_local251267886_0002 with errors
2024-04-30T20:03:06,239  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-2
2024-04-30T20:03:06,238  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1 operation was queued
2024-04-30T20:03:06,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:06,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:06,239  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1
2024-04-30T20:03:06,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37 without delay
2024-04-30T20:03:06,239  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b378f5e8-6cd0-45f6-82c6-7ff33cfd1f1a]
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Removed queryId: alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b378f5e8-6cd0-45f6-82c6-7ff33cfd1f1a] with tag: null
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1 operation was queued
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08 without delay
Error during job, obtaining debugging information...
2024-04-30T20:03:06,240 ERROR [Thread-223] exec.Task: Error during job, obtaining debugging information...
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=84999181-c8d8-4863-ba80-ae3fee57c3c3]
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Removed queryId: alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=84999181-c8d8-4863-ba80-ae3fee57c3c3] with tag: null
2024-04-30T20:03:06,240  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486
2024-04-30T20:03:06,241  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-30T20:03:06,241  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30T20:03:06,241  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-02-59_727_233255231666187559-1
2024-04-30T20:03:06,241  WARN [Thread-186] mapred.LocalJobRunner: job_local1463583598_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30 20:03:06,241 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,241  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-4
2024-04-30T20:03:06,241  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: 2024-04-30 20:03:06,241 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,242  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-4 operation was queued
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-30T20:03:06,242  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,243  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,243  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,243  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1
2024-04-30T20:03:06,243  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1 operation was queued
2024-04-30T20:03:06,243  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:06,243  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:06,244  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486 without delay
2024-04-30T20:03:06,244  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=29799042-15c2-4aea-bd0e-199890275188]
2024-04-30T20:03:06,244  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Removed queryId: alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=29799042-15c2-4aea-bd0e-199890275188] with tag: null
2024-04-30T20:03:06,244  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1
2024-04-30T20:03:06,244  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd
2024-04-30T20:03:06,246  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30T20:03:06,246  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-4
2024-04-30T20:03:06,246  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30 20:03:06,246 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,246  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: 2024-04-30 20:03:06,246 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,247  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-30T20:03:06,247 ERROR [HiveServer2-Background-Pool: Thread-121] ql.Driver: FAILED: Operation cancelled
2024-04-30T20:03:06,248  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:06,248  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-30T20:03:06,248  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: MapReduce Jobs Launched: 
2024-04-30T20:03:06,250  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-30T20:03:06,250  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Ended Job = job_local1463583598_0004 with errors
2024-04-30T20:03:06,250 ERROR [HiveServer2-Background-Pool: Thread-196] exec.Task: Ended Job = job_local1463583598_0004 with errors
Error during job, obtaining debugging information...
2024-04-30T20:03:06,251 ERROR [Thread-227] exec.Task: Error during job, obtaining debugging information...
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-30T20:03:06,251  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:06,251  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:06,251  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-3
2024-04-30T20:03:06,251  WARN [Thread-150] mapred.LocalJobRunner: job_local1320099443_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:03:06,251  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240430200305_5c592c21-3382-4817-91e3-cc04652ebc37) has been interrupted after 0.994 seconds
2024-04-30T20:03:06,251  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-3 operation was queued
2024-04-30T20:03:06,251  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1 operation was queued
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd without delay
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=114a1ad4-b70a-4e2e-ab53-f72f1361fa84]
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.OperationManager: Removed queryId: alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=114a1ad4-b70a-4e2e-ab53-f72f1361fa84] with tag: null
2024-04-30T20:03:06,252  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f
2024-04-30T20:03:06,254  WARN [HiveServer2-Background-Pool: Thread-121] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-30T20:03:06,254  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:06,256  WARN [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-30T20:03:06,256  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,256  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,256  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,256  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30 20:03:06,256 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,257  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: 2024-04-30 20:03:06,256 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:06,257  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-3
2024-04-30T20:03:06,257  INFO [EventualCleanupService thread 6] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1
2024-04-30T20:03:06,257  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-5
2024-04-30T20:03:06,258  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-5 operation was queued
2024-04-30T20:03:06,258  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1
2024-04-30T20:03:06,258  INFO [HiveServer2-Background-Pool: Thread-196] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-04-30T20:03:06,258  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1 operation was queued
2024-04-30T20:03:06,258  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:06,258  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
FAILED: Operation cancelled
2024-04-30T20:03:06,258 ERROR [HiveServer2-Background-Pool: Thread-196] ql.Driver: FAILED: Operation cancelled
2024-04-30T20:03:06,258  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f without delay
2024-04-30T20:03:06,259  INFO [acb24ed1-3bbd-4b8a-a58c-680a3715469b main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b
2024-04-30T20:03:06,259  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-5
2024-04-30T20:03:06,264  INFO [HiveServer2-Background-Pool: Thread-196] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:06,264  INFO [EventualCleanupService thread 8] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1
2024-04-30T20:03:06,264  INFO [HiveServer2-Background-Pool: Thread-196] metadata.Hive: Total time spent in each metastore function (ms): {}
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-30T20:03:06,264  WARN [Thread-218] mapred.LocalJobRunner: job_local1989692915_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:03:06,264  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,265  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,265  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_tmp.-ext-10002/000000_0
MapReduce Jobs Launched: 
2024-04-30T20:03:06,267  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: MapReduce Jobs Launched: 
2024-04-30T20:03:06,270 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-30T20:03:06,270  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:06,270  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-30T20:03:06,270  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:06,270  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:06,270  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:06,270  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:06,271  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:06,271  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:06,271  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-30T20:03:06,271  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:06,271  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:06,271  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Executing command(queryId=alex_20240430200305_70ba1760-b9bc-4f59-9e63-f81ebf203486) has been interrupted after 0.702 seconds
2024-04-30T20:03:06,271  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,272  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,272  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_084_1539635336550838187-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_084_1539635336550838187-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,272  WARN [HiveServer2-Background-Pool: Thread-196] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-30T20:03:06,272  INFO [HiveServer2-Background-Pool: Thread-196] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:06,272  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/acb24ed1-3bbd-4b8a-a58c-680a3715469b operation was queued
2024-04-30T20:03:06,272  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b operation was queued
2024-04-30T20:03:06,272  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/acb24ed1-3bbd-4b8a-a58c-680a3715469b
2024-04-30T20:03:06,273  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b
2024-04-30T20:03:06,275 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,276  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_569_6719325515963231451-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_569_6719325515963231451-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,287 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-30T20:03:06,288  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,289  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,289  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_253_5420510127660307748-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_253_5420510127660307748-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:03:06,289  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4466cf5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c60ce47 will be shutdown
2024-04-30T20:03:06,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:03:06,289  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-30T20:03:06,294 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_task_tmp.-ext-10002/._tmp.000000_0.crc': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_task_tmp.-ext-10002/._tmp.000000_0.crc': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_task_tmp.-ext-10002/._tmp.000000_0.crc': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:239)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:405)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-30T20:03:06,294  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,295  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/acb24ed1-3bbd-4b8a-a58c-680a3715469b/hive_2024-04-30_20-03-05_415_6262669892292259404-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-05_415_6262669892292259404-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,308  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="1.851">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-30T20:03:06,316  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-30T20:03:06,320  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-30T20:03:06,322  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:03:06,372  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:03:06,373  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:03:06,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:03:06,373  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = d4b17d78-9cd8-495a-841d-bd4792c38c10
2024-04-30T20:03:06,373  INFO [main] SessionState: Hive Session ID = d4b17d78-9cd8-495a-841d-bd4792c38c10
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:06,374  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:06,381  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/d4b17d78-9cd8-495a-841d-bd4792c38c10
2024-04-30T20:03:06,384  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/d4b17d78-9cd8-495a-841d-bd4792c38c10
2024-04-30T20:03:06,387  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/d4b17d78-9cd8-495a-841d-bd4792c38c10/_tmp_space.db
2024-04-30T20:03:06,388  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=d4b17d78-9cd8-495a-841d-bd4792c38c10, clientType=HIVESERVER2]
2024-04-30T20:03:06,388  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:03:06,389  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:03:06,389  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:03:06,390  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: null will be shutdown
2024-04-30T20:03:06,391  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5216532a created in the thread with id: 1
2024-04-30T20:03:06,395  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5 from thread id: 1
2024-04-30T20:03:06,396  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:03:06,396  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:03:06,396  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-30T20:03:06,397  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-30T20:03:06,397  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-30T20:03:06,397  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-30T20:03:06,397  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-30T20:03:06,398  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-30T20:03:06,401  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-30T20:03:06,411  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-30T20:03:06,411  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:06,412  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:06,419  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/fd4ead45-4be2-4668-8f47-6cbef75cc872
2024-04-30T20:03:06,423  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872
2024-04-30T20:03:06,426  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/fd4ead45-4be2-4668-8f47-6cbef75cc872/_tmp_space.db
2024-04-30T20:03:06,426  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-30T20:03:06,426  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-30T20:03:06,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:03:06,427  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@517d9cd5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5216532a will be shutdown
2024-04-30T20:03:06,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:03:06,427  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-30T20:03:06,427  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872
2024-04-30T20:03:06,427  INFO [main] service.CompositeService: Session opened, SessionHandle [fd4ead45-4be2-4668-8f47-6cbef75cc872], current sessions:1
2024-04-30T20:03:06,427  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-30T20:03:06,427  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:06,428  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fcb3bd40-643a-4aee-acd4-94bb5de412a6] SessionHandle [fd4ead45-4be2-4668-8f47-6cbef75cc872]
2024-04-30T20:03:06,428  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd.test
2024-04-30T20:03:06,432  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd, startTime=1714532586427, sessionId=fd4ead45-4be2-4668-8f47-6cbef75cc872, createTime=1714532586411, userName=anonymous, ipAddress=null]
2024-04-30T20:03:06,434  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Compiling command(queryId=alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd): select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:06,435  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:03:06,436  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:03:06,436  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:03:06,437  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: null will be shutdown
2024-04-30T20:03:06,437  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fc40856 created in the thread with id: 1
2024-04-30T20:03:06,443  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016 from thread id: 1
2024-04-30T20:03:06,443  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:03:06,443  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:03:06,444  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd
2024-04-30T20:03:06,444  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:06,444  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=fd4ead45-4be2-4668-8f47-6cbef75cc872, clientType=HIVESERVER2]
2024-04-30T20:03:06,444  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:06,444  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:06,445  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:06,445  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:06,445  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:06,460  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:06,505  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:06,505  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:06,507  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:06,507  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:06,508  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-06_434_3325078634972396499-1
2024-04-30T20:03:06,515  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:06,518  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:06,518  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd
2024-04-30T20:03:06,530  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:06,531  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:06,532  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:06,532  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:06,532  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-04-30T20:03:06,532  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Completed compiling command(queryId=alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd); Time taken: 0.098 seconds
2024-04-30T20:03:06,532  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:06,533  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-30T20:03:06,533  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:06,533  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Executing command(queryId=alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:06,533  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-30T20:03:06,533  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:06,533  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001
2024-04-30T20:03:06,534  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001
2024-04-30T20:03:06,534  WARN [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd
2024-04-30T20:03:06,534  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Query ID = alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd
Total jobs = 1
2024-04-30T20:03:06,534  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:06,534  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:06,536  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:06,536  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:06,540  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:06,540  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:06,540  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/dummy_path
2024-04-30T20:03:06,552  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:06,553  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-30T20:03:06,554  WARN [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:06,559  WARN [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:06,567  WARN [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:06,573  WARN [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:06,573  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:06,575  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/dummy_path
2024-04-30T20:03:06,579  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:06,580  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:06,580  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:06,604  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:06,628  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1512366058_0006
2024-04-30T20:03:06,628  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:06,699  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:03:06,699  INFO [Thread-302] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-30T20:03:06,699  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:06,699  INFO [Thread-302] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:06,702  INFO [Thread-302] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:06,702  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1512366058_0006_m_000000_0
2024-04-30T20:03:06,705  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:06,706  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:06,709  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:06,710  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-30T20:03:06,711  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:06,714  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:06,715  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:06,716  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:06,716  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:06,716  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:06,716  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:06,717  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@181f5bab, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@77f81437, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@5d8a8570
2024-04-30T20:03:06,718  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-06_434_3325078634972396499-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,718  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-06_434_3325078634972396499-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:06,718  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-06_434_3325078634972396499-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:06,730  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-30T20:03:06,731  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-30T20:03:06,731  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:03:06,734  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1512366058_0006_m_000000_0 is done. And is in the process of committing
2024-04-30T20:03:06,735  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:03:06,735  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1512366058_0006_m_000000_0' done.
2024-04-30T20:03:06,735  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1512366058_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33482
		FILE: Number of bytes written=6938210
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=989331456
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:03:06,735  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1512366058_0006_m_000000_0
2024-04-30T20:03:06,735  INFO [Thread-302] mapred.LocalJobRunner: map task executor complete.
2024-04-30T20:03:07,247  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1320099443_0003 with errors
2024-04-30T20:03:07,247 ERROR [HiveServer2-Background-Pool: Thread-156] exec.Task: Ended Job = job_local1320099443_0003 with errors
Error during job, obtaining debugging information...
2024-04-30T20:03:07,248 ERROR [Thread-309] exec.Task: Error during job, obtaining debugging information...
2024-04-30T20:03:07,249  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-30T20:03:07,249 ERROR [HiveServer2-Background-Pool: Thread-156] ql.Driver: FAILED: Operation cancelled
2024-04-30T20:03:07,249  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:07,249  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Total time spent in each metastore function (ms): {close_()=0}
MapReduce Jobs Launched: 
2024-04-30T20:03:07,249  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: MapReduce Jobs Launched: 
2024-04-30T20:03:07,250  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-30T20:03:07,250  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:07,250  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:07,250  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240430200305_4ce4b234-0794-4984-95e1-c24fc3f018bd) has been interrupted after 1.84 seconds
2024-04-30T20:03:07,250  WARN [HiveServer2-Background-Pool: Thread-156] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-30T20:03:07,251  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:07,257  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1989692915_0005 with errors
2024-04-30T20:03:07,258 ERROR [HiveServer2-Background-Pool: Thread-236] exec.Task: Ended Job = job_local1989692915_0005 with errors
Error during job, obtaining debugging information...
2024-04-30T20:03:07,258 ERROR [Thread-311] exec.Task: Error during job, obtaining debugging information...
2024-04-30T20:03:07,259  INFO [HiveServer2-Background-Pool: Thread-236] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-30T20:03:07,260 ERROR [HiveServer2-Background-Pool: Thread-236] ql.Driver: FAILED: Operation cancelled
2024-04-30T20:03:07,260  INFO [HiveServer2-Background-Pool: Thread-236] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:07,260  INFO [HiveServer2-Background-Pool: Thread-236] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-30T20:03:07,260  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: MapReduce Jobs Launched: 
2024-04-30T20:03:07,260  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-30T20:03:07,260  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:07,260  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:07,260  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Executing command(queryId=alex_20240430200305_f8533865-cfbc-49a8-8453-e102ab7dd93f) has been interrupted after 1.539 seconds
2024-04-30T20:03:07,261  WARN [HiveServer2-Background-Pool: Thread-236] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-30T20:03:07,261  INFO [HiveServer2-Background-Pool: Thread-236] common.LogUtils: Unregistered logging context.
2024-04-30 20:03:07,702 Stage-1 map = 100%,  reduce = 0%
2024-04-30T20:03:07,702  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Task: 2024-04-30 20:03:07,702 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1512366058_0006
2024-04-30T20:03:07,703  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.Task: Ended Job = job_local1512366058_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1/-mr-10001
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:07,706  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Completed executing command(queryId=alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd); Time taken: 1.173 seconds
2024-04-30T20:03:07,707  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:07,707  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-30T20:03:07,708  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=88a8e310-518b-40d1-9704-cf30c32ae408] SessionHandle [fd4ead45-4be2-4668-8f47-6cbef75cc872]
2024-04-30T20:03:07,708  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3.test
2024-04-30T20:03:07,712  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3, startTime=1714532587707, sessionId=fd4ead45-4be2-4668-8f47-6cbef75cc872, createTime=1714532586411, userName=anonymous, ipAddress=null]
2024-04-30T20:03:07,713  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Compiling command(queryId=alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-30T20:03:07,715  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3
2024-04-30T20:03:07,715  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:07,715  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-04-30T20:03:07,717  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-30T20:03:07,808  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] reflections.Reflections: Reflections took 80 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-30T20:03:07,875  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3
2024-04-30T20:03:07,875  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:07,875  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-30T20:03:07,875  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:07,875  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=9, flushCache_()=0}
2024-04-30T20:03:07,875  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Completed compiling command(queryId=alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3); Time taken: 0.162 seconds
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Executing command(queryId=alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-04-30T20:03:07,876  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-04-30T20:03:07,877  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-30T20:03:07,982  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1714532587, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFiles=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-30T20:03:07,991  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/service/target/warehouse/sample_shutdown_hook
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=173}
2024-04-30T20:03:08,156  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Driver: Completed executing command(queryId=alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3); Time taken: 0.28 seconds
2024-04-30T20:03:08,157  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:08,157  INFO [main] service.CompositeService: Session closed, SessionHandle [fd4ead45-4be2-4668-8f47-6cbef75cc872], current sessions:0
2024-04-30T20:03:08,157  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=88a8e310-518b-40d1-9704-cf30c32ae408]
2024-04-30T20:03:08,157  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.OperationManager: Removed queryId: alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=88a8e310-518b-40d1-9704-cf30c32ae408] with tag: null
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200307_a0dd0638-ccf2-4b31-99a1-6a8c0c8181c3 without delay
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fcb3bd40-643a-4aee-acd4-94bb5de412a6]
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.OperationManager: Removed queryId: alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fcb3bd40-643a-4aee-acd4-94bb5de412a6] with tag: null
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1 operation was queued
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:08,158  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872/alex_20240430200306_b55f6546-f13c-49c0-816a-60b605236bfd without delay
2024-04-30T20:03:08,159  INFO [fd4ead45-4be2-4668-8f47-6cbef75cc872 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/fd4ead45-4be2-4668-8f47-6cbef75cc872
2024-04-30T20:03:08,159  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872/hive_2024-04-30_20-03-06_434_3325078634972396499-1
2024-04-30T20:03:08,160  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/fd4ead45-4be2-4668-8f47-6cbef75cc872 operation was queued
2024-04-30T20:03:08,161  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872 operation was queued
2024-04-30T20:03:08,161  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/fd4ead45-4be2-4668-8f47-6cbef75cc872
2024-04-30T20:03:08,161  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/fd4ead45-4be2-4668-8f47-6cbef75cc872
2024-04-30T20:03:08,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:03:08,161  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e210016, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fc40856 will be shutdown
2024-04-30T20:03:08,162  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:03:08,162  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.076">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-30T20:03:08,228  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-30T20:03:08,228  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-30T20:03:08,229  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 373711de-0353-409e-8461-1b32e08eba5b
2024-04-30T20:03:08,230  INFO [main] SessionState: Hive Session ID = 373711de-0353-409e-8461-1b32e08eba5b
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:08,231  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:08,238  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/373711de-0353-409e-8461-1b32e08eba5b
2024-04-30T20:03:08,242  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/373711de-0353-409e-8461-1b32e08eba5b
2024-04-30T20:03:08,261  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/373711de-0353-409e-8461-1b32e08eba5b/_tmp_space.db
2024-04-30T20:03:08,262  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=373711de-0353-409e-8461-1b32e08eba5b, clientType=HIVESERVER2]
2024-04-30T20:03:08,264  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:03:08,264  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:03:08,264  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:03:08,265  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: null will be shutdown
2024-04-30T20:03:08,265  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7097ead6 created in the thread with id: 1
2024-04-30T20:03:08,276  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848 from thread id: 1
2024-04-30T20:03:08,276  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:03:08,276  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:03:08,276  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-30T20:03:08,276  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-30T20:03:08,276  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-30T20:03:08,276  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-30T20:03:08,276  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-30T20:03:08,278  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-30T20:03:08,279  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-30T20:03:08,279  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-30T20:03:08,279  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-30T20:03:08,279  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-30T20:03:08,280  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-30T20:03:08,280  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-30T20:03:08,280  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-30T20:03:08,289  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-30T20:03:08,290  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:08,291  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-30T20:03:08,298  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/aad44566-0820-4f17-8ce2-6cf3f474866a
2024-04-30T20:03:08,301  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a
2024-04-30T20:03:08,304  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/aad44566-0820-4f17-8ce2-6cf3f474866a/_tmp_space.db
2024-04-30T20:03:08,304  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-30T20:03:08,304  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-30T20:03:08,304  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:03:08,305  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e041848, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7097ead6 will be shutdown
2024-04-30T20:03:08,305  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:03:08,305  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-30T20:03:08,305  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a
2024-04-30T20:03:08,305  INFO [main] service.CompositeService: Session opened, SessionHandle [aad44566-0820-4f17-8ce2-6cf3f474866a], current sessions:1
2024-04-30T20:03:08,305  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-30T20:03:08,305  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:08,306  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=cea12f57-255a-434b-9134-2d6b57d682e4] SessionHandle [aad44566-0820-4f17-8ce2-6cf3f474866a]
2024-04-30T20:03:08,306  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7.test
2024-04-30T20:03:08,310  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7, startTime=1714532588305, sessionId=aad44566-0820-4f17-8ce2-6cf3f474866a, createTime=1714532588290, userName=anonymous, ipAddress=null]
2024-04-30T20:03:08,311  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Compiling command(queryId=alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7): select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:08,312  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-30T20:03:08,313  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-30T20:03:08,313  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-30T20:03:08,314  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: null will be shutdown
2024-04-30T20:03:08,314  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@460df441 created in the thread with id: 1
2024-04-30T20:03:08,317  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f from thread id: 1
2024-04-30T20:03:08,318  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-30T20:03:08,318  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-30T20:03:08,318  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7
2024-04-30T20:03:08,318  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:08,319  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=aad44566-0820-4f17-8ce2-6cf3f474866a, clientType=HIVESERVER2]
2024-04-30T20:03:08,319  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:08,319  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:08,319  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:08,319  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:08,319  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:08,333  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:08,429  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:08,430  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:08,435  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:08,435  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:08,436  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-08_311_7316015193828179064-1
2024-04-30T20:03:08,442  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:08,444  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:08,445  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:08,456  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:08,457  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:08,457  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:08,457  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=59, flushCache_()=0}
2024-04-30T20:03:08,457  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Completed compiling command(queryId=alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7); Time taken: 0.146 seconds
2024-04-30T20:03:08,458  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:08,458  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-30T20:03:08,458  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:08,458  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Executing command(queryId=alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001
2024-04-30T20:03:08,459  WARN [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Query ID = alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7
Total jobs = 1
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:08,459  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:08,461  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:08,462  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:08,465  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:08,465  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:08,465  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/dummy_path
2024-04-30T20:03:08,477  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:08,478  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-30T20:03:08,479  WARN [aad44566-0820-4f17-8ce2-6cf3f474866a main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:08,484  WARN [aad44566-0820-4f17-8ce2-6cf3f474866a main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:08,492  WARN [aad44566-0820-4f17-8ce2-6cf3f474866a main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:08,498  WARN [aad44566-0820-4f17-8ce2-6cf3f474866a main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:08,498  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:08,499  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/dummy_path
2024-04-30T20:03:08,504  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:08,504  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:08,504  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:08,528  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:08,551  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1883046017_0007
2024-04-30T20:03:08,551  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:08,619  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-30T20:03:08,620  INFO [Thread-354] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)2024-04-30T20:03:08,620  INFO [Thread-354] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter

2024-04-30T20:03:08,620  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:08,622  INFO [Thread-354] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:08,622  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1883046017_0007_m_000000_0
2024-04-30T20:03:08,626  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:08,627  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:08,629  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:08,631  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-30T20:03:08,631  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:08,634  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:08,634  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:08,634  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:08,634  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:08,634  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:08,635  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:08,635  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@102093d5, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@6d7cb72f, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@aeaf848
2024-04-30T20:03:08,635  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-08_311_7316015193828179064-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:08,636  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-08_311_7316015193828179064-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:08,636  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-08_311_7316015193828179064-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-30T20:03:08,647  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-30T20:03:08,648  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-30T20:03:08,649  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-30T20:03:08,652  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1883046017_0007_m_000000_0 is done. And is in the process of committing
2024-04-30T20:03:08,653  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-30T20:03:08,653  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1883046017_0007_m_000000_0' done.
2024-04-30T20:03:08,653  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1883046017_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39068
		FILE: Number of bytes written=8095394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=994050048
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-30T20:03:08,653  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1883046017_0007_m_000000_0
2024-04-30T20:03:08,653  INFO [Thread-354] mapred.LocalJobRunner: map task executor complete.
2024-04-30 20:03:09,624 Stage-1 map = 100%,  reduce = 0%
2024-04-30T20:03:09,624  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Task: 2024-04-30 20:03:09,624 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1883046017_0007
2024-04-30T20:03:09,625  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.Task: Ended Job = job_local1883046017_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1/-mr-10001
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:09,627  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Completed executing command(queryId=alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7); Time taken: 1.169 seconds
2024-04-30T20:03:09,628  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:09,628  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-30T20:03:09,629  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fd514254-5105-4372-9bf3-3faa22692027] SessionHandle [aad44566-0820-4f17-8ce2-6cf3f474866a]
2024-04-30T20:03:09,629  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272.test
2024-04-30T20:03:09,632  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272, startTime=1714532589628, sessionId=aad44566-0820-4f17-8ce2-6cf3f474866a, createTime=1714532588290, userName=anonymous, ipAddress=null]
2024-04-30T20:03:09,633  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Compiling command(queryId=alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Starting caching scope for: alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:09,634  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-30T20:03:09,648  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:09,703  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for source tables
2024-04-30T20:03:09,704  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-30T20:03:09,706  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-30T20:03:09,706  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-30T20:03:09,707  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-09_633_1218231940385778945-1
2024-04-30T20:03:09,714  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-30T20:03:09,718  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-30T20:03:09,718  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-30T20:03:09,730  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-30T20:03:09,730  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map vectorization enabled: false
2024-04-30T20:03:09,730  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map vectorized: false
2024-04-30T20:03:09,730  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-30T20:03:09,730  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-30T20:03:09,731  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-30T20:03:09,731  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-30T20:03:09,731  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Completed plan generation
2024-04-30T20:03:09,731  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] parse.CalcitePlanner: Ending caching scope for: alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272
2024-04-30T20:03:09,731  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-30T20:03:09,731  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-30T20:03:09,732  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-30T20:03:09,732  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-30T20:03:09,732  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=0}
2024-04-30T20:03:09,732  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Completed compiling command(queryId=alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272); Time taken: 0.099 seconds
2024-04-30T20:03:09,733  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] common.LogUtils: Unregistered logging context.
2024-04-30T20:03:09,733  INFO [HiveServer2-Background-Pool: Thread-447] common.LogUtils: Thread context registration is done.
2024-04-30T20:03:09,733  INFO [HiveServer2-Background-Pool: Thread-447] reexec.ReExecDriver: Execution #1 of query
2024-04-30T20:03:09,734  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Operation QUERY obtained 2 locks
2024-04-30T20:03:09,734  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Executing command(queryId=alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-30T20:03:09,734  INFO [HiveServer2-Background-Pool: Thread-447] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-04-30T20:03:09,734  INFO [HiveServer2-Background-Pool: Thread-447] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-30T20:03:09,734  INFO [HiveServer2-Background-Pool: Thread-447] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/-mr-10001
2024-04-30T20:03:09,735  INFO [HiveServer2-Background-Pool: Thread-447] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/-mr-10001
2024-04-30T20:03:09,735  WARN [HiveServer2-Background-Pool: Thread-447] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272
2024-04-30T20:03:09,735  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Query ID = alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272
Total jobs = 1
2024-04-30T20:03:09,735  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-30T20:03:09,735  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Launching Job 1 out of 1
2024-04-30T20:03:09,738  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:09,739  INFO [HiveServer2-Background-Pool: Thread-447] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-30T20:03:09,745  INFO [HiveServer2-Background-Pool: Thread-447] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-30T20:03:09,745  INFO [HiveServer2-Background-Pool: Thread-447] exec.Utilities: Processing alias _dummy_table
2024-04-30T20:03:09,745  INFO [HiveServer2-Background-Pool: Thread-447] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/dummy_path
2024-04-30T20:03:09,758  INFO [HiveServer2-Background-Pool: Thread-447] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-30T20:03:09,759  INFO [HiveServer2-Background-Pool: Thread-447] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:09,760  WARN [HiveServer2-Background-Pool: Thread-447] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:09,765  WARN [HiveServer2-Background-Pool: Thread-447] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-30T20:03:09,772  WARN [HiveServer2-Background-Pool: Thread-447] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-30T20:03:09,778  WARN [HiveServer2-Background-Pool: Thread-447] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-30T20:03:09,778  INFO [HiveServer2-Background-Pool: Thread-447] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-30T20:03:09,779  INFO [HiveServer2-Background-Pool: Thread-447] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/dummy_path
2024-04-30T20:03:09,784  INFO [HiveServer2-Background-Pool: Thread-447] input.FileInputFormat: Total input files to process : 1
2024-04-30T20:03:09,784  INFO [HiveServer2-Background-Pool: Thread-447] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-30T20:03:09,784  INFO [HiveServer2-Background-Pool: Thread-447] io.CombineHiveInputFormat: Number of all splits 1
2024-04-30T20:03:09,808  INFO [HiveServer2-Background-Pool: Thread-447] mapreduce.JobSubmitter: number of splits:1
2024-04-30T20:03:09,831  INFO [HiveServer2-Background-Pool: Thread-447] mapreduce.JobSubmitter: Submitting tokens for job: job_local1534958873_0008
2024-04-30T20:03:09,831  INFO [HiveServer2-Background-Pool: Thread-447] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-30T20:03:09,900  INFO [HiveServer2-Background-Pool: Thread-447] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-30T20:03:09,901  INFO [HiveServer2-Background-Pool: Thread-447] exec.Task: Job running in-process (local Hadoop)
2024-04-30T20:03:09,901  INFO [Thread-393] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:09,901  INFO [Thread-393] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-30T20:03:09,902  INFO [Thread-393] mapred.LocalJobRunner: Waiting for map tasks
2024-04-30T20:03:09,902  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1534958873_0008_m_000000_0
2024-04-30T20:03:09,903  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-30T20:03:09,904  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-30T20:03:09,905  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-30T20:03:09,906  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-30T20:03:09,906  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-30T20:03:09,906  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-30T20:03:09,907  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-30T20:03:09,907  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-30T20:03:09,907  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-30T20:03:09,907  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-30T20:03:09,907  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-30T20:03:09,908  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@3adc2e0a, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@434a8938>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7c84b9e4, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@3f65dce0
DEBUG StatusLogger Removing appender alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
DEBUG StatusLogger Removing appender alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
DEBUG StatusLogger Deleting route with alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08 key 
DEBUG StatusLogger Deleting route with alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08 key 
DEBUG StatusLogger Stopping route with alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08 key
DEBUG StatusLogger Stopping route with alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08 key
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/acb24ed1-3bbd-4b8a-a58c-680a3715469b/alex_20240430200259_6ea8f0d3-08d2-42b1-b88d-1244b01b7a08, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
2024-04-30T20:03:10,234  INFO [main] service.CompositeService: Session closed, SessionHandle [aad44566-0820-4f17-8ce2-6cf3f474866a], current sessions:0
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=cea12f57-255a-434b-9134-2d6b57d682e4]
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.OperationManager: Removed queryId: alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=cea12f57-255a-434b-9134-2d6b57d682e4] with tag: null
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1 operation was queued
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200308_321754cb-7eb5-46c9-a6ba-8b37548b41c7 without delay
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fd514254-5105-4372-9bf3-3faa22692027]
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.OperationManager: Removed queryId: alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fd514254-5105-4372-9bf3-3faa22692027] with tag: null
2024-04-30T20:03:10,234  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272
2024-04-30T20:03:10,235  WARN [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-04-30T20:03:10,235  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-09_633_1218231940385778945-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:10,235  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-6
2024-04-30T20:03:10,235  WARN [Thread-393] mapred.LocalJobRunner: job_local1534958873_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-30T20:03:10,235  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-09_633_1218231940385778945-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-30T20:03:10,235  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-08_311_7316015193828179064-1
2024-04-30T20:03:10,235  WARN [HiveServer2-Background-Pool: Thread-447] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30T20:03:10,235  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1/-mr-10001/.hive-staging_hive_2024-04-30_20-03-09_633_1218231940385778945-1/_tmp.-ext-10002/000000_0
2024-04-30T20:03:10,235  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-6 operation was queued
2024-04-30T20:03:10,236  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1
2024-04-30 20:03:10,235 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:10,236  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1 operation was queued
2024-04-30T20:03:10,236  INFO [HiveServer2-Background-Pool: Thread-447] exec.Task: 2024-04-30 20:03:10,235 Stage-1 map = 0%,  reduce = 0%
2024-04-30T20:03:10,236  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-30T20:03:10,236  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-30T20:03:10,236  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-6
2024-04-30T20:03:10,236  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a/alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272 without delay
2024-04-30T20:03:10,236  WARN [HiveServer2-Background-Pool: Thread-447] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-30T20:03:10,236  INFO [aad44566-0820-4f17-8ce2-6cf3f474866a main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/aad44566-0820-4f17-8ce2-6cf3f474866a
2024-04-30T20:03:10,236  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a/hive_2024-04-30_20-03-09_633_1218231940385778945-1
Ended Job = job_local1534958873_0008 with errors
2024-04-30T20:03:10,236 ERROR [HiveServer2-Background-Pool: Thread-447] exec.Task: Ended Job = job_local1534958873_0008 with errors
Error during job, obtaining debugging information...
2024-04-30T20:03:10,237 ERROR [Thread-398] exec.Task: Error during job, obtaining debugging information...
2024-04-30T20:03:10,237  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/aad44566-0820-4f17-8ce2-6cf3f474866a operation was queued
2024-04-30T20:03:10,238  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a operation was queued
2024-04-30T20:03:10,238  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/aad44566-0820-4f17-8ce2-6cf3f474866a
2024-04-30T20:03:10,238  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/aad44566-0820-4f17-8ce2-6cf3f474866a
2024-04-30T20:03:10,239  INFO [HiveServer2-Background-Pool: Thread-447] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-04-30T20:03:10,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-30T20:03:10,239  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1892865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@460df441 will be shutdown
FAILED: Operation cancelled
2024-04-30T20:03:10,239 ERROR [HiveServer2-Background-Pool: Thread-447] ql.Driver: FAILED: Operation cancelled
2024-04-30T20:03:10,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-30T20:03:10,239  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-04-30T20:03:10,239  INFO [HiveServer2-Background-Pool: Thread-447] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-30T20:03:10,239  INFO [HiveServer2-Background-Pool: Thread-447] metadata.Hive: Total time spent in each metastore function (ms): {close_()=0}
MapReduce Jobs Launched: 
2024-04-30T20:03:10,239  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: MapReduce Jobs Launched: 
2024-04-30T20:03:10,239  WARN [HiveServer2-Background-Pool: Thread-447] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-30T20:03:10,239  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:10,239  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-30T20:03:10,240  INFO [HiveServer2-Background-Pool: Thread-447] ql.Driver: Executing command(queryId=alex_20240430200309_6d41f9e9-bb48-4ecb-9c6e-e6a2ce486272) has been interrupted after 0.505 seconds
]]></system-err>
  </testcase>
</testsuite>