<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="54.454" tests="8" errors="0" skipped="2" failures="6">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter5330755219989502875.jar /home/alex/Repositories/hive/hcatalog/core/target/surefire 2024-05-01T18-25-52_277-jvmRun1 surefire1023892534046402460tmp surefire_9336191300492501433776tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/hcatalog/core/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter5330755219989502875.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/hcatalog/core/../../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/hcatalog/core/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/hcatalog/core/../../"/>
  </properties>
  <testcase name="testHCatPartitionedTable[0]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="9.323">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,157477 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@5aa9e4eb
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,034502 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 51821857
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T14:18:59.485-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-14:19:01.706, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-14:19:01.708, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@247bddad OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@64d2d351 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@488d1cd7
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@33d512c1
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@33d512c1) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@33d512c1] started OK.
2024-05-01T14:19:02,068  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T14:19:02,258  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/core/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1714598341817/warehouse
2024-05-01T14:19:02,741  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T14:19:02,851  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:02,851  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:02,852  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:02,852  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:02,852  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:02,853  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:02,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:02,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:02,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:02,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:02,855  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:02,861  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=0 initial-capacity=50 maximum-capacity=50
2024-05-01T14:19:02,954  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:03,307  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:03,360  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:03,374  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T14:19:03,374  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T14:19:03,411  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T14:19:03,418  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T14:19:04,657  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T14:19:04,666  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T14:19:05,650  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T14:19:05,651  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: null will be shutdown
2024-05-01T14:19:05,697  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 created in the thread with id: 1
2024-05-01T14:19:09,707  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T14:19:09,708  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T14:19:09,708  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133 from thread id: 1
2024-05-01T14:19:10,551  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T14:19:10,601  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T14:19:10,654  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T14:19:10,657  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T14:19:10,853  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T14:19:10,863  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T14:19:10,864  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T14:19:10,868  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T14:19:10,900  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T14:19:10,903  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T14:19:10,905  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T14:19:10,905  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T14:19:10,907  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T14:19:10,912  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T14:19:10,914  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T14:19:10,915  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T14:19:10,921  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T14:19:10,922  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T14:19:10,923  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T14:19:10,928  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:11,157  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:11,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:11,201  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ade133, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c52298 will be shutdown
2024-05-01T14:19:11,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:11,202  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T14:19:11,202  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:11,205  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:11,208  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: null will be shutdown
2024-05-01T14:19:11,208  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 created in the thread with id: 1
2024-05-01T14:19:11,276  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff from thread id: 1
2024-05-01T14:19:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:11,414  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:11,416  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:11,416  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:11,416  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:11,455  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:11,456  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:11,460  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a84a12 will be shutdown
2024-05-01T14:19:11,460  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 created in the thread with id: 1
2024-05-01T14:19:11,467  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = fcd66600-ef14-4d74-a3dc-251602adf8d3
2024-05-01T14:19:11,477  INFO [main] SessionState: Hive Session ID = fcd66600-ef14-4d74-a3dc-251602adf8d3
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:11,498  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:11,656  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/fcd66600-ef14-4d74-a3dc-251602adf8d3
2024-05-01T14:19:11,665  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/fcd66600-ef14-4d74-a3dc-251602adf8d3
2024-05-01T14:19:11,673  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/fcd66600-ef14-4d74-a3dc-251602adf8d3/_tmp_space.db
2024-05-01T14:19:11,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:11,950  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_TEXTFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_TEXTFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T14:19:11,964  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile
2024-05-01T14:19:12,241  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:12,242  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:12,242  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:12,242  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:12,242  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:12,243  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:12,243  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:12,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:12,244  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:12,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:12,244  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:12,245  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:12,246  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:12,266  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:12,266  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:12,268  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e54a6b1 will be shutdown
2024-05-01T14:19:12,268  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d created in the thread with id: 1
2024-05-01T14:19:12,279  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:12,280  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:12,280  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:12,280  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5b202ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30922f8d will be shutdown
2024-05-01T14:19:12,281  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:12,281  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T14:19:12,281  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:12,284  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:12,285  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: null will be shutdown
2024-05-01T14:19:12,285  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 created in the thread with id: 1
2024-05-01T14:19:12,291  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0 from thread id: 1
2024-05-01T14:19:12,298  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:12,370  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:12,675  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T14:19:12,698  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T14:19:12,721  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T14:19:12,721  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T14:19:12,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:12,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:12,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:12,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:12,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:12,804  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:12,804  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:12,804  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:12,804  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:12,804  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:12,805  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:12,805  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:12,809  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:12,810  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:12,811  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@450f0235 will be shutdown
2024-05-01T14:19:12,811  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 created in the thread with id: 1
2024-05-01T14:19:12,819  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:12,819  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:12,820  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:12,820  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f930e0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b57dba4 will be shutdown
2024-05-01T14:19:12,820  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:12,820  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T14:19:12,820  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:12,822  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:12,823  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: null will be shutdown
2024-05-01T14:19:12,823  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb created in the thread with id: 1
2024-05-01T14:19:12,831  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933 from thread id: 1
2024-05-01T14:19:12,834  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value1,501]	
2024-05-01T14:19:12,928  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:12,941  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:13,001  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:13,088  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:13,132  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1838936995_0001
2024-05-01T14:19:13,132  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:13,332  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:13,334  INFO [main] mapreduce.Job: Running job: job_local1838936995_0001
2024-05-01T14:19:13,336  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:13,373  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,374  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,382  INFO [Thread-43] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:13,393  INFO [Thread-43] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,393  INFO [Thread-43] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,425  INFO [Thread-43] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:13,426  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1838936995_0001_m_000000_0
2024-05-01T14:19:13,467  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,467  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,473  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,473  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,495  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:13,501  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T14:19:13,526  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,527  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,633  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:13,647  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1838936995_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:13,647  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,647  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,653  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:13,653  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1838936995_0001_m_000000_0 is allowed to commit now
2024-05-01T14:19:13,654  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:13,654  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:13,670  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1838936995_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,23598769550849097/part1=p1value1/part0=501
2024-05-01T14:19:13,672  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:13,672  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1838936995_0001_m_000000_0' done.
2024-05-01T14:19:13,677  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1838936995_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=512500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:13,677  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1838936995_0001_m_000000_0
2024-05-01T14:19:13,678  INFO [Thread-43] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:13,754  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:13,754  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:13,755  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:13,755  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:13,755  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:13,755  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:13,755  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:13,756  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:13,756  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:13,756  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:13,757  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:13,758  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:13,760  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:13,761  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:13,761  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:13,762  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447ca9d6, with PersistenceManager: null will be shutdown
2024-05-01T14:19:13,763  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447ca9d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b6cc699 created in the thread with id: 69
2024-05-01T14:19:13,783  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447ca9d6 from thread id: 69
2024-05-01T14:19:13,784  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:13,785  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:13,786  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:13,786  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@447ca9d6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b6cc699 will be shutdown
2024-05-01T14:19:13,787  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:13,787  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-05-01T14:19:13,787  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:13,789  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:13,790  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c308d8f, with PersistenceManager: null will be shutdown
2024-05-01T14:19:13,790  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c308d8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36a08746 created in the thread with id: 69
2024-05-01T14:19:13,806  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c308d8f from thread id: 69
2024-05-01T14:19:13,897  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:13,897  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:13,897  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:13,897  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:13,897  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:13,897  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:13,898  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:13,898  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:13,898  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:13,898  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:13,898  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:13,899  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T14:19:13,943  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,23598769550849097/part1=p1value1/part0=501].
2024-05-01T14:19:13,944  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:14,002  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:14,002  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:14,002  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:14,003  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:14,004  WARN [Thread-43] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:14,004  INFO [Thread-43] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:14,006  INFO [Thread-43] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:14,007  INFO [Thread-43] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:14,008  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c308d8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36a08746 will be shutdown
2024-05-01T14:19:14,008  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c308d8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35f032b3 created in the thread with id: 69
2024-05-01T14:19:14,013  INFO [Thread-43] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:14,013  INFO [Thread-43] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:14,013  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:14,014  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c308d8f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35f032b3 will be shutdown
2024-05-01T14:19:14,014  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:14,014  INFO [Thread-43] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T14:19:14,014  INFO [Thread-43] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:14,015  INFO [Thread-43] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:14,016  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@591bab92, with PersistenceManager: null will be shutdown
2024-05-01T14:19:14,017  INFO [Thread-43] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@591bab92, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5aaed9df created in the thread with id: 69
2024-05-01T14:19:14,024  INFO [Thread-43] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@591bab92 from thread id: 69
2024-05-01T14:19:14,026  INFO [Thread-43] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:14,026  WARN [Thread-43] mapred.LocalJobRunner: job_local1838936995_0001
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,23598769550849097/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:14,343  INFO [main] mapreduce.Job: Job job_local1838936995_0001 running in uber mode : false
2024-05-01T14:19:14,344  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:14,347  INFO [main] mapreduce.Job: Job job_local1838936995_0001 failed with state FAILED due to: NA
2024-05-01T14:19:14,352  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=512500
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:14,418  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:14,419  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:14,419  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:14,419  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:14,419  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:14,420  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:14,428  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:14,428  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:14,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79be91eb will be shutdown
2024-05-01T14:19:14,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61853c7e created in the thread with id: 1
2024-05-01T14:19:14,435  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:14,435  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:14,436  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:14,436  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d1c933, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61853c7e will be shutdown
2024-05-01T14:19:14,436  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:14,436  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T14:19:14,436  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:14,437  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:14,438  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: null will be shutdown
2024-05-01T14:19:14,438  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ccc1026 created in the thread with id: 1
2024-05-01T14:19:14,445  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52 from thread id: 1
2024-05-01T14:19:14,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:14,466  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:14,478  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:14,548  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:14,548  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:14,549  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:14,550  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:14,551  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:14,551  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:14,552  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ccc1026 will be shutdown
2024-05-01T14:19:14,552  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5be51aa created in the thread with id: 1
2024-05-01T14:19:14,559  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:14,560  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:14,561  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:14,561  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@55c50f52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5be51aa will be shutdown
2024-05-01T14:19:14,562  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:14,562  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-05-01T14:19:14,562  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:14,564  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:14,565  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: null will be shutdown
2024-05-01T14:19:14,565  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@577bfadb created in the thread with id: 1
2024-05-01T14:19:14,569  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb from thread id: 1
2024-05-01T14:19:14,572  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T14:19:14,618  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:14,629  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:14,630  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:14,659  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:14,681  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local678625918_0002
2024-05-01T14:19:14,681  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:14,771  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:14,772  INFO [main] mapreduce.Job: Running job: job_local678625918_0002
2024-05-01T14:19:14,774  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:14,781  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,781  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,784  INFO [Thread-91] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:14,786  INFO [Thread-91] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,786  INFO [Thread-91] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,807  INFO [Thread-91] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:14,807  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local678625918_0002_m_000000_0
2024-05-01T14:19:14,820  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,820  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,836  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,836  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,846  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:14,847  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:14,873  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,874  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,896  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:14,897  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local678625918_0002_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:14,897  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,897  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,902  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:14,902  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local678625918_0002_m_000000_0 is allowed to commit now
2024-05-01T14:19:14,902  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:14,902  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:14,917  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local678625918_0002_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9761330176890333/part1=p1value2/part0=502
2024-05-01T14:19:14,918  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:14,918  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local678625918_0002_m_000000_0' done.
2024-05-01T14:19:14,918  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local678625918_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1022829
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:14,918  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local678625918_0002_m_000000_0
2024-05-01T14:19:14,918  INFO [Thread-91] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:15,024  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:15,025  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:15,025  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:15,025  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:15,025  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:15,025  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:15,026  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:15,026  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:15,026  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:15,026  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:15,026  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:15,027  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:15,028  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:15,029  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:15,029  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:15,029  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796841ed, with PersistenceManager: null will be shutdown
2024-05-01T14:19:15,029  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796841ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c28e124 created in the thread with id: 119
2024-05-01T14:19:15,038  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796841ed from thread id: 119
2024-05-01T14:19:15,040  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:15,042  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:15,042  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:15,042  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@796841ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c28e124 will be shutdown
2024-05-01T14:19:15,043  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:15,043  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-05-01T14:19:15,044  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:15,045  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:15,046  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fc5a88, with PersistenceManager: null will be shutdown
2024-05-01T14:19:15,046  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fc5a88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bb440d2 created in the thread with id: 119
2024-05-01T14:19:15,052  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fc5a88 from thread id: 119
2024-05-01T14:19:15,133  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:15,133  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:15,133  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:15,134  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:15,135  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:15,135  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:15,169  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9761330176890333/part1=p1value2/part0=502].
2024-05-01T14:19:15,170  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:15,230  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:15,230  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:15,230  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:15,231  WARN [Thread-91] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:15,232  INFO [Thread-91] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:15,233  INFO [Thread-91] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:15,233  INFO [Thread-91] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:15,234  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fc5a88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bb440d2 will be shutdown
2024-05-01T14:19:15,234  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fc5a88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f4fe5c4 created in the thread with id: 119
2024-05-01T14:19:15,239  INFO [Thread-91] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:15,240  INFO [Thread-91] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:15,240  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:15,240  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fc5a88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5f4fe5c4 will be shutdown
2024-05-01T14:19:15,241  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:15,241  INFO [Thread-91] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -9
2024-05-01T14:19:15,241  INFO [Thread-91] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:15,242  INFO [Thread-91] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:15,243  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed7a845, with PersistenceManager: null will be shutdown
2024-05-01T14:19:15,244  INFO [Thread-91] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed7a845, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ec4baab created in the thread with id: 119
2024-05-01T14:19:15,249  INFO [Thread-91] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2ed7a845 from thread id: 119
2024-05-01T14:19:15,251  INFO [Thread-91] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:15,251  WARN [Thread-91] mapred.LocalJobRunner: job_local678625918_0002
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9761330176890333/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:15,772  INFO [main] mapreduce.Job: Job job_local678625918_0002 running in uber mode : false
2024-05-01T14:19:15,773  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:15,773  INFO [main] mapreduce.Job: Job job_local678625918_0002 failed with state FAILED due to: NA
2024-05-01T14:19:15,775  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1022829
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:15,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:15,855  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:15,855  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:15,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:15,855  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:15,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:15,856  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:15,856  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:15,856  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:15,856  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:15,856  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:15,857  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:15,858  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:15,862  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:15,862  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:15,863  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@577bfadb will be shutdown
2024-05-01T14:19:15,863  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c2ab536 created in the thread with id: 1
2024-05-01T14:19:15,868  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:15,869  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:15,869  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:15,869  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64bba0eb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c2ab536 will be shutdown
2024-05-01T14:19:15,869  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:15,870  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -10
2024-05-01T14:19:15,870  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:15,872  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:15,873  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: null will be shutdown
2024-05-01T14:19:15,873  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1805383 created in the thread with id: 1
2024-05-01T14:19:15,878  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300 from thread id: 1
2024-05-01T14:19:15,880  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:15,896  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:15,910  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:15,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:15,976  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:15,976  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:15,976  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:15,976  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:15,976  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:15,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:15,978  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:15,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:15,979  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:15,979  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:15,980  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:15,981  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:15,981  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:15,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1805383 will be shutdown
2024-05-01T14:19:15,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47eaf55c created in the thread with id: 1
2024-05-01T14:19:15,996  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:16,010  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:16,056  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:16,056  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4fd80300, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47eaf55c will be shutdown
2024-05-01T14:19:16,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:16,057  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -11
2024-05-01T14:19:16,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:16,059  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:16,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: null will be shutdown
2024-05-01T14:19:16,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@333d44f6 created in the thread with id: 1
2024-05-01T14:19:16,064  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554 from thread id: 1
2024-05-01T14:19:16,066  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-05-01T14:19:16,094  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:16,099  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:16,101  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:16,128  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:16,150  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local149694123_0003
2024-05-01T14:19:16,150  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:16,234  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:16,234  INFO [main] mapreduce.Job: Running job: job_local149694123_0003
2024-05-01T14:19:16,235  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:16,239  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,239  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,240  INFO [Thread-137] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:16,242  INFO [Thread-137] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,242  INFO [Thread-137] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,259  INFO [Thread-137] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:16,259  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local149694123_0003_m_000000_0
2024-05-01T14:19:16,264  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,264  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,267  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,267  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,267  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:16,268  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:16,275  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,275  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,295  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:16,295  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local149694123_0003_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:16,296  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,296  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,301  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:16,301  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local149694123_0003_m_000000_0 is allowed to commit now
2024-05-01T14:19:16,302  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:16,302  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:16,317  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local149694123_0003_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,13487439596928663/part1=p1value2/part0=502
2024-05-01T14:19:16,318  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:16,318  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local149694123_0003_m_000000_0' done.
2024-05-01T14:19:16,318  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local149694123_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1533163
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:16,318  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local149694123_0003_m_000000_0
2024-05-01T14:19:16,318  INFO [Thread-137] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:16,392  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:16,392  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:16,392  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:16,392  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:16,392  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:16,392  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:16,393  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:16,393  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:16,393  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:16,393  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:16,394  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:16,394  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:16,396  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:16,397  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:16,397  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:16,398  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4affeb94, with PersistenceManager: null will be shutdown
2024-05-01T14:19:16,398  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4affeb94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76f9cbd created in the thread with id: 167
2024-05-01T14:19:16,407  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4affeb94 from thread id: 167
2024-05-01T14:19:16,407  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:16,407  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:16,408  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:16,408  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4affeb94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76f9cbd will be shutdown
2024-05-01T14:19:16,408  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:16,408  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -12
2024-05-01T14:19:16,408  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:16,409  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:16,410  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b846540, with PersistenceManager: null will be shutdown
2024-05-01T14:19:16,411  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b846540, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@41193924 created in the thread with id: 167
2024-05-01T14:19:16,415  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b846540 from thread id: 167
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:16,495  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:16,496  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:16,496  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:16,496  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:16,496  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:16,496  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:16,534  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,13487439596928663/part1=p1value2/part0=502].
2024-05-01T14:19:16,535  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:16,600  WARN [Thread-137] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:16,601  INFO [Thread-137] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:16,601  INFO [Thread-137] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:16,602  INFO [Thread-137] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:16,602  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b846540, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@41193924 will be shutdown
2024-05-01T14:19:16,602  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b846540, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53e269bc created in the thread with id: 167
2024-05-01T14:19:16,607  INFO [Thread-137] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:16,608  INFO [Thread-137] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:16,608  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:16,608  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b846540, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53e269bc will be shutdown
2024-05-01T14:19:16,608  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:16,608  INFO [Thread-137] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -13
2024-05-01T14:19:16,608  INFO [Thread-137] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:16,609  INFO [Thread-137] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:16,610  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13b5c0b3, with PersistenceManager: null will be shutdown
2024-05-01T14:19:16,610  INFO [Thread-137] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13b5c0b3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e6a498b created in the thread with id: 167
2024-05-01T14:19:16,613  INFO [Thread-137] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13b5c0b3 from thread id: 167
2024-05-01T14:19:16,615  INFO [Thread-137] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:16,615  WARN [Thread-137] mapred.LocalJobRunner: job_local149694123_0003
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,13487439596928663/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:17,235  INFO [main] mapreduce.Job: Job job_local149694123_0003 running in uber mode : false
2024-05-01T14:19:17,235  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:17,236  INFO [main] mapreduce.Job: Job job_local149694123_0003 failed with state FAILED due to: NA
2024-05-01T14:19:17,238  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1533163
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:17,301  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:17,302  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:17,302  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:17,302  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:17,302  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:17,302  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:17,303  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:17,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:17,303  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:17,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:17,303  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:17,304  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:17,305  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:17,307  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:17,307  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:17,308  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@333d44f6 will be shutdown
2024-05-01T14:19:17,308  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e1add6f created in the thread with id: 1
2024-05-01T14:19:17,311  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:17,312  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:17,312  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:17,312  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a39e554, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2e1add6f will be shutdown
2024-05-01T14:19:17,312  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:17,312  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -14
2024-05-01T14:19:17,313  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:17,314  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,314  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bbdb220, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,314  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bbdb220, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d001fbe created in the thread with id: 1
2024-05-01T14:19:17,319  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bbdb220 from thread id: 1
2024-05-01T14:19:17,321  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:17,331  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:17,341  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:17,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:17,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:17,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:17,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:17,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:17,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:17,395  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:17,395  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:17,395  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:17,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:17,396  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:17,396  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:17,397  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:17,397  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:17,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bbdb220, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d001fbe will be shutdown
2024-05-01T14:19:17,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bbdb220, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d85b399 created in the thread with id: 1
2024-05-01T14:19:17,402  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:17,403  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:17,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:17,404  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bbdb220, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d85b399 will be shutdown
2024-05-01T14:19:17,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:17,404  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -15
2024-05-01T14:19:17,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:17,406  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fc1c7e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,407  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fc1c7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75cacb3e created in the thread with id: 1
2024-05-01T14:19:17,409  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fc1c7e from thread id: 1
2024-05-01T14:19:17,479  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:17,479  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:17,479  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:17,479  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:17,479  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:17,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:17,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:17,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:17,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:17,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:17,480  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:17,481  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:17,482  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:17,485  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:17,485  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:17,486  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fc1c7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75cacb3e will be shutdown
2024-05-01T14:19:17,486  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fc1c7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a6195b8 created in the thread with id: 1
2024-05-01T14:19:17,492  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:17,492  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:17,493  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:17,493  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fc1c7e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a6195b8 will be shutdown
2024-05-01T14:19:17,494  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:17,494  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -16
2024-05-01T14:19:17,494  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:17,495  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,496  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f471037, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,496  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f471037, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d1cfe4 created in the thread with id: 1
2024-05-01T14:19:17,500  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f471037 from thread id: 1
2024-05-01T14:19:17,504  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:17,516  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:17,598  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:17,599  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:17,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:17,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:17,607  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:17,608  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:17,608  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:17,611  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:17,611  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:17,611  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f471037, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d1cfe4 will be shutdown
2024-05-01T14:19:17,612  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f471037, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a336377 created in the thread with id: 1
2024-05-01T14:19:17,615  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:17,617  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:17,621  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:17,621  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f471037, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a336377 will be shutdown
2024-05-01T14:19:17,621  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:17,622  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -17
2024-05-01T14:19:17,622  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:17,623  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,624  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12f8682a, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,627  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12f8682a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f7a20da created in the thread with id: 1
2024-05-01T14:19:17,630  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12f8682a from thread id: 1
2024-05-01T14:19:17,632  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:17,644  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:17,652  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:17,703  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:17,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:17,704  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:17,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:17,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:17,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:17,705  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:17,705  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:17,705  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:17,705  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:17,705  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:17,706  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:17,707  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:17,707  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:17,708  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12f8682a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f7a20da will be shutdown
2024-05-01T14:19:17,708  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12f8682a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14dbfdb1 created in the thread with id: 1
2024-05-01T14:19:17,711  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:17,711  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:17,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:17,712  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@12f8682a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14dbfdb1 will be shutdown
2024-05-01T14:19:17,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:17,712  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -18
2024-05-01T14:19:17,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:17,713  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,713  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@334b392d, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,713  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@334b392d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59f7c106 created in the thread with id: 1
2024-05-01T14:19:17,716  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@334b392d from thread id: 1
2024-05-01T14:19:17,728  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:17,734  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:17,735  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:17,760  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:17,783  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1142089671_0004
2024-05-01T14:19:17,783  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:17,853  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:17,854  INFO [main] mapreduce.Job: Running job: job_local1142089671_0004
2024-05-01T14:19:17,855  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:17,860  INFO [Thread-188] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:17,862  INFO [Thread-188] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:17,862  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1142089671_0004_m_000000_0
2024-05-01T14:19:17,867  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:17,868  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T14:19:17,884  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1142089671_0004_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.6986159904952459/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T14:19:17,884  INFO [Thread-188] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:17,890  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.6986159904952459].
2024-05-01T14:19:17,890  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:17,946  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:17,946  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:17,946  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:17,946  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:17,946  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:17,946  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:17,947  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:17,947  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:17,947  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:17,947  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:17,947  WARN [Thread-188] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:17,947  INFO [Thread-188] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:17,949  INFO [Thread-188] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:17,950  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,950  INFO [Thread-188] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:17,950  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@43748e4c, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,951  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@43748e4c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8eb07da created in the thread with id: 220
2024-05-01T14:19:17,956  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@43748e4c from thread id: 220
2024-05-01T14:19:17,956  INFO [Thread-188] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:17,956  INFO [Thread-188] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:17,957  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:17,957  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@43748e4c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8eb07da will be shutdown
2024-05-01T14:19:17,957  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:17,957  INFO [Thread-188] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -19
2024-05-01T14:19:17,957  INFO [Thread-188] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:17,958  INFO [Thread-188] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:17,959  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13c445d3, with PersistenceManager: null will be shutdown
2024-05-01T14:19:17,959  INFO [Thread-188] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13c445d3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e03cb63 created in the thread with id: 220
2024-05-01T14:19:17,962  INFO [Thread-188] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13c445d3 from thread id: 220
2024-05-01T14:19:17,964  INFO [Thread-188] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:17,964  WARN [Thread-188] mapred.LocalJobRunner: job_local1142089671_0004
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T14:19:18,854  INFO [main] mapreduce.Job: Job job_local1142089671_0004 running in uber mode : false
2024-05-01T14:19:18,854  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:18,855  INFO [main] mapreduce.Job: Job job_local1142089671_0004 failed with state FAILED due to: NA
2024-05-01T14:19:18,855  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:18,912  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:18,913  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:18,913  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:18,913  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:18,913  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:18,913  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:18,913  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:18,914  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:18,914  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:18,914  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:18,914  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:18,914  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:18,915  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:18,918  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:18,919  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:18,920  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@334b392d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59f7c106 will be shutdown
2024-05-01T14:19:18,920  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@334b392d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27dfd12b created in the thread with id: 1
2024-05-01T14:19:18,924  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:18,924  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:18,924  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:18,924  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@334b392d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27dfd12b will be shutdown
2024-05-01T14:19:18,924  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:18,924  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -20
2024-05-01T14:19:18,925  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:18,926  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:18,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: null will be shutdown
2024-05-01T14:19:18,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ab455e2 created in the thread with id: 1
2024-05-01T14:19:18,929  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad from thread id: 1
2024-05-01T14:19:18,930  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:18,944  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:18,944  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:18,971  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:18,979  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:18,986  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:19,015  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T14:19:19,043  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1738517230_0005
2024-05-01T14:19:19,043  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:19,110  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:19,110  INFO [main] mapreduce.Job: Running job: job_local1738517230_0005
2024-05-01T14:19:19,110  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:19,113  INFO [Thread-208] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:19,113  INFO [Thread-208] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:19,113  INFO [Thread-208] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T14:19:19,123  INFO [Thread-208] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:19,123  INFO [Thread-208] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:20,110  INFO [main] mapreduce.Job: Job job_local1738517230_0005 running in uber mode : false
2024-05-01T14:19:20,111  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:20,111  INFO [main] mapreduce.Job: Job job_local1738517230_0005 completed successfully
2024-05-01T14:19:20,111  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:20,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:20,120  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:20,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-05-01T14:19:20,602  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:20,603  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:20,603  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:20,603  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:20,603  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:20,603  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:20,604  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:20,604  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:20,604  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:20,605  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:20,605  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[1]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="7.413">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T14:19:20,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:20,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:20,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:20,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:20,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:20,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:20,676  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:20,676  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:20,676  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:20,676  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:20,676  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:20,678  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:20,678  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:20,678  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ab455e2 will be shutdown
2024-05-01T14:19:20,679  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@615ef20 created in the thread with id: 1
2024-05-01T14:19:20,691  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 5ef8730a-900d-4f39-8c06-bc94baf35dc0
2024-05-01T14:19:20,691  INFO [main] SessionState: Hive Session ID = 5ef8730a-900d-4f39-8c06-bc94baf35dc0
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:20,692  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:20,698  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/5ef8730a-900d-4f39-8c06-bc94baf35dc0
2024-05-01T14:19:20,704  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/5ef8730a-900d-4f39-8c06-bc94baf35dc0
2024-05-01T14:19:20,709  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/5ef8730a-900d-4f39-8c06-bc94baf35dc0/_tmp_space.db
2024-05-01T14:19:20,709  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:20,725  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_SEQUENCEFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.mapred.SequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_SEQUENCEFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T14:19:20,729  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile
2024-05-01T14:19:20,876  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:20,876  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:20,876  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:20,876  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:20,876  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:20,877  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:20,877  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:20,877  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:20,877  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:20,877  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:20,877  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:20,878  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:20,879  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:20,882  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:20,883  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:20,884  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@615ef20 will be shutdown
2024-05-01T14:19:20,884  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cff5aa3 created in the thread with id: 1
2024-05-01T14:19:20,888  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:20,889  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:20,889  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:20,889  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23df7fad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cff5aa3 will be shutdown
2024-05-01T14:19:20,889  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:20,889  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -21
2024-05-01T14:19:20,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:20,891  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:20,891  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:20,891  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69bca406 created in the thread with id: 1
2024-05-01T14:19:20,895  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e from thread id: 1
2024-05-01T14:19:20,898  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:20,936  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:20,984  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:21,089  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:21,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:21,091  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:21,091  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:21,092  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:21,092  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:21,093  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69bca406 will be shutdown
2024-05-01T14:19:21,093  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e998033 created in the thread with id: 1
2024-05-01T14:19:21,097  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:21,097  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:21,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:21,097  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7672960e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e998033 will be shutdown
2024-05-01T14:19:21,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:21,098  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -22
2024-05-01T14:19:21,098  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:21,099  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:21,100  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: null will be shutdown
2024-05-01T14:19:21,100  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c910acd created in the thread with id: 1
2024-05-01T14:19:21,103  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341 from thread id: 1
2024-05-01T14:19:21,106  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value1,501]	
2024-05-01T14:19:21,145  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:21,152  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:21,154  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:21,180  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:21,202  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local157234140_0006
2024-05-01T14:19:21,202  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:21,265  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:21,266  INFO [main] mapreduce.Job: Running job: job_local157234140_0006
2024-05-01T14:19:21,267  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:21,270  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,270  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,272  INFO [Thread-242] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:21,273  INFO [Thread-242] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,273  INFO [Thread-242] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,292  INFO [Thread-242] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:21,292  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local157234140_0006_m_000000_0
2024-05-01T14:19:21,304  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,304  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,306  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,306  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,307  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:21,308  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T14:19:21,320  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,320  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,362  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:21,370  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local157234140_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:21,371  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,371  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,376  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:21,376  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local157234140_0006_m_000000_0 is allowed to commit now
2024-05-01T14:19:21,376  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:21,376  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:21,388  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local157234140_0006_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,1896729433324148/part1=p1value1/part0=501
2024-05-01T14:19:21,389  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:21,389  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local157234140_0006_m_000000_0' done.
2024-05-01T14:19:21,389  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local157234140_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3066832
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:21,389  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local157234140_0006_m_000000_0
2024-05-01T14:19:21,389  INFO [Thread-242] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:21,453  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:21,453  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:21,454  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:21,455  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:21,455  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:21,455  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:21,457  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:21,458  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:21,458  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:21,459  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f4762b, with PersistenceManager: null will be shutdown
2024-05-01T14:19:21,459  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f4762b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@126bc037 created in the thread with id: 276
2024-05-01T14:19:21,462  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f4762b from thread id: 276
2024-05-01T14:19:21,462  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:21,463  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:21,463  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:21,463  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f4762b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@126bc037 will be shutdown
2024-05-01T14:19:21,463  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:21,463  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -23
2024-05-01T14:19:21,463  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:21,464  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:21,465  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36e15f3f, with PersistenceManager: null will be shutdown
2024-05-01T14:19:21,465  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36e15f3f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1066d140 created in the thread with id: 276
2024-05-01T14:19:21,470  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36e15f3f from thread id: 276
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:21,528  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:21,529  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:21,529  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T14:19:21,563  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,1896729433324148/part1=p1value1/part0=501].
2024-05-01T14:19:21,563  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:21,626  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:21,626  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:21,627  WARN [Thread-242] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:21,628  INFO [Thread-242] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:21,630  INFO [Thread-242] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:21,630  INFO [Thread-242] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:21,630  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36e15f3f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1066d140 will be shutdown
2024-05-01T14:19:21,631  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36e15f3f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c74c9f created in the thread with id: 276
2024-05-01T14:19:21,635  INFO [Thread-242] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:21,641  INFO [Thread-242] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:21,641  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:21,642  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36e15f3f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76c74c9f will be shutdown
2024-05-01T14:19:21,642  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:21,642  INFO [Thread-242] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -24
2024-05-01T14:19:21,642  INFO [Thread-242] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:21,643  INFO [Thread-242] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:21,645  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b380a6, with PersistenceManager: null will be shutdown
2024-05-01T14:19:21,645  INFO [Thread-242] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b380a6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f87ebbb created in the thread with id: 276
2024-05-01T14:19:21,651  INFO [Thread-242] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b380a6 from thread id: 276
2024-05-01T14:19:21,654  INFO [Thread-242] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:21,654  WARN [Thread-242] mapred.LocalJobRunner: job_local157234140_0006
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,1896729433324148/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:22,267  INFO [main] mapreduce.Job: Job job_local157234140_0006 running in uber mode : false
2024-05-01T14:19:22,267  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:22,267  INFO [main] mapreduce.Job: Job job_local157234140_0006 failed with state FAILED due to: NA
2024-05-01T14:19:22,268  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3066832
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:22,328  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:22,329  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:22,329  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:22,329  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:22,329  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:22,329  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:22,330  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:22,334  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:22,334  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:22,335  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c910acd will be shutdown
2024-05-01T14:19:22,335  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@312819ae created in the thread with id: 1
2024-05-01T14:19:22,338  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:22,338  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:22,338  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:22,338  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4780341, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@312819ae will be shutdown
2024-05-01T14:19:22,338  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:22,339  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -25
2024-05-01T14:19:22,339  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:22,339  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:22,340  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: null will be shutdown
2024-05-01T14:19:22,340  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15ad5acb created in the thread with id: 1
2024-05-01T14:19:22,342  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b from thread id: 1
2024-05-01T14:19:22,343  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:22,357  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:22,366  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:22,410  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:22,411  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:22,411  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:22,412  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:22,412  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:22,412  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15ad5acb will be shutdown
2024-05-01T14:19:22,413  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5831989d created in the thread with id: 1
2024-05-01T14:19:22,416  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:22,417  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:22,417  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:22,417  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408d945b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5831989d will be shutdown
2024-05-01T14:19:22,417  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:22,417  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -26
2024-05-01T14:19:22,417  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:22,419  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:22,420  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: null will be shutdown
2024-05-01T14:19:22,420  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2006fdaa created in the thread with id: 1
2024-05-01T14:19:22,423  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671 from thread id: 1
2024-05-01T14:19:22,425  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T14:19:22,461  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:22,467  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:22,468  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:22,494  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:22,514  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local865953345_0007
2024-05-01T14:19:22,515  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:22,582  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:22,582  INFO [main] mapreduce.Job: Running job: job_local865953345_0007
2024-05-01T14:19:22,582  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:22,585  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,585  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,586  INFO [Thread-288] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:22,587  INFO [Thread-288] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,587  INFO [Thread-288] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,604  INFO [Thread-288] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:22,604  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local865953345_0007_m_000000_0
2024-05-01T14:19:22,607  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,607  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,610  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,610  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,610  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:22,611  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:22,616  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,616  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,636  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:22,636  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local865953345_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:22,636  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,636  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,640  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:22,640  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local865953345_0007_m_000000_0 is allowed to commit now
2024-05-01T14:19:22,640  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:22,640  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:22,654  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local865953345_0007_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8520559327377407/part1=p1value2/part0=502
2024-05-01T14:19:22,655  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:22,655  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local865953345_0007_m_000000_0' done.
2024-05-01T14:19:22,656  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local865953345_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3577507
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:22,656  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local865953345_0007_m_000000_0
2024-05-01T14:19:22,656  INFO [Thread-288] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:22,733  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:22,734  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:22,734  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:22,734  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:22,734  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:22,734  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:22,735  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:22,736  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:22,736  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:22,737  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d2eec2a, with PersistenceManager: null will be shutdown
2024-05-01T14:19:22,737  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d2eec2a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@275d4896 created in the thread with id: 324
2024-05-01T14:19:22,740  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d2eec2a from thread id: 324
2024-05-01T14:19:22,740  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:22,740  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:22,741  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:22,741  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d2eec2a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@275d4896 will be shutdown
2024-05-01T14:19:22,741  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:22,741  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -27
2024-05-01T14:19:22,741  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:22,743  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:22,743  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4667ea, with PersistenceManager: null will be shutdown
2024-05-01T14:19:22,743  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4667ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@664ea008 created in the thread with id: 324
2024-05-01T14:19:22,747  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4667ea from thread id: 324
2024-05-01T14:19:22,815  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:22,815  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:22,815  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:22,815  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:22,815  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:22,815  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:22,816  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:22,816  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:22,816  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:22,816  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:22,816  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:22,816  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:22,850  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8520559327377407/part1=p1value2/part0=502].
2024-05-01T14:19:22,851  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:22,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:22,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:22,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:22,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:22,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:22,920  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:22,921  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:22,921  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:22,921  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:22,921  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:22,921  WARN [Thread-288] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:22,921  INFO [Thread-288] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:22,922  INFO [Thread-288] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:22,923  INFO [Thread-288] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:22,923  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4667ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@664ea008 will be shutdown
2024-05-01T14:19:22,923  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4667ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e37200a created in the thread with id: 324
2024-05-01T14:19:22,928  INFO [Thread-288] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:22,928  INFO [Thread-288] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:22,929  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:22,929  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4667ea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e37200a will be shutdown
2024-05-01T14:19:22,929  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:22,929  INFO [Thread-288] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -28
2024-05-01T14:19:22,929  INFO [Thread-288] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:22,930  INFO [Thread-288] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:22,931  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@134ad7f, with PersistenceManager: null will be shutdown
2024-05-01T14:19:22,931  INFO [Thread-288] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@134ad7f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52fa930e created in the thread with id: 324
2024-05-01T14:19:22,935  INFO [Thread-288] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@134ad7f from thread id: 324
2024-05-01T14:19:22,937  INFO [Thread-288] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:22,937  WARN [Thread-288] mapred.LocalJobRunner: job_local865953345_0007
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,8520559327377407/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:23,583  INFO [main] mapreduce.Job: Job job_local865953345_0007 running in uber mode : false
2024-05-01T14:19:23,583  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:23,583  INFO [main] mapreduce.Job: Job job_local865953345_0007 failed with state FAILED due to: NA
2024-05-01T14:19:23,584  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3577507
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:23,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:23,648  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:23,649  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:23,650  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:23,652  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:23,652  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:23,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2006fdaa will be shutdown
2024-05-01T14:19:23,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57eed461 created in the thread with id: 1
2024-05-01T14:19:23,656  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:23,657  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:23,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:23,657  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5621a671, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57eed461 will be shutdown
2024-05-01T14:19:23,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:23,657  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -29
2024-05-01T14:19:23,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:23,659  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:23,659  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: null will be shutdown
2024-05-01T14:19:23,660  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74450c9b created in the thread with id: 1
2024-05-01T14:19:23,662  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8 from thread id: 1
2024-05-01T14:19:23,665  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:23,677  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:23,689  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:23,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:23,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:23,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:23,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:23,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:23,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:23,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:23,744  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:23,744  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:23,744  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:23,744  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:23,744  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:23,745  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:23,745  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:23,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74450c9b will be shutdown
2024-05-01T14:19:23,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d90764a created in the thread with id: 1
2024-05-01T14:19:23,750  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:23,750  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:23,750  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:23,750  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@254513e8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d90764a will be shutdown
2024-05-01T14:19:23,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:23,751  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -30
2024-05-01T14:19:23,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:23,752  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:23,752  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: null will be shutdown
2024-05-01T14:19:23,752  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db06c50 created in the thread with id: 1
2024-05-01T14:19:23,755  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26 from thread id: 1
2024-05-01T14:19:23,758  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-05-01T14:19:23,792  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:23,800  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:23,801  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:23,828  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:23,848  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local415803883_0008
2024-05-01T14:19:23,848  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:23,912  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:23,912  INFO [main] mapreduce.Job: Running job: job_local415803883_0008
2024-05-01T14:19:23,912  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:23,916  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,916  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,918  INFO [Thread-334] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:23,919  INFO [Thread-334] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,919  INFO [Thread-334] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,936  INFO [Thread-334] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:23,936  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local415803883_0008_m_000000_0
2024-05-01T14:19:23,939  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,939  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,941  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,941  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,941  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:23,942  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:23,946  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,946  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,969  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:23,969  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local415803883_0008_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:23,969  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,969  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,974  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:23,974  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local415803883_0008_m_000000_0 is allowed to commit now
2024-05-01T14:19:23,974  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:23,974  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:23,987  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local415803883_0008_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,571359937174024/part1=p1value2/part0=502
2024-05-01T14:19:23,987  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:23,988  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local415803883_0008_m_000000_0' done.
2024-05-01T14:19:23,988  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local415803883_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4088177
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:23,988  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local415803883_0008_m_000000_0
2024-05-01T14:19:23,988  INFO [Thread-334] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:24,048  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:24,048  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:24,049  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:24,051  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:24,051  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:24,051  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:24,054  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:24,055  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:24,055  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:24,056  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac3892, with PersistenceManager: null will be shutdown
2024-05-01T14:19:24,056  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac3892, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b4ae805 created in the thread with id: 372
2024-05-01T14:19:24,059  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac3892 from thread id: 372
2024-05-01T14:19:24,059  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:24,059  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:24,059  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:24,059  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ac3892, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b4ae805 will be shutdown
2024-05-01T14:19:24,060  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:24,060  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -31
2024-05-01T14:19:24,060  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:24,061  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:24,062  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b35b057, with PersistenceManager: null will be shutdown
2024-05-01T14:19:24,062  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b35b057, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35f76ab0 created in the thread with id: 372
2024-05-01T14:19:24,067  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b35b057 from thread id: 372
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:24,137  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:24,138  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:24,138  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:24,138  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:24,165  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,571359937174024/part1=p1value2/part0=502].
2024-05-01T14:19:24,166  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:24,234  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:24,235  WARN [Thread-334] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:24,235  INFO [Thread-334] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:24,237  INFO [Thread-334] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:24,237  INFO [Thread-334] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:24,238  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b35b057, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@35f76ab0 will be shutdown
2024-05-01T14:19:24,238  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b35b057, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@206a6f5b created in the thread with id: 372
2024-05-01T14:19:24,241  INFO [Thread-334] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:24,241  INFO [Thread-334] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:24,242  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:24,242  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b35b057, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@206a6f5b will be shutdown
2024-05-01T14:19:24,242  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:24,242  INFO [Thread-334] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -32
2024-05-01T14:19:24,242  INFO [Thread-334] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:24,244  INFO [Thread-334] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:24,245  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e54146b, with PersistenceManager: null will be shutdown
2024-05-01T14:19:24,245  INFO [Thread-334] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e54146b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e63fc01 created in the thread with id: 372
2024-05-01T14:19:24,248  INFO [Thread-334] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e54146b from thread id: 372
2024-05-01T14:19:24,253  INFO [Thread-334] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:24,253  WARN [Thread-334] mapred.LocalJobRunner: job_local415803883_0008
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,571359937174024/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:24,913  INFO [main] mapreduce.Job: Job job_local415803883_0008 running in uber mode : false
2024-05-01T14:19:24,913  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:24,913  INFO [main] mapreduce.Job: Job job_local415803883_0008 failed with state FAILED due to: NA
2024-05-01T14:19:24,916  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4088177
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=824180736
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:24,976  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:24,976  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:24,976  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:24,977  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:24,977  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:24,978  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:24,980  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:24,981  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:24,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db06c50 will be shutdown
2024-05-01T14:19:24,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3180aee created in the thread with id: 1
2024-05-01T14:19:24,985  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:24,985  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:24,986  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:24,986  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c116f26, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3180aee will be shutdown
2024-05-01T14:19:24,986  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:24,986  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -33
2024-05-01T14:19:24,986  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:24,988  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:24,988  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: null will be shutdown
2024-05-01T14:19:24,988  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32d8710a created in the thread with id: 1
2024-05-01T14:19:24,992  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1 from thread id: 1
2024-05-01T14:19:24,994  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:25,007  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:25,016  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:25,061  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:25,062  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:25,062  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:25,062  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:25,062  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:25,062  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:25,064  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:25,064  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:25,064  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32d8710a will be shutdown
2024-05-01T14:19:25,064  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@603b9d4b created in the thread with id: 1
2024-05-01T14:19:25,067  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:25,067  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:25,067  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:25,067  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69fd99c1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@603b9d4b will be shutdown
2024-05-01T14:19:25,067  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:25,067  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -34
2024-05-01T14:19:25,067  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:25,068  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:25,069  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: null will be shutdown
2024-05-01T14:19:25,069  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ca6bd01 created in the thread with id: 1
2024-05-01T14:19:25,071  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba from thread id: 1
2024-05-01T14:19:25,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:25,141  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:25,142  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:25,143  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:25,187  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:25,188  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:25,190  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:25,190  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:25,191  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ca6bd01 will be shutdown
2024-05-01T14:19:25,191  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44da745f created in the thread with id: 1
2024-05-01T14:19:25,194  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:25,195  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:25,195  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:25,195  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23263ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44da745f will be shutdown
2024-05-01T14:19:25,196  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:25,196  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -35
2024-05-01T14:19:25,196  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:25,197  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:25,198  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: null will be shutdown
2024-05-01T14:19:25,198  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8bde368 created in the thread with id: 1
2024-05-01T14:19:25,203  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896 from thread id: 1
2024-05-01T14:19:25,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:25,215  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:25,280  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:25,280  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:25,280  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:25,280  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:25,280  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:25,280  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:25,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:25,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:25,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:25,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:25,281  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:25,281  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:25,282  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:25,284  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:25,284  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:25,285  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8bde368 will be shutdown
2024-05-01T14:19:25,285  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6fe243a created in the thread with id: 1
2024-05-01T14:19:25,288  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:25,288  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:25,288  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:25,288  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1782896, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6fe243a will be shutdown
2024-05-01T14:19:25,288  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:25,288  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -36
2024-05-01T14:19:25,288  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:25,289  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:25,289  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: null will be shutdown
2024-05-01T14:19:25,289  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@308be1a3 created in the thread with id: 1
2024-05-01T14:19:25,291  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f from thread id: 1
2024-05-01T14:19:25,293  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:25,303  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:25,310  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:25,371  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:25,372  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:25,373  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:25,373  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:25,373  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@308be1a3 will be shutdown
2024-05-01T14:19:25,373  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60b4c754 created in the thread with id: 1
2024-05-01T14:19:25,376  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:25,376  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:25,376  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:25,377  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66fff42f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60b4c754 will be shutdown
2024-05-01T14:19:25,377  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:25,377  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -37
2024-05-01T14:19:25,377  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:25,378  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:25,379  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47374fa5, with PersistenceManager: null will be shutdown
2024-05-01T14:19:25,379  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47374fa5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@289da1bc created in the thread with id: 1
2024-05-01T14:19:25,383  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47374fa5 from thread id: 1
2024-05-01T14:19:25,394  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:25,406  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:25,406  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:25,434  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:25,458  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local434682432_0009
2024-05-01T14:19:25,458  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:25,535  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:25,535  INFO [main] mapreduce.Job: Running job: job_local434682432_0009
2024-05-01T14:19:25,535  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:25,538  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:25,539  INFO [Thread-385] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:25,539  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local434682432_0009_m_000000_0
2024-05-01T14:19:25,543  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:25,545  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T14:19:25,556  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local434682432_0009_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.1858380520815628/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T14:19:25,556  INFO [Thread-385] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:25,558  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.1858380520815628].
2024-05-01T14:19:25,558  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:25,613  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:25,613  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:25,614  WARN [Thread-385] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:25,614  INFO [Thread-385] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:25,616  INFO [Thread-385] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:25,616  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:25,617  INFO [Thread-385] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:25,617  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e0b6d0e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:25,617  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e0b6d0e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e6a10a created in the thread with id: 425
2024-05-01T14:19:25,619  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e0b6d0e from thread id: 425
2024-05-01T14:19:25,619  INFO [Thread-385] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:25,620  INFO [Thread-385] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:25,620  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:25,620  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5e0b6d0e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e6a10a will be shutdown
2024-05-01T14:19:25,620  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:25,620  INFO [Thread-385] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -38
2024-05-01T14:19:25,620  INFO [Thread-385] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:25,621  INFO [Thread-385] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:25,621  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad4456e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:25,621  INFO [Thread-385] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad4456e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3843c0c9 created in the thread with id: 425
2024-05-01T14:19:25,623  INFO [Thread-385] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ad4456e from thread id: 425
2024-05-01T14:19:25,624  INFO [Thread-385] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:25,624  WARN [Thread-385] mapred.LocalJobRunner: job_local434682432_0009
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T14:19:26,535  INFO [main] mapreduce.Job: Job job_local434682432_0009 running in uber mode : false
2024-05-01T14:19:26,536  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:26,536  INFO [main] mapreduce.Job: Job job_local434682432_0009 failed with state FAILED due to: NA
2024-05-01T14:19:26,536  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:26,591  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:26,592  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:26,592  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:26,592  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:26,592  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:26,592  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:26,593  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:26,596  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:26,596  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:26,598  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47374fa5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@289da1bc will be shutdown
2024-05-01T14:19:26,599  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47374fa5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5fd31df7 created in the thread with id: 1
2024-05-01T14:19:26,602  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:26,608  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:26,609  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:26,609  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47374fa5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5fd31df7 will be shutdown
2024-05-01T14:19:26,609  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:26,609  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -39
2024-05-01T14:19:26,609  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:26,610  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:26,611  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: null will be shutdown
2024-05-01T14:19:26,611  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47666b39 created in the thread with id: 1
2024-05-01T14:19:26,614  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905 from thread id: 1
2024-05-01T14:19:26,625  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:26,639  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:26,640  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:26,652  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:26,660  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:26,673  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:26,704  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T14:19:26,733  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1017164229_0010
2024-05-01T14:19:26,733  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:26,798  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:26,798  INFO [main] mapreduce.Job: Running job: job_local1017164229_0010
2024-05-01T14:19:26,798  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:26,799  INFO [Thread-405] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:26,799  INFO [Thread-405] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:26,799  INFO [Thread-405] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T14:19:26,808  INFO [Thread-405] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:26,808  INFO [Thread-405] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:27,799  INFO [main] mapreduce.Job: Job job_local1017164229_0010 running in uber mode : false
2024-05-01T14:19:27,799  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:27,799  INFO [main] mapreduce.Job: Job job_local1017164229_0010 completed successfully
2024-05-01T14:19:27,799  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:27,800  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:27,810  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:27,810  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-05-01T14:19:28,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,003  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[2]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.837">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T14:19:28,096  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,096  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,096  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,096  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,096  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,096  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,097  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,097  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,097  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,097  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,097  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:28,099  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:28,099  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:28,100  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47666b39 will be shutdown
2024-05-01T14:19:28,100  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@167bb934 created in the thread with id: 1
2024-05-01T14:19:28,103  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 29370aa7-ba93-47f0-8395-34f29ff9c9f2
2024-05-01T14:19:28,103  INFO [main] SessionState: Hive Session ID = 29370aa7-ba93-47f0-8395-34f29ff9c9f2
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:28,104  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:28,112  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/29370aa7-ba93-47f0-8395-34f29ff9c9f2
2024-05-01T14:19:28,115  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/29370aa7-ba93-47f0-8395-34f29ff9c9f2
2024-05-01T14:19:28,118  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/29370aa7-ba93-47f0-8395-34f29ff9c9f2/_tmp_space.db
2024-05-01T14:19:28,118  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:28,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_RCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_RCFILE, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T14:19:28,124  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,236  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:28,237  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:28,238  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:28,241  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:28,241  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:28,241  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@167bb934 will be shutdown
2024-05-01T14:19:28,242  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8ce4320 created in the thread with id: 1
2024-05-01T14:19:28,246  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:28,246  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:28,247  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:28,247  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21780905, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@8ce4320 will be shutdown
2024-05-01T14:19:28,247  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:28,247  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -40
2024-05-01T14:19:28,247  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:28,248  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:28,249  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33239d72, with PersistenceManager: null will be shutdown
2024-05-01T14:19:28,249  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33239d72, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19c24321 created in the thread with id: 1
2024-05-01T14:19:28,252  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33239d72 from thread id: 1
2024-05-01T14:19:28,254  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:28,266  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:28,278  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:28,327  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,328  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:28,329  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:28,330  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:28,330  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:28,330  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33239d72, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19c24321 will be shutdown
2024-05-01T14:19:28,330  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33239d72, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2696b687 created in the thread with id: 1
2024-05-01T14:19:28,336  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:28,336  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:28,336  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:28,336  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33239d72, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2696b687 will be shutdown
2024-05-01T14:19:28,337  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:28,337  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -41
2024-05-01T14:19:28,337  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:28,338  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:28,338  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368d51ca, with PersistenceManager: null will be shutdown
2024-05-01T14:19:28,339  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368d51ca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a349a73 created in the thread with id: 1
2024-05-01T14:19:28,344  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368d51ca from thread id: 1
2024-05-01T14:19:28,347  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value1,501]	
2024-05-01T14:19:28,380  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:28,386  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:28,387  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:28,418  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:28,440  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1591874794_0011
2024-05-01T14:19:28,440  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:28,513  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:28,513  INFO [main] mapreduce.Job: Running job: job_local1591874794_0011
2024-05-01T14:19:28,513  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:28,516  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,516  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,518  INFO [Thread-439] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:28,518  INFO [Thread-439] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,518  INFO [Thread-439] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,534  INFO [Thread-439] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:28,535  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1591874794_0011_m_000000_0
2024-05-01T14:19:28,543  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,544  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,546  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,546  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,546  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:28,547  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T14:19:28,554  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,554  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,597  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:28,598  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T14:19:28,598  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T14:19:28,602  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1591874794_0011_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:28,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,607  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:28,607  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1591874794_0011_m_000000_0 is allowed to commit now
2024-05-01T14:19:28,607  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:28,607  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:28,627  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1591874794_0011_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,12702632642294076/part1=p1value1/part0=501
2024-05-01T14:19:28,627  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:28,628  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1591874794_0011_m_000000_0' done.
2024-05-01T14:19:28,628  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1591874794_0011_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5622227
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=826277888
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:28,628  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1591874794_0011_m_000000_0
2024-05-01T14:19:28,628  INFO [Thread-439] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,701  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:28,701  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:28,702  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:28,703  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:28,703  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:28,703  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bea7042, with PersistenceManager: null will be shutdown
2024-05-01T14:19:28,703  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bea7042, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19de9ebb created in the thread with id: 481
2024-05-01T14:19:28,705  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bea7042 from thread id: 481
2024-05-01T14:19:28,705  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:28,706  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:28,706  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:28,706  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5bea7042, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19de9ebb will be shutdown
2024-05-01T14:19:28,706  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:28,706  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -42
2024-05-01T14:19:28,706  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:28,707  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:28,708  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18c5ddd4, with PersistenceManager: null will be shutdown
2024-05-01T14:19:28,708  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18c5ddd4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@272a5d69 created in the thread with id: 481
2024-05-01T14:19:28,712  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18c5ddd4 from thread id: 481
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,773  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:28,774  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T14:19:28,804  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,12702632642294076/part1=p1value1/part0=501].
2024-05-01T14:19:28,805  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:28,864  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:28,864  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:28,864  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:28,864  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:28,864  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:28,864  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:28,865  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:28,865  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:28,865  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:28,865  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:28,865  WARN [Thread-439] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:28,865  INFO [Thread-439] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:28,866  INFO [Thread-439] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:28,866  INFO [Thread-439] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:28,866  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18c5ddd4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@272a5d69 will be shutdown
2024-05-01T14:19:28,867  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18c5ddd4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@157202a2 created in the thread with id: 481
2024-05-01T14:19:28,869  INFO [Thread-439] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:28,869  INFO [Thread-439] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:28,869  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:28,869  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18c5ddd4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@157202a2 will be shutdown
2024-05-01T14:19:28,869  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:28,869  INFO [Thread-439] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -43
2024-05-01T14:19:28,869  INFO [Thread-439] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:28,870  INFO [Thread-439] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:28,871  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4b0a27ed, with PersistenceManager: null will be shutdown
2024-05-01T14:19:28,871  INFO [Thread-439] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4b0a27ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d63ecfb created in the thread with id: 481
2024-05-01T14:19:28,873  INFO [Thread-439] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4b0a27ed from thread id: 481
2024-05-01T14:19:28,875  INFO [Thread-439] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:28,875  WARN [Thread-439] mapred.LocalJobRunner: job_local1591874794_0011
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,12702632642294076/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:29,514  INFO [main] mapreduce.Job: Job job_local1591874794_0011 running in uber mode : false
2024-05-01T14:19:29,514  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:29,514  INFO [main] mapreduce.Job: Job job_local1591874794_0011 failed with state FAILED due to: NA
2024-05-01T14:19:29,516  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5622227
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=826277888
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:29,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:29,585  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:29,585  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:29,585  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:29,585  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:29,585  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:29,586  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:29,588  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:29,588  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:29,588  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368d51ca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a349a73 will be shutdown
2024-05-01T14:19:29,588  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368d51ca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36c45149 created in the thread with id: 1
2024-05-01T14:19:29,591  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:29,591  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:29,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:29,592  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@368d51ca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36c45149 will be shutdown
2024-05-01T14:19:29,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:29,592  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -44
2024-05-01T14:19:29,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:29,594  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:29,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17d0d3d7, with PersistenceManager: null will be shutdown
2024-05-01T14:19:29,594  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17d0d3d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39fc17be created in the thread with id: 1
2024-05-01T14:19:29,597  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17d0d3d7 from thread id: 1
2024-05-01T14:19:29,598  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:29,611  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:29,619  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:29,669  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:29,670  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:29,670  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:29,670  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:29,670  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:29,671  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:29,671  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:29,671  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17d0d3d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@39fc17be will be shutdown
2024-05-01T14:19:29,671  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17d0d3d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23119bc3 created in the thread with id: 1
2024-05-01T14:19:29,674  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:29,674  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:29,674  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:29,674  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17d0d3d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23119bc3 will be shutdown
2024-05-01T14:19:29,674  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:29,674  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -45
2024-05-01T14:19:29,675  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:29,676  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:29,677  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2059c3ff, with PersistenceManager: null will be shutdown
2024-05-01T14:19:29,677  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2059c3ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f8ab988 created in the thread with id: 1
2024-05-01T14:19:29,679  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2059c3ff from thread id: 1
2024-05-01T14:19:29,681  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T14:19:29,701  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:29,706  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:29,707  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:29,734  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:29,754  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1117521712_0012
2024-05-01T14:19:29,754  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:29,820  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:29,820  INFO [main] mapreduce.Job: Running job: job_local1117521712_0012
2024-05-01T14:19:29,820  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:29,822  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,822  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,823  INFO [Thread-485] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:29,823  INFO [Thread-485] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,823  INFO [Thread-485] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,841  INFO [Thread-485] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:29,841  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1117521712_0012_m_000000_0
2024-05-01T14:19:29,845  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,845  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,848  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,848  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,848  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:29,849  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:29,851  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,852  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,865  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T14:19:29,870  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:29,870  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T14:19:29,870  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T14:19:29,870  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1117521712_0012_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:29,870  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,871  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,876  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:29,876  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1117521712_0012_m_000000_0 is allowed to commit now
2024-05-01T14:19:29,876  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:29,876  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:29,888  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1117521712_0012_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,5493082536825691/part1=p1value2/part0=502
2024-05-01T14:19:29,888  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:29,888  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1117521712_0012_m_000000_0' done.
2024-05-01T14:19:29,889  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1117521712_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6135400
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=826277888
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:29,889  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1117521712_0012_m_000000_0
2024-05-01T14:19:29,889  INFO [Thread-485] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:29,953  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:29,954  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:29,955  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:29,956  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:29,957  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:29,957  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:29,957  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72d71539, with PersistenceManager: null will be shutdown
2024-05-01T14:19:29,957  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72d71539, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62c42f64 created in the thread with id: 529
2024-05-01T14:19:29,996  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72d71539 from thread id: 529
2024-05-01T14:19:29,996  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:29,996  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:29,997  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:29,997  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72d71539, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62c42f64 will be shutdown
2024-05-01T14:19:29,997  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:29,997  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -46
2024-05-01T14:19:29,997  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:29,998  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:29,999  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@982e3a, with PersistenceManager: null will be shutdown
2024-05-01T14:19:29,999  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@982e3a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f8921f7 created in the thread with id: 529
2024-05-01T14:19:30,001  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@982e3a from thread id: 529
2024-05-01T14:19:30,072  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:30,072  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:30,072  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:30,072  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:30,072  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:30,072  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:30,073  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:30,073  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:30,073  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:30,073  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:30,073  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:30,074  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:30,108  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,5493082536825691/part1=p1value2/part0=502].
2024-05-01T14:19:30,108  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:30,163  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:30,163  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:30,163  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:30,163  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:30,163  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:30,163  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:30,164  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:30,164  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:30,164  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:30,164  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:30,164  WARN [Thread-485] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:30,164  INFO [Thread-485] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:30,165  INFO [Thread-485] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:30,165  INFO [Thread-485] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:30,165  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@982e3a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f8921f7 will be shutdown
2024-05-01T14:19:30,166  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@982e3a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59149f5d created in the thread with id: 529
2024-05-01T14:19:30,167  INFO [Thread-485] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:30,168  INFO [Thread-485] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:30,168  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:30,168  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@982e3a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59149f5d will be shutdown
2024-05-01T14:19:30,168  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:30,168  INFO [Thread-485] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -47
2024-05-01T14:19:30,168  INFO [Thread-485] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:30,169  INFO [Thread-485] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:30,170  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6d535, with PersistenceManager: null will be shutdown
2024-05-01T14:19:30,170  INFO [Thread-485] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6d535, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5363ac0 created in the thread with id: 529
2024-05-01T14:19:30,171  INFO [Thread-485] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e6d535 from thread id: 529
2024-05-01T14:19:30,172  INFO [Thread-485] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:30,172  WARN [Thread-485] mapred.LocalJobRunner: job_local1117521712_0012
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,5493082536825691/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:30,820  INFO [main] mapreduce.Job: Job job_local1117521712_0012 running in uber mode : false
2024-05-01T14:19:30,820  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:30,821  INFO [main] mapreduce.Job: Job job_local1117521712_0012 failed with state FAILED due to: NA
2024-05-01T14:19:30,822  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6135400
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=826277888
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:30,879  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:30,879  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:30,879  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:30,880  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:30,880  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:30,881  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:30,883  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:30,883  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:30,883  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2059c3ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f8ab988 will be shutdown
2024-05-01T14:19:30,883  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2059c3ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15d2ea6b created in the thread with id: 1
2024-05-01T14:19:30,885  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:30,886  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:30,886  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:30,886  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2059c3ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@15d2ea6b will be shutdown
2024-05-01T14:19:30,886  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:30,886  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -48
2024-05-01T14:19:30,886  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:30,887  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:30,887  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655278d, with PersistenceManager: null will be shutdown
2024-05-01T14:19:30,887  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655278d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dd46693 created in the thread with id: 1
2024-05-01T14:19:30,889  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655278d from thread id: 1
2024-05-01T14:19:30,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:30,902  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:30,910  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:30,955  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:30,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:30,956  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:30,956  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:30,957  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:30,957  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:30,958  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655278d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dd46693 will be shutdown
2024-05-01T14:19:30,958  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655278d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c19bb2a created in the thread with id: 1
2024-05-01T14:19:30,963  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:30,963  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:30,963  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:30,964  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5655278d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c19bb2a will be shutdown
2024-05-01T14:19:30,964  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:30,964  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -49
2024-05-01T14:19:30,964  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:30,965  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:30,966  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f2a7ca0, with PersistenceManager: null will be shutdown
2024-05-01T14:19:30,966  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f2a7ca0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23e297d9 created in the thread with id: 1
2024-05-01T14:19:30,968  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f2a7ca0 from thread id: 1
2024-05-01T14:19:30,969  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-05-01T14:19:30,987  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:30,999  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:31,000  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:31,026  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:31,048  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1643458602_0013
2024-05-01T14:19:31,048  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:31,113  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:31,113  INFO [main] mapreduce.Job: Running job: job_local1643458602_0013
2024-05-01T14:19:31,113  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:31,116  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,116  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,117  INFO [Thread-531] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:31,117  INFO [Thread-531] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,118  INFO [Thread-531] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,135  INFO [Thread-531] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:31,135  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1643458602_0013_m_000000_0
2024-05-01T14:19:31,138  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,138  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,139  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,139  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,140  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:31,140  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:31,143  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,143  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,162  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:31,163  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-05-01T14:19:31,163  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T14:19:31,163  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1643458602_0013_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:31,163  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,163  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,167  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:31,167  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1643458602_0013_m_000000_0 is allowed to commit now
2024-05-01T14:19:31,168  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:31,168  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:31,181  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1643458602_0013_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,25560216944696945/part1=p1value2/part0=502
2024-05-01T14:19:31,182  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:31,182  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1643458602_0013_m_000000_0' done.
2024-05-01T14:19:31,182  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1643458602_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6648586
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=894435328
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:31,182  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1643458602_0013_m_000000_0
2024-05-01T14:19:31,182  INFO [Thread-531] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:31,247  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:31,248  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:31,248  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:31,249  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:31,250  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:31,251  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:31,251  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@797eb868, with PersistenceManager: null will be shutdown
2024-05-01T14:19:31,252  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@797eb868, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@184d003b created in the thread with id: 577
2024-05-01T14:19:31,255  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@797eb868 from thread id: 577
2024-05-01T14:19:31,255  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:31,255  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:31,256  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:31,256  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@797eb868, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@184d003b will be shutdown
2024-05-01T14:19:31,256  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:31,256  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -50
2024-05-01T14:19:31,256  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:31,257  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:31,258  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70e062ae, with PersistenceManager: null will be shutdown
2024-05-01T14:19:31,258  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70e062ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@688172bc created in the thread with id: 577
2024-05-01T14:19:31,262  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70e062ae from thread id: 577
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:31,320  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:31,321  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:31,347  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,25560216944696945/part1=p1value2/part0=502].
2024-05-01T14:19:31,348  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:31,394  WARN [Thread-531] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:31,394  INFO [Thread-531] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:31,395  INFO [Thread-531] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:31,395  INFO [Thread-531] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:31,395  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70e062ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@688172bc will be shutdown
2024-05-01T14:19:31,396  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70e062ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@247f751 created in the thread with id: 577
2024-05-01T14:19:31,398  INFO [Thread-531] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:31,398  INFO [Thread-531] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:31,398  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:31,398  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70e062ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@247f751 will be shutdown
2024-05-01T14:19:31,398  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:31,398  INFO [Thread-531] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -51
2024-05-01T14:19:31,398  INFO [Thread-531] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:31,399  INFO [Thread-531] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:31,399  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79950f5c, with PersistenceManager: null will be shutdown
2024-05-01T14:19:31,400  INFO [Thread-531] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79950f5c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27a0bffb created in the thread with id: 577
2024-05-01T14:19:31,401  INFO [Thread-531] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79950f5c from thread id: 577
2024-05-01T14:19:31,402  INFO [Thread-531] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:31,402  WARN [Thread-531] mapred.LocalJobRunner: job_local1643458602_0013
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,25560216944696945/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:32,113  INFO [main] mapreduce.Job: Job job_local1643458602_0013 running in uber mode : false
2024-05-01T14:19:32,113  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:32,114  INFO [main] mapreduce.Job: Job job_local1643458602_0013 failed with state FAILED due to: NA
2024-05-01T14:19:32,115  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6648586
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=894435328
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:32,165  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:32,165  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:32,165  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:32,165  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:32,166  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:32,166  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:32,167  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:32,168  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:32,168  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:32,169  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f2a7ca0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23e297d9 will be shutdown
2024-05-01T14:19:32,169  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f2a7ca0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11fb1691 created in the thread with id: 1
2024-05-01T14:19:32,170  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:32,171  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:32,171  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:32,171  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f2a7ca0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11fb1691 will be shutdown
2024-05-01T14:19:32,171  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:32,171  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -52
2024-05-01T14:19:32,171  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:32,172  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40ebb56, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,173  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40ebb56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b2fc2c0 created in the thread with id: 1
2024-05-01T14:19:32,174  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40ebb56 from thread id: 1
2024-05-01T14:19:32,175  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:32,183  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:32,190  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:32,236  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:32,237  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:32,237  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:32,237  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:32,238  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:32,238  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:32,238  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40ebb56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b2fc2c0 will be shutdown
2024-05-01T14:19:32,238  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40ebb56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@396519b created in the thread with id: 1
2024-05-01T14:19:32,241  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:32,241  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:32,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:32,241  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@40ebb56, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@396519b will be shutdown
2024-05-01T14:19:32,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:32,242  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -53
2024-05-01T14:19:32,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:32,243  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,243  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d8a1456, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,244  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d8a1456, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351fadfa created in the thread with id: 1
2024-05-01T14:19:32,247  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d8a1456 from thread id: 1
2024-05-01T14:19:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:32,315  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:32,316  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:32,316  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:32,317  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:32,320  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:32,321  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:32,321  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d8a1456, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@351fadfa will be shutdown
2024-05-01T14:19:32,321  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d8a1456, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f3d5cd created in the thread with id: 1
2024-05-01T14:19:32,327  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:32,327  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:32,328  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:32,328  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d8a1456, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f3d5cd will be shutdown
2024-05-01T14:19:32,328  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:32,328  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -54
2024-05-01T14:19:32,329  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:32,330  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,330  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67683210, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,330  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67683210, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@329aa2d1 created in the thread with id: 1
2024-05-01T14:19:32,333  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67683210 from thread id: 1
2024-05-01T14:19:32,334  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:32,349  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:32,420  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:32,420  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:32,420  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:32,420  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:32,420  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:32,420  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:32,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:32,421  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:32,421  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:32,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:32,421  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:32,421  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:32,422  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:32,425  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:32,425  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:32,426  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67683210, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@329aa2d1 will be shutdown
2024-05-01T14:19:32,426  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67683210, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49741e80 created in the thread with id: 1
2024-05-01T14:19:32,430  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:32,430  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:32,430  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:32,430  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67683210, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49741e80 will be shutdown
2024-05-01T14:19:32,430  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:32,430  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -55
2024-05-01T14:19:32,431  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:32,431  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,432  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@325236f5, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,432  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@325236f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32eb38e5 created in the thread with id: 1
2024-05-01T14:19:32,434  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@325236f5 from thread id: 1
2024-05-01T14:19:32,436  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:32,447  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:32,454  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:32,505  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:32,505  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:32,506  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:32,506  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:32,507  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:32,508  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:32,508  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@325236f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32eb38e5 will be shutdown
2024-05-01T14:19:32,508  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@325236f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59509393 created in the thread with id: 1
2024-05-01T14:19:32,510  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:32,511  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:32,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:32,511  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@325236f5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59509393 will be shutdown
2024-05-01T14:19:32,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:32,511  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -56
2024-05-01T14:19:32,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:32,512  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,512  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16279a5d, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,513  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16279a5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f7949dc created in the thread with id: 1
2024-05-01T14:19:32,514  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16279a5d from thread id: 1
2024-05-01T14:19:32,522  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:32,528  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:32,529  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:32,553  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:32,572  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local440820821_0014
2024-05-01T14:19:32,572  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:32,631  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:32,631  INFO [main] mapreduce.Job: Running job: job_local440820821_0014
2024-05-01T14:19:32,632  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:32,634  INFO [Thread-582] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:32,635  INFO [Thread-582] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:32,635  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local440820821_0014_m_000000_0
2024-05-01T14:19:32,638  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:32,639  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T14:19:32,646  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local440820821_0014_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.6784463113403566/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T14:19:32,647  INFO [Thread-582] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:32,649  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.6784463113403566].
2024-05-01T14:19:32,649  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:32,696  WARN [Thread-582] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:32,696  INFO [Thread-582] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:32,697  INFO [Thread-582] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:32,697  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,697  INFO [Thread-582] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:32,698  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d7ac49b, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,698  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d7ac49b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1abd203f created in the thread with id: 630
2024-05-01T14:19:32,700  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d7ac49b from thread id: 630
2024-05-01T14:19:32,700  INFO [Thread-582] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:32,700  INFO [Thread-582] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:32,701  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:32,701  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d7ac49b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1abd203f will be shutdown
2024-05-01T14:19:32,701  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:32,701  INFO [Thread-582] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -57
2024-05-01T14:19:32,701  INFO [Thread-582] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:32,702  INFO [Thread-582] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:32,702  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b9a8d23, with PersistenceManager: null will be shutdown
2024-05-01T14:19:32,702  INFO [Thread-582] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b9a8d23, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38b037d created in the thread with id: 630
2024-05-01T14:19:32,704  INFO [Thread-582] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b9a8d23 from thread id: 630
2024-05-01T14:19:32,705  INFO [Thread-582] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:32,705  WARN [Thread-582] mapred.LocalJobRunner: job_local440820821_0014
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T14:19:33,632  INFO [main] mapreduce.Job: Job job_local440820821_0014 running in uber mode : false
2024-05-01T14:19:33,632  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:33,632  INFO [main] mapreduce.Job: Job job_local440820821_0014 failed with state FAILED due to: NA
2024-05-01T14:19:33,632  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:33,675  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:33,676  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:33,677  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:33,678  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:33,678  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:33,678  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16279a5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f7949dc will be shutdown
2024-05-01T14:19:33,679  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16279a5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@451f3f66 created in the thread with id: 1
2024-05-01T14:19:33,680  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:33,681  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:33,681  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:33,681  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16279a5d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@451f3f66 will be shutdown
2024-05-01T14:19:33,681  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:33,681  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -58
2024-05-01T14:19:33,681  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:33,682  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:33,682  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: null will be shutdown
2024-05-01T14:19:33,682  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ca5da54 created in the thread with id: 1
2024-05-01T14:19:33,684  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600 from thread id: 1
2024-05-01T14:19:33,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:33,691  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:33,691  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:33,695  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:33,702  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:33,708  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:33,731  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T14:19:33,747  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1941142144_0015
2024-05-01T14:19:33,747  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:33,800  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:33,800  INFO [main] mapreduce.Job: Running job: job_local1941142144_0015
2024-05-01T14:19:33,800  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:33,801  INFO [Thread-602] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:33,801  INFO [Thread-602] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:33,801  INFO [Thread-602] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T14:19:33,810  INFO [Thread-602] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:33,810  INFO [Thread-602] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:34,800  INFO [main] mapreduce.Job: Job job_local1941142144_0015 running in uber mode : false
2024-05-01T14:19:34,801  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:34,801  INFO [main] mapreduce.Job: Job job_local1941142144_0015 completed successfully
2024-05-01T14:19:34,801  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:34,801  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:34,808  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:34,808  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-05-01T14:19:34,868  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:34,869  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[3]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.833">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:34,922  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:34,924  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:34,924  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:34,925  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ca5da54 will be shutdown
2024-05-01T14:19:34,925  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7cf166db created in the thread with id: 1
2024-05-01T14:19:34,927  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = cf9d6e7d-30dd-49f9-8cd4-33aa051350a7
2024-05-01T14:19:34,927  INFO [main] SessionState: Hive Session ID = cf9d6e7d-30dd-49f9-8cd4-33aa051350a7
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:34,928  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:34,935  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/cf9d6e7d-30dd-49f9-8cd4-33aa051350a7
2024-05-01T14:19:34,938  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/cf9d6e7d-30dd-49f9-8cd4-33aa051350a7
2024-05-01T14:19:34,941  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/cf9d6e7d-30dd-49f9-8cd4-33aa051350a7/_tmp_space.db
2024-05-01T14:19:34,942  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:34,944  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_ORCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_ORCFILE, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T14:19:34,946  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:35,019  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:35,020  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:35,020  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:35,021  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:35,023  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:35,023  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:35,023  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7cf166db will be shutdown
2024-05-01T14:19:35,024  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e4bf55b created in the thread with id: 1
2024-05-01T14:19:35,027  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:35,027  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:35,027  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:35,027  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bf70600, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e4bf55b will be shutdown
2024-05-01T14:19:35,027  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:35,027  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -59
2024-05-01T14:19:35,027  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:35,028  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:35,029  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f3f0d25, with PersistenceManager: null will be shutdown
2024-05-01T14:19:35,029  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f3f0d25, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32eac39b created in the thread with id: 1
2024-05-01T14:19:35,031  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f3f0d25 from thread id: 1
2024-05-01T14:19:35,031  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:35,039  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:35,057  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:35,100  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:35,101  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:35,102  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:35,103  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:35,104  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:35,104  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f3f0d25, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@32eac39b will be shutdown
2024-05-01T14:19:35,104  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f3f0d25, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cdf61d created in the thread with id: 1
2024-05-01T14:19:35,107  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:35,107  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:35,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:35,108  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f3f0d25, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cdf61d will be shutdown
2024-05-01T14:19:35,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:35,108  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -60
2024-05-01T14:19:35,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:35,109  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:35,110  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: null will be shutdown
2024-05-01T14:19:35,110  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1067192a created in the thread with id: 1
2024-05-01T14:19:35,112  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c from thread id: 1
2024-05-01T14:19:35,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value1,501]	
2024-05-01T14:19:35,179  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:35,184  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:35,185  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:35,209  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:35,232  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1640371782_0016
2024-05-01T14:19:35,232  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:35,292  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:35,292  INFO [main] mapreduce.Job: Running job: job_local1640371782_0016
2024-05-01T14:19:35,293  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:35,295  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,295  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,296  INFO [Thread-636] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:35,297  INFO [Thread-636] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,297  INFO [Thread-636] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,315  INFO [Thread-636] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:35,315  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1640371782_0016_m_000000_0
2024-05-01T14:19:35,322  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,322  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,324  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,324  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,324  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:35,325  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T14:19:35,333  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,334  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,383  INFO [LocalJobRunner Map Task Executor #0] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-05-01T14:19:35,391  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,2924063803613841/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1640371782_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T14:19:35,474  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,2924063803613841/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1640371782_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T14:19:35,527  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:35,584  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1640371782_0016_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:35,584  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,584  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,588  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:35,588  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1640371782_0016_m_000000_0 is allowed to commit now
2024-05-01T14:19:35,588  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:35,588  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:35,598  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1640371782_0016_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,2924063803613841/part1=p1value1/part0=501
2024-05-01T14:19:35,598  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:35,598  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1640371782_0016_m_000000_0' done.
2024-05-01T14:19:35,599  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1640371782_0016_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8182594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=45
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:35,599  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1640371782_0016_m_000000_0
2024-05-01T14:19:35,599  INFO [Thread-636] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:35,650  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:35,650  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:35,651  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:35,652  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:35,652  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:35,652  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26e3a386, with PersistenceManager: null will be shutdown
2024-05-01T14:19:35,652  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26e3a386, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3bfb5087 created in the thread with id: 686
2024-05-01T14:19:35,654  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26e3a386 from thread id: 686
2024-05-01T14:19:35,654  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:35,654  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:35,654  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:35,654  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@26e3a386, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3bfb5087 will be shutdown
2024-05-01T14:19:35,654  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:35,654  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -61
2024-05-01T14:19:35,655  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:35,655  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:35,656  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e6f3c89, with PersistenceManager: null will be shutdown
2024-05-01T14:19:35,656  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e6f3c89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b6b9af8 created in the thread with id: 686
2024-05-01T14:19:35,658  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e6f3c89 from thread id: 686
2024-05-01T14:19:35,711  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:35,711  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:35,711  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:35,711  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:35,711  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:35,711  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:35,712  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:35,712  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:35,712  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:35,712  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:35,712  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:35,712  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T14:19:35,736  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,2924063803613841/part1=p1value1/part0=501].
2024-05-01T14:19:35,736  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:35,783  WARN [Thread-636] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:35,783  INFO [Thread-636] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:35,784  INFO [Thread-636] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:35,784  INFO [Thread-636] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:35,785  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e6f3c89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b6b9af8 will be shutdown
2024-05-01T14:19:35,785  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e6f3c89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@480bd41b created in the thread with id: 686
2024-05-01T14:19:35,786  INFO [Thread-636] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:35,786  INFO [Thread-636] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:35,787  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:35,787  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e6f3c89, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@480bd41b will be shutdown
2024-05-01T14:19:35,787  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:35,787  INFO [Thread-636] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -62
2024-05-01T14:19:35,787  INFO [Thread-636] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:35,787  INFO [Thread-636] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:35,788  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50d4f916, with PersistenceManager: null will be shutdown
2024-05-01T14:19:35,788  INFO [Thread-636] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50d4f916, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e806a26 created in the thread with id: 686
2024-05-01T14:19:35,790  INFO [Thread-636] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50d4f916 from thread id: 686
2024-05-01T14:19:35,790  INFO [Thread-636] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:35,790  WARN [Thread-636] mapred.LocalJobRunner: job_local1640371782_0016
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,2924063803613841/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:36,293  INFO [main] mapreduce.Job: Job job_local1640371782_0016 running in uber mode : false
2024-05-01T14:19:36,293  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:36,293  INFO [main] mapreduce.Job: Job job_local1640371782_0016 failed with state FAILED due to: NA
2024-05-01T14:19:36,295  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8182594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=45
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:36,365  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:36,365  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:36,366  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:36,369  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:36,369  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:36,369  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1067192a will be shutdown
2024-05-01T14:19:36,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27260f9c created in the thread with id: 1
2024-05-01T14:19:36,372  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:36,372  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:36,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:36,373  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@10c67c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27260f9c will be shutdown
2024-05-01T14:19:36,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:36,373  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -63
2024-05-01T14:19:36,373  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:36,374  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:36,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29612ee2, with PersistenceManager: null will be shutdown
2024-05-01T14:19:36,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29612ee2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20524816 created in the thread with id: 1
2024-05-01T14:19:36,376  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29612ee2 from thread id: 1
2024-05-01T14:19:36,377  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:36,385  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:36,392  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:36,434  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:36,435  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:36,435  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:36,436  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29612ee2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@20524816 will be shutdown
2024-05-01T14:19:36,436  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29612ee2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@627ad446 created in the thread with id: 1
2024-05-01T14:19:36,438  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:36,438  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:36,439  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:36,439  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29612ee2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@627ad446 will be shutdown
2024-05-01T14:19:36,439  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:36,439  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -64
2024-05-01T14:19:36,439  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:36,440  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:36,440  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bab8290, with PersistenceManager: null will be shutdown
2024-05-01T14:19:36,441  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bab8290, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a985388 created in the thread with id: 1
2024-05-01T14:19:36,442  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bab8290 from thread id: 1
2024-05-01T14:19:36,443  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T14:19:36,459  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:36,464  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:36,465  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:36,490  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:36,508  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1580337936_0017
2024-05-01T14:19:36,508  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:36,567  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:36,567  INFO [main] mapreduce.Job: Running job: job_local1580337936_0017
2024-05-01T14:19:36,567  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:36,570  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,570  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,571  INFO [Thread-682] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:36,572  INFO [Thread-682] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,572  INFO [Thread-682] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,587  INFO [Thread-682] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:36,587  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1580337936_0017_m_000000_0
2024-05-01T14:19:36,590  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,590  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,591  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,591  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,591  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:36,592  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:36,594  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,594  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,596  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,9145784760331233/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1580337936_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T14:19:36,609  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,9145784760331233/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1580337936_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T14:19:36,610  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:36,612  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1580337936_0017_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:36,612  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,612  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,616  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:36,616  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1580337936_0017_m_000000_0 is allowed to commit now
2024-05-01T14:19:36,616  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:36,616  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:36,629  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1580337936_0017_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,9145784760331233/part1=p1value2/part0=502
2024-05-01T14:19:36,630  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:36,630  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1580337936_0017_m_000000_0' done.
2024-05-01T14:19:36,630  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1580337936_0017_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8695337
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:36,630  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1580337936_0017_m_000000_0
2024-05-01T14:19:36,630  INFO [Thread-682] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:36,700  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:36,700  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:36,700  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:36,700  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:36,700  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:36,700  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:36,701  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:36,701  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:36,701  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:36,701  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:36,701  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:36,701  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:36,702  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:36,703  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:36,703  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:36,704  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@235ebad8, with PersistenceManager: null will be shutdown
2024-05-01T14:19:36,704  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@235ebad8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@759724b6 created in the thread with id: 734
2024-05-01T14:19:36,707  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@235ebad8 from thread id: 734
2024-05-01T14:19:36,707  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:36,707  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:36,708  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:36,708  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@235ebad8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@759724b6 will be shutdown
2024-05-01T14:19:36,708  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:36,708  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -65
2024-05-01T14:19:36,708  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:36,709  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:36,709  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27d91dff, with PersistenceManager: null will be shutdown
2024-05-01T14:19:36,709  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27d91dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ac43500 created in the thread with id: 734
2024-05-01T14:19:36,711  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27d91dff from thread id: 734
2024-05-01T14:19:36,763  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:36,763  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:36,763  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:36,763  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:36,763  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:36,764  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:36,764  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:36,764  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:36,764  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:36,764  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:36,764  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:36,764  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:36,792  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,9145784760331233/part1=p1value2/part0=502].
2024-05-01T14:19:36,792  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:36,840  WARN [Thread-682] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:36,840  INFO [Thread-682] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:36,841  INFO [Thread-682] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:36,841  INFO [Thread-682] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:36,842  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27d91dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ac43500 will be shutdown
2024-05-01T14:19:36,842  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27d91dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65966f94 created in the thread with id: 734
2024-05-01T14:19:36,843  INFO [Thread-682] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:36,844  INFO [Thread-682] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:36,844  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:36,844  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27d91dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65966f94 will be shutdown
2024-05-01T14:19:36,844  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:36,844  INFO [Thread-682] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -66
2024-05-01T14:19:36,844  INFO [Thread-682] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:36,845  INFO [Thread-682] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:36,845  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c158ba3, with PersistenceManager: null will be shutdown
2024-05-01T14:19:36,845  INFO [Thread-682] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c158ba3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eda8720 created in the thread with id: 734
2024-05-01T14:19:36,847  INFO [Thread-682] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7c158ba3 from thread id: 734
2024-05-01T14:19:36,848  INFO [Thread-682] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:36,848  WARN [Thread-682] mapred.LocalJobRunner: job_local1580337936_0017
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,9145784760331233/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:37,541  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T14:19:37,568  INFO [main] mapreduce.Job: Job job_local1580337936_0017 running in uber mode : false
2024-05-01T14:19:37,568  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:37,568  INFO [main] mapreduce.Job: Job job_local1580337936_0017 failed with state FAILED due to: NA
2024-05-01T14:19:37,570  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8695337
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:37,626  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:37,627  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:37,627  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:37,627  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:37,627  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:37,627  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:37,629  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:37,629  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:37,629  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bab8290, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a985388 will be shutdown
2024-05-01T14:19:37,629  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bab8290, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3445341 created in the thread with id: 1
2024-05-01T14:19:37,631  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:37,631  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:37,631  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:37,631  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6bab8290, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3445341 will be shutdown
2024-05-01T14:19:37,631  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:37,631  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -67
2024-05-01T14:19:37,631  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:37,632  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:37,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ceb7a60, with PersistenceManager: null will be shutdown
2024-05-01T14:19:37,632  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ceb7a60, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ab780fd created in the thread with id: 1
2024-05-01T14:19:37,634  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ceb7a60 from thread id: 1
2024-05-01T14:19:37,636  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:37,644  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:37,649  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:37,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:37,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:37,702  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:37,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:37,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:37,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:37,703  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:37,703  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:37,703  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:37,703  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:37,703  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:37,703  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:37,705  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:37,705  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:37,705  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ceb7a60, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ab780fd will be shutdown
2024-05-01T14:19:37,706  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ceb7a60, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@449f9628 created in the thread with id: 1
2024-05-01T14:19:37,708  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:37,708  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:37,709  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:37,709  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ceb7a60, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@449f9628 will be shutdown
2024-05-01T14:19:37,709  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:37,709  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -68
2024-05-01T14:19:37,709  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:37,710  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:37,710  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a41d17a, with PersistenceManager: null will be shutdown
2024-05-01T14:19:37,711  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a41d17a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a5b69c created in the thread with id: 1
2024-05-01T14:19:37,712  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a41d17a from thread id: 1
2024-05-01T14:19:37,714  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-05-01T14:19:37,741  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:37,747  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:37,748  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:37,784  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:37,804  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local286527856_0018
2024-05-01T14:19:37,804  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:37,869  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:37,869  INFO [main] mapreduce.Job: Running job: job_local286527856_0018
2024-05-01T14:19:37,869  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:37,872  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,872  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,874  INFO [Thread-728] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:37,875  INFO [Thread-728] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,875  INFO [Thread-728] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,890  INFO [Thread-728] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:37,890  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local286527856_0018_m_000000_0
2024-05-01T14:19:37,892  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,892  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,894  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,894  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,894  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:37,895  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:37,897  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,897  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,900  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,11581813481508185/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local286527856_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-05-01T14:19:37,913  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,11581813481508185/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local286527856_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-05-01T14:19:37,914  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:37,918  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local286527856_0018_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:37,918  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,918  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,923  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:37,923  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local286527856_0018_m_000000_0 is allowed to commit now
2024-05-01T14:19:37,923  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:37,923  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:37,934  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local286527856_0018_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,11581813481508185/part1=p1value2/part0=502
2024-05-01T14:19:37,934  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:37,934  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local286527856_0018_m_000000_0' done.
2024-05-01T14:19:37,934  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local286527856_0018_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9205695
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:37,934  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local286527856_0018_m_000000_0
2024-05-01T14:19:37,934  INFO [Thread-728] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:37,991  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:37,992  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:37,992  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:37,993  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:37,994  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:37,994  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:37,994  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bcf4258, with PersistenceManager: null will be shutdown
2024-05-01T14:19:37,994  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bcf4258, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21cf5198 created in the thread with id: 782
2024-05-01T14:19:37,996  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bcf4258 from thread id: 782
2024-05-01T14:19:37,996  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:37,996  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:37,997  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:37,997  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bcf4258, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21cf5198 will be shutdown
2024-05-01T14:19:37,997  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:37,997  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -69
2024-05-01T14:19:37,997  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:37,997  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:37,998  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b1edd, with PersistenceManager: null will be shutdown
2024-05-01T14:19:37,998  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b1edd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7be9b3d6 created in the thread with id: 782
2024-05-01T14:19:37,999  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b1edd from thread id: 782
2024-05-01T14:19:38,049  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:38,049  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:38,049  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:38,049  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:38,049  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:38,049  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:38,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:38,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:38,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:38,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:38,050  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:38,050  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:38,075  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,11581813481508185/part1=p1value2/part0=502].
2024-05-01T14:19:38,075  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:38,133  WARN [Thread-728] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:38,134  INFO [Thread-728] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:38,135  INFO [Thread-728] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:38,135  INFO [Thread-728] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:38,135  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b1edd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7be9b3d6 will be shutdown
2024-05-01T14:19:38,136  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b1edd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4114eaf created in the thread with id: 782
2024-05-01T14:19:38,139  INFO [Thread-728] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:38,139  INFO [Thread-728] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:38,139  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:38,140  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b1edd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4114eaf will be shutdown
2024-05-01T14:19:38,140  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:38,140  INFO [Thread-728] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -70
2024-05-01T14:19:38,140  INFO [Thread-728] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:38,141  INFO [Thread-728] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:38,141  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d6398cb, with PersistenceManager: null will be shutdown
2024-05-01T14:19:38,142  INFO [Thread-728] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d6398cb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5df2f10e created in the thread with id: 782
2024-05-01T14:19:38,143  INFO [Thread-728] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d6398cb from thread id: 782
2024-05-01T14:19:38,144  INFO [Thread-728] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:38,144  WARN [Thread-728] mapred.LocalJobRunner: job_local286527856_0018
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,11581813481508185/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:38,870  INFO [main] mapreduce.Job: Job job_local286527856_0018 running in uber mode : false
2024-05-01T14:19:38,870  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:38,870  INFO [main] mapreduce.Job: Job job_local286527856_0018 failed with state FAILED due to: NA
2024-05-01T14:19:38,871  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9205695
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:38,926  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:38,927  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:38,927  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:38,929  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:38,929  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:38,929  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a41d17a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58a5b69c will be shutdown
2024-05-01T14:19:38,929  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a41d17a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56897de0 created in the thread with id: 1
2024-05-01T14:19:38,931  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:38,931  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:38,931  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:38,931  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a41d17a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56897de0 will be shutdown
2024-05-01T14:19:38,931  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:38,931  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -71
2024-05-01T14:19:38,931  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:38,932  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:38,933  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: null will be shutdown
2024-05-01T14:19:38,933  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53a645a2 created in the thread with id: 1
2024-05-01T14:19:38,935  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d from thread id: 1
2024-05-01T14:19:38,935  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:38,942  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:38,949  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:38,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:38,995  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:38,995  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:38,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:38,995  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:38,996  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:38,996  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:38,996  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:38,996  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:38,996  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:38,996  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:38,996  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:38,997  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:38,997  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:38,998  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53a645a2 will be shutdown
2024-05-01T14:19:38,998  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3280a79a created in the thread with id: 1
2024-05-01T14:19:39,001  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:39,002  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:39,002  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:39,002  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240c626d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3280a79a will be shutdown
2024-05-01T14:19:39,002  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:39,002  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -72
2024-05-01T14:19:39,002  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:39,003  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:39,003  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: null will be shutdown
2024-05-01T14:19:39,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@374712f8 created in the thread with id: 1
2024-05-01T14:19:39,006  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0 from thread id: 1
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:39,071  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:39,072  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:39,073  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:39,075  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:39,075  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:39,075  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@374712f8 will be shutdown
2024-05-01T14:19:39,075  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4822fc53 created in the thread with id: 1
2024-05-01T14:19:39,077  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:39,078  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:39,078  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:39,078  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6259d7a0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4822fc53 will be shutdown
2024-05-01T14:19:39,078  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:39,078  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -73
2024-05-01T14:19:39,078  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:39,079  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:39,079  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: null will be shutdown
2024-05-01T14:19:39,079  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@163cd4a6 created in the thread with id: 1
2024-05-01T14:19:39,081  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761 from thread id: 1
2024-05-01T14:19:39,082  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:39,090  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:39,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:39,151  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:39,151  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:39,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:39,151  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:39,151  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:39,152  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:39,152  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:39,152  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:39,152  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:39,152  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:39,152  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:39,153  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:39,155  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:39,155  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:39,155  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@163cd4a6 will be shutdown
2024-05-01T14:19:39,155  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@221961f2 created in the thread with id: 1
2024-05-01T14:19:39,157  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:39,158  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:39,158  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:39,158  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@538fb761, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@221961f2 will be shutdown
2024-05-01T14:19:39,158  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:39,158  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -74
2024-05-01T14:19:39,158  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:39,159  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:39,159  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: null will be shutdown
2024-05-01T14:19:39,160  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b3b5252 created in the thread with id: 1
2024-05-01T14:19:39,161  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80 from thread id: 1
2024-05-01T14:19:39,163  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:39,172  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:39,178  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:39,224  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:39,224  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:39,224  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:39,224  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:39,224  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:39,224  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:39,225  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:39,225  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:39,225  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:39,225  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:39,225  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:39,225  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:39,226  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:39,226  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:39,226  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b3b5252 will be shutdown
2024-05-01T14:19:39,226  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21553c3a created in the thread with id: 1
2024-05-01T14:19:39,228  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:39,228  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:39,228  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:39,228  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2552cb80, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21553c3a will be shutdown
2024-05-01T14:19:39,228  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:39,228  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -75
2024-05-01T14:19:39,228  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:39,229  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:39,229  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: null will be shutdown
2024-05-01T14:19:39,230  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42718ebf created in the thread with id: 1
2024-05-01T14:19:39,231  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462 from thread id: 1
2024-05-01T14:19:39,238  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:39,243  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:39,244  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:39,269  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:39,289  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local721536362_0019
2024-05-01T14:19:39,289  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:39,352  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:39,352  INFO [main] mapreduce.Job: Running job: job_local721536362_0019
2024-05-01T14:19:39,352  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:39,356  INFO [Thread-779] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:39,357  INFO [Thread-779] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:39,357  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local721536362_0019_m_000000_0
2024-05-01T14:19:39,360  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:39,361  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T14:19:39,368  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local721536362_0019_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.6335546091251617/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T14:19:39,369  INFO [Thread-779] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:39,371  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.6335546091251617].
2024-05-01T14:19:39,371  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:39,427  WARN [Thread-779] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:39,428  INFO [Thread-779] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:39,429  INFO [Thread-779] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:39,429  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:39,429  INFO [Thread-779] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:39,430  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67b16977, with PersistenceManager: null will be shutdown
2024-05-01T14:19:39,430  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67b16977, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@546855c2 created in the thread with id: 835
2024-05-01T14:19:39,433  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67b16977 from thread id: 835
2024-05-01T14:19:39,433  INFO [Thread-779] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:39,433  INFO [Thread-779] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:39,433  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:39,433  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67b16977, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@546855c2 will be shutdown
2024-05-01T14:19:39,434  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:39,434  INFO [Thread-779] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -76
2024-05-01T14:19:39,434  INFO [Thread-779] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:39,435  INFO [Thread-779] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:39,436  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3917684c, with PersistenceManager: null will be shutdown
2024-05-01T14:19:39,436  INFO [Thread-779] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3917684c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77d376e created in the thread with id: 835
2024-05-01T14:19:39,439  INFO [Thread-779] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3917684c from thread id: 835
2024-05-01T14:19:39,441  INFO [Thread-779] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:39,441  WARN [Thread-779] mapred.LocalJobRunner: job_local721536362_0019
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T14:19:40,353  INFO [main] mapreduce.Job: Job job_local721536362_0019 running in uber mode : false
2024-05-01T14:19:40,353  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:40,353  INFO [main] mapreduce.Job: Job job_local721536362_0019 failed with state FAILED due to: NA
2024-05-01T14:19:40,353  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:40,397  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:40,397  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:40,398  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:40,400  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:40,400  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:40,401  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42718ebf will be shutdown
2024-05-01T14:19:40,401  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58d635de created in the thread with id: 1
2024-05-01T14:19:40,403  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:40,404  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:40,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:40,404  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14b4f462, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58d635de will be shutdown
2024-05-01T14:19:40,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:40,404  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -77
2024-05-01T14:19:40,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:40,405  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:40,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: null will be shutdown
2024-05-01T14:19:40,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@205d6f84 created in the thread with id: 1
2024-05-01T14:19:40,408  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444 from thread id: 1
2024-05-01T14:19:40,409  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:40,415  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:40,415  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:40,421  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:40,427  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:40,433  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:40,458  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T14:19:40,482  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2076183712_0020
2024-05-01T14:19:40,482  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:40,637  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:40,637  INFO [main] mapreduce.Job: Running job: job_local2076183712_0020
2024-05-01T14:19:40,638  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:40,639  INFO [Thread-799] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:40,639  INFO [Thread-799] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:40,639  INFO [Thread-799] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T14:19:40,648  INFO [Thread-799] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:40,648  INFO [Thread-799] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:41,639  INFO [main] mapreduce.Job: Job job_local2076183712_0020 running in uber mode : false
2024-05-01T14:19:41,639  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:41,639  INFO [main] mapreduce.Job: Job job_local2076183712_0020 completed successfully
2024-05-01T14:19:41,639  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:41,639  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:41,644  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:41,644  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:41,702  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:41,703  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[4]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:41,748  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:41,751  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:41,751  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:41,751  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@205d6f84 will be shutdown
2024-05-01T14:19:41,751  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d4b09c7 created in the thread with id: 1
2024-05-01T14:19:41,753  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 1914f0c4-70a0-4b74-b0d0-24399b612158
2024-05-01T14:19:41,753  INFO [main] SessionState: Hive Session ID = 1914f0c4-70a0-4b74-b0d0-24399b612158
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:41,754  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:41,760  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/1914f0c4-70a0-4b74-b0d0-24399b612158
2024-05-01T14:19:41,763  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/1914f0c4-70a0-4b74-b0d0-24399b612158
2024-05-01T14:19:41,766  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/1914f0c4-70a0-4b74-b0d0-24399b612158/_tmp_space.db
2024-05-01T14:19:41,766  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_PARQUETFILE	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[5]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:41,812  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:41,813  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:41,815  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:41,815  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:41,815  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d4b09c7 will be shutdown
2024-05-01T14:19:41,816  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67887bf2 created in the thread with id: 1
2024-05-01T14:19:41,818  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 3790987e-2903-4ad6-8627-e8da409e2174
2024-05-01T14:19:41,818  INFO [main] SessionState: Hive Session ID = 3790987e-2903-4ad6-8627-e8da409e2174
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:41,819  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:41,826  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3790987e-2903-4ad6-8627-e8da409e2174
2024-05-01T14:19:41,829  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/3790987e-2903-4ad6-8627-e8da409e2174
2024-05-01T14:19:41,833  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3790987e-2903-4ad6-8627-e8da409e2174/_tmp_space.db
2024-05-01T14:19:41,833  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_AVRO	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[6]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.49">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:41,889  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:41,891  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:41,891  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:41,891  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67887bf2 will be shutdown
2024-05-01T14:19:41,891  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fae1ec9 created in the thread with id: 1
2024-05-01T14:19:41,893  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = ea04e879-7735-4659-bcdd-8f21d1300557
2024-05-01T14:19:41,893  INFO [main] SessionState: Hive Session ID = ea04e879-7735-4659-bcdd-8f21d1300557
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:41,894  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:41,900  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/ea04e879-7735-4659-bcdd-8f21d1300557
2024-05-01T14:19:41,904  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/ea04e879-7735-4659-bcdd-8f21d1300557
2024-05-01T14:19:41,907  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/ea04e879-7735-4659-bcdd-8f21d1300557/_tmp_space.db
2024-05-01T14:19:41,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:41,909  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_JSONFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_JSONFILE, serializationLib:org.apache.hadoop.hive.serde2.JsonSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T14:19:41,910  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:41,977  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:41,977  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:41,978  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:41,980  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:41,980  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:41,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3fae1ec9 will be shutdown
2024-05-01T14:19:41,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@549dfe1d created in the thread with id: 1
2024-05-01T14:19:41,982  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:41,983  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:41,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:41,983  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79e3f444, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@549dfe1d will be shutdown
2024-05-01T14:19:41,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:41,983  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -78
2024-05-01T14:19:41,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:41,984  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:41,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50e336d9, with PersistenceManager: null will be shutdown
2024-05-01T14:19:41,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50e336d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73864c16 created in the thread with id: 1
2024-05-01T14:19:41,986  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50e336d9 from thread id: 1
2024-05-01T14:19:41,988  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:41,993  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:42,011  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:42,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:42,055  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:42,055  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:42,056  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:42,056  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:42,056  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50e336d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@73864c16 will be shutdown
2024-05-01T14:19:42,056  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50e336d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27879518 created in the thread with id: 1
2024-05-01T14:19:42,058  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:42,059  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:42,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:42,059  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50e336d9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27879518 will be shutdown
2024-05-01T14:19:42,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:42,059  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -79
2024-05-01T14:19:42,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:42,060  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:42,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: null will be shutdown
2024-05-01T14:19:42,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d837af7 created in the thread with id: 1
2024-05-01T14:19:42,062  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558 from thread id: 1
2024-05-01T14:19:42,062  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value1,501]	
2024-05-01T14:19:42,078  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:42,084  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:42,085  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:42,107  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:42,125  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local432908775_0021
2024-05-01T14:19:42,125  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:42,180  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:42,180  INFO [main] mapreduce.Job: Running job: job_local432908775_0021
2024-05-01T14:19:42,180  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:42,182  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,182  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,183  INFO [Thread-841] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:42,184  INFO [Thread-841] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,184  INFO [Thread-841] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,197  INFO [Thread-841] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:42,198  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local432908775_0021_m_000000_0
2024-05-01T14:19:42,202  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,202  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,204  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,204  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,204  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:42,204  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T14:19:42,211  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,211  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,237  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:42,240  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local432908775_0021_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:42,240  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,240  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,244  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:42,244  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local432908775_0021_m_000000_0 is allowed to commit now
2024-05-01T14:19:42,244  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:42,244  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:42,254  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local432908775_0021_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5678424742461153/part1=p1value1/part0=501
2024-05-01T14:19:42,254  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:42,254  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local432908775_0021_m_000000_0' done.
2024-05-01T14:19:42,254  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local432908775_0021_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10736658
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=964689920
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:42,254  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local432908775_0021_m_000000_0
2024-05-01T14:19:42,255  INFO [Thread-841] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:42,299  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:42,299  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:42,300  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:42,301  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:42,301  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:42,301  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@193d679c, with PersistenceManager: null will be shutdown
2024-05-01T14:19:42,301  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@193d679c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@257b4eb5 created in the thread with id: 899
2024-05-01T14:19:42,302  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@193d679c from thread id: 899
2024-05-01T14:19:42,303  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:42,303  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:42,303  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:42,303  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@193d679c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@257b4eb5 will be shutdown
2024-05-01T14:19:42,303  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:42,303  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -80
2024-05-01T14:19:42,303  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:42,304  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:42,304  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21282538, with PersistenceManager: null will be shutdown
2024-05-01T14:19:42,304  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21282538, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ed03c63 created in the thread with id: 899
2024-05-01T14:19:42,306  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21282538 from thread id: 899
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:42,350  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:42,351  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=501, part1=p1value1}].
2024-05-01T14:19:42,373  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5678424742461153/part1=p1value1/part0=501].
2024-05-01T14:19:42,373  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:42,413  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:42,413  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:42,413  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:42,413  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:42,414  WARN [Thread-841] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:42,414  INFO [Thread-841] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:42,415  INFO [Thread-841] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:42,415  INFO [Thread-841] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:42,415  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21282538, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ed03c63 will be shutdown
2024-05-01T14:19:42,416  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21282538, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d487ab4 created in the thread with id: 899
2024-05-01T14:19:42,417  INFO [Thread-841] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:42,417  INFO [Thread-841] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:42,418  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:42,418  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21282538, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d487ab4 will be shutdown
2024-05-01T14:19:42,418  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:42,418  INFO [Thread-841] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -81
2024-05-01T14:19:42,418  INFO [Thread-841] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:42,418  INFO [Thread-841] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:42,419  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21f944b9, with PersistenceManager: null will be shutdown
2024-05-01T14:19:42,419  INFO [Thread-841] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21f944b9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22f51c78 created in the thread with id: 899
2024-05-01T14:19:42,420  INFO [Thread-841] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21f944b9 from thread id: 899
2024-05-01T14:19:42,421  INFO [Thread-841] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:42,421  WARN [Thread-841] mapred.LocalJobRunner: job_local432908775_0021
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,5678424742461153/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:43,180  INFO [main] mapreduce.Job: Job job_local432908775_0021 running in uber mode : false
2024-05-01T14:19:43,181  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:43,181  INFO [main] mapreduce.Job: Job job_local432908775_0021 failed with state FAILED due to: NA
2024-05-01T14:19:43,182  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10736658
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=964689920
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:43,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:43,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:43,227  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:43,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:43,227  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:43,227  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:43,228  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:43,228  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:43,228  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:43,228  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:43,228  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:43,228  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:43,229  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:43,230  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:43,230  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:43,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d837af7 will be shutdown
2024-05-01T14:19:43,231  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b5f72fa created in the thread with id: 1
2024-05-01T14:19:43,232  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:43,232  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:43,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:43,233  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc558, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b5f72fa will be shutdown
2024-05-01T14:19:43,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:43,233  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -82
2024-05-01T14:19:43,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:43,234  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:43,234  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: null will be shutdown
2024-05-01T14:19:43,234  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2da7ef3e created in the thread with id: 1
2024-05-01T14:19:43,236  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34 from thread id: 1
2024-05-01T14:19:43,237  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:43,242  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:43,248  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:43,281  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:43,282  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:43,282  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:43,282  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:43,282  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:43,283  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:43,283  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2da7ef3e will be shutdown
2024-05-01T14:19:43,283  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52b4da7c created in the thread with id: 1
2024-05-01T14:19:43,284  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:43,285  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:43,285  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:43,285  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472d7f34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52b4da7c will be shutdown
2024-05-01T14:19:43,285  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:43,285  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -83
2024-05-01T14:19:43,285  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:43,286  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:43,286  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: null will be shutdown
2024-05-01T14:19:43,286  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48149568 created in the thread with id: 1
2024-05-01T14:19:43,287  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555 from thread id: 1
2024-05-01T14:19:43,288  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T14:19:43,299  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:43,305  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:43,305  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:43,326  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:43,342  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local39488080_0022
2024-05-01T14:19:43,342  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:43,390  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:43,391  INFO [main] mapreduce.Job: Running job: job_local39488080_0022
2024-05-01T14:19:43,391  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:43,393  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,393  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,394  INFO [Thread-887] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:43,394  INFO [Thread-887] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,394  INFO [Thread-887] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,408  INFO [Thread-887] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:43,408  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local39488080_0022_m_000000_0
2024-05-01T14:19:43,410  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,410  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,411  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,411  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,411  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:43,411  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:43,413  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,413  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,428  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:43,428  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local39488080_0022_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:43,428  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,428  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,432  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:43,432  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local39488080_0022_m_000000_0 is allowed to commit now
2024-05-01T14:19:43,432  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:43,432  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:43,442  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local39488080_0022_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7413347442661018/part1=p1value2/part0=502
2024-05-01T14:19:43,442  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:43,442  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local39488080_0022_m_000000_0' done.
2024-05-01T14:19:43,443  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local39488080_0022_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11244833
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=964689920
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:43,443  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local39488080_0022_m_000000_0
2024-05-01T14:19:43,443  INFO [Thread-887] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:43,487  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:43,487  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:43,488  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:43,488  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:43,489  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:43,489  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:43,489  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:43,490  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a, with PersistenceManager: null will be shutdown
2024-05-01T14:19:43,490  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ade14be created in the thread with id: 947
2024-05-01T14:19:43,491  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a from thread id: 947
2024-05-01T14:19:43,491  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:43,491  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:43,492  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:43,492  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63521a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ade14be will be shutdown
2024-05-01T14:19:43,492  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:43,492  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -84
2024-05-01T14:19:43,492  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:43,493  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:43,493  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: null will be shutdown
2024-05-01T14:19:43,493  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ae2afaa created in the thread with id: 947
2024-05-01T14:19:43,494  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181 from thread id: 947
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:43,537  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:43,538  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:43,560  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7413347442661018/part1=p1value2/part0=502].
2024-05-01T14:19:43,560  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:43,600  WARN [Thread-887] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:43,600  INFO [Thread-887] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:43,601  INFO [Thread-887] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:43,601  INFO [Thread-887] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:43,601  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ae2afaa will be shutdown
2024-05-01T14:19:43,601  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d9fd547 created in the thread with id: 947
2024-05-01T14:19:43,603  INFO [Thread-887] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:43,603  INFO [Thread-887] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:43,603  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:43,603  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9db181, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d9fd547 will be shutdown
2024-05-01T14:19:43,603  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:43,603  INFO [Thread-887] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -85
2024-05-01T14:19:43,603  INFO [Thread-887] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:43,604  INFO [Thread-887] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:43,604  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c9e3015, with PersistenceManager: null will be shutdown
2024-05-01T14:19:43,604  INFO [Thread-887] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c9e3015, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f92a1b created in the thread with id: 947
2024-05-01T14:19:43,606  INFO [Thread-887] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c9e3015 from thread id: 947
2024-05-01T14:19:43,606  INFO [Thread-887] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:43,606  WARN [Thread-887] mapred.LocalJobRunner: job_local39488080_0022
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,7413347442661018/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:44,391  INFO [main] mapreduce.Job: Job job_local39488080_0022 running in uber mode : false
2024-05-01T14:19:44,391  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:44,391  INFO [main] mapreduce.Job: Job job_local39488080_0022 failed with state FAILED due to: NA
2024-05-01T14:19:44,392  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11244833
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=964689920
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:44,444  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:44,444  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:44,445  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:44,447  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:44,447  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:44,447  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48149568 will be shutdown
2024-05-01T14:19:44,447  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@411b75b4 created in the thread with id: 1
2024-05-01T14:19:44,449  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:44,449  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:44,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:44,449  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@62857555, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@411b75b4 will be shutdown
2024-05-01T14:19:44,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:44,449  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -86
2024-05-01T14:19:44,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:44,450  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:44,450  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: null will be shutdown
2024-05-01T14:19:44,450  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31b2c451 created in the thread with id: 1
2024-05-01T14:19:44,452  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d from thread id: 1
2024-05-01T14:19:44,453  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:44,458  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:44,465  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:44,500  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:44,500  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:44,501  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:44,501  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:44,501  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@31b2c451 will be shutdown
2024-05-01T14:19:44,501  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d0f2154 created in the thread with id: 1
2024-05-01T14:19:44,503  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:44,503  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:44,503  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:44,503  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@14ca4b4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d0f2154 will be shutdown
2024-05-01T14:19:44,503  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:44,503  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -87
2024-05-01T14:19:44,503  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:44,504  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:44,504  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: null will be shutdown
2024-05-01T14:19:44,504  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75af5f2a created in the thread with id: 1
2024-05-01T14:19:44,506  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b from thread id: 1
2024-05-01T14:19:44,506  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-05-01T14:19:44,517  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:44,522  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:44,523  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:44,544  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:44,561  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1005166276_0023
2024-05-01T14:19:44,561  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:44,613  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:44,613  INFO [main] mapreduce.Job: Running job: job_local1005166276_0023
2024-05-01T14:19:44,614  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:44,615  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,615  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,616  INFO [Thread-933] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:44,617  INFO [Thread-933] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,617  INFO [Thread-933] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,631  INFO [Thread-933] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:44,631  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1005166276_0023_m_000000_0
2024-05-01T14:19:44,633  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,633  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,635  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,635  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,635  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:44,635  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:44,637  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T14:19:44,638  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,638  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,654  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:44,654  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1005166276_0023_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:44,654  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,654  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,659  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:44,659  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1005166276_0023_m_000000_0 is allowed to commit now
2024-05-01T14:19:44,659  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:44,659  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:44,669  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1005166276_0023_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,27401421370036017/part1=p1value2/part0=502
2024-05-01T14:19:44,669  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:44,669  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1005166276_0023_m_000000_0' done.
2024-05-01T14:19:44,669  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1005166276_0023_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11757793
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=964689920
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:44,669  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1005166276_0023_m_000000_0
2024-05-01T14:19:44,670  INFO [Thread-933] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:44,717  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:44,717  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:44,718  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:44,718  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:44,718  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:44,719  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dc463ba, with PersistenceManager: null will be shutdown
2024-05-01T14:19:44,719  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dc463ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a73f7df created in the thread with id: 995
2024-05-01T14:19:44,720  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dc463ba from thread id: 995
2024-05-01T14:19:44,720  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:44,720  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:44,721  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:44,721  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dc463ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a73f7df will be shutdown
2024-05-01T14:19:44,721  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:44,721  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -88
2024-05-01T14:19:44,721  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:44,721  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:44,722  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6cfc1657, with PersistenceManager: null will be shutdown
2024-05-01T14:19:44,722  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6cfc1657, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c9afca0 created in the thread with id: 995
2024-05-01T14:19:44,723  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6cfc1657 from thread id: 995
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:44,767  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:44,768  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:44,790  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,27401421370036017/part1=p1value2/part0=502].
2024-05-01T14:19:44,791  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:44,829  WARN [Thread-933] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:44,830  INFO [Thread-933] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:44,830  INFO [Thread-933] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:44,830  INFO [Thread-933] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:44,831  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6cfc1657, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c9afca0 will be shutdown
2024-05-01T14:19:44,831  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6cfc1657, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@dd409b9 created in the thread with id: 995
2024-05-01T14:19:44,832  INFO [Thread-933] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:44,833  INFO [Thread-933] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:44,833  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:44,833  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6cfc1657, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@dd409b9 will be shutdown
2024-05-01T14:19:44,833  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:44,833  INFO [Thread-933] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -89
2024-05-01T14:19:44,833  INFO [Thread-933] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:44,834  INFO [Thread-933] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:44,834  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@382eb4b7, with PersistenceManager: null will be shutdown
2024-05-01T14:19:44,834  INFO [Thread-933] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@382eb4b7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6a79d3d4 created in the thread with id: 995
2024-05-01T14:19:44,836  INFO [Thread-933] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@382eb4b7 from thread id: 995
2024-05-01T14:19:44,836  INFO [Thread-933] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:44,836  WARN [Thread-933] mapred.LocalJobRunner: job_local1005166276_0023
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,27401421370036017/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:45,614  INFO [main] mapreduce.Job: Job job_local1005166276_0023 running in uber mode : false
2024-05-01T14:19:45,614  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:45,614  INFO [main] mapreduce.Job: Job job_local1005166276_0023 failed with state FAILED due to: NA
2024-05-01T14:19:45,615  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11757793
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=964689920
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:45,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:45,664  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:45,664  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:45,665  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:45,666  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:45,666  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:45,667  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75af5f2a will be shutdown
2024-05-01T14:19:45,667  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78ba0a57 created in the thread with id: 1
2024-05-01T14:19:45,668  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:45,668  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:45,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:45,669  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c61011b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@78ba0a57 will be shutdown
2024-05-01T14:19:45,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:45,669  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -90
2024-05-01T14:19:45,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:45,669  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:45,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: null will be shutdown
2024-05-01T14:19:45,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eef8498 created in the thread with id: 1
2024-05-01T14:19:45,671  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325 from thread id: 1
2024-05-01T14:19:45,672  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:45,676  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:45,683  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:45,717  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:45,717  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:45,718  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:45,718  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:45,718  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4eef8498 will be shutdown
2024-05-01T14:19:45,719  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cb3c9e6 created in the thread with id: 1
2024-05-01T14:19:45,720  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:45,720  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:45,721  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:45,721  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eda5325, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cb3c9e6 will be shutdown
2024-05-01T14:19:45,721  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:45,721  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -91
2024-05-01T14:19:45,721  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:45,722  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:45,722  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: null will be shutdown
2024-05-01T14:19:45,722  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@165634aa created in the thread with id: 1
2024-05-01T14:19:45,724  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04 from thread id: 1
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:45,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:45,773  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:45,773  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:45,773  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:45,773  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:45,774  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:45,775  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:45,775  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:45,775  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@165634aa will be shutdown
2024-05-01T14:19:45,775  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e92f150 created in the thread with id: 1
2024-05-01T14:19:45,777  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:45,777  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:45,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:45,778  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@712adc04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e92f150 will be shutdown
2024-05-01T14:19:45,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:45,778  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -92
2024-05-01T14:19:45,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:45,779  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:45,779  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: null will be shutdown
2024-05-01T14:19:45,779  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fa35f7e created in the thread with id: 1
2024-05-01T14:19:45,782  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777 from thread id: 1
2024-05-01T14:19:45,783  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:45,788  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:45,854  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:45,855  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:45,856  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:45,858  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:45,858  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:45,858  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1fa35f7e will be shutdown
2024-05-01T14:19:45,858  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71b01319 created in the thread with id: 1
2024-05-01T14:19:45,860  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:45,860  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:45,861  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:45,861  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c683777, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71b01319 will be shutdown
2024-05-01T14:19:45,861  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:45,861  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -93
2024-05-01T14:19:45,861  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:45,862  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:45,862  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:45,862  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ea3b20d created in the thread with id: 1
2024-05-01T14:19:45,864  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e from thread id: 1
2024-05-01T14:19:45,865  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:45,872  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:45,879  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:45,957  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:45,957  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:45,957  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:45,957  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:45,957  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:45,957  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:45,958  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:45,958  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:45,959  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:45,959  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:45,959  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ea3b20d will be shutdown
2024-05-01T14:19:45,959  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c581e65 created in the thread with id: 1
2024-05-01T14:19:45,961  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:45,961  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:45,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:45,961  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7685912e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c581e65 will be shutdown
2024-05-01T14:19:45,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:45,961  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -94
2024-05-01T14:19:45,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:45,962  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:45,962  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: null will be shutdown
2024-05-01T14:19:45,962  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@445265b0 created in the thread with id: 1
2024-05-01T14:19:45,964  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04 from thread id: 1
2024-05-01T14:19:45,970  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:45,975  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:45,975  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:45,996  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:46,012  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local286911743_0024
2024-05-01T14:19:46,012  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:46,063  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:46,063  INFO [main] mapreduce.Job: Running job: job_local286911743_0024
2024-05-01T14:19:46,064  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:46,065  INFO [Thread-984] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:46,067  INFO [Thread-984] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:46,067  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local286911743_0024_m_000000_0
2024-05-01T14:19:46,069  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:46,070  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T14:19:46,074  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local286911743_0024_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.4147820819479545/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T14:19:46,074  INFO [Thread-984] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:46,075  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.4147820819479545].
2024-05-01T14:19:46,075  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:46,113  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:46,114  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:46,114  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:46,114  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:46,114  WARN [Thread-984] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:46,114  INFO [Thread-984] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:46,114  INFO [Thread-984] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:46,115  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:46,115  INFO [Thread-984] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:46,115  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9a7fea, with PersistenceManager: null will be shutdown
2024-05-01T14:19:46,115  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9a7fea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d943e37 created in the thread with id: 1048
2024-05-01T14:19:46,117  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9a7fea from thread id: 1048
2024-05-01T14:19:46,117  INFO [Thread-984] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:46,117  INFO [Thread-984] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:46,117  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:46,117  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9a7fea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d943e37 will be shutdown
2024-05-01T14:19:46,117  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:46,117  INFO [Thread-984] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -95
2024-05-01T14:19:46,117  INFO [Thread-984] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:46,118  INFO [Thread-984] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:46,118  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1177d952, with PersistenceManager: null will be shutdown
2024-05-01T14:19:46,118  INFO [Thread-984] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1177d952, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13c55341 created in the thread with id: 1048
2024-05-01T14:19:46,120  INFO [Thread-984] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1177d952 from thread id: 1048
2024-05-01T14:19:46,121  INFO [Thread-984] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:46,121  WARN [Thread-984] mapred.LocalJobRunner: job_local286911743_0024
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T14:19:47,064  INFO [main] mapreduce.Job: Job job_local286911743_0024 running in uber mode : false
2024-05-01T14:19:47,064  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:47,064  INFO [main] mapreduce.Job: Job job_local286911743_0024 failed with state FAILED due to: NA
2024-05-01T14:19:47,064  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:47,111  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:47,112  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:47,113  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:47,115  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:47,115  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:47,115  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@445265b0 will be shutdown
2024-05-01T14:19:47,115  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ef6a063 created in the thread with id: 1
2024-05-01T14:19:47,117  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:47,117  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:47,117  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:47,117  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@34f4fd04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ef6a063 will be shutdown
2024-05-01T14:19:47,117  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:47,117  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -96
2024-05-01T14:19:47,117  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:47,118  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:47,118  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: null will be shutdown
2024-05-01T14:19:47,119  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c821dc7 created in the thread with id: 1
2024-05-01T14:19:47,120  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5 from thread id: 1
2024-05-01T14:19:47,121  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:47,128  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:47,129  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:47,134  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:47,140  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:47,145  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:47,169  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T14:19:47,184  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local579713503_0025
2024-05-01T14:19:47,185  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:47,237  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:47,237  INFO [main] mapreduce.Job: Running job: job_local579713503_0025
2024-05-01T14:19:47,237  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:47,238  INFO [Thread-1004] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:47,238  INFO [Thread-1004] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:47,238  INFO [Thread-1004] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T14:19:47,246  INFO [Thread-1004] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:47,246  INFO [Thread-1004] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:48,237  INFO [main] mapreduce.Job: Job job_local579713503_0025 running in uber mode : false
2024-05-01T14:19:48,238  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:48,238  INFO [main] mapreduce.Job: Job job_local579713503_0025 completed successfully
2024-05-01T14:19:48,238  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:48,238  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:48,246  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:48,247  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,322  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[7]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.436">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,368  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:48,371  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:48,371  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:48,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c821dc7 will be shutdown
2024-05-01T14:19:48,371  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2de22e7 created in the thread with id: 1
2024-05-01T14:19:48,372  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 3ad88db2-7ff0-42e0-ad4f-094545ea8176
2024-05-01T14:19:48,373  INFO [main] SessionState: Hive Session ID = 3ad88db2-7ff0-42e0-ad4f-094545ea8176
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:48,373  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-05-01T14:19:48,379  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3ad88db2-7ff0-42e0-ad4f-094545ea8176
2024-05-01T14:19:48,382  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/3ad88db2-7ff0-42e0-ad4f-094545ea8176
2024-05-01T14:19:48,385  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/3ad88db2-7ff0-42e0-ad4f-094545ea8176/_tmp_space.db
2024-05-01T14:19:48,385  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:48,386  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_rcfile_columnar, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_rcfile_columnar, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-05-01T14:19:48,388  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,450  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:48,450  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:48,451  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:48,453  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:48,453  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:48,453  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2de22e7 will be shutdown
2024-05-01T14:19:48,453  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5930a229 created in the thread with id: 1
2024-05-01T14:19:48,455  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:48,455  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:48,455  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:48,455  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cae7d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5930a229 will be shutdown
2024-05-01T14:19:48,456  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:48,456  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -97
2024-05-01T14:19:48,456  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:48,457  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:48,457  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: null will be shutdown
2024-05-01T14:19:48,457  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d9db780 created in the thread with id: 1
2024-05-01T14:19:48,458  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9 from thread id: 1
2024-05-01T14:19:48,459  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:48,466  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:48,473  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,508  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:48,508  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:48,509  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:48,509  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:48,509  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d9db780 will be shutdown
2024-05-01T14:19:48,510  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6aa16117 created in the thread with id: 1
2024-05-01T14:19:48,511  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:48,511  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:48,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:48,511  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d91e9c9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6aa16117 will be shutdown
2024-05-01T14:19:48,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:48,512  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -98
2024-05-01T14:19:48,512  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:48,512  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:48,513  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:48,513  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56b4951a created in the thread with id: 1
2024-05-01T14:19:48,514  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e from thread id: 1
2024-05-01T14:19:48,516  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value1,501]	
2024-05-01T14:19:48,530  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:48,535  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:48,536  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:48,556  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:48,574  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local322384427_0026
2024-05-01T14:19:48,574  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:48,633  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:48,633  INFO [main] mapreduce.Job: Running job: job_local322384427_0026
2024-05-01T14:19:48,634  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:48,636  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,636  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,637  INFO [Thread-1038] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:48,637  INFO [Thread-1038] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,637  INFO [Thread-1038] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,651  INFO [Thread-1038] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:48,651  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local322384427_0026_m_000000_0
2024-05-01T14:19:48,657  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,657  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,658  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,658  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,658  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:48,659  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-05-01T14:19:48,666  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,666  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,681  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:48,682  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-05-01T14:19:48,682  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-05-01T14:19:48,684  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local322384427_0026_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:48,684  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,684  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,688  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:48,688  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local322384427_0026_m_000000_0 is allowed to commit now
2024-05-01T14:19:48,688  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:48,688  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:48,699  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local322384427_0026_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,5295637260165349/part1=p1value1/part0=501
2024-05-01T14:19:48,699  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:48,699  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local322384427_0026_m_000000_0' done.
2024-05-01T14:19:48,699  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local322384427_0026_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13286945
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=959971328
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:48,699  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local322384427_0026_m_000000_0
2024-05-01T14:19:48,699  INFO [Thread-1038] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,750  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,751  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:48,751  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:48,751  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:48,752  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:48,752  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:48,752  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@502056ad, with PersistenceManager: null will be shutdown
2024-05-01T14:19:48,752  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@502056ad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@498ebd7e created in the thread with id: 1104
2024-05-01T14:19:48,754  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@502056ad from thread id: 1104
2024-05-01T14:19:48,754  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:48,754  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:48,754  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:48,754  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@502056ad, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@498ebd7e will be shutdown
2024-05-01T14:19:48,755  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:48,755  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -99
2024-05-01T14:19:48,755  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:48,755  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:48,756  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8486406, with PersistenceManager: null will be shutdown
2024-05-01T14:19:48,756  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8486406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@419460be created in the thread with id: 1104
2024-05-01T14:19:48,757  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8486406 from thread id: 1104
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,808  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,809  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,809  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:48,809  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=501, part1=p1value1}].
2024-05-01T14:19:48,832  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,5295637260165349/part1=p1value1/part0=501].
2024-05-01T14:19:48,832  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:48,871  WARN [Thread-1038] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:48,872  INFO [Thread-1038] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:48,872  INFO [Thread-1038] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:48,872  INFO [Thread-1038] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:48,873  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8486406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@419460be will be shutdown
2024-05-01T14:19:48,873  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8486406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77ac80cb created in the thread with id: 1104
2024-05-01T14:19:48,875  INFO [Thread-1038] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:48,875  INFO [Thread-1038] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:48,875  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:48,875  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8486406, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77ac80cb will be shutdown
2024-05-01T14:19:48,875  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:48,875  INFO [Thread-1038] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -100
2024-05-01T14:19:48,875  INFO [Thread-1038] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:48,876  INFO [Thread-1038] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:48,876  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59428350, with PersistenceManager: null will be shutdown
2024-05-01T14:19:48,876  INFO [Thread-1038] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59428350, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49366011 created in the thread with id: 1104
2024-05-01T14:19:48,877  INFO [Thread-1038] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59428350 from thread id: 1104
2024-05-01T14:19:48,878  INFO [Thread-1038] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:48,878  WARN [Thread-1038] mapred.LocalJobRunner: job_local322384427_0026
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,5295637260165349/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:49,634  INFO [main] mapreduce.Job: Job job_local322384427_0026 running in uber mode : false
2024-05-01T14:19:49,634  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:49,634  INFO [main] mapreduce.Job: Job job_local322384427_0026 failed with state FAILED due to: NA
2024-05-01T14:19:49,635  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13286945
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=959971328
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:49,688  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:49,688  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:49,689  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:49,691  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:49,691  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:49,691  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56b4951a will be shutdown
2024-05-01T14:19:49,691  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b4133d0 created in the thread with id: 1
2024-05-01T14:19:49,693  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:49,693  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:49,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:49,693  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@139e291e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b4133d0 will be shutdown
2024-05-01T14:19:49,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:49,693  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -101
2024-05-01T14:19:49,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:49,694  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:49,695  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: null will be shutdown
2024-05-01T14:19:49,695  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c8ab21f created in the thread with id: 1
2024-05-01T14:19:49,697  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f from thread id: 1
2024-05-01T14:19:49,698  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:49,702  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:49,708  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:49,743  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:49,743  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:49,744  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:49,744  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:49,745  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c8ab21f will be shutdown
2024-05-01T14:19:49,745  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6142b9dd created in the thread with id: 1
2024-05-01T14:19:49,746  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:49,746  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:49,746  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:49,746  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5869f15f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6142b9dd will be shutdown
2024-05-01T14:19:49,747  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:49,747  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -102
2024-05-01T14:19:49,747  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:49,747  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:49,748  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: null will be shutdown
2024-05-01T14:19:49,748  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27d6ff8c created in the thread with id: 1
2024-05-01T14:19:49,749  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6 from thread id: 1
2024-05-01T14:19:49,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T14:19:49,763  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:49,769  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:49,769  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:49,790  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:49,807  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local853862830_0027
2024-05-01T14:19:49,807  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:49,863  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:49,863  INFO [main] mapreduce.Job: Running job: job_local853862830_0027
2024-05-01T14:19:49,863  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:49,864  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,865  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,865  INFO [Thread-1084] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:49,866  INFO [Thread-1084] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,866  INFO [Thread-1084] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,880  INFO [Thread-1084] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:49,880  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local853862830_0027_m_000000_0
2024-05-01T14:19:49,882  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,882  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,884  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,884  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,884  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:49,885  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:49,887  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,887  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,901  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:49,901  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T14:19:49,901  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T14:19:49,901  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local853862830_0027_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:49,901  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,901  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,905  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:49,905  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local853862830_0027_m_000000_0 is allowed to commit now
2024-05-01T14:19:49,905  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:49,906  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:49,916  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local853862830_0027_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,6063600751738815/part1=p1value2/part0=502
2024-05-01T14:19:49,917  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:49,917  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local853862830_0027_m_000000_0' done.
2024-05-01T14:19:49,917  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local853862830_0027_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13797857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=959971328
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:49,917  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local853862830_0027_m_000000_0
2024-05-01T14:19:49,917  INFO [Thread-1084] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:49,968  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:49,968  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:49,969  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:49,970  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:49,970  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:49,970  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6344fcb6, with PersistenceManager: null will be shutdown
2024-05-01T14:19:49,970  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6344fcb6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4381c324 created in the thread with id: 1152
2024-05-01T14:19:49,972  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6344fcb6 from thread id: 1152
2024-05-01T14:19:49,972  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:49,972  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:49,972  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:49,972  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6344fcb6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4381c324 will be shutdown
2024-05-01T14:19:49,972  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:49,972  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -103
2024-05-01T14:19:49,972  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:49,973  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:49,974  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@715bbb65, with PersistenceManager: null will be shutdown
2024-05-01T14:19:49,974  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@715bbb65, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65dd1eac created in the thread with id: 1152
2024-05-01T14:19:49,975  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@715bbb65 from thread id: 1152
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:50,022  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:50,022  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:50,046  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,6063600751738815/part1=p1value2/part0=502].
2024-05-01T14:19:50,046  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:50,087  WARN [Thread-1084] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:50,088  INFO [Thread-1084] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:50,088  INFO [Thread-1084] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:50,088  INFO [Thread-1084] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:50,089  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@715bbb65, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65dd1eac will be shutdown
2024-05-01T14:19:50,089  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@715bbb65, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76da9504 created in the thread with id: 1152
2024-05-01T14:19:50,091  INFO [Thread-1084] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:50,091  INFO [Thread-1084] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:50,091  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:50,091  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@715bbb65, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@76da9504 will be shutdown
2024-05-01T14:19:50,091  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:50,091  INFO [Thread-1084] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -104
2024-05-01T14:19:50,091  INFO [Thread-1084] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:50,092  INFO [Thread-1084] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:50,093  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69f4c841, with PersistenceManager: null will be shutdown
2024-05-01T14:19:50,093  INFO [Thread-1084] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69f4c841, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@289f5f53 created in the thread with id: 1152
2024-05-01T14:19:50,094  INFO [Thread-1084] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@69f4c841 from thread id: 1152
2024-05-01T14:19:50,095  INFO [Thread-1084] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:50,095  WARN [Thread-1084] mapred.LocalJobRunner: job_local853862830_0027
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,6063600751738815/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:50,863  INFO [main] mapreduce.Job: Job job_local853862830_0027 running in uber mode : false
2024-05-01T14:19:50,863  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:50,864  INFO [main] mapreduce.Job: Job job_local853862830_0027 failed with state FAILED due to: NA
2024-05-01T14:19:50,864  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13797857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=959971328
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:50,916  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:50,917  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:50,918  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:50,919  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:50,919  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:50,919  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27d6ff8c will be shutdown
2024-05-01T14:19:50,920  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@441e789e created in the thread with id: 1
2024-05-01T14:19:50,921  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:50,921  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:50,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:50,921  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35852b6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@441e789e will be shutdown
2024-05-01T14:19:50,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:50,922  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -105
2024-05-01T14:19:50,922  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:50,922  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:50,923  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: null will be shutdown
2024-05-01T14:19:50,923  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8174ce created in the thread with id: 1
2024-05-01T14:19:50,924  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b from thread id: 1
2024-05-01T14:19:50,925  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:50,930  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:50,935  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:50,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:50,980  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:50,980  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:50,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:50,980  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:50,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:50,981  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:50,981  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:50,981  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:50,981  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:50,981  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:50,981  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:50,982  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:50,982  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:50,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2c8174ce will be shutdown
2024-05-01T14:19:50,983  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ba056ab created in the thread with id: 1
2024-05-01T14:19:50,984  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:50,985  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:50,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:50,985  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39a8905b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ba056ab will be shutdown
2024-05-01T14:19:50,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:50,985  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -106
2024-05-01T14:19:50,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:50,986  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:50,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: null will be shutdown
2024-05-01T14:19:50,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61ce2d47 created in the thread with id: 1
2024-05-01T14:19:50,989  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698 from thread id: 1
2024-05-01T14:19:50,990  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-05-01T14:19:51,006  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:51,011  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:51,012  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:51,034  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:51,053  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local125982471_0028
2024-05-01T14:19:51,053  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:51,118  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:51,118  INFO [main] mapreduce.Job: Running job: job_local125982471_0028
2024-05-01T14:19:51,119  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:51,120  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,120  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,122  INFO [Thread-1130] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:51,123  INFO [Thread-1130] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,123  INFO [Thread-1130] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,137  INFO [Thread-1130] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:51,137  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local125982471_0028_m_000000_0
2024-05-01T14:19:51,139  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,139  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,140  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,140  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,140  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:51,141  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-05-01T14:19:51,142  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,142  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,157  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:51,157  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-05-01T14:19:51,157  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-05-01T14:19:51,157  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local125982471_0028_m_000000_0 is done. And is in the process of committing
2024-05-01T14:19:51,157  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,157  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,161  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T14:19:51,161  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local125982471_0028_m_000000_0 is allowed to commit now
2024-05-01T14:19:51,161  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:51,161  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:51,172  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local125982471_0028_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9610738241727494/part1=p1value2/part0=502
2024-05-01T14:19:51,172  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T14:19:51,173  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local125982471_0028_m_000000_0' done.
2024-05-01T14:19:51,173  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local125982471_0028_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14308769
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=959971328
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:51,173  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local125982471_0028_m_000000_0
2024-05-01T14:19:51,173  INFO [Thread-1130] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:51,224  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:51,225  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:51,225  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:51,226  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:51,226  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:51,226  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@629da6b4, with PersistenceManager: null will be shutdown
2024-05-01T14:19:51,226  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@629da6b4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cdb3f05 created in the thread with id: 1200
2024-05-01T14:19:51,228  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@629da6b4 from thread id: 1200
2024-05-01T14:19:51,228  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:51,228  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:51,229  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:51,229  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@629da6b4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cdb3f05 will be shutdown
2024-05-01T14:19:51,229  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:51,229  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -107
2024-05-01T14:19:51,229  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:51,230  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:51,230  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@727a20af, with PersistenceManager: null will be shutdown
2024-05-01T14:19:51,230  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@727a20af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@518ae9b5 created in the thread with id: 1200
2024-05-01T14:19:51,232  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@727a20af from thread id: 1200
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:51,284  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:51,284  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part0=502, part1=p1value2}].
2024-05-01T14:19:51,310  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9610738241727494/part1=p1value2/part0=502].
2024-05-01T14:19:51,310  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:51,356  WARN [Thread-1130] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:51,356  INFO [Thread-1130] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:51,357  INFO [Thread-1130] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:51,357  INFO [Thread-1130] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:51,358  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@727a20af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@518ae9b5 will be shutdown
2024-05-01T14:19:51,358  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@727a20af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68f662e1 created in the thread with id: 1200
2024-05-01T14:19:51,359  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-05-01T14:19:51,361  INFO [Thread-1130] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:51,361  INFO [Thread-1130] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:51,361  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:51,361  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@727a20af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68f662e1 will be shutdown
2024-05-01T14:19:51,361  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:51,361  INFO [Thread-1130] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -108
2024-05-01T14:19:51,361  INFO [Thread-1130] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:51,362  INFO [Thread-1130] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:51,362  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68644c38, with PersistenceManager: null will be shutdown
2024-05-01T14:19:51,362  INFO [Thread-1130] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68644c38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30bace89 created in the thread with id: 1200
2024-05-01T14:19:51,364  INFO [Thread-1130] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68644c38 from thread id: 1200
2024-05-01T14:19:51,365  INFO [Thread-1130] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:51,365  WARN [Thread-1130] mapred.LocalJobRunner: job_local125982471_0028
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,9610738241727494/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T14:19:52,119  INFO [main] mapreduce.Job: Job job_local125982471_0028 running in uber mode : false
2024-05-01T14:19:52,119  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-05-01T14:19:52,119  INFO [main] mapreduce.Job: Job job_local125982471_0028 failed with state FAILED due to: NA
2024-05-01T14:19:52,119  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14308769
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=959971328
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-05-01T14:19:52,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:52,164  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:52,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:52,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:52,164  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:52,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:52,165  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:52,165  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:52,165  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:52,165  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:52,165  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:52,165  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:52,166  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:52,168  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:52,168  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:52,168  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@61ce2d47 will be shutdown
2024-05-01T14:19:52,168  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14021c10 created in the thread with id: 1
2024-05-01T14:19:52,197  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:52,197  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:52,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:52,198  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5abfb698, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14021c10 will be shutdown
2024-05-01T14:19:52,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:52,198  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -109
2024-05-01T14:19:52,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:52,199  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,199  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,199  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5655d64 created in the thread with id: 1
2024-05-01T14:19:52,201  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289 from thread id: 1
2024-05-01T14:19:52,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:52,206  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:52,212  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:52,244  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:52,244  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:52,245  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:52,245  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:52,246  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5655d64 will be shutdown
2024-05-01T14:19:52,246  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c37b0de created in the thread with id: 1
2024-05-01T14:19:52,247  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:52,247  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:52,248  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:52,248  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7cad6289, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c37b0de will be shutdown
2024-05-01T14:19:52,248  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:52,248  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -110
2024-05-01T14:19:52,248  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:52,249  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,249  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a837f7, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,249  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a837f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13ea9afc created in the thread with id: 1
2024-05-01T14:19:52,250  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a837f7 from thread id: 1
2024-05-01T14:19:52,295  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:52,295  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:52,295  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:52,296  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:52,296  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:52,297  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:52,298  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:52,298  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:52,299  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a837f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13ea9afc will be shutdown
2024-05-01T14:19:52,299  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a837f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@18a129b8 created in the thread with id: 1
2024-05-01T14:19:52,300  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:52,300  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:52,300  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:52,300  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a837f7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@18a129b8 will be shutdown
2024-05-01T14:19:52,300  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:52,301  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -111
2024-05-01T14:19:52,301  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:52,301  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,301  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,302  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1380a19b created in the thread with id: 1
2024-05-01T14:19:52,303  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d from thread id: 1
2024-05-01T14:19:52,304  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:52,308  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:52,352  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:52,353  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:52,353  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:52,354  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:52,355  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:52,355  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:52,355  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1380a19b will be shutdown
2024-05-01T14:19:52,356  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f0de07 created in the thread with id: 1
2024-05-01T14:19:52,357  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:52,357  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:52,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:52,357  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@688e2e8d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38f0de07 will be shutdown
2024-05-01T14:19:52,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:52,357  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -112
2024-05-01T14:19:52,358  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:52,358  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,358  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,359  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@632cfbc5 created in the thread with id: 1
2024-05-01T14:19:52,360  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47 from thread id: 1
2024-05-01T14:19:52,361  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:52,364  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:52,369  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:52,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:52,401  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:52,401  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:52,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:52,401  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:52,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:52,402  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:52,402  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:52,402  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:52,402  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:52,402  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:52,402  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:52,403  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:52,403  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:52,403  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@632cfbc5 will be shutdown
2024-05-01T14:19:52,403  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12ce9299 created in the thread with id: 1
2024-05-01T14:19:52,404  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:52,404  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:52,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:52,405  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@993bc47, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@12ce9299 will be shutdown
2024-05-01T14:19:52,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:52,405  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -113
2024-05-01T14:19:52,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:52,406  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b517988 created in the thread with id: 1
2024-05-01T14:19:52,407  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71 from thread id: 1
2024-05-01T14:19:52,413  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:52,418  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:52,418  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-05-01T14:19:52,439  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T14:19:52,454  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local7548616_0029
2024-05-01T14:19:52,454  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:52,504  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:52,504  INFO [main] mapreduce.Job: Running job: job_local7548616_0029
2024-05-01T14:19:52,504  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:52,506  INFO [Thread-1181] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-05-01T14:19:52,507  INFO [Thread-1181] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:52,507  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local7548616_0029_m_000000_0
2024-05-01T14:19:52,510  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T14:19:52,510  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-05-01T14:19:52,514  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local7548616_0029_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.3966587873265248/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-05-01T14:19:52,514  INFO [Thread-1181] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:52,516  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.3966587873265248].
2024-05-01T14:19:52,516  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-05-01T14:19:52,552  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:52,552  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:52,552  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:52,552  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:52,552  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:52,552  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:52,553  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:52,553  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:52,553  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:52,553  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:52,553  WARN [Thread-1181] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:52,553  INFO [Thread-1181] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-05-01T14:19:52,553  INFO [Thread-1181] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:52,554  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,554  INFO [Thread-1181] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:52,554  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6b7b2dda, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,554  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6b7b2dda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7899c1a5 created in the thread with id: 1253
2024-05-01T14:19:52,556  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6b7b2dda from thread id: 1253
2024-05-01T14:19:52,556  INFO [Thread-1181] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:52,556  INFO [Thread-1181] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:52,556  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:52,556  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6b7b2dda, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7899c1a5 will be shutdown
2024-05-01T14:19:52,556  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:52,556  INFO [Thread-1181] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -114
2024-05-01T14:19:52,556  INFO [Thread-1181] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:52,557  INFO [Thread-1181] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:52,557  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e77c121, with PersistenceManager: null will be shutdown
2024-05-01T14:19:52,557  INFO [Thread-1181] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e77c121, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b2cc3b7 created in the thread with id: 1253
2024-05-01T14:19:52,558  INFO [Thread-1181] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e77c121 from thread id: 1253
2024-05-01T14:19:52,559  INFO [Thread-1181] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-05-01T14:19:52,559  WARN [Thread-1181] mapred.LocalJobRunner: job_local7548616_0029
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-05-01T14:19:53,504  INFO [main] mapreduce.Job: Job job_local7548616_0029 running in uber mode : false
2024-05-01T14:19:53,505  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:53,505  INFO [main] mapreduce.Job: Job job_local7548616_0029 failed with state FAILED due to: NA
2024-05-01T14:19:53,505  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:53,547  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-05-01T14:19:53,547  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-05-01T14:19:53,548  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-05-01T14:19:53,549  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T14:19:53,549  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T14:19:53,550  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b517988 will be shutdown
2024-05-01T14:19:53,550  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f1bde96 created in the thread with id: 1
2024-05-01T14:19:53,551  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T14:19:53,551  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T14:19:53,551  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T14:19:53,551  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfb4b71, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f1bde96 will be shutdown
2024-05-01T14:19:53,551  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T14:19:53,551  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -115
2024-05-01T14:19:53,552  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-05-01T14:19:53,552  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T14:19:53,553  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c9cd06e, with PersistenceManager: null will be shutdown
2024-05-01T14:19:53,553  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c9cd06e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4afad6bd created in the thread with id: 1
2024-05-01T14:19:53,554  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@c9cd06e from thread id: 1
2024-05-01T14:19:53,555  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:53,561  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:53,561  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:53,566  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T14:19:53,573  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T14:19:53,579  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T14:19:53,601  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-05-01T14:19:53,618  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local596562560_0030
2024-05-01T14:19:53,619  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T14:19:53,673  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T14:19:53,673  INFO [main] mapreduce.Job: Running job: job_local596562560_0030
2024-05-01T14:19:53,673  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter set in config null
2024-05-01T14:19:53,673  INFO [Thread-1201] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-05-01T14:19:53,673  INFO [Thread-1201] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-05-01T14:19:53,673  INFO [Thread-1201] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-05-01T14:19:53,682  INFO [Thread-1201] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T14:19:53,682  INFO [Thread-1201] mapred.LocalJobRunner: map task executor complete.
2024-05-01T14:19:54,673  INFO [main] mapreduce.Job: Job job_local596562560_0030 running in uber mode : false
2024-05-01T14:19:54,673  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-05-01T14:19:54,674  INFO [main] mapreduce.Job: Job job_local596562560_0030 completed successfully
2024-05-01T14:19:54,674  INFO [main] mapreduce.Job: Counters: 0
2024-05-01T14:19:54,674  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:54,679  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-05-01T14:19:54,679  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-05-01T14:19:54,757  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T14:19:54,757  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T14:19:54,757  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T14:19:54,757  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T14:19:54,758  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
]]></system-err>
  </testcase>
</testsuite>