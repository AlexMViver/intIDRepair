<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="17.964" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="run_disabled" value=""/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5716570029165747051.jar /home/alex/Repositories/hive/service/target/surefire 2024-05-01T18-25-52_277-jvmRun1 surefire4999246408255033171tmp surefire_8126701795316392802662tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5716570029165747051.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="test.src.tables" value=""/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="initScript" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="14.016">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,075861 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4b520ea8
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,020822 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 894087
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-05-01T13:52:55.229-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/05/01-13:52:57.022, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/05/02-00:00:00.000, nextFileTime=2024/05/01-00:00:00.000, prevFileTime=2024/05/01-00:00:00.000, current=2024/05/01-13:52:57.023, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@157853da...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@157853da OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3a1dd365
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@3de8f619
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619] started OK.
2024-05-01T13:52:57,132  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-05-01T13:52:57,572  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-05-01T13:52:57,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T13:52:57,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T13:52:57,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T13:52:57,642  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T13:52:57,642  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T13:52:57,642  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T13:52:57,642  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T13:52:57,643  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T13:52:57,643  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T13:52:57,643  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T13:52:57,643  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T13:52:57,643  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 1bc9395a-52ec-403d-8d6a-7495e2a58450
2024-05-01T13:52:57,678  INFO [main] SessionState: Hive Session ID = 1bc9395a-52ec-403d-8d6a-7495e2a58450
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:52:57,691  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:52:58,045  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/1bc9395a-52ec-403d-8d6a-7495e2a58450
2024-05-01T13:52:58,048  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/1bc9395a-52ec-403d-8d6a-7495e2a58450
2024-05-01T13:52:58,052  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/1bc9395a-52ec-403d-8d6a-7495e2a58450/_tmp_space.db
2024-05-01T13:52:58,074  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=1bc9395a-52ec-403d-8d6a-7495e2a58450, clientType=HIVESERVER2]
2024-05-01T13:52:58,130  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T13:52:58,339  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T13:52:58,376  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T13:52:58,385  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-05-01T13:52:58,385  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-05-01T13:52:58,409  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T13:52:58,415  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-05-01T13:52:59,132  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T13:52:59,136  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-05-01T13:52:59,862  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-05-01T13:52:59,862  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: null will be shutdown
2024-05-01T13:52:59,887  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f created in the thread with id: 1
2024-05-01T13:53:02,577  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-05-01T13:53:02,577  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-05-01T13:53:02,577  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64 from thread id: 1
2024-05-01T13:53:02,707  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-05-01T13:53:02,738  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-05-01T13:53:02,766  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-05-01T13:53:02,767  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-05-01T13:53:02,879  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-05-01T13:53:02,886  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-05-01T13:53:02,887  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-05-01T13:53:02,890  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-05-01T13:53:02,916  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T13:53:02,919  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-05-01T13:53:02,920  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T13:53:02,921  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-05-01T13:53:02,923  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-05-01T13:53:02,925  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-05-01T13:53:02,927  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-05-01T13:53:02,927  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-05-01T13:53:02,933  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-05-01T13:53:02,935  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-05-01T13:53:02,936  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-05-01T13:53:02,940  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T13:53:03,082  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T13:53:03,601  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,607  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,610  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,611  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,611  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,613  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,613  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-05-01T13:53:03,662  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T13:53:03,664  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T13:53:03,664  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T13:53:03,664  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T13:53:03,665  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T13:53:03,668  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-05-01T13:53:03,674  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-05-01T13:53:03,688  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T13:53:03,689  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T13:53:03,689  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T13:53:03,689  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T13:53:03,690  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T13:53:03,690  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T13:53:03,713  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T13:53:03,718  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:03,724  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:03,735  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/f0a7829b-4714-442a-acd4-70e65954aff5
2024-05-01T13:53:03,740  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5
2024-05-01T13:53:03,744  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/f0a7829b-4714-442a-acd4-70e65954aff5/_tmp_space.db
2024-05-01T13:53:03,747  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T13:53:03,747  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T13:53:03,750  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T13:53:03,750  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T13:53:03,753  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f will be shutdown
2024-05-01T13:53:03,754  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f68a7f8 created in the thread with id: 1
2024-05-01T13:53:03,774  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T13:53:03,775  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T13:53:03,777  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-05-01T13:53:03,829  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T13:53:03,829  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f68a7f8 will be shutdown
2024-05-01T13:53:03,830  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T13:53:03,830  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-05-01T13:53:03,831  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5
2024-05-01T13:53:03,834  INFO [main] service.CompositeService: Session opened, SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5], current sessions:1
2024-05-01T13:53:03,839  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T13:53:03,845  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:03,863  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=31f0cb22-5909-4616-b47c-3bae8a8b414a] SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5]
2024-05-01T13:53:03,867  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da.test
2024-05-01T13:53:03,879  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da, startTime=1714596783859, sessionId=f0a7829b-4714-442a-acd4-70e65954aff5, createTime=1714596783721, userName=anonymous, ipAddress=null]
2024-05-01T13:53:03,936  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Compiling command(queryId=alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:04,644  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T13:53:04,647  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb, with PersistenceManager: null will be shutdown
2024-05-01T13:53:04,647  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4466cf5d created in the thread with id: 1
2024-05-01T13:53:04,657  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb from thread id: 1
2024-05-01T13:53:04,898  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] reflections.Reflections: Reflections took 203 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T13:53:05,053  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] reflections.Reflections: Reflections took 112 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T13:53:05,141  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] reflections.Reflections: Reflections took 81 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T13:53:05,231  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
2024-05-01T13:53:05,234  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:05,234  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f0a7829b-4714-442a-acd4-70e65954aff5, clientType=HIVESERVER2]
2024-05-01T13:53:05,237  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:05,238  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:05,238  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:05,242  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:05,252  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:06,413  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:07,086  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:07,091  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:07,103  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:07,103  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:07,145  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-03_902_672209105428087651-1
2024-05-01T13:53:07,188  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:07,269  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:07,294  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:07,367  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:07,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:07,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:07,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:07,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:07,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:07,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:07,378  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:07,378  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
2024-05-01T13:53:07,379  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:07,381  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:07,394  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:07,400  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:07,400  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=104, flushCache_()=14, getAllFunctions_()=53}
2024-05-01T13:53:07,401  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Completed compiling command(queryId=alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da); Time taken: 3.467 seconds
2024-05-01T13:53:07,402  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:07,403  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T13:53:07,410  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:07,414  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Executing command(queryId=alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:07,416  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T13:53:07,416  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:07,416  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001
2024-05-01T13:53:07,416  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001
2024-05-01T13:53:07,418  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
2024-05-01T13:53:07,419  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Query ID = alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
Total jobs = 1
2024-05-01T13:53:07,419  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:07,419  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:07,425  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:07,425  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:07,435  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:07,440  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:07,440  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/dummy_path
2024-05-01T13:53:07,527  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:07,549  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:07,686  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-05-01T13:53:07,703  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-05-01T13:53:07,717  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-05-01T13:53:07,718  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-05-01T13:53:07,739  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:07,788  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:07,797  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:07,801  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:07,802  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-05-01T13:53:07,811  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/dummy_path
2024-05-01T13:53:07,852  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:07,878  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:07,880  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:07,915  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:07,969  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1213752969_0001
2024-05-01T13:53:07,969  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:08,192  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)2024-05-01T13:53:08,194  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter

2024-05-01T13:53:08,194  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:08,196  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:08,208  INFO [Thread-61] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:08,214  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1213752969_0001_m_000000_0
2024-05-01T13:53:08,263  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:08,274  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:08,281  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:08,308  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:08,315  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:08,323  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:08,325  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:08,328  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:08,329  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:08,333  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:08,334  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:08,335  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@75d7d706, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5d37b516, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@6a294cc
2024-05-01T13:53:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-03_902_672209105428087651-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-03_902_672209105428087651-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-03_902_672209105428087651-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:08,388  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T13:53:08,388  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T13:53:08,388  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:08,388  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:08,389  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T13:53:08,391  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T13:53:08,395  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T13:53:08,402  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1213752969_0001_m_000000_0 is done. And is in the process of committing
2024-05-01T13:53:08,403  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T13:53:08,403  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1213752969_0001_m_000000_0' done.
2024-05-01T13:53:08,406  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1213752969_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5576
		FILE: Number of bytes written=1157168
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=340
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=884473856
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T13:53:08,406  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1213752969_0001_m_000000_0
2024-05-01T13:53:08,407  INFO [Thread-61] mapred.LocalJobRunner: map task executor complete.
2024-05-01 13:53:09,211 Stage-1 map = 100%,  reduce = 0%
2024-05-01T13:53:09,211  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Task: 2024-05-01 13:53:09,211 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1213752969_0001
2024-05-01T13:53:09,215  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.Task: Ended Job = job_local1213752969_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:09,227  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T13:53:09,227  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:09,227  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001
2024-05-01T13:53:09,227  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1/-mr-10001
2024-05-01T13:53:09,228  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:09,228  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T13:53:09,229  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T13:53:09,237  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:09,237  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:09,237  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Completed executing command(queryId=alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da); Time taken: 1.815 seconds
2024-05-01T13:53:09,238  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:09,241  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,242  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a2b005e8-bbd8-4a09-a167-95deecb371ac] SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5]
2024-05-01T13:53:09,242  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761.test
2024-05-01T13:53:09,246  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761, startTime=1714596789241, sessionId=f0a7829b-4714-442a-acd4-70e65954aff5, createTime=1714596783721, userName=anonymous, ipAddress=null]
2024-05-01T13:53:09,247  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Compiling command(queryId=alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,249  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761
2024-05-01T13:53:09,249  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:09,249  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:09,249  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,250  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,250  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,250  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:09,265  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,348  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,348  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,350  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,350  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,352  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1
2024-05-01T13:53:09,359  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:09,361  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:09,362  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:09,374  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:09,374  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:09,375  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:09,376  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:09,377  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:09,377  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-05-01T13:53:09,377  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Completed compiling command(queryId=alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761); Time taken: 0.13 seconds
2024-05-01T13:53:09,378  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:09,378  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,380  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Thread context registration is done.
2024-05-01T13:53:09,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=494a672f-f6fd-4da9-8447-6f1cc25a3714] SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5]
2024-05-01T13:53:09,380  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:09,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4.test
2024-05-01T13:53:09,384  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4, startTime=1714596789378, sessionId=f0a7829b-4714-442a-acd4-70e65954aff5, createTime=1714596783721, userName=anonymous, ipAddress=null]
2024-05-01T13:53:09,385  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:09,385  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,386  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T13:53:09,386  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:09,386  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:09,386  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Compiling command(queryId=alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001
2024-05-01T13:53:09,386  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001
2024-05-01T13:53:09,386  WARN [HiveServer2-Background-Pool: Thread-121] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761
2024-05-01T13:53:09,387  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Query ID = alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761
Total jobs = 1
2024-05-01T13:53:09,387  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:09,387  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:09,388  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4
2024-05-01T13:53:09,388  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:09,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:09,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:09,390  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,391  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,399  INFO [HiveServer2-Background-Pool: Thread-121] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:09,400  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:09,400  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/dummy_path
2024-05-01T13:53:09,407  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,417  INFO [HiveServer2-Background-Pool: Thread-121] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:09,420  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,421  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,426  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,434  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:09,440  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:09,441  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:09,442  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/dummy_path
2024-05-01T13:53:09,448  INFO [HiveServer2-Background-Pool: Thread-121] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:09,449  INFO [HiveServer2-Background-Pool: Thread-121] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:09,449  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:09,476  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:09,499  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,499  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,502  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,502  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,503  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Submitting tokens for job: job_local38337915_0002
2024-05-01T13:53:09,503  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:09,503  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1
2024-05-01T13:53:09,512  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:09,516  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:09,517  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:09,534  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:09,534  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:09,534  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:09,534  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:09,535  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:09,536  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:09,537  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:09,537  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-05-01T13:53:09,537  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Completed compiling command(queryId=alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4); Time taken: 0.151 seconds
2024-05-01T13:53:09,537  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:09,538  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Thread context registration is done.
2024-05-01T13:53:09,538  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,538  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:09,539  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:09,540  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,540  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=99526f0f-f721-4ce3-9fc7-633bcb3ecf05] SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5]
2024-05-01T13:53:09,540  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d.test
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))2024-05-01T13:53:09,547  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d, startTime=1714596789539, sessionId=f0a7829b-4714-442a-acd4-70e65954aff5, createTime=1714596783721, userName=anonymous, ipAddress=null]

2024-05-01T13:53:09,547  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T13:53:09,547  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:09,548  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001
2024-05-01T13:53:09,548  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001
2024-05-01T13:53:09,548  WARN [HiveServer2-Background-Pool: Thread-156] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4
2024-05-01T13:53:09,548  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Query ID = alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4
Total jobs = 1
2024-05-01T13:53:09,548  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:09,548  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:09,549  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Compiling command(queryId=alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,551  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d
2024-05-01T13:53:09,551  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:09,551  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:09,551  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,551  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,551  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,552  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:09,553  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,553  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,562  INFO [HiveServer2-Background-Pool: Thread-156] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:09,563  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:09,563  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/dummy_path
2024-05-01T13:53:09,572  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,581  INFO [HiveServer2-Background-Pool: Thread-156] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:09,584  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,585  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,591  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,601  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:09,610  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:09,610  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:09,612  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/dummy_path
2024-05-01T13:53:09,619  INFO [HiveServer2-Background-Pool: Thread-156] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:09,620  INFO [HiveServer2-Background-Pool: Thread-156] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:09,620  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:09,640  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T13:53:09,642  INFO [Thread-111] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:09,642  INFO [Thread-111] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T13:53:09,645  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:09,646  INFO [Thread-111] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:09,648  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local38337915_0002_m_000000_0
2024-05-01T13:53:09,652  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:09,653  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:09,654  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:09,656  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,656  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:09,658  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:09,659  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:09,659  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:09,660  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:09,661  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:09,661  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:09,661  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:09,662  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@79b43e17, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5b2c22f9, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@1fe690b
2024-05-01T13:53:09,665  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,666  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,668  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,668  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,669  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1
2024-05-01T13:53:09,678  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:09,680  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:09,681  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:09,689  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Submitting tokens for job: job_local1218830358_0003
2024-05-01T13:53:09,689  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:09,697  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:09,698  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:09,698  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d
2024-05-01T13:53:09,698  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:09,698  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:09,699  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:09,699  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:09,699  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-05-01T13:53:09,699  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Completed compiling command(queryId=alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d); Time taken: 0.15 seconds
2024-05-01T13:53:09,700  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:09,700  INFO [HiveServer2-Background-Pool: Thread-197] common.LogUtils: Thread context registration is done.
2024-05-01T13:53:09,700  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,700  INFO [HiveServer2-Background-Pool: Thread-197] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:09,702  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:09,702  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Executing command(queryId=alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,702  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=58fdf42f-c6d1-4c51-b540-957b7bcb74b3] SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5]
2024-05-01T13:53:09,702  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4.test
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))2024-05-01T13:53:09,708  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4, startTime=1714596789701, sessionId=f0a7829b-4714-442a-acd4-70e65954aff5, createTime=1714596783721, userName=anonymous, ipAddress=null]

2024-05-01T13:53:09,708  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T13:53:09,708  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:09,709  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001
2024-05-01T13:53:09,709  INFO [HiveServer2-Background-Pool: Thread-197] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001
2024-05-01T13:53:09,709  WARN [HiveServer2-Background-Pool: Thread-197] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-05-01T13:53:09,710  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Compiling command(queryId=alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4): select reflect("java.lang.Thread", "sleep", bigint(1000))
Query ID = alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d
2024-05-01T13:53:09,710  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Query ID = alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d
Total jobs = 1
2024-05-01T13:53:09,710  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:09,710  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:09,711  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4
2024-05-01T13:53:09,712  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:09,712  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:09,712  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,712  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,712  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,712  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:09,715  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,715  INFO [HiveServer2-Background-Pool: Thread-197] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,723  INFO [HiveServer2-Background-Pool: Thread-197] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:09,724  INFO [HiveServer2-Background-Pool: Thread-197] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:09,724  INFO [HiveServer2-Background-Pool: Thread-197] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/dummy_path
2024-05-01T13:53:09,733  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,740  INFO [HiveServer2-Background-Pool: Thread-197] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:09,742  INFO [HiveServer2-Background-Pool: Thread-197] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,743  WARN [HiveServer2-Background-Pool: Thread-197] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,749  WARN [HiveServer2-Background-Pool: Thread-197] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,758  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:09,769  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:09,769  INFO [HiveServer2-Background-Pool: Thread-197] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:09,770  INFO [HiveServer2-Background-Pool: Thread-197] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/dummy_path
2024-05-01T13:53:09,777  INFO [HiveServer2-Background-Pool: Thread-197] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:09,777  INFO [HiveServer2-Background-Pool: Thread-197] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:09,778  INFO [HiveServer2-Background-Pool: Thread-197] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:09,792  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T13:53:09,793  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:09,794  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T13:53:09,795  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:09,797  INFO [Thread-150] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:09,798  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1218830358_0003_m_000000_0
2024-05-01T13:53:09,799  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:09,800  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:09,802  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:09,804  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,805  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:09,805  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:09,806  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:09,806  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:09,807  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:09,807  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:09,807  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:09,808  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@16d2a29, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@49b1a35c, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@7935e8a6
2024-05-01T13:53:09,812  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:09,827  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:09,827  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:09,830  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:09,830  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:09,831  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1
2024-05-01T13:53:09,843  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:09,846  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:09,848  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.JobSubmitter: Submitting tokens for job: job_local1210554995_0004
2024-05-01T13:53:09,848  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:09,848  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:09,860  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:09,861  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:09,862  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:09,863  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:09,863  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0}
2024-05-01T13:53:09,863  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Completed compiling command(queryId=alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4); Time taken: 0.154 seconds
2024-05-01T13:53:09,863  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:09,863  INFO [HiveServer2-Background-Pool: Thread-237] common.LogUtils: Thread context registration is done.
2024-05-01T13:53:09,863  INFO [HiveServer2-Background-Pool: Thread-237] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:09,864  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:09,865  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Executing command(queryId=alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-05-01T13:53:09,865  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-05-01T13:53:09,866  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:09,866  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001
2024-05-01T13:53:09,866  INFO [HiveServer2-Background-Pool: Thread-237] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001
2024-05-01T13:53:09,866  WARN [HiveServer2-Background-Pool: Thread-237] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4
2024-05-01T13:53:09,866  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Query ID = alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4
Total jobs = 1
2024-05-01T13:53:09,866  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:09,866  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:09,869  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,870  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:09,887  INFO [HiveServer2-Background-Pool: Thread-237] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:09,889  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:09,890  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/dummy_path
2024-05-01T13:53:09,904  INFO [HiveServer2-Background-Pool: Thread-237] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:09,906  INFO [HiveServer2-Background-Pool: Thread-237] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,906  WARN [HiveServer2-Background-Pool: Thread-237] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,911  WARN [HiveServer2-Background-Pool: Thread-237] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:09,918  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:09,924  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:09,925  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:09,926  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/dummy_path
2024-05-01T13:53:09,932  INFO [HiveServer2-Background-Pool: Thread-237] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:09,932  INFO [HiveServer2-Background-Pool: Thread-237] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:09,932  INFO [HiveServer2-Background-Pool: Thread-237] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:09,949  INFO [HiveServer2-Background-Pool: Thread-197] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T13:53:09,949  INFO [Thread-187] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:09,949  INFO [HiveServer2-Background-Pool: Thread-197] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:09,949  INFO [Thread-187] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:09,951  INFO [Thread-187] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:09,951  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1210554995_0004_m_000000_0
2024-05-01T13:53:09,952  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:09,953  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:09,954  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:09,956  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:09,956  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:09,956  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:09,957  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:09,957  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:09,957  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:09,957  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:09,957  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:09,958  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@7166a53f, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@73d16ee, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@204319fb
2024-05-01T13:53:09,959  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:09,988  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: Submitting tokens for job: job_local1602379593_0005
2024-05-01T13:53:09,988  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:10,072  INFO [HiveServer2-Background-Pool: Thread-237] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T13:53:10,072  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T13:53:10,072  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:10,072  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:10,074  INFO [Thread-218] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:10,074  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1602379593_0005_m_000000_0
2024-05-01T13:53:10,075  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:10,076  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:10,076  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:10,078  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:10,078  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:10,078  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:10,079  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:10,079  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:10,079  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:10,079  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:10,079  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:10,080  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@1ab35fe5, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@6ab1dbb1, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@62c89d31
2024-05-01T13:53:10,376  INFO [main] service.CompositeService: Session closed, SessionHandle [f0a7829b-4714-442a-acd4-70e65954aff5], current sessions:0
2024-05-01T13:53:10,376  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a2b005e8-bbd8-4a09-a167-95deecb371ac]
2024-05-01T13:53:10,377  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Removed queryId: alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=a2b005e8-bbd8-4a09-a167-95deecb371ac] with tag: null
2024-05-01T13:53:10,377  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761
2024-05-01T13:53:10,377  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T13:53:10,378  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 13:53:10,378 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,378  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,378  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: 2024-05-01 13:53:10,378 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,378  WARN [Thread-111] mapred.LocalJobRunner: job_local38337915_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T13:53:10,378  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,378  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-2
2024-05-01T13:53:10,378  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,378  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T13:53:10,379  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-2 operation was queued
Ended Job = job_local38337915_0002 with errors
2024-05-01T13:53:10,379 ERROR [HiveServer2-Background-Pool: Thread-121] exec.Task: Ended Job = job_local38337915_0002 with errors
2024-05-01T13:53:10,379  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1
2024-05-01T13:53:10,379  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-2
2024-05-01T13:53:10,380  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1 operation was queued
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761 without delay
Error during job, obtaining debugging information...
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=58fdf42f-c6d1-4c51-b540-957b7bcb74b3]
2024-05-01T13:53:10,380 ERROR [Thread-223] exec.Task: Error during job, obtaining debugging information...
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Removed queryId: alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=58fdf42f-c6d1-4c51-b540-957b7bcb74b3] with tag: null
2024-05-01T13:53:10,380  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4
2024-05-01T13:53:10,381  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T13:53:10,382  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-5
2024-05-01T13:53:10,382  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T13:53:10,382  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-5 operation was queued
2024-05-01 13:53:10,382 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,382  INFO [HiveServer2-Background-Pool: Thread-237] exec.Task: 2024-05-01 13:53:10,382 Stage-1 map = 0%,  reduce = 0%
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T13:53:10,382  WARN [Thread-218] mapred.LocalJobRunner: job_local1602379593_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T13:53:10,382  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,382  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,382  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,382  WARN [HiveServer2-Background-Pool: Thread-237] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T13:53:10,382  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1
2024-05-01T13:53:10,382  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1 operation was queued
2024-05-01T13:53:10,383  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:10,383  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T13:53:10,383  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-5
2024-05-01T13:53:10,383  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4 without delay
2024-05-01T13:53:10,383  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=494a672f-f6fd-4da9-8447-6f1cc25a3714]
Ended Job = job_local1602379593_0005 with errors
2024-05-01T13:53:10,384 ERROR [HiveServer2-Background-Pool: Thread-237] exec.Task: Ended Job = job_local1602379593_0005 with errors
2024-05-01T13:53:10,384  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Removed queryId: alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=494a672f-f6fd-4da9-8447-6f1cc25a3714] with tag: null
2024-05-01T13:53:10,384  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1
Error during job, obtaining debugging information...
2024-05-01T13:53:10,384 ERROR [Thread-226] exec.Task: Error during job, obtaining debugging information...
2024-05-01T13:53:10,385  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T13:53:10,385 ERROR [HiveServer2-Background-Pool: Thread-121] ql.Driver: FAILED: Operation cancelled
2024-05-01T13:53:10,385  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:10,385  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T13:53:10,386  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T13:53:10,386  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4
2024-05-01T13:53:10,386  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01 13:53:10,386 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,386  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: 2024-05-01 13:53:10,386 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,388  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-05-01T13:53:10,388  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T13:53:10,389  WARN [Thread-150] mapred.LocalJobRunner: job_local1218830358_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T13:53:10,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-3
2024-05-01T13:53:10,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-3 operation was queued
2024-05-01T13:53:10,389  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAILUDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]

2024-05-01T13:53:10,389  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T13:53:10,390  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,390  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,390  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,390  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-3
2024-05-01T13:53:10,390  INFO [HiveServer2-Background-Pool: Thread-237] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T13:53:10,390 ERROR [HiveServer2-Background-Pool: Thread-237] ql.Driver: FAILED: Operation cancelled
2024-05-01T13:53:10,391  INFO [HiveServer2-Background-Pool: Thread-237] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:10,391  INFO [HiveServer2-Background-Pool: Thread-237] metadata.Hive: Total time spent in each metastore function (ms): {}
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:10,391  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:10,391  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240501135309_81eca27d-660a-4490-aca8-371884e52761) has been interrupted after 1.0 seconds
2024-05-01T13:53:10,393  WARN [HiveServer2-Background-Pool: Thread-121] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
MapReduce Jobs Launched: 
2024-05-01T13:53:10,394  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T13:53:10,395  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1 operation was queued
2024-05-01T13:53:10,395  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:10,395  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:10,395  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T13:53:10,395  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:10,395  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:10,395  INFO [HiveServer2-Background-Pool: Thread-237] ql.Driver: Executing command(queryId=alex_20240501135309_d623e8b3-37f6-4489-ba51-a28ab9f967c4) has been interrupted after 0.526 seconds
2024-05-01T13:53:10,395  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4 without delay
2024-05-01T13:53:10,395  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=99526f0f-f721-4ce3-9fc7-633bcb3ecf05]
2024-05-01T13:53:10,395  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1
2024-05-01T13:53:10,395  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Removed queryId: alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=99526f0f-f721-4ce3-9fc7-633bcb3ecf05] with tag: null
2024-05-01T13:53:10,395  WARN [HiveServer2-Background-Pool: Thread-237] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T13:53:10,396  INFO [HiveServer2-Background-Pool: Thread-237] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:10,396  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d
2024-05-01T13:53:10,396  WARN [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T13:53:10,397  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-4
2024-05-01T13:53:10,397  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T13:53:10,397  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-4 operation was queued
2024-05-01 13:53:10,397 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,397  INFO [HiveServer2-Background-Pool: Thread-197] exec.Task: 2024-05-01 13:53:10,397 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:10,397  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1
2024-05-01T13:53:10,397  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1 operation was queued
2024-05-01T13:53:10,397  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:10,397  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T13:53:10,398  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d without delay
2024-05-01T13:53:10,398  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=31f0cb22-5909-4616-b47c-3bae8a8b414a]
2024-05-01T13:53:10,398  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.OperationManager: Removed queryId: alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=31f0cb22-5909-4616-b47c-3bae8a8b414a] with tag: null
2024-05-01T13:53:10,398  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1
2024-05-01T13:53:10,399  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1
2024-05-01T13:53:10,399  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1 operation was queued
2024-05-01T13:53:10,399  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:10,399  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-05-01T13:53:10,399  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,399  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,399  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,400  INFO [EventualCleanupService thread 8] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-03_902_672209105428087651-1
2024-05-01T13:53:10,398  WARN [Thread-187] mapred.LocalJobRunner: job_local1210554995_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T13:53:10,398  INFO [EventualCleanupService thread 6] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-4
2024-05-01T13:53:10,399  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da without delay
2024-05-01T13:53:10,403  INFO [f0a7829b-4714-442a-acd4-70e65954aff5 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5
2024-05-01T13:53:10,404  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/f0a7829b-4714-442a-acd4-70e65954aff5 operation was queued
2024-05-01T13:53:10,405  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5 operation was queued
2024-05-01T13:53:10,405  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/f0a7829b-4714-442a-acd4-70e65954aff5
2024-05-01T13:53:10,405  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5
2024-05-01T13:53:10,407 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T13:53:10,407 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T13:53:10,407 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T13:53:10,407  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:10,408 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:10,407  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T13:53:10,408  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_247_2321293621766407558-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_247_2321293621766407558-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_386_4491417134881898484-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_386_4491417134881898484-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:10,409  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:10,410  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:10,410  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:10,410  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:10,410  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T13:53:10,410  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-05-01T13:53:10,411  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,411  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,411  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,411  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,411  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_709_2012677373200899019-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_709_2012677373200899019-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,411  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/f0a7829b-4714-442a-acd4-70e65954aff5/hive_2024-05-01_13-53-09_548_4481523194481695762-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-09_548_4481523194481695762-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,418  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T13:53:10,418  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4466cf5d will be shutdown
2024-05-01T13:53:10,418  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T13:53:10,418  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-05-01T13:53:10,435  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T13:53:10,435  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T13:53:10,436  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="1.823">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T13:53:10,439  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-05-01T13:53:10,495  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T13:53:10,495  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T13:53:10,496  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T13:53:10,496  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T13:53:10,496  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T13:53:10,496  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T13:53:10,496  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T13:53:10,497  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T13:53:10,497  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T13:53:10,497  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T13:53:10,497  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T13:53:10,497  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = dc792eb5-40f6-42f2-9a96-af796e2b8287
2024-05-01T13:53:10,498  INFO [main] SessionState: Hive Session ID = dc792eb5-40f6-42f2-9a96-af796e2b8287
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:10,498  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:10,506  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/dc792eb5-40f6-42f2-9a96-af796e2b8287
2024-05-01T13:53:10,509  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/dc792eb5-40f6-42f2-9a96-af796e2b8287
2024-05-01T13:53:10,512  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/dc792eb5-40f6-42f2-9a96-af796e2b8287/_tmp_space.db
2024-05-01T13:53:10,513  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=dc792eb5-40f6-42f2-9a96-af796e2b8287, clientType=HIVESERVER2]
2024-05-01T13:53:10,513  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T13:53:10,514  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T13:53:10,514  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T13:53:10,515  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c, with PersistenceManager: null will be shutdown
2024-05-01T13:53:10,515  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@517d9cd5 created in the thread with id: 1
2024-05-01T13:53:10,519  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c from thread id: 1
2024-05-01T13:53:10,519  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T13:53:10,519  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T13:53:10,519  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T13:53:10,520  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T13:53:10,520  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T13:53:10,520  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T13:53:10,520  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T13:53:10,521  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T13:53:10,524  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T13:53:10,534  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T13:53:10,534  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:10,536  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:10,543  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bb6ad29f-a0e0-4282-8db3-3449bc04d72a
2024-05-01T13:53:10,546  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a
2024-05-01T13:53:10,549  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/_tmp_space.db
2024-05-01T13:53:10,549  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T13:53:10,549  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T13:53:10,550  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T13:53:10,550  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@517d9cd5 will be shutdown
2024-05-01T13:53:10,550  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T13:53:10,550  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-05-01T13:53:10,550  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a
2024-05-01T13:53:10,550  INFO [main] service.CompositeService: Session opened, SessionHandle [bb6ad29f-a0e0-4282-8db3-3449bc04d72a], current sessions:1
2024-05-01T13:53:10,550  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T13:53:10,550  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:10,551  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fb6eb377-cdbe-42dc-ba9d-fc77f058fadf] SessionHandle [bb6ad29f-a0e0-4282-8db3-3449bc04d72a]
2024-05-01T13:53:10,551  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134.test
2024-05-01T13:53:10,555  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134, startTime=1714596790551, sessionId=bb6ad29f-a0e0-4282-8db3-3449bc04d72a, createTime=1714596790535, userName=anonymous, ipAddress=null]
2024-05-01T13:53:10,556  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Compiling command(queryId=alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:10,557  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T13:53:10,558  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T13:53:10,558  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T13:53:10,559  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: null will be shutdown
2024-05-01T13:53:10,559  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e210016 created in the thread with id: 1
2024-05-01T13:53:10,563  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148 from thread id: 1
2024-05-01T13:53:10,563  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T13:53:10,563  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=bb6ad29f-a0e0-4282-8db3-3449bc04d72a, clientType=HIVESERVER2]
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:10,564  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:10,565  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:10,578  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:10,629  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:10,629  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:10,631  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:10,631  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:10,632  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-10_556_8803032857081621304-1
2024-05-01T13:53:10,639  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:10,642  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:10,644  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:10,657  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:10,658  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:10,658  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134
2024-05-01T13:53:10,658  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:10,658  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:10,659  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:10,660  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:10,660  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=0}
2024-05-01T13:53:10,660  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Completed compiling command(queryId=alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134); Time taken: 0.104 seconds
2024-05-01T13:53:10,660  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:10,660  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T13:53:10,661  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:10,661  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Executing command(queryId=alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:10,661  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T13:53:10,661  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:10,661  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001
2024-05-01T13:53:10,661  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001
2024-05-01T13:53:10,661  WARN [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134
2024-05-01T13:53:10,662  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Query ID = alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134
Total jobs = 1
2024-05-01T13:53:10,662  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:10,662  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:10,664  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:10,664  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:10,667  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:10,668  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:10,668  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/dummy_path
2024-05-01T13:53:10,681  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:10,682  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T13:53:10,682  WARN [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:10,687  WARN [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:10,695  WARN [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:10,701  WARN [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:10,702  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:10,703  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/dummy_path
2024-05-01T13:53:10,708  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:10,708  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:10,708  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:10,734  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:10,757  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1676227706_0006
2024-05-01T13:53:10,757  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:10,830  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-05-01T13:53:10,831  INFO [Thread-295] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-05-01T13:53:10,831  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:10,831  INFO [Thread-295] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:10,832  INFO [Thread-295] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:10,833  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1676227706_0006_m_000000_0
2024-05-01T13:53:10,836  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:10,837  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:10,840  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:10,841  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T13:53:10,841  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:10,844  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:10,844  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:10,845  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:10,845  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:10,845  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:10,845  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:10,846  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@5cf6b1b3, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@25af1cd8, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@75d3b12d
2024-05-01T13:53:10,846  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-10_556_8803032857081621304-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,846  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-10_556_8803032857081621304-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:10,846  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-10_556_8803032857081621304-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:10,858  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T13:53:10,859  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T13:53:10,859  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T13:53:10,862  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1676227706_0006_m_000000_0 is done. And is in the process of committing
2024-05-01T13:53:10,863  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T13:53:10,863  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1676227706_0006_m_000000_0' done.
2024-05-01T13:53:10,863  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1676227706_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33482
		FILE: Number of bytes written=6933392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=966787072
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T13:53:10,863  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1676227706_0006_m_000000_0
2024-05-01T13:53:10,863  INFO [Thread-295] mapred.LocalJobRunner: map task executor complete.
2024-05-01T13:53:11,387  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1218830358_0003 with errors
2024-05-01T13:53:11,387 ERROR [HiveServer2-Background-Pool: Thread-156] exec.Task: Ended Job = job_local1218830358_0003 with errors
Error during job, obtaining debugging information...
2024-05-01T13:53:11,388 ERROR [Thread-302] exec.Task: Error during job, obtaining debugging information...
2024-05-01T13:53:11,389  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T13:53:11,389 ERROR [HiveServer2-Background-Pool: Thread-156] ql.Driver: FAILED: Operation cancelled
2024-05-01T13:53:11,389  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:11,389  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Total time spent in each metastore function (ms): {close_()=1}
MapReduce Jobs Launched: 
2024-05-01T13:53:11,390  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T13:53:11,390  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T13:53:11,390  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:11,390  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:11,390  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240501135309_57b6de0a-e168-4e78-93ec-f11e49f477f4) has been interrupted after 1.849 seconds
2024-05-01T13:53:11,390  WARN [HiveServer2-Background-Pool: Thread-156] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T13:53:11,391  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:11,398  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1210554995_0004 with errors
2024-05-01T13:53:11,398 ERROR [HiveServer2-Background-Pool: Thread-197] exec.Task: Ended Job = job_local1210554995_0004 with errors
Error during job, obtaining debugging information...
2024-05-01T13:53:11,398 ERROR [Thread-304] exec.Task: Error during job, obtaining debugging information...
2024-05-01T13:53:11,400  INFO [HiveServer2-Background-Pool: Thread-197] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T13:53:11,400 ERROR [HiveServer2-Background-Pool: Thread-197] ql.Driver: FAILED: Operation cancelled
2024-05-01T13:53:11,400  INFO [HiveServer2-Background-Pool: Thread-197] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:11,400  INFO [HiveServer2-Background-Pool: Thread-197] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T13:53:11,400  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T13:53:11,400  WARN [HiveServer2-Background-Pool: Thread-197] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-05-01T13:53:11,400  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:11,401  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:11,401  INFO [HiveServer2-Background-Pool: Thread-197] ql.Driver: Executing command(queryId=alex_20240501135309_1ace972d-a4bf-426b-8679-ed485fb1cc6d) has been interrupted after 1.698 seconds
2024-05-01T13:53:11,401  WARN [HiveServer2-Background-Pool: Thread-197] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-05-01T13:53:11,402  INFO [HiveServer2-Background-Pool: Thread-197] common.LogUtils: Unregistered logging context.
2024-05-01 13:53:11,834 Stage-1 map = 100%,  reduce = 0%
2024-05-01T13:53:11,835  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Task: 2024-05-01 13:53:11,834 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1676227706_0006
2024-05-01T13:53:11,836  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.Task: Ended Job = job_local1676227706_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1/-mr-10001
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T13:53:11,838  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T13:53:11,839  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:11,839  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:11,839  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Completed executing command(queryId=alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134); Time taken: 1.177 seconds
2024-05-01T13:53:11,839  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:11,839  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T13:53:11,840  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=079ff2aa-3ce4-4051-91ee-7784631ab07c] SessionHandle [bb6ad29f-a0e0-4282-8db3-3449bc04d72a]
2024-05-01T13:53:11,840  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59.test
2024-05-01T13:53:11,844  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59, startTime=1714596791840, sessionId=bb6ad29f-a0e0-4282-8db3-3449bc04d72a, createTime=1714596790535, userName=anonymous, ipAddress=null]
2024-05-01T13:53:11,846  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Compiling command(queryId=alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T13:53:11,848  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59
2024-05-01T13:53:11,848  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:11,849  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-05-01T13:53:11,850  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-05-01T13:53:11,937  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] reflections.Reflections: Reflections took 75 ms to scan 2 urls, producing 53 keys and 784 values 
2024-05-01T13:53:12,002  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59
2024-05-01T13:53:12,002  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:12,002  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=10, flushCache_()=0}
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Completed compiling command(queryId=alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59); Time taken: 0.157 seconds
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Executing command(queryId=alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T13:53:12,003  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-05-01T13:53:12,004  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-05-01T13:53:12,004  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T13:53:12,004  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-05-01T13:53:12,004  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-05-01T13:53:12,116  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1714596792, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFiles=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-05-01T13:53:12,124  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/service/target/warehouse/sample_shutdown_hook
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-05-01T13:53:12,256  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-05-01T13:53:12,256  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-05-01T13:53:12,256  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T13:53:12,256  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-05-01T13:53:12,257  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:12,257  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=140}
2024-05-01T13:53:12,257  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Driver: Completed executing command(queryId=alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59); Time taken: 0.253 seconds
2024-05-01T13:53:12,257  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:12,257  INFO [main] service.CompositeService: Session closed, SessionHandle [bb6ad29f-a0e0-4282-8db3-3449bc04d72a], current sessions:0
2024-05-01T13:53:12,257  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fb6eb377-cdbe-42dc-ba9d-fc77f058fadf]
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.OperationManager: Removed queryId: alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=fb6eb377-cdbe-42dc-ba9d-fc77f058fadf] with tag: null
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1 operation was queued
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135310_5c5227db-6fde-487e-aeec-7365cb0a8134 without delay
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=079ff2aa-3ce4-4051-91ee-7784631ab07c]
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.OperationManager: Removed queryId: alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=079ff2aa-3ce4-4051-91ee-7784631ab07c] with tag: null
2024-05-01T13:53:12,258  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/alex_20240501135311_a8e86a84-eb51-46a8-bfcd-6708806a1b59 without delay
2024-05-01T13:53:12,259  INFO [bb6ad29f-a0e0-4282-8db3-3449bc04d72a main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/bb6ad29f-a0e0-4282-8db3-3449bc04d72a
2024-05-01T13:53:12,259  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a/hive_2024-05-01_13-53-10_556_8803032857081621304-1
2024-05-01T13:53:12,260  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bb6ad29f-a0e0-4282-8db3-3449bc04d72a operation was queued
2024-05-01T13:53:12,260  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a operation was queued
2024-05-01T13:53:12,260  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/bb6ad29f-a0e0-4282-8db3-3449bc04d72a
2024-05-01T13:53:12,260  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/bb6ad29f-a0e0-4282-8db3-3449bc04d72a
2024-05-01T13:53:12,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T13:53:12,261  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e210016 will be shutdown
2024-05-01T13:53:12,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T13:53:12,261  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.102">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-05-01T13:53:12,324  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-05-01T13:53:12,325  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-05-01T13:53:12,325  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-05-01T13:53:12,325  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-05-01T13:53:12,325  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-05-01T13:53:12,325  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = ca5c588f-5488-4752-8c6f-73c87a98cea7
2024-05-01T13:53:12,326  INFO [main] SessionState: Hive Session ID = ca5c588f-5488-4752-8c6f-73c87a98cea7
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:12,326  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:12,333  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ca5c588f-5488-4752-8c6f-73c87a98cea7
2024-05-01T13:53:12,337  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/ca5c588f-5488-4752-8c6f-73c87a98cea7
2024-05-01T13:53:12,340  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ca5c588f-5488-4752-8c6f-73c87a98cea7/_tmp_space.db
2024-05-01T13:53:12,341  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ca5c588f-5488-4752-8c6f-73c87a98cea7, clientType=HIVESERVER2]
2024-05-01T13:53:12,341  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T13:53:12,342  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T13:53:12,342  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T13:53:12,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@121f9c52, with PersistenceManager: null will be shutdown
2024-05-01T13:53:12,343  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@121f9c52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47cf65f1 created in the thread with id: 1
2024-05-01T13:53:12,352  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@121f9c52 from thread id: 1
2024-05-01T13:53:12,352  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T13:53:12,352  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T13:53:12,353  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-05-01T13:53:12,353  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-05-01T13:53:12,353  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-05-01T13:53:12,353  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-05-01T13:53:12,353  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-05-01T13:53:12,354  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-05-01T13:53:12,356  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-05-01T13:53:12,356  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-05-01T13:53:12,356  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-05-01T13:53:12,356  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-05-01T13:53:12,356  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-05-01T13:53:12,357  INFO [main] service.AbstractService: Service:CLIService is started.
2024-05-01T13:53:12,357  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-05-01T13:53:12,368  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-05-01T13:53:12,368  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:12,369  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-05-01T13:53:12,378  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/52722bc8-b995-46a2-9838-48a2fd5cf00f
2024-05-01T13:53:12,381  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f
2024-05-01T13:53:12,385  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/52722bc8-b995-46a2-9838-48a2fd5cf00f/_tmp_space.db
2024-05-01T13:53:12,385  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-05-01T13:53:12,385  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-05-01T13:53:12,385  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T13:53:12,385  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@121f9c52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47cf65f1 will be shutdown
2024-05-01T13:53:12,385  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T13:53:12,385  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-05-01T13:53:12,385  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f
2024-05-01T13:53:12,386  INFO [main] service.CompositeService: Session opened, SessionHandle [52722bc8-b995-46a2-9838-48a2fd5cf00f], current sessions:1
2024-05-01T13:53:12,386  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-05-01T13:53:12,386  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:12,387  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=bbfb45c7-21c3-4113-88e6-eeba14857877] SessionHandle [52722bc8-b995-46a2-9838-48a2fd5cf00f]
2024-05-01T13:53:12,387  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4.test
2024-05-01T13:53:12,391  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4, startTime=1714596792386, sessionId=52722bc8-b995-46a2-9838-48a2fd5cf00f, createTime=1714596792368, userName=anonymous, ipAddress=null]
2024-05-01T13:53:12,392  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Compiling command(queryId=alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4): select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:12,394  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-05-01T13:53:12,394  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-05-01T13:53:12,394  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-05-01T13:53:12,395  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c40402c, with PersistenceManager: null will be shutdown
2024-05-01T13:53:12,395  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c40402c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@198524ec created in the thread with id: 1
2024-05-01T13:53:12,399  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c40402c from thread id: 1
2024-05-01T13:53:12,399  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-05-01T13:53:12,400  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-05-01T13:53:12,400  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4
2024-05-01T13:53:12,400  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:12,400  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=52722bc8-b995-46a2-9838-48a2fd5cf00f, clientType=HIVESERVER2]
2024-05-01T13:53:12,401  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:12,401  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:12,401  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:12,401  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:12,401  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:12,415  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:12,506  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:12,506  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:12,512  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:12,512  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:12,513  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-12_392_3741224478110762908-1
2024-05-01T13:53:12,519  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:12,521  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:12,522  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:12,534  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:12,536  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:12,536  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:12,536  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=50, flushCache_()=0}
2024-05-01T13:53:12,536  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Completed compiling command(queryId=alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4); Time taken: 0.144 seconds
2024-05-01T13:53:12,536  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:12,536  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-05-01T13:53:12,537  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:12,537  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Executing command(queryId=alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:12,537  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-05-01T13:53:12,537  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:12,537  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001
2024-05-01T13:53:12,537  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001
2024-05-01T13:53:12,537  WARN [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4
2024-05-01T13:53:12,538  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Query ID = alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4
Total jobs = 1
2024-05-01T13:53:12,538  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:12,538  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:12,541  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:12,541  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:12,545  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:12,545  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:12,545  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/dummy_path
2024-05-01T13:53:12,558  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:12,559  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T13:53:12,560  WARN [52722bc8-b995-46a2-9838-48a2fd5cf00f main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:12,565  WARN [52722bc8-b995-46a2-9838-48a2fd5cf00f main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:12,572  WARN [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:12,578  WARN [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:12,578  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:12,579  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/dummy_path
2024-05-01T13:53:12,584  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:12,584  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:12,584  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:12,608  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:12,657  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mapreduce.JobSubmitter: Submitting tokens for job: job_local283055292_0007
2024-05-01T13:53:12,658  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:12,737  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)2024-05-01T13:53:12,737  INFO [Thread-347] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter

2024-05-01T13:53:12,737  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:12,737  INFO [Thread-347] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:12,739  INFO [Thread-347] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:12,739  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local283055292_0007_m_000000_0
2024-05-01T13:53:12,743  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:12,744  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:12,747  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:12,748  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-05-01T13:53:12,748  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:12,751  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:12,751  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:12,752  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:12,752  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:12,752  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:12,752  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:12,752  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@48be3be3, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@897cf1a, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@728436d0
2024-05-01T13:53:12,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-12_392_3741224478110762908-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:12,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-12_392_3741224478110762908-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01T13:53:12,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-12_392_3741224478110762908-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-05-01T13:53:12,764  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-05-01T13:53:12,765  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-05-01T13:53:12,765  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-05-01T13:53:12,765  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-05-01T13:53:12,765  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-05-01T13:53:12,766  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-05-01T13:53:12,769  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local283055292_0007_m_000000_0 is done. And is in the process of committing
2024-05-01T13:53:12,770  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-05-01T13:53:12,770  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local283055292_0007_m_000000_0' done.
2024-05-01T13:53:12,770  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local283055292_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39068
		FILE: Number of bytes written=8085762
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=970981376
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-05-01T13:53:12,771  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local283055292_0007_m_000000_0
2024-05-01T13:53:12,771  INFO [Thread-347] mapred.LocalJobRunner: map task executor complete.
2024-05-01 13:53:13,740 Stage-1 map = 100%,  reduce = 0%
2024-05-01T13:53:13,740  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Task: 2024-05-01 13:53:13,740 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local283055292_0007
2024-05-01T13:53:13,741  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.Task: Ended Job = job_local283055292_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-05-01T13:53:13,743  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1/-mr-10001
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-05-01T13:53:13,744  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Completed executing command(queryId=alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4); Time taken: 1.207 seconds
2024-05-01T13:53:13,745  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:13,745  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T13:53:13,746  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=ea637935-a8ad-46ab-92fa-8594a6a93bf0] SessionHandle [52722bc8-b995-46a2-9838-48a2fd5cf00f]
2024-05-01T13:53:13,746  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4.test
2024-05-01T13:53:13,750  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4, startTime=1714596793745, sessionId=52722bc8-b995-46a2-9838-48a2fd5cf00f, createTime=1714596792368, userName=anonymous, ipAddress=null]
2024-05-01T13:53:13,751  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Compiling command(queryId=alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Starting caching scope for: alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Starting Semantic Analysis
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:13,752  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-05-01T13:53:13,766  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:13,829  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for source tables
2024-05-01T13:53:13,830  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-05-01T13:53:13,832  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for subqueries
2024-05-01T13:53:13,832  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Get metadata for destination tables
2024-05-01T13:53:13,833  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-13_751_8839056134632449954-1
2024-05-01T13:53:13,839  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-05-01T13:53:13,844  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-05-01T13:53:13,844  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-05-01T13:53:13,855  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map vectorization enabled: false
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map vectorized: false
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Completed plan generation
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] parse.CalcitePlanner: Ending caching scope for: alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-05-01T13:53:13,856  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-05-01T13:53:13,857  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-05-01T13:53:13,857  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-05-01T13:53:13,857  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=1}
2024-05-01T13:53:13,857  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Completed compiling command(queryId=alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4); Time taken: 0.106 seconds
2024-05-01T13:53:13,858  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] common.LogUtils: Unregistered logging context.
2024-05-01T13:53:13,858  INFO [HiveServer2-Background-Pool: Thread-441] common.LogUtils: Thread context registration is done.
2024-05-01T13:53:13,858  INFO [HiveServer2-Background-Pool: Thread-441] reexec.ReExecDriver: Execution #1 of query
2024-05-01T13:53:13,859  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Operation QUERY obtained 2 locks
2024-05-01T13:53:13,859  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Executing command(queryId=alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-05-01T13:53:13,859  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-05-01T13:53:13,859  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-05-01T13:53:13,859  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/-mr-10001
2024-05-01T13:53:13,860  INFO [HiveServer2-Background-Pool: Thread-441] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/-mr-10001
2024-05-01T13:53:13,860  WARN [HiveServer2-Background-Pool: Thread-441] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4
2024-05-01T13:53:13,860  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Query ID = alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4
Total jobs = 1
2024-05-01T13:53:13,860  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-05-01T13:53:13,860  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Launching Job 1 out of 1
2024-05-01T13:53:13,862  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:13,862  INFO [HiveServer2-Background-Pool: Thread-441] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-05-01T13:53:13,869  INFO [HiveServer2-Background-Pool: Thread-441] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-05-01T13:53:13,869  INFO [HiveServer2-Background-Pool: Thread-441] exec.Utilities: Processing alias _dummy_table
2024-05-01T13:53:13,869  INFO [HiveServer2-Background-Pool: Thread-441] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/dummy_path
2024-05-01T13:53:13,882  INFO [HiveServer2-Background-Pool: Thread-441] exec.SerializationUtilities: Serializing MapWork using kryo
2024-05-01T13:53:13,883  INFO [HiveServer2-Background-Pool: Thread-441] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:13,884  WARN [HiveServer2-Background-Pool: Thread-441] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:13,888  WARN [HiveServer2-Background-Pool: Thread-441] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-05-01T13:53:13,895  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-01T13:53:13,902  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-05-01T13:53:13,902  INFO [HiveServer2-Background-Pool: Thread-441] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-05-01T13:53:13,903  INFO [HiveServer2-Background-Pool: Thread-441] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/dummy_path
2024-05-01T13:53:13,908  INFO [HiveServer2-Background-Pool: Thread-441] input.FileInputFormat: Total input files to process : 1
2024-05-01T13:53:13,908  INFO [HiveServer2-Background-Pool: Thread-441] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-05-01T13:53:13,908  INFO [HiveServer2-Background-Pool: Thread-441] io.CombineHiveInputFormat: Number of all splits 1
2024-05-01T13:53:13,932  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.JobSubmitter: number of splits:1
2024-05-01T13:53:13,955  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.JobSubmitter: Submitting tokens for job: job_local638973779_0008
2024-05-01T13:53:13,955  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.JobSubmitter: Executing with tokens: []
2024-05-01T13:53:14,023  INFO [HiveServer2-Background-Pool: Thread-441] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-05-01T13:53:14,024  INFO [Thread-386] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:14,024  INFO [HiveServer2-Background-Pool: Thread-441] exec.Task: Job running in-process (local Hadoop)
2024-05-01T13:53:14,024  INFO [Thread-386] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-05-01T13:53:14,026  INFO [Thread-386] mapred.LocalJobRunner: Waiting for map tasks
2024-05-01T13:53:14,026  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local638973779_0008_m_000000_0
2024-05-01T13:53:14,027  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-05-01T13:53:14,028  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-05-01T13:53:14,029  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-05-01T13:53:14,030  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-05-01T13:53:14,030  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-05-01T13:53:14,030  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-05-01T13:53:14,031  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-05-01T13:53:14,031  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-05-01T13:53:14,031  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-05-01T13:53:14,031  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-05-01T13:53:14,031  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-05-01T13:53:14,032  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@676816ec, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@550f11fb, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@23d09079
DEBUG StatusLogger Removing appender alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
DEBUG StatusLogger Removing appender alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
DEBUG StatusLogger Deleting route with alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da key 
DEBUG StatusLogger Deleting route with alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da key 
DEBUG StatusLogger Stopping route with alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da key
DEBUG StatusLogger Stopping route with alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da key
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/f0a7829b-4714-442a-acd4-70e65954aff5/alex_20240501135303_d03fc908-731d-4dd5-b6c5-bbd7520df9da.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-05-01T13:53:14,359  INFO [main] service.CompositeService: Session closed, SessionHandle [52722bc8-b995-46a2-9838-48a2fd5cf00f], current sessions:0
2024-05-01T13:53:14,359  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=bbfb45c7-21c3-4113-88e6-eeba14857877]
2024-05-01T13:53:14,359  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.OperationManager: Removed queryId: alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=bbfb45c7-21c3-4113-88e6-eeba14857877] with tag: null
2024-05-01T13:53:14,359  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1
2024-05-01T13:53:14,359  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1 operation was queued
2024-05-01T13:53:14,359  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:14,359  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T13:53:14,360  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135312_a6d11c48-e180-4eb3-aa7f-07691dd5c1e4 without delay
2024-05-01T13:53:14,360  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=ea637935-a8ad-46ab-92fa-8594a6a93bf0]
2024-05-01T13:53:14,360  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.OperationManager: Removed queryId: alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=ea637935-a8ad-46ab-92fa-8594a6a93bf0] with tag: null
2024-05-01T13:53:14,360  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4
2024-05-01T13:53:14,360  WARN [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-05-01T13:53:14,360  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-6
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-6 operation was queued
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-05-01T13:53:14,361  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-12_392_3741224478110762908-1
2024-05-01T13:53:14,361  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T13:53:14,360  WARN [Thread-386] mapred.LocalJobRunner: job_local638973779_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-05-01T13:53:14,361  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-13_751_8839056134632449954-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1
2024-05-01T13:53:14,361  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-13_751_8839056134632449954-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-05-01 13:53:14,361 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:14,361  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1/-mr-10001/.hive-staging_hive_2024-05-01_13-53-13_751_8839056134632449954-1/_tmp.-ext-10002/000000_0
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1 operation was queued
2024-05-01T13:53:14,361  INFO [HiveServer2-Background-Pool: Thread-441] exec.Task: 2024-05-01 13:53:14,361 Stage-1 map = 0%,  reduce = 0%
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-05-01T13:53:14,361  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-05-01T13:53:14,361  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-6
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f/alex_20240501135313_f9359f9e-328d-49c4-8e41-bcd63c98eaf4 without delay
Ended Job = job_local638973779_0008 with errors
2024-05-01T13:53:14,361 ERROR [HiveServer2-Background-Pool: Thread-441] exec.Task: Ended Job = job_local638973779_0008 with errors
2024-05-01T13:53:14,361  INFO [52722bc8-b995-46a2-9838-48a2fd5cf00f main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/52722bc8-b995-46a2-9838-48a2fd5cf00f
2024-05-01T13:53:14,361  WARN [EventualCleanupService thread 2] fs.FileUtil: Failed to delete file or dir [/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1]: it still exists.
2024-05-01T13:53:14,362  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f/hive_2024-05-01_13-53-13_751_8839056134632449954-1
Error during job, obtaining debugging information...
2024-05-01T13:53:14,362 ERROR [Thread-391] exec.Task: Error during job, obtaining debugging information...
2024-05-01T13:53:14,362  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/52722bc8-b995-46a2-9838-48a2fd5cf00f operation was queued
2024-05-01T13:53:14,363  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f operation was queued
2024-05-01T13:53:14,363  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/52722bc8-b995-46a2-9838-48a2fd5cf00f
2024-05-01T13:53:14,363  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/52722bc8-b995-46a2-9838-48a2fd5cf00f
2024-05-01T13:53:14,363  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-05-01T13:53:14,363  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c40402c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@198524ec will be shutdown
2024-05-01T13:53:14,364  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-05-01T13:53:14,364  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-05-01T13:53:14,364  INFO [HiveServer2-Background-Pool: Thread-441] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-05-01T13:53:14,364 ERROR [HiveServer2-Background-Pool: Thread-441] ql.Driver: FAILED: Operation cancelled
2024-05-01T13:53:14,364  INFO [HiveServer2-Background-Pool: Thread-441] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-05-01T13:53:14,364  INFO [HiveServer2-Background-Pool: Thread-441] metadata.Hive: Total time spent in each metastore function (ms): {close_()=1}
MapReduce Jobs Launched: 
2024-05-01T13:53:14,364  INFO [HiveServer2-Background-Pool: Thread-441] ql.Driver: MapReduce Jobs Launched: 
2024-05-01T13:53:14,364  WARN [HiveServer2-Background-Pool: Thread-441] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
]]></system-err>
  </testcase>
</testsuite>